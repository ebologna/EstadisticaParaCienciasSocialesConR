---
output:
  pdf_document: default
---

```{r message=FALSE, warning=FALSE, include=FALSE}
source("depencias.R")
```

# Tamaño del efecto

## Significación estadística y significación práctica

El procedimiento de prueba de hipótesis concluye con la aseveración
acerca del rechazo o no de la hipótesis nula. Esto se hace observando
cuán probable es hallar los resultados muestrales bajo el supuesto de
$H_0$ verdadera. El valor $p$ es una medida de esa probabilidad, por eso es que cuando es pequeño, la decisión es rechazar $H_0$ y decimos que el
resultado (la diferencia, el coeficiente, o lo que sea que se haya
puesto a prueba) es significativo, o significativamente distinto de
cero.

Sin embargo, que una prueba haya dado significativa no implica
directamente que el resultado tenga interés práctico. Como se vio en el
cálculo de la potencia, un tamaño de muestra grande, puede detectar
diferencias muy pequeñas que quizá en la práctica tengan poco interés.
La palabra significación contribuye a la confusión, porque en el
lenguaje cotidiano, una diferencia significativa a menudo quiere decir
una diferencia importante. La significación estadística, como hemos
visto, es otra cosa y puede suceder que una prueba dé significativa pero
la diferencia sea insignificante.

Por eso es necesario introducir otro concepto; el de **tamaño del efecto**. Se trata de una cuantificación de lo importante que es una
diferencia o un coeficiente, luego de haber obtenido un resultado
significativo en la prueba de hipótesis. Conocer el tamaño del efecto es
absolutamente necesario para interpretar los resultados de una
investigación. La @APA2010 destaca que "las pruebas de hipótesis no son sino el punto de partida y se requiere informar elementos adicionales tales como tamaños del efecto, intervalos de confianza y descripciones extensivas" (p. 33, traducción del autor).

Las medidas de tamaño del efecto expresan de manera estandarizada cuán
diferente de cero es una diferencia o un coeficiente. Que estén
estandarizadas permite dos cosas: evaluarlas en su magnitud, dados
ciertos criterios; y comparar efectos entre experimentos diseñados de
manera diferente, por ejemplo con distintos tamaños de muestra, lo cual
permite el meta-análisis[^113]. Para decidir cuándo un efecto es grande
mediano o pequeño, existen criterios, casi todos propuestos por @Cohen1988, quien es autor también de la mayoría de las medidas de
tamaño del efecto.

## Medidas de tamaño del efecto

Hay una gran diversidad de medidas del tamaño del efecto, @kirk1996 
las estima en más de setenta, y @ellis2010 las clasifica en dos
familias: las medidas de diferencias entre grupos y las medidas de
asociación. Para esta presentación, elegiremos algunas medidas de uso
difundido y sugerimos @ellis2010, así como @cumming2012 para una
descripción más detallada. Las siguientes son las medidas que más se
usan para evaluar el tamaño del efecto, según cuál sea la prueba que se
haya realizado.

### Prueba t para diferencia de medias

Conocido como *d de Cohen*, se define como:

$$\frac{{\overline{x}}_{1} - {\overline{x}}_{2}}{s_{\text{comb}}}$$

Y mide la distancia entre las medias observadas, expresada en términos
de la desviación estándar combinada de los dos grupos. @Cohen1988
sugiere que valores de $d$ de 0.20, 0.50, y 0.80 indican tamaños de
efecto: pequeño, mediano y grande respectivamente. Medidas alternativas
al d de Cohen son *delta de Glass* y *g de Hedge*, que difieren en el
modo de calcular el denominador de la expresión anterior, pero
conceptualmente consisten también en una estandarización de la
diferencia observada.

### Análisis de la varianza

La medida se llama *f de Cohen* y se define así:

$$f = \sqrt{\frac{\sum_{i = 1}^{k}{p_{i}*{({\overline{x}}_{i} - \overline{\overline{x}})}^{2}}}{s_{res}^{2}}}$$

En la que las $p_{i}$ de la fórmula representan la proporción de casos
en cada grupo que se compara. Los valores sugeridos por Cohen son 0.10,
0.25, y 0.40 para efectos de tamaño pequeño, mediano y grande
respectivamente. Otras medidas usadas en ANOVA son $\eta^{2}$ (eta
cuadrado) y $\varepsilon^{2}$ (épsilon cuadrado). La relación entre $\eta$ y $f$ es $$f=\sqrt\frac{\eta^2}{1-\eta^2}$$

### Correlaciones

El coeficiente de correlación es una medida estandarizada y se usa como
medida del tamaño del efecto, es decir, de la magnitud de la asociación.
Cohen considera que un efecto grande corresponde a $r = 0.50$, mediano a
$r = 0.30$ y pequeño $r = 0.10$.


### Regresión lineal

La medida estandarizada para evaluar la calidad de un modelo lineal es:

$$f^{2} = \frac{R^{2}}{1 - R^{2}}$$

Es una medida de tamaño del efecto alternativa al el coeficiente general
de correlación $R^{2}$. Cohen fija en 0.02, 0.15 y 0.35 los criterios de
pequeño, mediano y gran efecto.


### Pruebas ji cuadrado


Se utiliza la medida definida como:

$$w = \sqrt{\sum_{i = 1}^{m}\frac{{(f_{i}^{e} - f_{i}^{e1})}^{2}}{f_{i}^{e}}}$$

En la que $f_{i}^{e}$ y $f_{i}^{e1}$ son las frecuencias relativas
esperadas en la celda i bajo $H_0$ y $H_1$ respectivamente.


## Análisis de la potencia

El cálculo del tamaño del efecto permite entonces comparar resultados de
diferentes diseños experimentales y evaluar si un efecto es grande o
pequeño. Este es el análisis a posteriori, luego de haber realizado las
pruebas y haber hallado resultados estadísticamente significativos.
Cuando se trató la potencia de la prueba, se indicó que ésta crece a
medida que la diferencia entre el valor hipotético y el verdadero valor
del parámetro se agranda, es decir que si el valor real difiere mucho
del valor hipotético (tamaño del efecto grande), la probabilidad de
rechazar la hipótesis nula es también grande (potencia alta).

También participa de esta relación el tamaño de la muestra, ya que si la
muestra es de mayor tamaño, las varianzas de los estimadores se reducen
(por su propiedad de ser consistentes) y el área que corresponde a la potencia aumenta. Es decir
que muestras grandes dan lugar a mayor probabilidad de rechazar
hipótesis nulas falsas, dicho de otra manera, las muestras grandes
tienen más probabilidad de detectar diferencias, aunque éstas sean
pequeñas. Esto conduce a que muestras muy grandes pueden dar resultados
significativos aunque las diferencias sean ínfimas, por eso es muy
necesario informar el tamaño del efecto para que se pueda tener una
interpretación correcta de los resultados.  

Aún queda un componente más en esta relación: la probabilidad de cometer
error de tipo I, es decir la significación de la prueba. Si esta es muy
pequeña, fijada así para reducir el riesgo de rechazar una hipótesis
nula que sea verdadera, entonces también decrece la potencia, es decir,
se vuelve más probable aceptar una hipótesis nula que es falsa y así
pasar por alto un resultado que podría haber sido detectado.  

Son entonces cuatro los elementos que interactúan: potencia,
significación, tamaño del efecto y tamaño de la muestra. Si se establece
a priori i) cuál es el tamaño del efecto que se quiere detectar (grande,
mediano o pequeño), ii) qué riesgo de rechazar una hipótesis nula que es
verdadera se está dispuesto a correr (significación) y iii) qué
probabilidad de detectar diferencias se pretende (potencia); entonces el
tamaño de la muestra queda fijado. Análogamente, si se tiene un número
de casos dado y se fija la potencia y la significación, se puede
calcular el tamaño del efecto que la prueba será capaz de detectar. Así,
con tres de los elementos mencionados, queda determinado el cuarto. Las
previsiones sobre la relación entre estos cuatro elementos se conocen
como **análisis de la potencia** y es una parte importante del diseño de
una investigación, porque sirve para calcular a priori el tamaño de
muestra requerido para detectar un determinado tamaño de efecto con un
nivel de significación dado. Si el tamaño de muestra está fijado (por
presupuesto o tiempo), el análisis de la potencia permite saber qué
probabilidad hay de detectar un determinado tamaño del efecto. También
es posible establecer cuál es la potencia que deseamos para nuestro
estudio o, al revés, qué probabilidad de cometer Error de Tipo II (no
rechazar una $H_0$ que es falsa) estamos dispuestos a asumir.

Los gráficos siguientes ilustran la relación entre estos elementos para diferentes combinaciones de tamaño del efecto, nivel de significación y tamaño de muestra. Las áreas sombreadas más claro corresponden a la probabilidad de cometer Error de Tipo II (el complemento de la potencia), las oscuras a la probabilidad de cometer Error de Tipo I (el nivel de significación), la distancia entre los centros de las campanas representa el tamaño del efecto, la diferente amplitud de las campanas indica la diferente varianza según el tamaño de la muestra.  

```{r warning=FALSE}
library("ggplot2")
library("ggthemes")
library("gridExtra")

s <- 1
alpha <- .05
mu_1 <- .5

efecto_chico_alpha5_s1 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


mu_1 <- 1
efecto_mediano_alpha5_s1 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


mu_1 <- 3
efecto_grande_alpha5_s1 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


alpha <- .01
mu_1 <- .5

efecto_chico_alpha1_s1 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


mu_1 <- 1
efecto_mediano_alpha1_s1 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


mu_1 <- 3
efecto_grande_alpha1_s1 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")

##

s <- .7
alpha <- .05
mu_1 <- .5

efecto_chico_alpha5_s.5 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


mu_1 <- 1
efecto_mediano_alpha5_s.5 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


mu_1 <- 3
efecto_grande_alpha5_s.5 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


alpha <- .01
mu_1 <- .5

efecto_chico_alpha1_s.5 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


mu_1 <- 1
efecto_mediano_alpha1_s.5 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")


mu_1 <- 3
efecto_grande_alpha1_s.5 <- ggplot(data.frame(x = c(-3.5, 7.5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = s), col = "grey17") +
  stat_function(
    fun = dnorm, args = list(mean = 0, sd = s), fill = "grey17",
    xlim = c(qnorm(1 - alpha), 4),
    geom = "area"
  ) +
  stat_function(fun = dnorm, args = list(mean = mu_1, sd = s), col = "grey57") +
  stat_function(
    fun = dnorm, args = list(mean = mu_1, sd = s),
    xlim = c(-4, qnorm(1 - alpha)), fill = "grey57", alpha = .5, geom = "area"
  ) + geom_vline(xintercept = 0, col = "grey17") +
  geom_vline(xintercept = mu_1, col = "grey57") +
  scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) +
  theme_tufte() + xlab("") + ylab("")

grid.arrange(efecto_chico_alpha5_s1, efecto_mediano_alpha5_s1,
  efecto_grande_alpha5_s1, efecto_chico_alpha1_s1,
  efecto_mediano_alpha1_s1, efecto_grande_alpha1_s1,
  efecto_chico_alpha5_s.5, efecto_mediano_alpha5_s.5,
  efecto_grande_alpha5_s.5, efecto_chico_alpha1_s.5,
  efecto_mediano_alpha1_s.5, efecto_grande_alpha1_s.5,
  ncol = 3, nrow = 4
)
```

\pagebreak  

## Hacerlo en R  
Las relaciones entre el tamaño de muestra, la potencia, el tamaño del
efecto y el nivel de significación dependen de cuál sea el tipo de
estudio planteado y cuál la medida de tamaño del efecto elegida. Eso
hace que las operaciones para calcular uno de ellos conociendo los otros
tres, sean complejas. En el capítulo 12 se construyeron las curvas de
potencia para diferentes valores de la hipótesis alternativa (es decir
del verdadero valor del parámetro) y diferentes tamaños de muestra. Sin
embargo, esos cálculos dependen de los valores concretos de los
parámetros (en particular, de las diferencias entre el valor paramétrico
que sostiene $H_0$ y el que sostienen las diferentes alternativas $H_k$); ahora, con el tamaño del efecto estandarizado, solo hace falta saber qué prueba se realiza para obtener la curva de potencia.

Si bien existen calculadoras on line[^114], es recomendable, por su
flexibilidad, usar el paquete `pwr` [@champely2018] en R. Este conjunto
de rutinas genera, para cada prueba estadística, uno de los cuatro
valores a partir de los otros tres. Para estimar a priori el tamaño de muestra, hay que establecer: el tipo de prueba, el nivel de significación, la potencia que se espera y el tamaño del efecto que se puede detectar. Por ejemplo, ¿Cuántos casos hacen falta en cada grupo si se va a realizar una prueba t unilateral derecha, a un nivel de significación del 5%, y se requiere una probabilidad 0.80 (potencia) de detectar un efecto grande (d=0.85)? Ese es el modo en que debe formularse la pregunta para encontrar uno de los cuatro valores que interjuegan.  
Primero se instala el paquete y se carga en la sesión:

```{r echo=TRUE, eval=FALSE}
install.packages("pwr")
```

```{r echo=TRUE}
library("pwr")
```

Las convenciones estándar propuestas por Cohen1988 se solicitan con el comando cohen.ES, al que debe indicarse qué prueba es (las opciones son: "p", "t", "r", "anov", "chisq", "f2") y la magnitud del efecto (con opciones: "small", "medium", "large"). Por ejemplo, un tamaño del efecto grande para una prueba t es:
```{r echo=TRUE}
cohen.ES(test = "t", size = "large")
```

0.80. 

Para el cálculo del tamaño del efecto, de la potencia, del tamaño muestral o de la significación, primero se elige el tipo de prueba; para una prueba t el comando es `pwr.t.test`, y se indican, además de la lateralidad de la prueba, los valores de tres de los siguientes cuatro elementos:  
- significación ($sig.level$)  
- potencia ($power$)  
- tamaño del efecto ($d$)  
- tamaño de la muestra ($n$).  

Uno de ellos debe quedar sin mención (o como "NULL"), y ese es el que se calcula como función de los demás.  
Para conocer el tamaño de la muestra a partir del tamaño del efecto, la potencia y la significación en una prueba unilateral derecha (no se nombra $n$):  
```{r echo=TRUE}
pwr.t.test(sig.level = .05, power = .8, d = 0.85,
           alternative = "greater")
```

Para lograr detectar el mismo tamaño de efecto con una  muestra de 25 casos:

```{r echo=TRUE}
pwr.t.test(sig.level = .05, n=25, d = 0.85,
           alternative = "greater")
```
La probabilidad de detectarlo (la potencia) aumenta a 0.90.  

El  comando `pwr.t.test` sirve para pruebas t de una muestra, de diferencia de medias independientes y apareadas, se debe indicar el tipo de prueba en el argumento `type`, con opciones "two.sample" (dos muestras independientes), "one.sample" (una muestra), "paired" (apareadas). Por ejemplo, para conocer la potencia que tiene una prueba de comparación de medias provenientes de muestras independientes para detectar un efecto de tamaño 0.3, si los grupos tienen 25 casos cada uno, se realiza una prueba bilateral, a un nivel de significación de 0.01. Se solicita:

```{r echo=TRUE}
pwr.t.test(n = 25, d=0.3, sig.level = 0.01, power = NULL,
           type = "two.sample", alternative = "two.sided")
```

Si ahora se quisiera, para la misma prueba, elevar la potencia a 0.10, el número de casos requerido es:

```{r echo=TRUE}
pwr.t.test(d = 0.3, sig.level = 0.01, power = 0.10,
           type = "two.sample", alternative = "two.sided")
```
Hacen falta casi 40 casos en cada grupo.

Para el  Análisis de la Varianza, se agrega como dato requerido, el numero de grupos de comparación. Si se trata de cuatro grupos a un nivel de 5%, para tener una probabilidad de 0.50 (potencia) detectar un efecto de tamaño 0.2, se requieren:

```{r echo=TRUE}
pwr.anova.test(power=0.5, k=4, f=0.2, sig.level=0.05)
```

37 casos en cada uno de los grupos. Pero si solo se cuenta con 15 casos en cada grupo, entonces el tamaño del efecto que se puede detectar con probabilidad 0.50 es:  
```{r echo=TRUE}
pwr.anova.test(power=0.5, k=4, n=15, sig.level=0.05)
```
Es de 0.32.

El vídeo *tamaño del efecto*, en https://youtu.be/s2nGqz5Nh4A ofrece detalles adicionales sobre el uso del paquete `pwr` en el entorno RStudio.

[^113]: Meta-análisis es una revisión sistemática que usa procedimientos estadísticos para comparar los resultados obtenidos en diferentes estudios sobre un determinado tema.

[^114]: Por ejemplo [http://www.socscistatistics.com/effectsize/Default3.aspx](http://www.socscistatistics.com/effectsize/Default3.aspx) o también [https://www.uccs.edu/~lbecker/](https://www.uccs.edu/~lbecker/).
