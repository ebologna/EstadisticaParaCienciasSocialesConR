[
["index.html", "Estadística para Ciencias Sociales con R", " Estadística para Ciencias Sociales con R Eduardo Bologna 20 de octubre de 2019 "],
["los-datos-estadísticos.html", "Capítulo 1 Los datos estadísticos 1.1 La selección de la información pertinente 1.2 Los individuos 1.3 Las variables 1.4 Las categorías 1.5 Los símbolos numéricos 1.6 La medición 1.7 Resumen de los niveles de medición", " Capítulo 1 Los datos estadísticos En este capítulo se desarrollan procedimientos para presentar la información de manera accesible para que pueda ser analizada y luego interpretada. Para poder extraer significado de los datos recogidos es necesario primero dedicar un esfuerzo a organizarlos, a presentarlos de manera comprensible, una operación previa a la aplicación de las técnicas de análisis que se verán más adelante. La ciencia se interesa por la producción de conocimiento validado, uno de cuyos requisitos es que pueda ser comunicado de manera inequívoca, que se confronten las conclusiones a que llegan y los métodos que usan diferentes investigadores. Esto implica la necesidad de usar un lenguaje que permita el intercambio entre investigadores y que dependa, en el menor grado posible, de las impresiones subjetivas o de las interpretaciones que cada investigador individual dé a los conceptos. Se busca un vocabulario tan unívoco como sea posible. Un modo de acercarse a lograr esta comunicabilidad de las ideas, de los métodos y de los resultados, es definir, de la manera más precisa posible, los elementos acerca de los que se habla. Alguna vez hemos dado con expresiones como “esta persona es más inteligente que aquella”. ¿Qué se quiere decir exactamente con eso?, la afirmación podría provenir de algún evento en que se vio a esa persona actuando de manera que llamaríamos inteligente, aunque esto también puede confundirse con astucia: no es infrecuente usar el adjetivo inteligente para un estafador, alguien a quien le resulta fácil engañar a otros; y, a la inversa, sería poco inteligente quien se deja engañar con facilidad. O bien, a menudo decimos que alguien es inteligente porque obtiene buenos resultados en sus estudios. Esto es parte de la imprecisión en la definición de un concepto. Si se dispone de una definición de inteligencia, se puede saber cuándo aplicar esa idea a alguien, cuándo una conducta es inteligente, inclusive, cómo ayudar a desarrollar la inteligencia. Si se puede definir el concepto con el que se trabaja, se pueden indicar ciertas operaciones a realizar para evaluarlo y así conocer cuál es el nivel de inteligencia de un sujeto en particular. Luego de definir el concepto con el que se trabaja, se requiere diseñar un instrumento que refleje esa definición y finalmente aplicar este instrumento a las personas que se evaluarán. Al hacer esto último se obtiene un resultado que, si se expresa de manera cuantitativa, permite hacer comparaciones del aspecto que representa ese concepto, entre personas, entre grupos, etc. ¿Pueden compararse personas? La respuesta es no, porque cada persona tiene una infinidad de aspectos que la caracterizan y la hacen única. Por el contrario lo que sí pueden compararse son características claramente definidas de las personas. Del mismo modo no se pueden comparar escuelas, ni hogares, ni países si no se especifica en qué aspecto se realiza la comparación. O dicho de otro modo, cuál es la característica que se compara, y cómo se mide esa característica. Podemos decir que una persona tiene más escolarización formal que otra, indicando con eso que ha aprobado más años de la escuela o de la universidad. Podemos decir que un hogar es diferente a otro si uno se compone de una pareja sola y el otro incluye tres hijos. Un país puede tener más habitantes, un régimen político diferente, o mayor libertad de expresión que otro. En todos los casos especificamos una característica (un rasgo o un estado), sobre la base del cual hacemos la comparación. 1.1 La selección de la información pertinente Cuando se ha decidido quienes son los sujetos de la observación; es decir, una vez que se sabe a quiénes se observará, deben elegirse ciertas características de esos sujetos para observar1. Cada unidad que resulta de interés para la investigación tiene un conjunto muy grande de características observables y siempre se realiza una selección de esas características. Se trata de un recorte que permite comprender mejor ciertos aspectos, dejando de lado otros. La información que seleccionamos para observar se denomina pertinente para la investigación. Cuando se decide cuál es la información pertinente, se la puede recabar de varios individuos y cambiar la óptica desde el caso particular a la regularidad colectiva. Es un cambio desde el individuo hacia el grupo. La siguiente es una lista que indica el área en que les gustaría trabajar cuando se reciban, a nueve estudiantes de primer año de Psicología: Tabla 1.1: Área de trabajo preferida. Alumno Área Susana Clínica Marcos Laboral Daniel Clínica Federico Social María Clínica Pedro Educacional Eugenia Clínica Mabel Educacional Francisco Laboral La lista los individualiza, los reconoce por su nombre, indica qué área le gustaría a cada uno y solo eso, no se sabe la edad de cada uno, ni sus intereses políticos ni el deporte favorito, solo se seleccionó como pertinente para este ejemplo, el área en que le gustaría trabajar. Si ahora se transforma esa lista en una tabla: Tabla 1.2: Área de trabajo preferida. Área Casos Clínica 4 Educacional 2 Laboral 2 Social 1 Se lee que Clínica es un área preferida por cuatro alumnos, Laboral y Educacional por dos y a Social solo la menciona uno. Las personas desaparecieron, ya no hay nombres, hemos abstraído para referirnos al área preferida, no a los alumnos. En la tabla se ve que lo más frecuente es que se prefiera Clínica, y que Social es poco frecuente. Se pasó de la lista de individuos a la tabla de valores. Nos despegamos de los casos a fin de buscar la regularidad en el conjunto. Más adelante diremos que se ha pasado de la matriz de datos a la distribución de frecuencias, que constituye una reducción o un primer resumen de la información disponible. Consideremos el siguiente cuestionario, que se aplicó en 2019 a personas con edades 18 y 35 años. Figura 1.1: Cuestionario 2019 Figura 1.1: Cuestionario 2019 Este instrumento de producción de datos que es el cuestionario, se dirige a una población definida: personas entre 18 y 35 años. En él se solicita información sobre un conjunto seleccionado de características; los ítems numerados desde P1 hasta P16. Se trata de unos pocos aspectos de cada persona los que interesan para esta investigación; no se tiene en cuenta, por ejemplo la opinión política de quienes responden, ni su estatura o la región en que viven. Estas últimas y muchas más son características de estas personas, pero están fuera del alcance de la investigación. Esto muestra a qué nos referimos con que la información seleccionada constituye un recorte, es una parcialización de los individuos que responden, en la que se eligen solo los aspectos que son de interés para una investigación particular. El cuestionario tiene 16 ítems, cada persona que lo responde marca una sola de las opciones indicadas en cada ítem. Una vez completados los cuestionarios, la información está “en bruto” y es necesario ordenarla para poder tener una visión de conjunto. Eso se logra organizando los datos recogidos en la matriz de datos que tiene, para el cuestionario mostrado, la siguiente forma: ## ## 1 2 3 4 ## 974 2692 456 422 ## ## 1 2 3 4 ## 1610 479 581 254 ## sexo edad acceso.redes red.usada red.otra tiempo.red con.q.vive ## 1 mujer 19 si Instagram &lt;NA&gt; 120 con.otres ## 2 varón 29 si Facebook &lt;NA&gt; 90 con.otres ## 3 mujer 31 si Facebook &lt;NA&gt; 30 flia.nueva ## 4 mujer 28 si Otra gmail 30 flia.nueva ## 5 mujer 22 si Instagram &lt;NA&gt; 120 hermanes.o.amigues ## 6 varón 22 si Facebook &lt;NA&gt; 240 solo ## relacion.otros q.aporta q.aporta.amigos edad.partida razon.partida ## 1 &lt;NA&gt; entre.amigos 2 19 estudio ## 2 primo entre.amigos 1 26 ganas ## 3 &lt;NA&gt; flia.nueva NA 21 otras ## 4 &lt;NA&gt; flia.nueva NA 18 ganas ## 5 &lt;NA&gt; entre.amigos 2 18 estudio ## 6 &lt;NA&gt; el.mismo NA 18 estudio ## razon.partida.otra calidad.sueño preocupacion golpeo robo cuanto.da ## 1 &lt;NA&gt; 4 4 1 1 30 ## 2 &lt;NA&gt; 8 2 1 2 50 ## 3 problemas flia 6 7 1 1 30 ## 4 &lt;NA&gt; 9 5 1 2 100 ## 5 &lt;NA&gt; 6 8 1 4 100 ## 6 &lt;NA&gt; 6 5 3 2 75 ## comision ## 1 5 ## 2 5 ## 3 5 ## 4 5 ## 5 5 ## 6 5 Este ordenamiento de la información tiene filas (horizontales) y columnas (verticales), en esta imagen solo se ven las primeras filas de la matriz, y además, porque no cabe horizontalmente, está subdividida en cuatro bloques de variables (columnas). Cada fila es un individuo y cada columna es un ítem. La primera fila (que continúa en los cuatro bloques) muestra los nombres de los ítems del cuestionario y las seis filas mostradas, las respuestas dadas por los encuestados. Así, la persona que respondió al primer cuestionario es una mujer, que tiene 19 años, tiene acceso a redes sociales y la que más usa es Instagram, como no respodió “otra”, en la columna siguiente tiene NA, que indica que no hay dato allí (Not Available), vive “con otres” y aportan entre amigos y así sigue toda la fila correspondiente a esa persona. La matriz de datos contiene toda la información que será insumo de los análisis posteriores, luego será necesario definir qué es cada elemento que la constituye. La matriz de datos es un arreglo en el que cada fila (horizontal) representa un individuo del cual proviene la información, cada columna (vertical) es un aspecto de los individuos, que se ha seleccionado para observar, y cada celda es el valor que tiene el individuo de la fila en el aspecto de la columna correspondiente. 1.2 Los individuos Hemos dicho que cada fila representa un caso, un individuo al que se observa. Este individuo puede ser una persona como en este ejemplo, pero también una entidad colectiva: un hogar, una empresa, una escuela. Cada una de ellas se denomina unidad de análisis. Es importante que las unidades de análisis estén claras para la interpretación de los resultados. Por ejemplo, si se afirma que “las personas de menores recursos acceden menos frecuentemente a la educación superior”, hablamos de personas, y éstas son las unidades de análisis. Y es muy diferente a decir que “en los países más pobres, es menor la proporción de personas que acceden a la educación superior”, porque aquí las unidades de análisis son los países. Las unidades de análisis son los entes individuales acerca de los que se analizan sus cualidades. Si las unidades de análisis fuesen escuelas, sus características, dependiendo de la investigación de que se trate, podrían ser: dependencia (estatal o privada), nivel (primaria, secundaria, ambas), cantidad de alumnos, turnos (mañana, tarde, ambos), etc. Si se tratara de hogares, puede observarse: cantidad de miembros, composición, actividad económica, etc. 1.3 Las variables Cada columna de la matriz de datos es un ítem del cuestionario, es decir un aspecto seleccionado de las unidades de análisis sobre el que se llama la atención. Esos aspectos se denominan variables. Así, el sexo es una variable, como lo es con quién vive, cuánto daría en el experimento, etc. Cada ítem del cuestionario se constituye en una variable, a veces su expresión interrogativa en el cuestionario se transforma en algo más abreviado, como: “¿Cuánto tiempo (en minutos) estuviste conectado/a a las redes sociales en el día de ayer?” se vuela “tiempo.red”. Las variables son los aspectos de los individuos que se someterán al análisis. Su cualidad central es la que le da nombre: la de variar. Una variable es una característica de las unidades de análisis que puede asumir diferentes valores en cada una de ellas. Cada vez que se haga referencia a una variable, debe conocerse cuál es la unidad de análisis a la que se refiere, si no resulta claro, se debe indicar. Es diferente afirmar que un país es rico que decir que sus habitantes lo son. 1.4 Las categorías El cuerpo de la matriz de datos tiene números que corresponden a las respuestas que cada respondente dio a cada ítem. El primer caso tiene un número 2 en la primera columna, que quiere decir que esa persona respondió que es una mujer. En esta pregunta, se podía elegir entre dos respuestas diferentes (varón, mujer), en el lenguaje que estamos introduciendo, diremos que esta variable (sexo) puede asumir dos categorías diferentes. Para el primer caso, la variable sexo asume la categoría 2. Las categorías son las “posibilidades” que tiene una variable, dentro de las cuales a todas las unidades de análisis les corresponde una y solo una. Las categorías de una variable son los valores que ésta puede asumir. Cada vez que se define una variable -es decir cada vez que se selecciona un aspecto de las unidades de análisis para observar-, debe indicarse también el conjunto de categorías que le corresponden, aunque a veces esto está implícito. Si la variable es nivel de escolaridad alcanzado, pueden considerarse las siguientes categorías: ninguno, primario incompleto, primario completo, secundario incompleto, secundario completo, terciario o universitario incompleto, terciario o universitario completo y postgrado. Si tratamos con la variable edad, sus categorías son valores numéricos, entre cero y un máximo de años que se fija según el caso. Hay dos propiedades que debemos asegurar que cumplan las categorías que construyamos. La primera se llama exclusión mutua, es decir que cada categoría excluya a todas las demás. Dicho de otra manera, si a un individuo le corresponde una categoría, entonces sabemos que no le corresponde ninguna otra. Si analizamos hogares y a cada persona le preguntamos por su parentesco, sin indicar con quién, tendremos una categorización defectuosa, porque una persona del hogar puede al mismo tiempo ser hijo y hermano, o hijo y padre, si conviven tres generaciones. En cualquiera de los dos casos, a una misma persona le corresponderían dos categorías y se viola el requisito de exclusión mutua. Esto se resuelve estableciendo respecto de quién se declara el parentesco, y todos los integrantes del hogar lo refieren a la misma persona2. Al analizar los tipos de lectura preferida, nos equivocaríamos si los categorizáramos como de ficción, de misterio, policiales, románticas, biográficas, de aventuras; ya que la categoría ficción puede incluir misterio, policiales, novelas románticas o de aventuras. También se comete ese error si se clasifica a las escuelas como céntricas, parroquiales, urbanas y rurales. Dado que una escuela puede ser al mismo tiempo parroquial y urbana. Es necesario separar, para que quede claro, lo que interesa en el análisis: si lo que queremos distinguir son escuelas céntricas de barriales, entonces la variable será la ubicación geográfica y no importa si la escuela depende de una iglesia o del estado; es decir, identificar la variable y luego sus categorías. Las categorías de una variable son mutuamente excluyentes si a cada individuo le corresponde no más de una categoría. El segundo requisito que solicitaremos a las categorías de una variable es que agoten todas las posibilidades de variación, es decir, que todos los valores posibles estén contemplados. Esta cualidad se llama exhaustividad. Veamos qué sucede si no respetamos este requisito. Si evaluamos la variable situación conyugal y ofrecemos como categorías: casado, soltero, divorciado, viudo; las personas que estén viviendo juntas sin estar casadas no encuentran un lugar donde ubicarse, como tampoco lo encuentran quienes están separados sin haberse divorciado. Para resolver esto es necesario, o bien incluir estas categorías explícitamente: casado, unido, soltero, separado, divorciado, viudo; ampliando así el número de categorías, o bien fusionarlas con las existentes: casado o unido, soltero, separado o divorciado, viudo. Con la edad, las categorías son valores numéricos que pueden ir del cero hasta el un máximo, pero ¿dónde fijarlo? Si se eligiera un límite como 100 años, algunas personas quedarían fuera, quizás sean pocas, pero no pueden quedar sin categoría donde incluirse. Por lo demás, puede haber solo una persona de 103 años, otra de 105, por lo que no se justifica seguir extendiendo categorías. Una solución frecuente es la de tomar una categoría “abierta final”, fijando como última categoría 100 y más, e incluir allí a todas las personas que declaren una edad de 100 años o superior. Puede verse que esta opción conlleva una pérdida de información, ya que no sabemos la edad exacta de quienes se ubican en esa categoría. Aceptamos esa pérdida a cambio de reducir el número de categorías de la variable, luego volveremos sobre eso. Algunas preguntas de cuestionarios, luego de un conjunto de opciones para responder, incluyen una categoría que dice “Otro\\(\\ldots\\) especificar”. Se trata de casos de categorizaciones en las que no se sabe de antemano cuáles son todas las respuestas posibles; son frecuentes en las encuestas de opinión. Por ejemplo, si alguien declara que en las próximas elecciones va a votar en blanco y preguntamos por qué, podemos conocer de antemano algunas de las respuestas posibles, pero debemos dejar espacio para que los encuestados expresen razones que no habíamos previsto. De este modo aseguramos la exhaustividad de las categorías. En el cuestionario del ejemplo, la P7 tiene, en la opción 5, la posibilidad de otras alternativas de convivencia, aparte de las ofrecidas. Las categorías de una variable son exhaustivas si todo individuo tiene alguna categoría que le corresponda. En algunas situaciones, el número de categorías de una variable es parte de la decisión del investigador. Hay casos en que las categorías están establecidas de antemano: por ejemplo, en la variable sexo se tiende a usar como categorías las de varón y mujer; sin embargo, si estamos frente a un estudio que trate precisamente sobre orientación sexual de las personas, deberá considerarse un espectro más amplio de categorías, o bien ofrecer preguntas abiertas, sin establecer categorías de antemano. Como ha sido el caso de P2 en el cuestionario, que no ha sido cargada en la matriz de datos, porque requiere una codificación posterior. Como se señaló,en la edad de las personas suele elegirse terminar las categorías con “100 y más”. De hecho, también se podrían mantener las edades exactas hasta 109 años y cerrar con 110 y más. Qué se elija depende de cuánta información y cuánta claridad se decida que tenga la clasificación; lamentablemente, no es posible lograr al mismo tiempo el máximo de información y de claridad en la presentación3. 1.5 Los símbolos numéricos Las categorías pueden tener diferente naturaleza: algunas se expresan con números (como la edad) y otras con palabras (como la carrera que cursa), otras en graduaciones (como el grado de acuerdo); sin embargo es muy común representar con números a las categorías, aun cuando lo que se observe no sea numérico. Así, en la variable nivel de educación, pueden codificarse las categorías de la siguiente manera: Tabla 1.3: Nivel de educación alcanzado. Código Máximo nivel de educación formal alcanzado 1 ninguno 2 primario incompleto 3 primario completo 4 secundario incompleto 5 secundario completo 6 terciario o universitario incompleto 7 terciario o universitario completo 8 postgrado Hemos usado números para referirnos a las categorías a fin de simplificar la notación. De manera equivalente podemos codificar las categorías de otras variables: Tabla 1.4: Distribución por sexos. Código Sexo 1 Varón 2 Mujer Tabla 1.5: Satisfacción con el progreso en la carrera. Código Estoy muy satisfecho con el modo en que he progresado en mi carrera 1 Completamente en desacuerdo 2 En desacuerdo 3 Indiferente 4 De acuerdo 5 Completamente de acuerdo En las variables cuyas categorías son numéricas, no es necesario hacer ninguna codificación. Así, la edad quedará expresada de manera numérica directamente por la cantidad de años, como sucede con la cantidad de materias aprobadas. En estos casos, la exclusión mutua y la exhaustividad se cumplen. 1.6 La medición En Ciencias Sociales tiene plena vigencia el debate acerca de las posibilidades de medición de los fenómenos que se estudian. Buena parte de la discusión gira en torno a una definición de medición, ya que según qué sea lo que se considere como tal, se tratará de una medición o no. La posición más tradicional corresponde a lo que el sentido común trata como medición: la estatura, las distancias, el peso, etc. Esta definición demanda que los números que codifican a las categorías tengan algunas propiedades para considerarlos como mediciones. Se conoce como teoría clásica de la medición, y desde ese punto de vista sería muy difícil realizar mediciones sobre las variables que manejamos en Ciencias Sociales. Una definición menos restrictiva es la que propuso Stevens (1946), según la cual: “medir es asignar números a los objetos según cierta regla, de manera que los números asignados en la medición, no representan propiamente cantidades, sino relaciones”. Esta última definición, basada en la teoría representacional de la medición, es la que adoptaremos en este curso aunque la discusión sigue vigente. Desde esta definición, evaluar una variable para una unidad de análisis dada, equivale a medir esa unidad de análisis en el aspecto que la variable expresa. Aun cuando se adopte una definición amplia de lo que es medir, podemos intuir que no se mide una opinión del mismo modo que se mide el salario o la estatura. Esto sugiere que, dentro de las variables de las que hemos hablado hasta aquí habrá que reconocer diferencias, y estas diferencias vendrán dadas por el significado que tengan los números que asignamos a las categorías, es decir, por las reglas que ligan los números con lo que se observa. El nivel de medición de una variable está determinado por el significado que tengan los símbolos numéricos que se asignan a las categorías. Existe una graduación en el significado que tienen los números, y por eso se habla de niveles, que pueden ser más altos o más bajos. En la variable sexo, haber elegido 1 para varones y 2 para mujeres es de una arbitrariedad total (de la que alguien podría quejarse). Si la codificación hubiese sido al revés, habría estado igual de bien, y también habría estado bien usar el número 25 para representar a los varones y el 38 para las mujeres, aunque esto resulta un poco incómodo. Por el contrario, en la variable edad, asignar el número 20 a quien tiene 20 años, parece totalmente “natural” ¿qué otro número podríamos haber asignado? ¿Qué sucede con el nivel de educación? En el ejemplo elegimos numerar las categorías del 1 al 8; habría habido otras opciones, por ejemplo usar solo números pares o números impares u otra secuencia arbitraria, pero algo importante es que cualquier secuencia que se elija debe respetar el orden de las categorías de la variable, por lo que los números deben reflejarlo; no habría sido correcto usar números que no vayan aumentando, como lo hacen los niveles de educación. Así entonces, hay grados diferentes en la libertad que existe para asignar los números a las categorías. Esas diferencias distinguen los niveles de medición de las variables. 1.6.1 Niveles de medición Según la mayor o menor arbitrariedad que exista en la relación que liga los números a las categorías, hablaremos de diferentes niveles de medición: cuánta más restricción haya en la asignación de los números a las categorías, más alto será el nivel de medición de las variables. Si los números se asignan de manera totalmente arbitraria, el nivel de medición es el más bajo de todos y se llama nivel nominal (como en la variable sexo); si los números deben respetar el orden de las categorías (como en la educación), la variable se llama de nivel ordinal. Por ahora, nos detenemos en estos dos niveles. 1.6.1.1 El nivel nominal Es el nivel más elemental de medición: las variables de este nivel tienen categorías que son solo nombres (de allí que se llamen nominales). La asignación de códigos numéricos cumple la función de designar las categorías, es decir, de distinguirlas una de otras. Sexo, área de especialización preferida (UA = estudiantes de Psicología), carrera que cursa (UA = estudiantes universitarios); cuyas codificaciones podrían ser: Tabla 1.6: Ejemplos de codificación de variables nominales. Código Carrera Código Área 1 Psicología 1 Clínica 2 Filosofía 2 Educacional 3 Medicina 3 Jurídica 4 Otras 4 Laboral 5 Sanitaria 6 Social 7 Experimental 8 Otra Por comodidad, se empieza en el 1 y desde allí correlativamente, pero no hay ninguna prohibición para codificar con cualquier conjunto de números. Aun con esta amplia libertad para elegir los códigos numéricos, hay algo que no se puede hacer: no es válido usar el mismo número más de una vez. Si hiciéramos esto, confundiríamos las categorías que corresponden a cada individuo. Así, a un estudiante de Psicología, le asignamos el valor 1 en la variable “carrera”, y no podría usarse ese mismo número en la misma variable también para alguien que estudia Medicina. Diremos que la condición que deben cumplir los números en este nivel de medición es que: a categorías diferentes correspondan números distintos. Entonces, en este nivel de medición a cada categoría puede asignarse, de manera arbitraria, uno y solo un número. Esta forma de asignar los valores numéricos solo implica que éstos designan las categorías (que las distinguen a una de otra), por eso, no es posible tratarlos como números en cuanto a sus propiedades aritméticas. En particular no puede sumárselos: nada puede significar que se sumen los números 1 y 2 que codifican a las carreras de Psicología y Filosofía. Una variable está medida a nivel nominal si los números que representan cada categoría son asignados de manera arbitraria y solo cumplen con la función de designar y distinguir categorías diferentes. Para unidades de análisis medidas a través de una variable de nivel nominal, es posible saber si corresponden a la misma categoría o a una diferente, es decir si tienen la misma cualidad (o atributo) o una diferente. En la tabla 1.6 si a un alumno le corresponde el número 1 y a otro también, solo podemos decir que coinciden en esta variable, ambos estudian la misma carrera (Psicología), si a uno le corresponde el 1 y a otro el 3, sabremos que el primero estudia Psicología y el otro Medicina. El hecho que el número 3 sea más grande que el 1, no tiene ninguna interpretación en este nivel de medición, no puede decirse que Psicología sea menos que Medicina. Como tampoco vale que 3 sea el triple de 1. Si 1 y 2 son dos categorías de una variable medida a nivel nominal, el único tipo de relación que puede establecerse entre ellas es \\(1\\neq2\\), es decir que 1 es diferente de 2. La regla de transformación de una escala nominal en otra es que cualquier número puede cambiarse por cualquiera a condición de no repetir ninguno. La escala nominal 1, 2, 3, 4 puede cambiarse por la 5, 8, 4, 2. Aunque no es obligatorio, en la práctica, lo más frecuente es usar los primeros números naturales para codificar las categorías. 1.6.1.2 El nivel ordinal Aquí subimos un nivel, ya que a los números que solo tienen la propiedad de designar en las variables nominales, se agrega otra: la de reflejar el orden que existe entre las categorías. Simplemente ahora se trata de variables cuyas categorías indican alguna cualidad de las unidades de análisis que crece en una dirección. Eso equivale a decir que se pueden hacer entre ellas, juicios de orden, tales como una categoría es mayor que otra, una categoría es menor que otra. El grado de escolarización cumple con ese requisito: efectivamente, el “primario incompleto” es un nivel de estudios superior a “ninguno”, pero inferior a “primario completo”. Los valores numéricos que representan las categorías rescatan ahora una propiedad adicional: el orden. Además de poder distinguir si dos sujetos tienen la misma característica analizada o una distinta como en el nivel nominal, ahora también podemos saber si un individuo tiene esa característica en mayor o menor grado. Así como “ninguno” es menor que “primario incompleto”, los números correspondientes cumplen con que 1 es menor que 2 y resulta más sencillo escribirlo como \\(1 &lt; 2\\). Una variable está medida a nivel ordinal si los números que representan cada categoría son asignados de manera que respeten el orden según aumenta o disminuye la característica que la variable mide. Estos números designan las categorías y son expresión de la jerarquía que hay entre ellas. Otro ejemplos de variable medida a nivel ordinal y su correspondiente codificación numérica es la pregunta ¿Alguna vez en tu vida golpeaste a alguien tan fuerte que necesitó atención médica u hospitalaria? (P14) del cuestionario, que fue codificada de manera creciente con la intensidad: Tabla 1.7: Ejemplo de codificación de una variable ordinal. Código P14 1. Nunca 2. Una vez 3. Dos o tres veces 4. De cuatro a seis veces 5. Más de seis veces De aquí en adelante ya no usaremos una columna especial de la tabla para indicar el código, simplemente lo señalamos junto al nombre de la categoría, encabezado con el nombre abreviado de la variable: Tabla 1.8: Ejemplo de una variable ordinal codificada. Golpeo 1. Nunca 2. Una vez 3. Dos o tres veces 4. De cuatro a seis veces 5. Más de seis veces Acerca del significado de los valores numéricos en las variables de nivel ordinal, si bien hemos agregado el orden, aun no es posible hacer operaciones con ellos. Es decir, no es posible sumar dos valores y que la suma tenga algún significado. Por ejemplo, en la última variable, no es cierto que \\(3 = 2+1\\), porque no es cierto que “dos o tres veces” sea lo mismo que “nunca” más “una vez”. Tampoco es válido restarlos, veamos que la diferencia entre 1 y 2 es 1 y la diferencia entre 4 y 5 también es 1, pero eso no tiene un correlato entre las categorías: no es cierto que haya la misma distancia entre “nunca” y “una vez” que entre “de cuatro a seis” y “más de seis”, simplemente porque no tenemos definida la idea de distancia para esta variable. Si 1 y 2 son dos categorías de una variable medida a nivel ordinal, se pueden establecer las relaciones: \\(1 \\neq 2\\) y \\(1&lt;2\\), es decir que, uno es diferente que dos y que uno es menor que dos. A la relación de distinción que existe entre categorías de la escala nominal se agrega la relación de orden. La regla de transformación de una escala ordinal en otra consiste en cambiar los números por cualquiera, a condición que no se repita ninguno (como en la nominal) y además, que sigan el mismo orden. La escala ordinal 1, 2, 3, 4 puede cambiarse por la 5, 8, 15, 23. Nuevamente, esto es poco común y suelen usarse números correlativos. Los dos niveles (o escalas) de medición siguientes se llaman intervalares y proporcionales y usan las codificaciones numéricas con un significado un poco diferente al visto hasta aquí. La principal diferencia es que el grado de arbitrariedad para asignar los números se reduce sustancialmente. En primer lugar, las escalas intervalares conservan las distancias entre los valores. En las variables medidas a nivel proporcional, además de conservarse la distancia, se verifica la proporcionalidad de los valores: es decir que, recién en estas escalas, cuatro será el doble de dos. 1.6.1.3 El nivel intervalar Veamos un ejemplo antes de definir este nivel. Cuando decimos que estamos en el año 2020, hacemos implícitamente una afirmación que supone una medición del tiempo transcurrido desde un determinado evento, cuya elección no es única. En cierto modo decimos “han transcurrido 2020 años desde el momento que se acordó usar como inicio de este calendario”. En culturas no cristianas, el origen en la medición de los tiempos puede ubicarse en otro momento y, en consecuencia, el año actual es otro. En el calendario judío, por ejemplo, el presente es el año 5780. Hay entonces cierto grado de arbitrariedad en la ubicación del punto desde donde empezar a contar los años. Lo que podría llamarse el “año cero”, no es necesariamente el mismo. Sin embargo, el tiempo transcurrido entre 1975 y 2005 es de treinta años, como lo es el tiempo transcurrido entre 5735 y 5765. Es decir que la transformación que lleva los años de un calendario al otro, conserva las distancias. Independientemente de la escala con que hayamos medido el año, la diferencia entre dos años, se mantiene constante. Eso sucede porque las dos escalas (en este ejemplo, la medición del tiempo según las tradiciones cristiana y judía) se distinguen solo en la elección del origen (la posición del cero) pero no en la definición de lo que es un año. Para ambas escalas un año corresponde a una vuelta de la tierra al sol, por lo que la unidad de medición es la misma4. Si alguien tiene 30 años en el calendario cristiano, también tiene 30 años con el calendario judío; porque, aunque tanto el año de nacimiento como el actual sean diferentes en los dos calendarios, la diferencia (el tiempo transcurrido) entre las dos fechas es la misma. Ubicar el cero en un momento (en un determinado hecho histórico) o en otro es una elección; ese cero no indica la “ausencia de tiempo”. En este caso, cero no quiere decir “nada”, sino “origen elegido”. Una forma de medir la inteligencia es la de observar cuántos problemas de una serie de dificultad creciente es cada uno capaz de resolver correctamente. Pero, ¿podría decirse que quien no resuelve ninguno de ellos tiene inteligencia cero?, esto es claramente incorrecto, porque la ubicación del cero no implica la ausencia de lo que estamos midiendo (ausencia de inteligencia en este caso). Las escalas intervalares, mantienen las propiedades de las escalas ordinales y nominales, es decir, los números designan categorías y permiten ordenarlas; pero además permiten decir a qué distancia está una de otra, porque cada categoría se expresa también en sentido cuantitativo. La medición intervalar implica construir una escala en la que las categorías están proporcionalmente distanciadas entre sí. Esto permite especificar la distancia que separa a cada categoría de las demás. Este nivel de medición requiere que se establezca algún tipo de unidad de medida que pueda ser considerado por todos como una norma común y que sea repetible, esto es, que se pueda aplicar reiteradamente a los mismos individuos produciendo los mismos resultados. La medición de los rendimientos individuales por medio de pruebas suele expresarse en puntajes que provienen del tiempo requerido para realizar una determinada tarea o de la cantidad de trabajo realizado. En este tipo de prueba, es común que los puntajes partan de un mínimo establecido (por ejemplo el mínimo tiempo posible de ejecución o la mínima cantidad de tareas que una persona puede realizar en una prueba) y esto constituye el puntaje mínimo o la categoría más baja. Los puntajes de las pruebas mentales varían de acuerdo con el rendimiento y un mayor rendimiento siempre significará un mayor puntaje. Por ejemplo, el manual original del Inventario de Depresión de Beck-II (Upton (2013)) establece niveles (ordinales) para los puntajes (intervalares) que resultan de la aplicación del instrumento: Tabla 1.9: Ejemplo de codificación de rangos de puntajes para una variable intervalar. Puntaje en la escala Significado 0 - 13 depresión mínima 14 - 19 depresión leve 20 - 28 depresión moderada 29 - 63 depresión grave De este modo se ha bajado el nivel de medición, de intervalar a ordinal. A nivel intervalar, ya es posible expresar la regla de transformación de manera formal; así, si x e y representan la medición del mismo atributo en diferentes escalas, puede obtenerse y a partir de x a través de la siguiente operación: \\[y = b_0 + b_1*x\\] Se usan los símbolos \\(b_0\\) y \\(b_1\\) para indicar dos números fijos elegidos arbitrariamente. El primero de ellos indica el desplazamiento en el origen de la escala: allí donde \\(x\\) valga 0, y tomará el valor de \\(b_0\\). Por su parte, \\(b_1\\) es un factor de escala, que modifica el tamaño de la unidad de medida. En el ejemplo de la medición del año según dos calendarios diferentes, si x es la medición en el calendario cristiano e y con el calendario judío, la relación es: \\[y = 3760 + x\\] En la que \\(b_0\\) se reemplazó por 3760 y \\(b_0\\) ha desaparecido, es decir que vale 1 (que no tiene efecto cuando multiplica a x). El valor 3760 representa el cambio en el origen: cuando el calendario cristiano marcó cero (hipotéticamente, porque su implementación es posterior a esa época), el judío indicaba el año 3760. El 1 correspondiente a b1, indica que no hay cambio en el tamaño de la unidad, como dijimos antes, ambas culturas acuerdan en que el año es una vuelta de la tierra al sol5. Una variable está medida a nivel intervalar cuando las distancias entre las categorías son proporcionales. Si 1, 2, 3 y 4 son categorías de una variable medida a nivel intervalar, se pueden establecer las relaciones: \\[1 \\neq 2\\] \\[1 &lt; 2\\] \\[2 - 1 = 4 - 3\\] Se agrega la conservación de las distancias a las propiedades que ya tenía la escala anterior. 1.6.1.4 El nivel proporcional6 Este es el último nivel de medición que trataremos y es el más intuitivo, es el único nivel considerado efectivamente como medición por la teoría clásica, ya que en él se integran todas las propiedades de los niveles anteriores y además se agrega la proporcionalidad de los valores numéricos y el carácter absoluto del cero. Recién a este nivel, los números se comportan realmente como números, ya que se puede operar con ellos del modo al que estamos acostumbrados (sumarlos, multiplicarlos, etc.). ¿Qué variables pueden medirse a este nivel? Todas aquellas para las cuales tengan sentido las dos propiedades adicionales que esta escala incorpora: proporcionalidad de valores y cero absoluto. La cantidad de errores ortográficos cometidos en una prueba de dictado, admite el valor cero como correspondiente a “no errores”, es la ausencia de lo que se mide, se trata de un cero absoluto. Además, cometer 10 errores es el doble que cometer 5. Por eso, la variable Número de errores ortográficos cometidos es de nivel proporcional. El tiempo que una persona tarda en resolver una tarea, si se mide en minutos, admite considerar que 4 minutos es el doble de 2, por lo que estamos también en presencia de una escala proporcional, aunque el cero no sea un valor observable. También es proporcional la variable ingresos mensuales del hogar o el número de materias aprobadas. En general, los valores que provengan de procesos de conteo (como el número de errores) serán siempre proporcionales, como también aquellos que hagan referencia a una unidad de medida estándar como el tiempo7 o la distancia. La expresión formal de la regla de transformación entre escalas proporcionales es, si \\(x\\) e \\(y\\) representan la medición del mismo atributo en diferentes escalas: \\[y = b_1 * x\\] En la que ahora solo tenemos un número fijo: \\(b_1\\), que es el factor de escala, que modifica el tamaño de la unidad de medida. Esto simplemente significa que pueden cambiarse las unidades con que se miden las variables proporcionales. Por ejemplo para pasar de metros a centímetros: \\[y = 100 * x\\] Donde x es la medida en metros e y la misma medida expresada en centímetros. Si \\(x=3\\) metros entonces \\(y=300\\) centímetros De horas a minutos \\[y = 60 * x\\] El factor 60 transforma a las horas (x) en minutos (y). Si \\(x=2\\) horas entonces \\(y=120\\) minutos Otro ejemplo, si el tiempo que tardan sujetos experimentales para reconocer una expresión facial se mide en milisegundos (x), esa medición se puede pasar a segundos (y), dividiendo por mil. \\[y=\\dfrac{1}{1000}*x\\] Ninguna de esas transformaciones pueden modificar la posición del cero, porque en esta escala es absoluto: allí donde x valga cero, y deberá también valer cero, por eso no aparece el término b0 que estaba en las intervalares. Cero metros son también cero centímetros y cero horas son cero minutos. Una variable está medida a nivel proporcional cuando sus valores respetan relaciones de proporcionalidad y, en consecuencia, el cero tiene un valor absoluto. Si 1, 2, 3 y 4 son categorías de una variable medida a nivel proporcional, se pueden establecer las relaciones: \\[1 \\neq 2\\] \\[1 &lt; 2\\] \\[2 - 1 = 4 - 3\\] \\[4 = 2 * 2\\] 1.6.1.4.1 Una subdivisión en las escalas proporcionales Entre las variables medidas a nivel proporcional, debe hacerse una diferenciación, según los valores solo puedan ser números enteros o admitan números decimales, porque cambia la forma de presentación. El primer tipo es el que se llama variable discreta, los siguientes son ejemplos de ella: Tabla 1.10: Ejemplos de variable proporcional discreta. Cantidad de aplazos Número de materias aprobadas 0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 o más Aquí podría suceder que la variable tenga un gran número de valores. En el ejemplo de la cantidad de materias aprobadas, puede restringirse a las aprobadas por alumnos de primer año y en condición de regular, de modo que el máximo sea de 6. Pero si fueran alumnos de toda la carrera, la cantidad podría ir desde cero hasta el número total de materias. En esos casos, resultaría poco claro hacer la lista con todos los valores posibles. Cuando una variable discreta tiene una cantidad grande de valores, el problema de la presentación de las categorías se resuelve agrupándolas. Esto se llama recategorización porque consiste en construir nuevas categorías (volver a categorizar) a partir de las originales de la variable, a fin de resumir la información. Por ejemplo, la primera categoría puede incluir a quienes aprobaron una materia o ninguna, la segunda a los que aprobaron dos o tres y así sucesivamente: Tabla 1.11: Ejemplo de recategorización de una variable discreta. Número de materias aprobadas 0-1 2-3 4-6 Cuando la variable admite números decimales se la llama continua, y allí el problema es mayor, porque el número de valores puede ser muy elevado8 y la única opción es la de construir categorías. Tabla 1.12: Ejemplo de recategorización de una variable continua Estatura (en metros) hasta 1,55 1,55 - 1,65 1.65 - 1.75 1,75 - 1,85 1,85 - 1,95 1,95 - 2,05 más de 2,05 En el próximo capítulo nos detendremos en las formas de construir estos agrupamientos y despejaremos las dudas que provengan de la diferente cantidad de valores que se agruparon en la variable discreta de este ejemplo (las dos primera categorías contienen dos valores cada una, y la tercera tres) y la aparente superposición entre el inicio de una categoría y el fin de la anterior en el caso de la continua, que sería una violación de la exclusión mutua, porque alguien con una talla de 1,85 podría ir a la cuarta o a la quinta categoría. 1.7 Resumen de los niveles de medición Nivel de medición Significado de los símbolos numéricos Condición para cambio de escala Ubicación del cero Nominal Designan, distinguen No repetir los números Sin significado Ordinal Expresan orden Respetar el orden ascendente o descendente Sin signifcado Intervalar Proporcionalidad de distancias \\(y = b_0 + b_1*x\\) Arbitrario Proporcional Proporcionalidad de valores \\(y = b_1*x\\) Absoluto Ejemplos de diferentes niveles de medición Nominales: Valores (supervivencia vs autoexpresión, tradicionales vs racionales) Inglehart (2018), Norris and Inglehart (2011) Ordinales: Las escalas de compromiso politico, acuerdo partidario y consistencia ideológica (Doherty, Kiley, and Jameson (2016)), la pobreza medida según Línea de pobreza (INDEC (2016)), el grado de acuerdo en escalas de actitud Robinson (2014) Cuantitativas discretas: Cantidad de partidos políticos, tipo de vivienda INDEC (2018), cantidad de palabras recordadas en una prueba de memoria Cuantitativas continuas: Tiempo requerido para completar una tarea, ingreso per cápita familiar INDEC (2018), gasto total en campaña electoral Morales Quiroga and Pineiro Rodriguez (2010) References "],
["distribuciones-de-frecuencia.html", "Capítulo 2 Distribuciones de frecuencia 2.1 Tablas de distribución de frecuencia 2.2 Recategorización 2.3 La presentación gráfica de los resultados", " Capítulo 2 Distribuciones de frecuencia Una vez identificadas las variables y reconocido su nivel de medición, es necesario darle a la matriz de datos un formato que permita hacer lecturas de los resultados, ya que es imposible observar una tabla que tenga gran cantidad de filas (casos) y muchas columnas (variables). El siguiente fragmento de matriz de datos: ## ANO4 TRIMESTRE AGLOMERADO CH03 CH04 ## 1 2018 3 2 1 2 ## 2 2018 3 2 1 1 ## 3 2018 3 2 6 2 ## 4 2018 3 2 3 1 ## 5 2018 3 2 1 1 ## 6 2018 3 2 2 2 Muestra las primeras variables y primeros casos correspondiente a la aplicación del cuestionario individual de la Encuesta Permanente de Hogares INDEC (2018) del tercer trimestre de 2018, que tiene 56879 casos. Las variables están codificadas, tanto en su nombre como en sus categorías. Por ejemplo, CH06 es la edad y los números representan años cumplidos, CH04 es sexo y sus categorías son 1 = varones, 2 = mujeres. Esas codificaciones están en el documento Diseño de Registro de la Base Usuario de la EPH (???) Cada columna de la matriz de datos contiene los valores que se han observado en cada uno de los individuos (filas); si se observa verticalmente, cada columna es una secuencia de números, que algunos programas denominan vector. Para el caso de CH04 (sexo), los primeros 25 valores de esta columna son: ## [1] 2 1 2 1 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 2 1 1 1 2 1 Así presentada, la secuencia se llama serie simple y solo puede analizarse cuando son muy pocos casos, sería imposible en este ejemplo, con 56879 filas. El más elemental de los resúmenes consiste en contar, para una variable determinada, cuantas apariciones tiene cada categoría. En la columna encabezada CH04 (sexo) pueden contarse cuántos unos (1s) y cuántos doses (2s) hay en total. 2.1 Tablas de distribución de frecuencia Las tablas resumen los recuentos, en este ejemplo: Tabla 2.1: Distribución por sexos. Var1 Freq 1 27219 2 29660 Total 56879 Cuando se rotulan la variable y sus categorías: Tabla 2.2: Distribución por sexos (categorías rotuladas. sexo casos varones 27219 mujeres 29660 Total 56879 A la cantidad de casos, que proviene del recuento del número de unos y doses en la columna de sexo, se lo llama técnicamente frecuencia absoluta simple y se la indica como f. La tabla resulta entonces: Tabla 2.3: Distribución por sexos: frecuencia absoluta. sexo f varones 27219 mujeres 29660 Total 56879 El total de 56879 casos resulta de la suma de todas las frecuencias absolutas simples, de manera breve, esto se indica así: \\[\\sum_{i=1}^{k}f_i =n\\] Que se lee “La sumatoria de las frecuencias (f) desde 1 hasta k es igual al total de observaciones (n)”. En esa expresión: \\(\\sum\\) es el símbolo de suma o sumatoria e indica la realización de esa operación (sumar). Las \\(f_i\\) son las frecuencias absolutas simples. El subíndice i va cambiando entre categorías. La expresión \\(i=1\\) señala desde qué valor de i se inicia la suma, así como k señala la última categoría a sumar. En el ejemplo de las tablas, el valor de k es 2 (solo hay dos categorías), por lo que solo hay dos frecuencias a sumar: \\(f_1\\) y \\(f_2\\), correspondientes a las cantidades de varones y de mujeres. n es el total de casos (observaciones). Lo mismo puede indicarse como: \\[f_1 + f_2 + ⋯ + f_k = n\\] Que, en el caso de la tabla anterior resulta simplemente: \\[f_1 + f_2 = 27219 + 29660 = 56879\\] La frecuencia absoluta simple de cada valor de la variable es el número de casos que asumen ese valor. Se indica \\(f\\). Si se quisieran comparar estas frecuencias con las de otra matriz de datos que tuviera un número total de casos diferente de 56879, sería inadecuado usar los valores absolutos aquí presentados. Por ejemplo, la comparación de la distribución por sexos entre las personas que trabajan en el sector estatal y en el sector privado. Tabla 2.4: Distribución por sexos según sector de trabajo. sexo (sector estatal) f 1 2468 2 2810 Total 5278 sexo (sector privado) f 1 10618 2 7276 Total 17894 No es clara la comparación entre el número de mujeres en los dos sectores, porque la cantidad total de casos es muy diferente, por eso es necesario comparar el peso relativo de las mujeres respecto del total, y no su número absoluto, se trata de su contribución al total de casos. Para calcularlo se divide el número de mujeres en el total general. En el ejemplo, para el sector estatal es 0.532 que es el 53.2% de los casos. Es decir que las mujeres constituyen una proporción de 0.532 o bien que representan el 53.2% del total. Mientras que en la segunda tabla, la proporción de mujeres es 0.407 que es el 40.7% de los casos. Estas proporciones se denominan frecuencias relativas simples, se simbolizan como \\(f&#39;\\) (efe prima), y se calculan dividiendo la frecuencia absoluta por el total. Ahora puede completarse la tabla anterior agregando otra columna. Tabla 2.5: Distribución por sexos sector privado: frecuencias relativas. sexo (sector privado) f f’ 1 10618 0.59 2 7276 0.41 Total 17894 1 El valor 1 que resulta de sumar las dos frecuencias relativas corresponde al 100% de los casos, es decir a las 17894 observaciones. Usando la misma simbología que antes: \\[\\sum_{i=1}^{k} f&#39;_i =1\\] Que afirma que la suma de las frecuencias relativas simples (\\(f’\\)) es igual a uno. La salida para la variable ESTADO tiene la siguiente forma: Tabla 2.6: Condición laboral. ESTADO f’ 0 0.00 1 0.41 2 0.03 3 0.41 4 0.15 Total 1.00 Cuando se codifica, queda: Tabla 2.7: Condición laboral (categorías rotuladas). ESTADO f’ entrevista no realizada 0.00 ocupado 0.41 desocupado 0.03 inactivo 0.41 menor de 10 años 0.15 Total 1.00 Al construir estas tablas de distribución de frecuencias se renuncia a una parte de la información que estaba en la matriz de datos. En ella se podía seguir por la fila a cada individuo y describirlo en cada uno de sus aspectos relevados (variables). Por el contrario, la tabla de distribución de frecuencias de sexo solo dice que hay 27219 varones y 29660 mujeres o, en la tabla de ESTADO, que hay 23398 ocupados, 1870 desocupados, etc., pero no se informa quiénes son. Esta pérdida de información es parte inevitable del proceso en el que se resumen datos, cuanto más sintética sea la presentación, tanta más información habremos perdido. Esto puede visualizarse como el proceso en el que se “toma distancia” de los datos originales: cada vez se tiene una mejor visión de conjunto, pero al mismo tiempo se pierden detalles. La frecuencia relativa simple de cada valor de la variable es la proporción de casos que asumen ese valor. Se indica \\(f&#39;\\). Los dos ejemplos mostrados hasta aquí corresponden a variables medidas a nivel nominal, por lo que los números no son más que códigos, no representan orden ni puede considerarse la distancia entre ellos. ¿Qué cambia con un nivel de medición más elevado? Con el mismo principio usado para las variables nominales, la forma de la tabla de distribución de frecuencia para la edad (CH06) de estudiantes universitarios sería: Tabla 2.8: Distribución por edades. edad f f’ 17 8 0.00 18 247 0.07 19 355 0.09 20 377 0.10 21 372 0.10 22 364 0.10 23 331 0.09 24 241 0.06 25 237 0.06 26 188 0.05 27 156 0.04 28 134 0.04 29 98 0.03 30 84 0.02 31 76 0.02 32 65 0.02 33 61 0.02 34 36 0.01 35 46 0.01 36 44 0.01 37 20 0.01 38 21 0.01 39 27 0.01 40 21 0.01 41 18 0.00 42 14 0.00 43 19 0.01 44 18 0.00 45 4 0.00 46 10 0.00 47 7 0.00 48 8 0.00 49 4 0.00 50 6 0.00 51 7 0.00 52 10 0.00 53 3 0.00 54 5 0.00 Total 3742 1.00 Sobre esta tabla se pueden calcular otras frecuencias, que respondan a preguntas como ¿cuántos alumnos de menos de 20 años fueron encuestados? Para saber eso, hay que contar cuántos casos hay con edades menores a 20: con 17, 18 o 19 años hay 610 casos, que provienen de sumar las frecuencias de esas categorías (8+247+355). Así, además de indicar cuántos casos (o qué porcentaje de ellos) tiene determinados valores de la variable, resulta de interés mostrar cuantos (y también que porcentaje) tienen valores iguales o menores a uno determinado. Esto va a ser indicado por las frecuencias acumuladas, que responden a la pregunta por la cantidad de casos que hay por debajo de una categoría de la variable. Pero solo para variables medidas a escala ordinal o superior, porque con variables nominales no se pueden hacer juicios de orden, como decir que una categoría es mayor o menor que otra. El cálculo de las frecuencias acumuladas consiste en contar las frecuencias de la categoría que interesa y sumarla a las frecuencias de las categorías anteriores a ella. En el ejemplo de la distribución de las edades de estudiantes universitarios resulta: Tabla 2.9: Distribución por edades: frecuencias acumuladas. edad f f’ F F’ 17 8 0.002 8 0.002 18 247 0.066 255 0.068 19 355 0.095 610 0.163 20 377 0.101 987 0.264 21 372 0.099 1359 0.363 22 364 0.097 1723 0.46 23 331 0.088 2054 0.548 24 241 0.064 2295 0.612 25 237 0.063 2532 0.675 26 188 0.050 2720 0.725 27 156 0.042 2876 0.767 28 134 0.036 3010 0.803 29 98 0.026 3108 0.829 30 84 0.022 3192 0.851 31 76 0.020 3268 0.871 32 65 0.017 3333 0.888 33 61 0.016 3394 0.904 34 36 0.010 3430 0.914 35 46 0.012 3476 0.926 36 44 0.012 3520 0.938 37 20 0.005 3540 0.943 38 21 0.006 3561 0.949 39 27 0.007 3588 0.956 40 21 0.006 3609 0.962 41 18 0.005 3627 0.967 42 14 0.004 3641 0.971 43 19 0.005 3660 0.976 44 18 0.005 3678 0.981 45 4 0.001 3682 0.982 46 10 0.003 3692 0.985 47 7 0.002 3699 0.987 48 8 0.002 3707 0.989 49 4 0.001 3711 0.99 50 6 0.002 3717 0.992 51 7 0.002 3724 0.994 52 10 0.003 3734 0.997 53 3 0.001 3737 0.998 54 5 0.001 3742 1 Total 3742 1.000 Se agregaron dos columnas más, las frecuencias acumuladas absolutas (F) y relativas (F’). Las primeras se obtuvieron sumando a la frecuencia absoluta de cada categoría, las frecuencias absolutas de las categorías anteriores a ella. Así, la primera categoría tiene frecuencia acumulada igual a la absoluta simple, porque no hay ningún caso por debajo de 17 años; la segunda es 255, que proviene de contar los 247 de la segunda categoría y sumarle los 8 de la anterior y del mismo modo se construyen las siguientes. La última categoría tiene por frecuencia absoluta acumulada al total de casos (en el ejemplo 3742), porque todos (los 3742) están en esa categoría o por debajo de ella, es decir, todos tienen de 54 años para abajo. La lectura que hacemos de estas frecuencias es que, por ejemplo, “hay 987 alumnos que tienen 20 años o menos.” La frecuencia absoluta acumulada de cada valor de la variable es la cantidad de casos que asumen ese valor y todos los valores menores a él. Se indica \\(F\\). La última columna de la tabla es la transformación en relativas de las frecuencias absolutas acumuladas y se logra con el mismo procedimiento que se usó para las relativas simples; el de dividir por el total de casos. Se denominan frecuencias acumuladas relativas. La lectura de una de estas frecuencias es, por ejemplo, que el 46% de los alumnos que respondieron tiene 22 años o menos. Notemos la diferencia con la frecuencia relativa simple: el 9.7% de los alumnos tiene exactamente 22 años. La frecuencia relativa simple es la fracción de casos que tienen una determinada categoría (o valor) de la variable, la frecuencia relativa acumulada es la fracción de casos que tiene un valor de la variable o cualquiera de los anteriores a ese valor. Por eso la lectura del ejemplo es “22 años” en la simple y “22 años o menos” en la acumulada. La frecuencia relativa acumulada de cada valor de la variable es la proporción de casos que asumen ese valor y todos los valores menores a él. Se indica \\(F&#39;\\). 2.2 Recategorización Como se señaló al final del capítulo 1, hay dos situaciones en que se apela a la presentación de los valores de la variable en forma agrupada, es decir que se recategoriza la variable en intervalos: si se trata de una variable discreta con muchas categorías (como la edad) o si es una variable continua. 2.2.1 Variable discreta con muchas categorías La construcción de intervalos es una elección; podríamos optar por mostrar todas las categorías, con lo que quedaría una tabla grande, pero muy detallada; o bien agrupar para ganar en sencillez de presentación. Es muy común optar por la construcción de intervalos, de manera de mantener la cantidad de categorías entre cinco y diez. En tablas en que se precisa mostrar mucho detalle, se opta por la enumeración de todas las categorías. 2.2.2 Variable continua Si la variable es continua la recategorización es necesaria, porque no es posible mostrar “todas las categorías” de una variable continua, ya que éstas son, en teoría, infinitas9. Para resolver el problema de la exclusión mutua no es posible pasar de un valor al siguiente, por lo que se utiliza un criterio de intervalos abiertos o cerrados. Esto quiere decir que si una categoría es 1,75 - 1,85, se entiende que entran en el intervalo todos quienes tengan estatura superior a 1,75 (excluido este valor) hasta 1,85 (incluido). Se dice que este intervalo es abierto a la izquierda (excluye al valor inicial) y cerrado a la derecha (incluye al valor final). Una persona de 1,75 se contará en el intervalo anterior: 1,65 - 1,75, que sí incluye al 1,75 y excluye al 1,65. A continuación se usará la convención de intervalos abiertos a la izquierda y cerrados a la derecha, eso se indica \\((L_i; L_s]\\). Se utilizan tres criterios para recategorizar variables: intervalos iguales, intervalos proporcionales e intervalos teóricos. 2.2.2.1 Intervalos iguales: Se organizan los valores de la variable para lograr que el campo de variación quede dividido en tantos intervalos como se desee siendo ellos de igual amplitud. Si es una variable discreta y la cantidad de categorías originales no es múltiplo de número de intervalos que se desean, la cantidad de valores en cada uno no será idéntica, sino aproximadamente igual. La variable edad, con cuatro categorías queda, según este criterio, así: Tabla 2.10: Categorización de la edad en intervalos de igual amplitud. EdadCat f (17,26.2] 2720 (26.2,35.5] 756 (35.5,44.8] 202 (44.8,54] 64 Los intervalos son de la misma amplitud, pero el primero de ellos tiene más del 70% de las observaciones, con lo que se pierde detalle de la distribuciión. 2.2.2.2 Criterio proporcional Este criterio busca que los intervalos incluyan aproximadamente a la misma cantidad de casos, por lo que su amplitud puede ser diferente. En el capítulo siguiente se verá que los puntos para establecer los cortes de intervalos, se llaman percentiles. Por ahora interesa que con este criterio se logran grupos homogéneos en términos de cantidad de observaciones. la edad de los estudiantes, con cuatro intervalos resulta así categorizada: Tabla 2.11: Categorización de la edad en intervalos proporcionales. EdadCat f (17,20] 979 (20,23] 1067 (23,27] 822 (27,54] 866 Ahora la distribución está más equilibrada (hay alrededor de 1000 casos en cada una), y los intervalos tienen amplitud diferente. El último intervalo, de 26 años de amplitud, tiene casi la misma cantidad de casos que el primero, que cubre tres años. 2.2.2.3 Criterio teórico Aquí la decisión por el lugar donde establecer los puntos de corte para definir los intervalos es del investigador y debe estar fundamentada. Si se considera que la edad esperada de los alumnos observados es entre 19 y 20 años, se pueden hacer cuatro intervalos con quienes tienen menos de esa edad, quienes tienen la edad esperada, los que tienen más de esa edad y los más mayores (superan los 40 años). Los intervalos resultan así: Tabla 2.12: Categorización de la edad con un criterio teórico. EdadCat f (17,18] 247 (18,20] 732 (20,40] 2622 (40,54] 133 El intervalo (18,20] incluye las edades de 19 y 20 años, porque es abierto a la izquierda. 2.3 La presentación gráfica de los resultados En la misma dirección de ofrecer una presentación de los datos recogidos que sea accesible para la interpretación, se muestran a continuación las representaciones gráficas que más se usan para describir información cuantitativa. Nuevamente aquí se debe aceptar la pérdida de parte de la información que se muestra, en aras del impacto visual y facilidad de lectura que proveen los gráficos. Cuando se trata de variables nominales, normalmente con pocas categorías, son adecuados los gráficos de barras. Veamos un ejemplo para la tabla de la “ESTADO”: Figura 2.1: Condición laboral: frecuencias absolutas (barras adyacentes). La categoría NA (not available) reúne a quienes no respondieron al cuestionario y a los menores de 10 años, que no se les hace la pregunta. Figura 2.2: Condición laboral: frecuencias absolutas (barras apiladas). O bien, en relativos: Figura 2.3: Condición laboral: frecuencias relativas (barras apiladas). Para variables categóricas también se usa el gráfico de sectores Figura 2.4: Condición laboral: frecuencias relativas (gráfico de sectores). Este gráfico solo es adecuado cuando la variable tiene pocas categorías (no más de cuatro) y además cuando las frecuencias difieren sustancialmente. De lo contrario, resulta muy difícil apreciar diferencias entre ángulos, éstas son mucho más claras entre alturas de barras. La opción de agregar una leyenda con los porcentajes resuelve este problema, pero hace perder parte de la claridad visual del gráfico. La representación gráfica de la tabla de frecuencias de variables cuantitativas (categorizadas), se llama histograma: Figura 2.5: Histograma de edades. El ancho de los rectángulos es la amplitud de las categorías que resultan de la categorización. Esta siempre se realiza con el criterio de intervalos iguales, que puede regularse, por ejemplo, si se toman intervalos de 5 años, el histograma queda: Figura 2.6: Histograma de edades: categorías de 5 años. Cuando estos rectángulos se unen en sus puntos medios por una poligonal, resulta el polígono de frecuencias: Figura 2.7: Polígono de frecuencias de las edades sobre el histograma. En este gráfico se agregaron dos intervalos, uno anterior al primero y uno posterior al último, cuyas frecuencias son cero, con el objetivo de “cerrar” el polígono sobre el eje horizontal. El área que queda bajo este polígono es igual a la que encierran los rectángulos del histograma, y valdrá n si se grafican frecuencias absolutas ó 1 si son las relativas. Si se muestra solo el polígono, se tiene una representacón simplificada de la distribución que sirve para apreciar aspectos que se verán más adelante: forma, dispersión, simetría, etc. Además es preferible presentar en el eje vertical, frecuencias relativas antes que absolutas. Figura 2.8: Polígono de frecuencias de las edades. En variables cuantitativas es posible calcular frecuencias acumuladas, por lo que también ellas pueden representarse gráficamente. Si la variable es discreta, cada valor aporta su frecuencia, que “salta” en el valor siguiente, por eso el gráfico tiene forma escalonada. Nuevamente, con la variable edad (CH06) de la EPH es: Figura 2.9: Ojiva de las edades. En el que el eje horizontal se indican los valores de la variable discreta edad y en el vertical las frecuencias acumuladas de cada categoría (de cada valor discreto). Si la variable es continua, las frecuencias se van acumulando gradualmente a medida que aumenta el valor de la variable, el siguiente gráfico muestra las frecuencias acumuladas de los pesos de un conjunto grande de niños (de la base bayley): Figura 2.10: Ojiva de los pesos al nacer. Debido a que en la práctica las variables nunca son completamente continuas, siempre habra “escalones” cuyo tamaño es el de la minima medición posible de la variable (la apreciación del instrumento de medicion). Este gráfico se llama ojiva de Galton y tiene otra virtud además de la claridad visual, ya que permite interpolar valores no observados, o que no aparecen en la tabla. Así, con el gráfico podemos responder a la pregunta ¿Qué proporción de niños tiene 2512 g o menos? La respuesta consiste en buscar el valor 2512 gramos en el eje x, e identificar la frecuencia acumulada que le corresponde. Figura 2.11: Estimación de la frecuencia acumulada para un valor del peso al nacer. En este ejemplo, la ordenada (valor en el eje vertical) correspondiente a los 2512 gramos es aproximadamente 0,17, este resultado se lee diciendo que, de esta muestra, el 17% de los niños nació con 2512 gramos o menos. En los capítulos siguientes veremos otras aplicaciones útiles de este procedimiento. Además, el establecimiento de los límites de los intervalos según el criterio proporcional, puede realizarse en base a este gráfico. Según cuántos intervalos se quiera construir, se ubican los puntos correspondientes a las frecuencias acumuladas en el eje vertical y se buscan los valores de la variable (eje horizontal), que delimitan los intervalos. Por ejemplo, para cuatro intervalos, cada uno debe contener aproximadamente el 25% de los casos, que corresponden a las frecuencias acumuladas de 25, 50 y 75%. Figura 2.12: Identificación de los valores de la variable para determinadas frecuencias absolutas. Los valores hallados corresponden a 2646, 2968 y 3320 gramos. Que quiere decir que un cuarto de los niños nació con pesos entre el mínimo y 2646, otro cuarto pesó entre 2646 y 2968 gramos, y así con los demás. La distribución de frecuencias de esta variable así categorizada resulta: Tabla 2.13: Distribución de los pesos al nacer categorizados en cuatro intervalos proporcionales. Peso.nacCat f (1302.5,2646.5] 113 (2646.5,2967.5] 113 (2967.5,3319.8] 113 (3319.8,4268.5] 114 References "],
["la-expresión-resumida-de-la-información.html", "Capítulo 3 La expresión resumida de la información 3.1 Medidas de posición 3.2 La forma de la distribución 3.3 Box-plots 3.4 Medidas de dispersión 3.5 El individuo en relación a su grupo 3.6 Resumen de medidas descriptivas", " Capítulo 3 La expresión resumida de la información La segunda etapa en la descripción de datos consiste en calcular medidas que los resuman, que los expresen de manera sintética. Esta etapa implica un nuevo alejamiento de la información bruta, ya que se pierde de vista no solo a los individuos -presentes en la matriz de datos-, sino también a las distribuciones de frecuencia. La ventaja de resumir es la posibilidad de presentar la información de modo muy sintético; con unas pocas medidas descriptivas se ofrece bastante información sobre los datos que se observan. Estas medidas requieren operaciones de diferente nivel de complejidad, por lo que apelan a diferentes propiedades de las escalas de medición, entonces no serán las mismas las medidas que se puedan calcular en una escala nominal que en una ordinal, intervalar o proporcional. El objetivo de describir el conjunto de datos se logrará indicando tres tipos diferentes de medidas. En primer lugar, haremos referencia a las medidas de posición. Estas medidas indican en torno a qué valores se distribuyen las observaciones. En segundo lugar, mencionaremos las medidas de dispersión (conocidas también como de variabilidad), que muestran si los datos están concentrados alrededor de las medidas de centralidad o si están alejados de esas medidas centrales. En tercer lugar, se describe la forma que toma la distribución, medida con dos indicadores: simetría y curtosis. A los fines de la notación usada para referirse a cada una de estas medidas descriptivas, asumiremos que trabajamos sobre datos provenientes de una muestra, de la que n representa la cantidad de casos observados. 3.1 Medidas de posición Como las operaciones que pueda hacerse entre las categorías dependen del nivel de medición de las variables, las medidas que se puedan calcular también dependerán del nivel de medición. Por eso las presentaremos separadamente para cada nivel, siempre recordando que las operaciones que son válidas a un determinado nivel de medición también son válidas para niveles más altos. Por ejemplo: lo que pueda hacerse con variables nominales, vale también para ordinales y métricas, con los ajustes de casa caso. 3.1.1 Variables nominales: proporciones Cuando se trabaja con una variable de nivel nominal, una manera sintética de presentar la información que ofrece la tabla de distribución de frecuencias es indicando la proporción de casos que se encuentran en una determinada categoría. Se trata de la frecuencia relativa simple (f’) de una categoría particular. La siguiente es la distribución de las respuestas a la pregunta “¿Con cuál de las siguientes frases está Ud. más de acuerdo?” (P8STGBS), proveniente de la base latinobarómetro: ¿Con qué frase está más de acuerdo? f f’ Se puede confiar en la mayoría de las personas 0.143 14.3 Uno nunca es lo suficientemente cuidadoso en el trato con los demás 0.857 85.7 Total 1 100 Podemos indicar la proporción de personas que respondió que se puede confiar caso como 0.143, que puede también expresarse como 14.3%. La elección de cuál categoría se elige para indicar la proporción depende de los objetivos de la descripción. Al elegir una categoría se llama la atención sobre ella, se la destaca, ya que la proporción restante incluye a todas las demás categorías, los “otros”. Esa proporción restante se obtiene restando de 1 (uno) la proporción indicada, o restando de 100 (cien) si ha expresado como porcentaje. En este ejemplo, diremos que 0.857 (que proviene de hacer 0.857) es la proporción de quienes no creen que se pueda confiar, o bien que éstos representan el 85.7% (85.7). La proporción es la frecuencia relativa correspondiente a una categoría particular. Usualmente se expresa como porcentaje. Se indica como \\(p\\). Esta medida descriptiva se usa a menudo cuando la variable nominal tiene solo dos categorías (variable dicotómica), ya que se presenta la proporción de una de ellas e inmediatamente se sabe que el complemento es la proporción de la otra. Esta medida ya apareció al definir la proporción como el cociente entre la frecuencia propia de la categoría y el total de casos. Esta proporción puede también indicarse en variables de nivel de medición superior al nominal, pero no resulta de interés cuando hay gran cantidad de categorías. Así, por ejemplo, si se trata de la distribución de las notas de un parcial, no resulta útil indicar cuál es la proporción de cada calificación e indicar algo como “el 20% sacó 8” (lo que se vería en una tabla de distribución de frecuencias de las notas). Por el contrario, es común construir variables nominales a partir de las notas y, sí es de mucho interés indicar, por ejemplo, la proporción de promocionados, o la proporción de quienes quedaron libres, luego de haber categorizado las notas con un criterio teórico (el que define quiénes son los promocionados, regulares y libres) 3.1.2 Variables nominales: tasas Se define habitualmente como tasa a la frecuencia relativa de un fenómeno en referencia a una población total, con la característica de tener en cuenta un período de tiempo. También es común el uso del término cuando se trata de hechos de poca incidencia, es decir que su frecuencia es pequeña. En esos casos se la suele expresar cada 1.000, cada 10.000, o inclusive cada 100.000 casos, en lugar de porciento. Por ejemplo, la tasa de desocupación en Argentina se define como la proporción de personas desocupadas, respecto del total de personas activas. Estas últimas son quienes tienen una ocupación o que sin tenerla la están buscando activamente. Está compuesta por la población ocupada más la población desocupada arrobaINDEC2018. Las tasas de mortalidad por causas, indican la proporción de muertes ocurridas en un período de tiempo (usualmente un año), en un espacio geográfico (país, provincia, etc) por una determinada causa, respecto del total de la población que vivía a la mitad de ese año. 3.1.3 Variables nominales: razones La palabra razones se usa a menudo para referirse a cocientes calculados entre conjuntos que no tienen elementos en común. Por ejemplo, se llama razón de masculinidad a la cantidad de hombres por cada 100 mujeres que hay en una población. Se obtiene dividiendo el total de varones por el total de mujeres (y luego multiplicando por 100), que son dos conjuntos que no se superponen. Esta medida se conoce también como índice de masculinidad. Según el censo de 2010, la siguiente es el distribución por sexos de la población de Argentina en ese momento: sexo personas prop.sexos varones 19523766 0.487 mujeres 20593330 0.513 Total 40117096 1.000 La proporción de varones es 48.7% y la de mujeres de 51.3%; se calculan respecto de la población total. La razón de feminidad se obtiene dividiendo el total de mujeres en el de varones y a la inversa para la de masculinidad. El cociente \\(\\frac{20593330}{19523766}*100\\), que es 105.5 indica que hay en la población 105 mujeres por cada 100 varones. La diferencia entre una razón y una tasa es que en la primera, el numerador no está incluido en el denominador. Las tasas a veces son llamadas ratio. 3.1.4 Variables nominales: el modo El modo, o moda, o valor modal es el valor de la variable (la categoría) que tiene la mayor frecuencia. Dicho de otra manera, el valor de la variable más frecuentemente observado10. Esta medida no requiere ningún cálculo, no exige ninguna propiedad de la escala de medición, por lo tanto se puede indicar en variables desde el nivel nominal, es decir en todos los niveles de medición. Por ejemplo, la variable carrera que cursa, tiene la siguiente distribución: carrera f f’ Educación 44 0.29 Psicología 48 0.32 Psicopedagogía 58 0.39 Total 150 1.00 El modo es Psicopedagogía, que es la categoría de mayor frecuencia. Debe cuidarse de no cometer el error de señalar la frecuencia 58 como el modo; el modo no es la frecuencia más alta, sino la categoría de la variable que tiene mayor frecuencia. Para hallarlo, se identifica la más alta de las frecuencias y se señala la categoría que le corresponde. Puede usarse la frecuencia absoluta o la relativa para determinar cuál es el modo de la distribución. La pregunta “¿Con cuál de las siguientes frases está Ud. más de acuerdo?” (P8STGBS), procedente de la base Latinobarómetro, tiene la siguiente distribución de frecuencias: P8STGBS f La democracia es preferible a cualquier otra forma de gobierno 10785 En algunas circunstancias, un gobierno autoritario puede ser preferible a uno democrático 2526 A la gente como uno, nos da lo mismo un régimen democrático que uno no democrático 5075 Allí, la categoría modal es la que privilegia a la democracia como sistema de gobierno. Si se trata de una variable de mayor nivel de medición, no hay ninguna diferencia. La variable concepto que los docentes asignan a los alumnos tiene la distribución de frecuencias siguiente: concepto f Excelente 150 Muy bueno 350 Bueno 200 Satisfactorio 120 No satisfactorio 50 Total 870 En este ejemplo, 350 es la frecuencia más alta, por lo tanto, la categoría que a ella corresponde es el modo: el modo de la distribución es “Muy bueno”. El modo es la categoría -o el valor- de la variable que tiene mayor frecuencia. Se indica \\(M_o\\). Cuando se trabaja sobre variables intervalares o proporcionales discretas no hay diferencia en la identificación del modo de la distribución. El número de materias que tienen aprobadas alumnos que han terminado de cursar el primer año de su carrera se distribuye así: Cantidad de materias aprobadas f 0 30 1 150 2 200 3 300 4 250 5 200 6 20 Total 1150 En esta distribución, el modo es 3 materias aprobadas (\\(M_o = 3\\)), que es la categoría que tiene mayor frecuencia. Expresamos esto como “la mayor cantidad de alumnos que terminaron de cursar primer año han aprobado tres materias”. Puede suceder que en una distribución no haya una única categoría de mayor frecuencia, sino que dos o más compartan la mayor frecuencia. Para 160 alumnos clasificados según la facultad en que cursan su carrera, tenemos: Facultad a la que pertenece f Arquitectura 50 Ingeniería 40 Psicología 50 Sociales 20 Total 160 Vemos aquí que hay dos categorías que presentan la mayor frecuencia: Arquitectura y Psicología. Decimos en este caso que la distribución es bimodal que quiere decir que tiene dos modos. Una distribución es bimodal cuando dos categorías tienen la mayor frecuencia. Si son más las categorías que comparten la mayor frecuencia, la distribución se denomina multimodal. Una representación gráfica de una distribución bimodal, para la variable número de respuestas correctas en una prueba de opción múltiple, la siguiente: Como modo en 6 y 9 aciertos, por eso se llama bimodal. La moda tiene el inconveniente de ser independiente de la mayor parte de los datos, por lo que es sensible a cambios en los valores de la distribución. En efecto, las siguientes dos muestras de 130 escuelas tienen la misma moda (\\(M_o = Pública\\)), aunque son muy dispares: Gestión de la escuela f Gestión de la escuela f Pública 50 Pública 100 Privada laica 45 Privada laica 20 Privada confesional 35 Privada confesional 10 Total 130 Total 130 3.1.5 Variables ordinales: percentiles Como ya hemos visto, cuando las categorías de la variable están ordenadas pueden hacerse juicios como “mayor que” (\\(&gt;\\)) o “menor que” (\\(&lt;\\)), y el nivel de medición es ordinal. En este tipo de variables puede calcularse un conjunto de medidas de posición, que usan esa propiedad: la del orden entre categorías. Se trata de los percentiles, que se podrán también calcular para escalas superiores (intervalar y proporcional) pero no para escalas nominales, en las que el orden entre categorías no está presente. Los percentiles usan las frecuencias relativas acumuladas, por eso solo existen para variables de nivel superior al nominal. Veamos la presentación por medio de un ejemplo, con la tabla siguiente que tiene calculadas las frecuencias acumuladas y se muestran solo ellas: edad F’ 17 0.00 18 0.07 19 0.16 20 0.26 21 0.36 22 0.46 23 0.55 24 0.61 25 0.68 26 0.73 27 0.77 28 0.80 29 0.83 30 0.85 31 0.87 32 0.89 33 0.91 34 0.92 35 0.93 36 0.94 37 0.95 38 0.95 39 0.96 40 0.96 41 0.97 42 0.97 43 0.98 44 0.98 45 0.98 46 0.99 47 0.99 48 0.99 49 0.99 50 0.99 51 1.00 52 1.00 53 1.00 54 1.00 La frecuencia acumulada 0.26 indica que el 26% de los estudiantes tiene 20 años o menos. Se dice que el valor 20 años es el percentil 26 y se indica \\(P_{26}\\). El “percentil” en sí mismo no es una medida descriptiva, para que lo sea se debe especificar qué percentil es el que se calcula. En este ejemplo, cada frecuencia acumulada conduce a un percentil particular. El percentil 68 de la variable es 25 años, y se escribe \\(P_{68} = 25\\) años. Estas medidas se definen como el valor de la variable que deja por debajo un determinado porcentaje de observaciones. Los percentiles tienen utilidad como medidas resumen cuando hay un volumen importante de observaciones, de lo contrario, es preferible mostrar la serie de datos. Su aplicación es que permiten describir cada valor de la variable de manera relativa al conjunto completo. Si la nota de un individuo corresponde al percentil 95, se sabe que es una nota alta, porque el 95% de todos los sujetos tiene una nota com esa o inferior. Eso puede expresarse diferente como: solo el 5% del conjunto tiene nota superior a la de él. A continuación veremos algunos medidas que se definen del mismo modo que los percentiles; en base a las frecuencias relativas acumuladas. 3.1.6 Variables ordinales: la mediana La mediana es el percentil 50, es decir que se define como el valor de la variable que deja por debajo la mitad del total de observaciones. Es importante tener en cuenta que se trata de la mitad de los casos y no la mitad de las categorías. La siguiente distribución presenta en serie simple ordenada el número de sesiones de psicoterapia que recibieron 9 pacientes internados en un hospital: \\[2, 2, 3, 5, 7, 10, 15, 19, 50\\] La mediana de estos datos es 7, porque es el valor que deja cuatro casos por debajo y también cuatro casos por encima. Atención a que la serie simple debe estar ordenada para poder identificar a la mediana. Si la cantidad de observaciones fuera par como por ejemplo: \\[2, 2, 3, 5, 7, 10, 15, 19\\] El punto de corte correspondiente a la mitad de las observaciones se ubica entre 5 y 7, en este caso, la mediana es el promedio entre los dos valores centrales, que es 6. Cuando hay valores repetidos en la parte central no resulta posible indicar la mediana, por ejemplo si la serie fuera: \\[2, 3, 7, 7, 7, 10, 15, 19\\] No puede señalarse a 7 como la mediana, porque es superado por tres valores (10, 15 y 19) pero supera solo a dos (2 y 3). La mediana es una medida muy adecuada cuando se necesitan resumir datos que provienen de escalas ordinales o de nivel superior. Sin embargo, su cálculo no aporta nada en series simples con pocos casos (como los que acabamos de ver) ya que allí es más sencillo mostrar el conjunto completo de datos y no usar medidas resumen. Los ejemplos sirven para ilustrar el concepto, pero no se usa en la práctica. Las operaciones de resumen se justifican cuando se tiene un conjunto grande de datos. Se denomina mediana al valor de la variable que deja por debajo a la mitad de las observaciones. La mediana deja la misma cantidad de casos por debajo y por encima de ella. Se indica \\(M_{dn}\\). Veamos la forma de reconocer a la mediana cuando los datos están presentados en una distribución de frecuencias. La siguiente es una clasificación de hogares por nivel socioeconómico: Nivel socioeconómico f (número de hogares) F Marginal 40 40 Bajo 100 140 Medio-bajo 120 260 Medio 150 410 Alto 30 440 Total 440 El valor de la variable que acumula el 50% de los casos, es el que ocupa el lugar 220, que es mitad de los 440 casos del total. La serie ordenada de esta distribución, coloca a los 40 hogares marginales en lso primeros 40 lugares, pero indistintamente, porque no hay orden entre los hogares al interior de la categoría. Según la tabla, hasta la categoría “medio-bajo” se acumulan 260 hogares y hasta la categoría anterior hay 140 acumulados. De manera que el hogar que ocupa el lugar 220 (de la serie ordenada) es uno de los que se encuentran en la categoría “medio-bajo”. Diremos así que la mediana de esta distribución es “medio-bajo”. Como puede verse, esta categoría no acumula exactamente la mitad de las observaciones, pero es la que contiene a la observación que supera a la mitad y es superada por la otra mitad. Por esa razón la leemos como la mediana, diciendo que la mitad de los hogares tiene un nivel socioeconómico medio-bajo o inferior a ese. Decir que el que acumula 220 casos es “uno de los hogares de la categoría medio-bajo” es impreciso, porque todos los hogares son equivalentes en su nivel socioeconómico al interior de la categoría. Esta imprecisión también aparece si se trata de una variable cuantitativa discreta. Si la variable es el número de síntomas a partir de los cuales fueron diagnosticados de esquizofrenia un conjunto de pacientes11: Cantidad de síntomas f (número de pacientes) F 2 30 30 3 60 90 4 70 160 5 90 250 Total 250 La mitad del número total de casos es de 125 (\\(250/2\\) ó \\((1/2)*250\\)), ¿cuál es el caso que ocupa ese lugar? Vemos que hasta 3 síntomas se acumulan 90 pacientes y 160 hasta los 4. El paciente que ocupa el puesto 125 en la serie simple ordenada es uno de los que fueron diagnosticados a partir de 4 síntomas. Por esa razón indicamos a la mediana con ese valor: 4, \\(M_{dn} = 4\\). Nuevamente encontramos que no es exactamente el valor que acumula la mitad, sino uno de los que están en la categoría dentro de la cual se acumula la mitad de los casos. La primera categoría que tenga una frecuencia acumulada superior al 50% será la que contenga a la mediana. Es así porque la clase anterior no alcanza a acumular la mitad de las observaciones. La lectura del resultado es que la mitad de los pacientes fue diagnosticada de esquizofrenia en presencia de cuatro síntomas o menos. Sea la variable número de materias aprobadas: Número de materias aprobadas f F 0 30 30 1 150 180 2 200 380 3 300 680 4 250 930 5 200 1130 6 20 1150 Total 1150 La mitad de 1150 es 575, la primera frecuencia acumulada que supera a 575 es 680, que corresponde al valor 3. La mediana de esta distribución es entonces tres materias aprobadas y diremos que el 50% de los alumnos aprobó tres materias o menos. Cuando se trata de variables de nivel intervalar o proporcional y con categorías agrupadas, el cálculo anterior puede refinarse. Así, primero se identifica la categoría (el intervalo) en que se encuentra la mediana, igual que en los dos ejemplos anteriores y luego se interpola dentro del intervalo para encontrar su valor exacto. Tiempo de reacción (en segundos) f F 1.0 - 1.5 5 5 1.5 - 2.0 7 12 2.0 - 2.5 6 18 2.5 - 3.0 3 21 3.0 - 3.5 8 29 3.5 - 4.0 5 34 Total 34 La mitad de las 34 observaciones es 17, por lo que debe encontrarse una observación que tenga frecuencia acumulada de 17. Ese valor no aparece en la F, el primero que lo supera es 18, entonces la mediana estará en el intervalo 2,0-2,5. Esto es así porque hasta 2,0 se acumulan 12 casos (la F de la categoría anterior) y hasta 2,5 se acumulan 18. Nuestros 17 casos se acumulan para un valor de la variable que está entre 2,0 y 2,5. Debemos ahora encontrar qué valor exactamente es la mediana, dentro del intervalo 2,0-2,5. La fórmula para este procedimiento es la siguiente: \\[M_{dn} = l_{i} + i*\\left( \\frac{\\frac{n}{2} - F_d}{f_{p}} \\right)\\] En la que: \\(l_i\\) indica el límite inferior del intervalo en que se encuentra la mediana, en este caso es 80. \\(i\\) es la amplitud del intervalo, es decir la diferencia entre los límites \\(2.0-2.5 = 0.5\\). \\(\\frac{n}{2}\\) es la mitad del número total de observaciones, es este caso, 17. \\(F_d\\) es la frecuencia acumulada por debajo de la categoría que contiene la mediana, en esta tabla es 12. \\(f_p\\) es la frecuencia propia del intervalo en que se encuentra la mediana. Es la frecuencia absoluta (no la acumulada), en este ejemplo es 6. Reemplazando resulta: \\[M_{dn} = 2.0 + 0.5*\\left( \\frac{17 - 12}{6} \\right) = 2.0 + 0.5*\\left( \\frac{5}{6} \\right) = 2.42\\] Conviene detenerse en el orden en que se realizaron las operaciones. El signo más (+) separa términos, por lo que debe primero resolverse el segundo de ellos y luego recién sumar 2.0. Un error frecuente es el de sumar \\(2.0 + 0.5\\) y luego multiplicar por el resultado del paréntesis, eso es incorrecto. Por cierto que debe verificarse que el valor encontrado se ubique dentro del intervalo; en este ejemplo, la mediana no podría ser menor que 2.0 ni mayor que 2.5. Observemos también que el número de categorías de la variable, que es de 6, no participa en el cálculo de la mediana, de ningún modo se trata de una categoría que esté “al medio”. El resultado obtenido nos dice, según la definición de la mediana que “el 50% de los sujetos experimentales reaccionó en un tiempo de 2.42 segundos o inferior”. Es muy importante la última parte de la lectura, porque cuando decimos “o inferior” incluimos los valores por debajo del indicado. De lo contrario, si se omite “o menos” se estaría diciendo que la mitad de los sujetos tardó exactamente 2.42 segundos. La mediana encontrada, de 2.42, es un valor razonable a partir de la observación de la tabla: la categoría de la mediana acumulaba 18 casos, que es apenas más que la mitad de las observaciones (17), por lo que era de esperar que la mediana apareciera cerca del límite superior del intervalo, que es lo que sucedió. Este procedimiento para calcular la mediana es imperfecto, porque supone que los valores están distribuidos de manera uniforme dentro de cada intervalo. Si los 6 valores que contiene el intervalo 2.0 – 2.5, fueran todos iguales a 2.01, por ejemplo, la mediana sería un número bastante menor al que se calculó con este método. El uso de la interpolación solo se justifica en situaciones en que la única información disponible es la tabla con los valores agrupados; por el contrario, si se cuenta con la matriz de datos, el cálculo debe hacerse usando todos los valores observados de la variable. Como esto es largo para hacer manualmente, se solicita a un software especializado. Variables métricas: la media o promedio Si se ha alcanzado un nivel de medición intervalar o proporcional, es posible hacer uso de las propiedades12 que estas escalas tienen. Recordemos que además de designar y ordenar, las escalas intervalares conservan las distancias entre observaciones, y las proporcionales agregan la proporcionalidad de los valores absolutos y el carácter absoluto del cero. En este nivel los números que representan las categorías (o valores) pueden tratarse como tales y se puede operar con ellos. Antes de dar una definición de la media o promedio, veamos la idea intuitiva que tenemos, ya que se trata de una medida de mucho uso. Cuando queremos calcular un promedio “sumamos y dividimos por la cantidad de casos”. Así, si tres personas cometen 5, 8 y 12 errores cada uno, el promedio de esa variable (número de errores) es \\(\\frac{5 + 8 + 12}{3} = \\frac{25}{3} = 8.33\\). Usaremos la expresión \\(\\overline{x}\\) para referirnos a la media, con lo que el resultado se escribe: \\(\\overline{x} = 8.33\\) errores. ¿Cómo extenderemos esta forma de cálculo al caso en que la variable no está presentada en serie simple sino en distribución de frecuencias? Recordando que la frecuencia indica la cantidad de veces que cada valor se repite, por lo que habrá que considerar cada valor tantas veces como lo indique su frecuencia absoluta simple. Veamos un ejemplo en el que se cuenta el número de materias aprobadas: Número de materias aprobadas f 0 30 1 150 2 200 3 300 4 250 5 200 6 20 Total 1150 El valor 0 (cero) está repetido 30 veces, lo que indica que hay 30 alumnos que no han aprobado aún ninguna materia. Del mismo modo, 150 alumnos aprobaron 1 materia, etc., por lo que si estuvieran presentados en serie simple, se sumarían los 1150 valores (30 veces el 0, 150 veces el 1, etc.) y esa suma se dividiría por 1150. Para hacerlo sobre la distribución de frecuencia, se multiplica cada valor de la variable por su frecuencia (que es equivalente a sumarlo tantas veces como aparece) y se divide por el total de casos. Resulta: \\[\\overline{x} = \\frac{0*30 + 1*150 + 2*200 + 3*300 + 4*250 + 5*200 + 6*20}{1150} = 3.10\\] La expresión formal de este cálculo es: \\[\\overline{x} = \\frac{\\sum_{i = 1}^{k}{x_{i}*f_{i}}}{n}\\] En la que \\(x_i\\) es cada valor de la variable, \\(f_i\\) es su frecuencia absoluta simple, \\(k\\) es el número de categorías y \\(n\\) es el total de observaciones. La fórmula indica que cada valor de la variable (\\(x_i\\)) se multiplica por su frecuencia (\\(f_i\\)), se suman desde el primero (\\(i=1\\)) hasta el último (\\(k\\)) y el resultado se divide por el total de casos (\\(n\\)). Veamos que no se trató como podríamos haber pensado rápidamente, de sumar desde el cero hasta el seis y dividir por siete. Haber hecho eso habría implicado dos errores: el primero es el de no considerar cuántas veces está repetido cada valor (su frecuencia absoluta simple), el segundo es el de confundir el número de casos (1150) con el número de categorías (7). Este último error puede provenir de una confusión entre la presentación en serie simple o en distribución de frecuencias. Cuando se observa una serie simple, los valores “sueltos” de la variable coinciden con sus categorías, pero cuando se agrupa, cada categoría incluye cierta cantidad de casos que tienen el mismo valor, lo cual está indicado en la frecuencia de cada categoría. En el ejemplo anterior entonces, el número promedio de materias aprobadas es 3.10. Este número no es entero y no es un valor que se pueda observar; nadie tiene 3.10 materias aprobadas. Sin embargo, es valioso para caracterizar a la distribución completa y para hacer comparaciones. Por ejemplo, si en un grupo de alumnos la media es de 3,10 materias aprobadas y en otro de 3.90; puede decirse que en el segundo grupo los alumnos han aprobado -en promedio-, más materias; aunque ninguno haya aprobado 3.10 ni 3.90 materias. Por el momento ofreceremos una definición operacional de la media, más adelante podrá darse una definición conceptual, basada en sus propiedades. La media (o promedio) es un valor de la variable obtenido sumando todas las observaciones multiplicadas por su frecuencia absoluta y dividiendo el resultado en el número total de casos. Se indica como \\(\\overline{x}\\) (equis media). Cuando la distribución de frecuencias presenta los datos agrupados, aparece el problema de no tener un único valor en cada categoría. Por ejemplo y nuevamente en el caso de los tiempos de reacción: Tiempo de reacción (en segundos) f 1.0 - 1.5 5 1.5 - 2.0 7 2.0 - 2.5 6 2.5 - 3.0 3 3.0 - 3.5 8 3.5 - 4.0 5 Total 34 Aquí no hay un valor único en cada categoría, sino un intervalo que incluye diferentes valores. Esto se resuelve considerando, para cada intervalo, su marca de clase (el punto medio), que es el promedio de los extremos de cada intervalo. La siguiente tabla agrega las marcas de clase de cada intervalo, indicadas como \\(x&#39;\\): Tiempo de reacción (en segundos) x’ f 1.0 - 1.5 1.25 5 1.5 - 2.0 1.75 7 2.0 - 2.5 2.25 6 2.5 - 3.0 2.75 3 3.0 - 3.5 3.25 8 3.5 - 4.0 3.75 5 Total 34 Ahora puede usarse el método anterior para calcular la media, tomando las marcas de clase como los valores de la variable: \\[\\overline{x} = \\frac{1.25*5 + 1.75*7 + 2.25*6 + 2.75*3 + 3.25*8 + 3.75*5}{34} = 2.5\\] Resulta así que el tiempo promedio de reacción es de 2.5 segundos. Este procedimiento es impreciso, porque asigna a todos los casos que están dentro de cada categoría el mismo valor (el centro del intervalo) y se justifica en situaciones en que la única información disponible es la tabla con los valores agrupados; si se cuenta con la matriz de datos, el cálculo debe hacerse usando todos los valores observados de la variable, recurriendo a un software especializado cuando sean muchos datos. Si bien la media es una medida muy valiosa para resumir un conjunto de datos, a veces se hace un uso abusivo de ella, al aplicarla a variables que no tienen el nivel de medición adecuado para autorizar su uso. Un ejemplo de esto es el caso de las calificaciones escolares, que solo permiten ordenar a los alumnos según los resultados, pero que no implican la proporcionalidad de los valores (quien obtiene 10 no sabe el doble que quien obtiene 5). Aun así, es habitual que se calcule incorrectamente el “promedio de las notas”. 3.1.7 Los cuartiles Si la variable tiene un nivel de medición ordinal o superior, entonces podemos usar el mismo razonamiento con el que definimos la mediana para hacer cortes más finos en una distribución de frecuencia. Así, si la mediana nos indica el valor de la variable que deja por debajo la mitad de los casos, es lícito preguntar también por el valor que deja por debajo un cuarto de los casos, o también el que deja por debajo las tres cuartas partes de las observaciones. Estos puntos de corte se denominan respectivamente: primer cuartil y tercer cuartil. El primer cuartil es el valor de la variable que deja por debajo un cuarto, o el 25% del total de observaciones. El tercer cuartil es el valor que deja por debajo las tres cuartas partes o el 75% del total de observaciones. Como se ve, tanto el modo de cálculo como la interpretación son análogos a la mediana. Veamos su aplicación a los ejemplos anteriores: Número de materias aprobadas f F 0 30 30 1 150 180 2 200 380 3 300 680 4 250 930 5 200 1130 6 20 1150 Total 1150 Para encontrar el primer cuartil será ahora necesario buscar un cuarto del total de casos: 287.5 (\\(\\frac{1}{4}*1150\\)). La pregunta ahora es ¿cuál es la primera frecuencia acumulada que supera a 287.5? se trata de 380, que corresponde al valor 2 y éste es entonces el primer cuartil. Leemos así que un cuarto del total de alumnos tiene dos materias aprobadas o menos. También puede decirse que el 25% de los alumnos aprobó dos materias o menos. Si se toma la cantidad de materias aprobadas como un indicador del ritmo más rápido o más lento de avance en la carrera, aquí se lee que el 25% que avanza con más lentitud no llegó a aprobar tres materias El primer cuartil es el valor de la variable que deja un cuarto (25%) de los casos por debajo y tres cuartos (75%) por encima. Se indica \\(Q_1\\). Idéntico razonamiento seguimos para calcular el tercer cuartil: las tres cuartas partes del total es 862.5 (\\(\\frac{3}{4}*1150\\)). Buscamos luego la primera frecuencia acumulada que supera a ese valor y hallamos que es 930 y que su categoría correspondiente es 4. Entonces el tercer cuartil es 4 materias aprobadas. La lectura será: las tres cuartas partes (o el 75%) de los alumnos aprobó cuatro materias o menos. Esto último implica que el 25% restante aprobó más de cuatro materias. Así, el grupo que avanza más rápido en la carrera aprobó más de cuatro materias en su primer año. El tercer cuartil es el valor de la variable que deja tres cuartos (75%) de los casos por debajo y un cuarto (25%) por encima. Se indica \\(Q_3\\). Cuando se trata de distribuciones con categorías agrupadas, procedemos como antes con una leve modificación en la fórmula: Tiempo de reacción (en segundos) f F 1.0 - 1.5 5 5 1.5 - 2.0 7 12 2.0 - 2.5 6 18 2.5 - 3.0 3 21 3.0 - 3.5 8 29 3.5 - 4.0 5 34 Total 34 Para el primer cuartil debe hallarse la primera frecuencia que supera a un cuarto de las observaciones, de las 34, un cuarto es 8.5 y la primera frecuencia mayor que ese número es 12, por lo que el primer cuartil se encuentra en la categoría 1.5-2.0. Para interpolar en valor exacto usamos una expresión equivalente a la de la mediana: \\[Q_{1} = l_{i} + i*\\left( \\frac{\\frac{n}{4} - f_{d}}{f_{p}} \\right)\\] En la que se cambia \\(\\frac{n}{2}\\) por \\(\\frac{n}{4}\\) y lo demás mantiene el mismo significado. Aplicándola a estos datos resulta: \\[Q_{1} = 1.5 + 0.5*\\left( \\frac{8.5 - 5}{7} \\right) = 1.5 + 0.5*\\left( 0.5 \\right) = 1.75\\] Leemos en resultado como: el 25% de los sujetos reaccionó en un tiempo de 1.75s o menos. Para el tercer cuartil la fórmula se transforma en: \\[Q_{3} = l_{i} + i*\\left( \\frac{\\frac{3*n}{4} - f_{d}}{f_{p}} \\right)\\] Cuyo cambio consiste en que va \\(\\frac{3*n}{4}\\) en lugar de \\(\\frac{n}{4}\\) y manteniendo el resto de los símbolos con el mismo significado. Usando esta expresión, verifique el lector que para la distribución de los tiempos de reacción, el tercer cuartil es 3.28. No hemos hecho mención a un “segundo cuartil”, que sería el valor de la variable que acumula las dos cuartas partes de los casos, pero como las dos cuartas partes es la mitad, se trata simplemente de la mediana \\(Q_{2} = M_{dn}\\). 3.1.8 Los percentiles Por el mismo camino pueden definirse cortes en otros puntos de la distribución, los más frecuentemente usados, por su generalidad, se conocen como percentiles. Se trata de valores de la variable que dejan por debajo (acumulan) distintos porcentajes de casos. El percentil \\(r\\) de una distribución es el valor de la variable que deja el \\(r\\) por ciento de los casos por debajo de él y \\((1-r)\\) por ciento de los casos por encima. Se indica \\(P_r\\). Así por ejemplo, el percentil 10 (indicado como \\(P_{10}\\)) es el valor de la variable que acumula el 10% de las observaciones. Se representa de modo general un percentil dado como \\(P_r\\) en el que \\(r\\) indica el porcentaje del que se trata. La expresión para el cálculo de cualquier percentil es: \\[P_{r} = l_{i} + i*\\left( \\frac{\\frac{r}{100}*n - f_{d}}{f_{p}} \\right)\\] Son fáciles de observar las siguientes equivalencias: \\[Q_{1} = P_{25}\\] \\[M_{dn} = P_{50}\\] \\[Q_{3} = P_{75}\\] También suelen mencionarse, en algunas publicaciones, otros puntos de corte, como por ejemplo los quintiles, muy comunes para establecer cortes en los niveles de ingreso. Esta medida representa valores que acumulan quintos (20%) de la distribución. La equivalencia es la siguiente: Quintil: Equivale a: Primero \\(P_{20}\\) Segundo \\(P_{40}\\) Tercero \\(P_{60}\\) Cuarto \\(P_{80}\\) Así, el primer quintil de ingresos representa el valor de ingreso que deja por debajo al 20% de menores ingresos, Para los cálculos con la fórmula de interpolación se reemplaza el \\(\\frac{n}{2}\\) de la mediana por \\(\\frac{r}{100}\\) para el percentil \\(r\\). Esta manera de calcular los percentiles tiene la misma limitación mencionada para la mediana. Resulta entonces que la mediana, los muartiles y los quintiles son solo casos particulares de un conjunto de medidas general: los percentiles. Esta medidas tienen en cuenta el orden de las categorías y se calculan en base a lafrecuencia acumulada (absoluta o relativa). Por el contrario, la media tiene en cuenta los valores de la variable y las frecuencias simples (absolutas o relativas). Para ser precisos, debe decirse que los percentiles son también casos particulares, de los llamados cuantiles, que son valores de la variable que acumulan una proporciónn dada de la distribucion. La particularidad de los percentiles es que hacen los cortes en 100. No existe por ejemplo, el percentil 22.5, solo el 22 o el 23; el valor que acumula 22.5% de los casos se llama cuantil .225. Debido a que no usamos cortes tan precisos, nos quedaremos con los percentiles como los más finos. 3.1.8.1 Obtención gráfica de los percentiles Todas las medidas que hacen uso de las frecuencias acumuladas (mediana, cuartiles, quintiles, percentiles) pueden obtenerse de manera aproximada a través del gráfico de frecuencias acumuladas, la ojiva de Galton. Veamos el recorte de los niveles de ingresos salariales en cinco grupos, por medio de los quintiles: Los quintiles de esta distribución son los siguientes: \\(P_{20} =\\) 7000 \\(P_{40} =\\) 12000 \\(P_{60} =\\) 16000 \\(P_{80} =\\) 21000 Y representan valores de ingreso salarial que contienen un qunito de los asalariados cada uno. 3.1.9 Hacerlo en R Los nombres de las medidas descriptivas en R están en inglés, por lo que hay que recordarlas. Para el caso de la variable ingreso salarial (PP08D1 en los microdatos de la EPH), hemos generado una base nueva que solo contiene personas que trabajan como obreros o empleados (son asalariados), sobre ella, las medidas de posición se piden así: attach(eph.3.18.asal) length(PP08D1) # cantidad de casos (n) ## [1] 13410 mean(PP08D1) # la media ## [1] 14586.19 median(PP08D1) # la mediana ## [1] 15000 Para los percentiles, se debe especificar cuál o cuáles cuantiles se piden: quantile(PP08D1, .2) # percentil 20 ## 20% ## 7000 quantile(PP08D1, .05) # percentil 5 ## 5% ## 3000 quantile(PP08D1, .95) # percentil 95 ## 95% ## 30000 quantile(PP08D1, .5) # percentil 50, coincide con la mediana ## 50% ## 15000 Si se necesitan varios juntos, por ejemplo los quintiles, se usa el comando c, para “concatenar” los valores: quantile(PP08D1, c(.2, .4, .6, .8)) ## 20% 40% 60% 80% ## 7000 12000 16000 21000 Esta descripción de los datos se lee: En la muestra de 13410 personas que trabajan como obreros o empleados, el salario promedio es de 14586.19. El 50% tiene salario de 15000, el 20% de más bajos salarios está de 7000 para abajo y el 5% de los menores salarios son de 3000 o menos. El 95% tiene salario de 30000 o menos; que es lo mismo que decir que el 5% de los salarios superan los 30000. Para realizar la categorización con los tres criterios vistos antes, se cuenta en R con la función cut que se aplica sobre una variable cuantitativa y se controla la cantidad de intervalos y la forma de construirlos en el argumento “breaks”. Por ejemlo, para categorizar la edad de la base EPH en cuatro intervalos de igual amplitud, se indica ese número en el argumento. El resultado de esa categorización se guarda en una nueva variable a la que llamamos z y luego se solicita su distribución de frecuencia: z &lt;- cut(eph.3.18$CH06, breaks = 4) table(z) ## z ## (-0.101,25.2] (25.2,50.5] (50.5,75.8] (75.8,101] ## 23233 18769 12342 2535 El límite inferior del primer intervalo es negativo por la aplicación de una fórmula de cálculo de las amplitudes, cuando se edita para presentarla, ese número debe ser cero. La otra opción del argumento “breaks” es indicarle un vector con los límites de los intervalos que se desea. La categorización con criterio proporcional debe indicar que los puntos de corte sean los percentiles correspondientes a la cantidad requerida, para cuatro intervalos, se indica el mínimo de la variable como inicio, luego los cuartiles y termina en el máximo: t &lt;- cut(eph.3.18$CH06, breaks = c( min(eph.3.18$CH06), quantile(eph.3.18$CH06, .25), quantile(eph.3.18$CH06, .5), quantile(eph.3.18$CH06, .75), max(eph.3.18$CH06) )) table(t) ## t ## (0,16] (16,32] (32,52] (52,101] ## 13913 14280 14292 13673 Con estos cortes, los grupos tienen cantidades de casos similares. Si el criterio es teórico, se eligen los puntos de corte y se indican en “breaks”. Para hacer cuatro grupos de: hasta 14 años, de 15 a 44, de 45 a 64 y 65 o más, se solicita: u &lt;- cut(eph.3.18$CH06, breaks = c( min(eph.3.18$CH06), 14, 44, 64, max(eph.3.18$CH06) )) table(u) ## u ## (0,14] (14,44] (44,64] (64,101] ## 12052 25333 11780 6993 3.2 La forma de la distribución La media es una medida muy completa como resumen de los datos, ya que los considera a todos con la frecuencia de cada uno. Opera como un punto de equilibrio en un conjunto de datos. Sin embargo esto puede ser una dificultad en algunos tipos de distribución. Consideremos el siguiente ejemplo simple: x f 3 16 4 7 5 5 6 6 10 3 Total 37 Estos datos muestran una marcada concentración en el valor 3, donde se encuentra la mitad de las observaciones. El resto de los valores son superiores y hay uno extremo, el 10, que tiene poca frecuencia: hay solo tres observaciones con ese valor. Veamos cuál es el efecto de esta forma de distribuirse de los datos. La media es: ## [1] 4.51 \\[\\overline{x} = \\frac{3*16 + 4*7 + 5*5 + 6*6 + 10*3}{37} = 4.51\\] A pesar de la concentración en 3 que se observa, la media es superior a 4, que es un resultado contrario a lo que intuitivamente esperaríamos, porque habríamos supuesto que se ubicaría más cerca de 3, ya que 3 parece ser un valor muy “representativo” de esta distribución, sin embargo, la media da un número bastante más grande. Esto se debe a la presencia de valores extremos, en este ejemplo el 10. Aunque este número tiene poca frecuencia, su efecto es de “tirar de la media” hacia valores más grandes. Esto sucede siempre con la media y proviene de su característica de tener en cuenta todos los valores de la distribución. Por esa razón, cuando la distribución se presenta como la anterior, la media no es una buena medida de centralidad. Este inconveniente de la media aparece a menudo en las discusiones salariales por sectores. A menudo se escucha que no se justifica un aumento porque el salario promedio de todos los empleados del sector es de X pesos. Argumento al que se contrapone (expresado de diferentes maneras) que ese promedio incluye al personal que tiene salarios muy altos. Se trata de distribuciones asimétricas, que tienen la mayor parte de los casos con salarios bajos o intermedios y unos pocos casos con salarios muy superiores, por eso cuando se calcula la media se obtiene un resultado que representa mal al conjunto de datos. El histograma siguiente muestra la forma de la distribución anterior: En el gráfico se ve el carácter atípico del valor 10, que aparece muy alejado de la parte principal de la distribución. Decimos en este caso que la distribución es asimétrica. 3.2.1 Asimetría La asimetría de una distribución se indica señalando hacia dónde se sitúan los valores extremos. Si, como en este ejemplo, los valores extremos son mayores que la mayor parte de los datos, la asimetría es hacia la derecha. La asimetría puede ser en sentido opuesto, si hay observaciones particularmente pequeñas y en ese caso se tratará de una distribución asimétrica hacia la izquierda. Como en el ejemplo siguiente: X F 100 5 200 10 300 20 400 20 500 50 600 70 Total 175 Cuyo histograma es: Aquí los valores extremos se encuentran por debajo del grupo principal de datos y la media se inclinará hacia los valores más pequeños. Así, aunque la mayoría de los casos se encuentra entre 500 y 600, la media es: ## [1] 477.14 \\[\\overline{x} = \\frac{100*5 + 200*10 + 300*20 + 400*20 + 500*50 + 600*70}{175} = 477,14\\] Un resultado que está por debajo de esos valores que concentran muchos casos. Decimos ahora que la asimetría es hacia la izquierda. Los siguientes histogramas, son ejemplos de formas posibles en cuanto a simetría: La asimetría puede evaluarse directamente a partir de las medidas de centralidad, ya que la posición relativa de la media y la mediana indican hacia dónde ésta sucede. Cuando la media y la mediana coinciden, la distribución es simétrica, es decir carece de asimetría. Si la media supera a la mediana, se trata de una distribución asimétrica a la derecha y si la media es menor que la mediana, la asimetría será hacia la izquierda. En estas distribuciones las medias y medianas son: x1: media = 0.0095716, mediana = 0.0061682 x2: media = 10.3625202, mediana = 7.4364779 x3: media = 58.6815715, mediana = 61.7529703 Posición relativa de la media y la mediana: Asimetría de la Distribución: \\(\\overline{x} = M_{dn}\\) Simétrica \\(\\overline{x} &gt; M_{dn}\\) Asimétrica a la derecha \\(\\overline{x} &lt; M_{dn}\\) Asimétrica a la izquierda Una distribución es simétrica si la media coincide con la mediana. La distribución se llama asimétrica a la derecha si la media es mayor que la mediana, y asimétrica a la izquierda si la media es menor que la mediana. La evaluación cuantitativa de la asimetría de una distribución permite la comparación entre distribuciones en cuanto al grado de asimetría, para indicar cuando una distribución es más asimétrica que otra. Para hacerlo se usan los coeficientes de asimetría. Estos coeficientes miden dos aspectos de la asimetría: hacia qué lado sucede y cuán acentuada es. Su signo positivo indica asimetría hacia la derecha y negativo hacia la izquierda. El valor absoluto del coeficiente indica si es muy asimétrica o poco. Por ejemplo, una distribución cuya asimetría vale 1,5 es más asimétrica que una con coeficiente 1,2, y ambas son asimétricas hacia la derecha. Cuando la distribución es simétrica, el coeficiente vale cero, no es positivo ni negativo. Uno de los más frecuentemente usados es el coeficiente de asimetría de Fisher13, que se calcula como: \\[g_{1} = \\frac{\\sum_{i = 1}^{n}{\\left( x_{i} - \\overline{x} \\right)^{3}*f_{i}}}{n*s^{3}}\\] Y cuya interpretación es: \\(g_{1} = 0\\) La distribución es simétrica. \\(g_{1} &gt; 0\\) Asimétrica hacia la derecha. \\(g_{1} &lt; 0\\) Asimétrica hacia la izquierda. En la práctica, es improbable que el coeficiente valga exactamente cero, por lo que se considera simétrica a una distribución cuyo coeficiente esté entre -0,5 y 0,5. 3.2.2 Curtosis Además de la simetría, disponemos de otro indicador de la forma de la distribución, una medida de cuán “puntiaguda” es la curva, se denomina curtosis y distingue distribuciones con forma estrecha y elevada de que tienen forma amplia y baja. Como en los siguientes gráficos: Estos tres ejemplos corresponden a distribuciones simétricas, pero también pueden ser asimétricas. La curtosis se mide con un coeficiente específico, que vale cero para distribuciones mesocúrticas, es negativo para las platicúrticas y positivo para las leptocúrticas. Su cálculo es: \\[g_{2} = \\frac{\\sum_{i = 1}^{n}{\\left( x_{i} - \\overline{x} \\right)^{4}*f_{i}}}{n*s^{4}} - 3\\] Su interpretación es: \\(g_{2} = 0\\) La distribución es mesocúrtica \\(g_{2} &gt; 0\\) Leptocúrtica \\(g_{2} &lt; 0\\) Platicúrtica Con datos reales, muy raramente el valor será exactamente cero, por lo que se trata como mesocúrtica a una distribución cuyo coeficiente se encuentre entre -0,5 y 0,5. 3.3 Box-plots Un gráfico que puede resumir de manera muy compacta la información sobre una distribución de frecuencias es el que se llama diagrama de caja, o también diagrama de caja y bigotes o box-plot, que fue propuesto por John Tukey en 1977. Aplicado a las edades de estudiantes universitarios de la EPH genera: Este gráfico representa sobre el eje vertical los valores de la variable y muestra una “caja” delimitada por los cuartiles 1 y 3. Según la definición de los cuartiles, esa caja contiene al 50% central de los casos. Dentro de la caja se muestra la mediana en la línea horizontal. Se aprecia la concentración de casos en los valores bajos de la variable y unos pocos casos extremos que acusan la asimetría hacia la derecha de la distribución. El box-plot es adecuado para comparar grupos, en este ejemplo, se puede incluir la condición de actividad de los estudiantes y obtener: Se observa que, aunque en todos los grupos hay estudiantes con edades altas, los inactivos (que no trabajan ni buscan trabajo) son los que se concentran en la edades más bajas. Además de la caja, se ven dos segmentos que se extienden hasta los valores máximo y mínimo de la distribución. La longitud de estos segmentos (llamados a veces “bigotes”) depende de una caracteírística de la distribución que se trata en el apartado siguiente: la dispersión. 3.4 Medidas de dispersión Además de indicar alrededor de qué valores se distribuyen los datos,también es necesario indicar si se encuentran concentrados alrededor deesos valores (si son cercanos a ellos) o dispersos (si están alejados).Por ejemplo, un promedio de 20 sesiones de psicoterapia puede provenir de cuatro casos que utilizaron 18, 19, 21 y 22 sesiones o de otros cuatro que hayan insumido 5, 10, 30 y 35 sesiones. En la primer situación las cuatro observaciones son cercanas entre sí, están concentradas, mientras que en la segunda están lejos, dispersas. Diremos que en el primer caso la distribución es homogénea o que presenta poca dispersión y en el segundo que es heterogénea o que presenta mucha dispersión. Conocer esto tiene importancia para poder evaluar la calidad de las medidas de centralidad, en particular de la media. Esto es así porque en una distribución muy dispersa, la media será un promedio de valores muy diferentes entre sí y no será tan fiel a los datos como si estos valores fueran similares. La media de 20 sesiones del primer ejemplo es una mejor medida resumen que la misma media de 20 del segundo, porque la primera representa mejor los datos de origen. Debido a esto, decimos que en la primera de las situaciones del ejemplo, la media es más representativa de los datos de los que proviene. Nos ocuparemos ahora del modo en que puede medirse esa dispersión, cómo transformarla en una medida resumen que indique brevemente si los datos están dispersos o concentrados. 3.4.1 Recorrido Una primera aproximación al problema es la de considerar la distancia que hay entre los valores extremos, entre el más pequeño y el más grande. Si usamos este procedimiento en el ejemplo anterior vemos que en la primera distribución hay 4 unidades entre la primera y la última observación (de 18 a 22) y en la segunda hay 30 unidades de extremo a extremo (de 5 a 35). Por lo que ésta sería una medida de la dispersión. Esta medida se llama recorrido, se indica con la letra \\(R\\) y la expresión formal de su cálculo es: \\[R = x_{\\max} - x_{\\min}\\] Donde \\(x_{\\max}\\) y \\(x_{\\min}\\) representan a los valores máximo y mínimo respectivamente. En las distribuciones del ejemplo, los recorridos son \\(R=4\\) y \\(R=30\\) respectivamente, que resumen la mayor dispersión de la segunda. Se llama recorrido de una distribución a la diferencia entre los valores máximo y mínimo de la variable. Se indica \\(R\\). Cuando la distribución tiene más casos, el recorrido es insuficiente como medida de dispersión, ya que está determinado solo por los valores extremos. Por ejemplo, las dos siguientes series tienen la misma media, igual a 8: \\[2, 8, 8, 8, 8, 8, 14\\] 7, 8, 8, 8, 8, 8, 9 El recorrido vale 12 para la primera (\\(R=14–2\\)) y 2 para la segunda (\\(R=9–7\\)) es una diferencia muy acentuada aunque las dos distribuciones solo difieren en los valores extremos. Dicho de otra manera, si sucede que hay un caso (o unos pocos) que tiene un valor excepcionalmente alto (o bajo), el recorrido dará un valor alto, indicando gran dispersión, lo que nos puede hacer pensar que todos los datos están dispersos. Por esa razón se dice que es una medida “gruesa” de la variabilidad de los datos. 3.4.2 Amplitud intercuartílica Un modo de afinar la calidad de esta medida es la de tomar la distancia que hay, no ya entre los valores extremos, sino entre los cuartiles primero y tercero. La medida que usa esta distancia se llama amplitud intercuartílica y es simplemente la diferencia entre el tercer cuartil y el primero: \\[AIQ = Q_{3}{- Q}_{1}\\] Si bien tampoco es ésta una medida que considere todas las observaciones -ya que solo tiene en cuenta los dos cuartiles-, es mejor que el recorrido, porque deja de lado los valores extremos, aquellos que pertenecen al 25% más bajo y al 25% más alto de la distribución. La amplitud intercuartílica es la diferencia entre los cuartiles tercero y primero. Se indica \\(AIQ\\). Gráficamente, esta medida es la altura de la caja del Box-plot. Algunos autores prefieren informar como medida de dispersión a la mitad de la distancia entre los cuartiles 1 y 3, a la que se denomina semi recorrido intercuartilar, y se abrevia SRIC. No tiene diferencia conceptual con la AIQ, porque ambas consideran distancia entre cuartiles, solo difieren en la convención de informar la distancia completa (AIC) o su mitad (SRIC). El semi recorrido intercuartilar es la mitad de la amplitud intercuartílica. Se indica \\(SRIC\\). Que en el Box-plot representa al mitad de la altura de la caja. \\[SRIC = \\frac{Q_{3}{- Q}_{1}}{2}\\] 3.4.3 Medidas de dispersión basadas en la media Las medidas de variabilidad que más se usan son las que tienen en cuenta todas las observaciones, es decir aquellas que están basadas en la media. Una manera de ver si el conjunto de datos está concentrado o disperso, consiste en observar la distancia de la media a la que se encuentra cada observación, luego esas distancias individuales pueden promediarse y tener una idea global de qué tan lejos están los casos del promedio. Intentemos hacer eso y veamos qué limitación aparece. Tomemos un conjunto pequeño de datos, presentado en serie simple: \\[5, 7, 9, 11\\] La media es 8, como lo es la mediana. Aunque no hay modo, ya que todos los valores tienen frecuencia igual a uno, la distribución es simétrica. Hemos elegido así el ejemplo solo para darle simplicidad, no es una condición necesaria para lo que sigue. Consideremos las distancias desde cada observación hasta la media, restando a cada una de ellas el valor 8 (la media): \\(x_{i}\\) \\(x_{i} - \\overline{x}\\) 5 -3 7 -1 9 1 11 3 Las distancias positivas corresponden a valores superiores a la media y las negativas a los inferiores, si un valor acertara en la media, su distancia sería cero. Si sumamos todas las diferencias \\(x_{i} - \\overline{x}\\), el resultado es cero (\\(-3-1+1+3=0\\)); además, éstas son simétricas, como efecto de la forma de la distribución original. Pero el hecho que la suma sea cero no depende de la distribución, sino que es una propiedad de la media. Por ser la media un punto de equilibrio entre las observaciones, las que se distancian por encima de ella están compensadas por las que lo hacen por debajo14. Los valores \\(x_{i} - \\overline{x}\\) se llaman desvíos, que indican cuánto se aleja cada observación de la media. Como vemos pueden ser positivos o negativos según se trate de observaciones que superen a la media o que estén por debajo de ella. Acabamos de ver también que su suma vale cero, es decir que \\(\\sum_{i = 1}^{n}{\\left( x_{i} - \\overline{x} \\right) = 0}\\) y que esta es una cualidad de la media, que no depende de los datos15. La representación gráfica de esta propiedad puede verse pensando en una analogía física; como si cada caso graficado en el histograma fuese un bloque de ciert0, situado en el valor de la variable. Con esa idea, la ubicación de la media es el punto donde habria que apoyar el histograma para que éste quede en equilibrio: El punto (triángulo) del gráfico equivale al punto de apoyo que permite el equilibrio de ese “objeto”. Tan importante es esta propiedad que la usaremos para dar una definición más completa de la media: La media es el valor de la variable que anula la suma de los desvíos en torno suyo. El tema que nos ocupa en este momento, es el de medición de la variabilidad del conjunto de casos, y entonces, la consecuencia de esta propiedad es que no será posible usar la suma de los desvíos como indicador de dispersión, ya que da siempre cero, con datos homogéneos o heterogéneos. A fin de resolver este problema vamos a eliminar el signo, usando el hecho que todo número elevado a una potencia par es positivo, sin importar el signo que haya tenido el número. Elevaremos entonces al cuadrado cada una de los desvíos y así se perderá su signo y ya no será cero la suma de todos ellos. 3.4.4 Varianza Usando ese recurso, definimos la varianza16, a la que simbolizaremos como \\(V(x)\\) o más frecuentemente como \\(s^2\\) de la siguiente forma: \\[s^{2} = \\frac{\\sum_{i = 1}^{n}\\left( x_{i} - \\overline{x} \\right)^{2}}{n - 1}\\] Se llama varianza de una distribución a la suma de los cuadrados de los desvíos alrededor de la media, dividida por el total de observaciones menos uno. Se indica \\(s^2\\). Es una medida muy valiosa de la dispersión que tiene un conjunto de datos, cuanto mayor es, tanto más dispersos éstos se encuentran, es decir, son más heterogéneos. No puede ser negativa, porque es una suma de cuadrados y solo es cero si todos los desvíos son cero, es decir si todas las observaciones coinciden con la media17. Hay tres propiedades de la varianza que señalaremos porque serán necesarias más adelante: -La varianza de una constante es cero. Esto resulta claro ya que la varianza mide la dispersión y si todas las observaciones son iguales no hay dispersión: \\[V\\left( k \\right) = 0\\] -La varianza de una constante que multiplica a una variable es la constante elevada al cuadrado multiplicada por la varianza de la variable: \\[V\\left( k*x \\right) = k^{2}*V(x)\\] -La varianza de la suma de dos variables independientes es la suma de las varianzas de cada una de ellas: \\[V\\left( x + y \\right) = V\\left( x \\right) + V(y)\\] A los fines de la interpretación, la varianza presenta dos inconvenientes. Uno es que sus unidades están elevadas al cuadrado; por lo que, si medimos número de errores, la varianza quedará expresada en número de errores al cuadrado una entidad que no tiene significado, como tampoco lo tienen hijos al cuadrado para la fecundidad, pesos al cuadrado para ingresos o segundos al cuadrado para los tiempos de reacción. El otro inconveniente es que no tiene límite superior, puede ser muy grande y no tenemos con qué compararla para saber si indica una gran variabilidad o si es grande porque los valores de la variable lo son. 3.4.5 Desviación estándar Para resolver el primer inconveniente, definiremos una medida derivada de la varianza, que se denomina desviación estándar (en algunos textos y programas de análisis de datos es llamada desviación típica). Esta medida, indicada con la letra \\(s\\) es la raíz cuadrada de la varianza: \\[s = \\sqrt{\\frac{\\sum_{i = 1}^{n}\\left( x_{i} - \\overline{x} \\right)^{2}}{n - 1}}\\] O más simplemente: \\[s = \\sqrt{s^{2}}\\] La desviación estándar es la raíz cuadrada de la varianza. Se indica \\(s\\). Ahora, por el sencillo trámite de introducir una raíz cuadrada, las unidades de s son las mismas que las de la variable original y no hay problemas con la interpretación del valor. 3.4.6 Coeficiente de variación Para hacer frente al problema de la magnitud de la varianza y de la comparación de la dispersión entre medidas expresadas en diferentes unidades -que sigue siéndolo para la desviación estándar-, definimos una medida relativa de la dispersión: el coeficiente de variación, indicado como CV como el cociente entre la desviación estándar y la media: \\[CV=\\frac{s}{\\overline{x}}*100\\] Esta medida carece de unidades, porque la media tiene las mismas que las de la desviación estándar, por lo que se trata de una medida relativa de la dispersión. Indica la importancia relativa de la desviación estándar respecto de la media. El factor 100 que acompaña al cociente cumple la función de expresarlo como porcentaje, por comodidad para la lectura. El coeficiente de variación expresa de manera relativa la dispersión, midiendo el peso de la desviación estándar comparado con la media. Se indica \\(CV\\). Conocer la dispersión de una distribución de frecuencias es muy necesario para poder decidir si la media es una medida adecuada para resumir los datos, y esto no sucede si hay mucha dispersión. Para aclarar esto veamos un ejemplo: sea un grupo de seis alumnos que hacen una prueba y que obtienen las siguientes notas: 2, 2, 2, 2, 10, 10. Si calculamos la media obtenemos 4.6666667 4,7. Este número no representa lo que sucede con los seis alumnos, quienes tuvieron resultados muy dispares: cuatro de ellos obtuvieron 2 y los otros dos, 10. Si calculamos el CV, resultado es 88.5253336 100%, un valor muy elevado, indicativo que la media no es una medida adecuada para sintetizar al conjunto de datos. Muchas de las críticas mal fundadas hacia la Estadística se equivocan por ignorancia, porque calculan la media cuando no corresponde usarla. En la práctica se considera que si el coeficiente de variación es menor al 10% (algunas referencias ponen como límite al 15%), la distribución tiene poca dispersión y entonces podemos confiar en la media como medida de centralidad y tratarla como representativa de los datos que resume. Si el CV supera estos valores, la media no alcanza para resumir los datos y es necesario acompañarla de otras medidas, como la mediana, los cuartiles, el mínimo y máximo. Calcularemos por única vez las medidas de dispersión de manera manual para un pequeño conjunto de datos, a fin de seguir de cerca las operaciones que involucra. Se trata de seis pacientes diagnosticados de depresión a partir de cinco o más de los síntomas que indica el manual DSM IV18 y que para cada uno de ellos observamos (como variable) el número de síntomas que llevaron al diagnóstico: Paciente \\(x_{i}\\) (número de síntomas) \\(x_{i} - \\overline{x}\\) (desvíos) \\({{(x}_{i} - \\overline{x})}^{2}\\) (cuadrados de los desvíos) 1 5 -2 4 2 6 -1 1 3 6 -1 1 4 8 1 1 5 8 1 1 6 9 2 4 \\[\\overline{x} = \\frac{5 + 6 + 6 + 8 + 8 + 9}{6} = 7\\] \\[\\sum_{i = 1}^{6}{\\left( x_{i} - \\overline{x} \\right)^{2} = 4 + 1 + 1 + 1 + 1 + 4 = 12}\\] \\[s^{2} = \\frac{\\sum_{i = 1}^{6}\\left( x_{i} - \\overline{x} \\right)^{2}}{n - 1} = \\frac{12}{6 - 1} = 2,4\\] \\[s = \\sqrt{s^{2}} = \\sqrt{2,4} = 1,55\\] \\[CV = \\frac{s}{\\overline{x}}*100 = \\frac{1,55}{7}*100 = 22,13\\%\\] La lectura de este resultado es que para el conjunto de seis personas a las que se observa, el número promedio de síntomas a través de los cuales es diagnosticada la depresión es de siete. Sin embargo este número de síntomas es bastante variable según los pacientes y, seguramente también según los terapeutas. 3.4.7 Hacerlo en R La solicitud de estas medidas es directa en R, para la base de la aplicación del test de Bayley, los pesos al nacer tienen las siguientes medidas de dispersión: attach(bayley) R &lt;- max(peso.nac) - min(peso.nac) names(R) &lt;- &quot;R&quot; round(R, 2) ## R ## 3078.56 AIQ &lt;- quantile(peso.nac, .75) - quantile(peso.nac, .25) names(AIQ) &lt;- &quot;AIQ&quot; round(AIQ, 2) ## AIQ ## 660.82 SRIC &lt;- (quantile(peso.nac, .75) - quantile(peso.nac, .25)) / 2 names(SRIC) &lt;- &quot;SRIC&quot; round(SRIC, 2) ## SRIC ## 330.41 var &lt;- var(peso.nac) names(var) &lt;- &quot;s2&quot; round(var, 2) ## s2 ## 250641.9 s &lt;- sd(peso.nac) names(s) &lt;- &quot;s&quot; round(s, 2) ## s ## 500.64 CV &lt;- sd(peso.nac) / mean(peso.nac) * 100 names(CV) &lt;- &quot;CV&quot; round(CV, 2) ## CV ## 16.62 La medida relativa de la variabilidad (el \\(CV\\)) es adecuada para comparar variables que tienen diferentes unidades, por ejemplo para responder ¿qué es más variable, el peso o la estatura de los niños? Es decir, ¿en cuál de esas dos medidas se diferencian más? Las siguientes son las salidas descriptivas c( summary(peso.nac), s = sd(peso.nac), CV = sd(peso.nac) / mean(peso.nac) * 100 ) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1338.54612 2694.23792 2996.67572 3011.78179 3355.05345 4417.10653 ## s CV ## 500.64151 16.62277 c( summary(long.nac), s = sd(long.nac), CV = sd(long.nac) / mean(long.nac) * 100 ) ## Min. 1st Qu. Median Mean 3rd Qu. Max. s ## -8.69347 47.08004 72.12837 69.62115 89.98179 144.67646 31.50275 ## CV ## 45.24882 Se trata los 454 niños y niñas, evaluados en dos aspectos; su peso y su talla al naces, el primero en gramos y la segunda en centímetros. La comparación de las desviaciones estándar no da información sobre la diferente variabilidad, porque dependen de esas unidades de medida; una está expresada en gramos y la otra en centímetros. Por el contrario, los coeficientes de variación, (17% para el peso y 719% para la talla) indican que hay más diferencias entre entre las longitudes de los recién nacidos que entre los pesos al nacer. 3.4.8 Box-plots y dispersión La observación del diagrama de caja (box-plot) nos da también indicios acerca de la dispersión de la variable que se analiza. Cuando la caja es larga estamos en presencia de distribuciones muy dispersas en la parte central, los cuartiles están lejanos, hay mucha amplitud intercuartilar. Mientras que si la caja es corta, se trata de una concentración de datos de la parte central de la distribución. La longitud de los bigotes señala la mayor o menor concentración de los datos en las zonas extremas. Como dijimos antes, el box-plot es un gráfico que ayuda a explorar los datos, a hacerse una idea inicial de la distribución y esto puede ser muy valioso cuando se trata de interpretarlos, porque permite sugerir hipótesis que expliquen la distribución que se observa. Haciendo uso de la amplitud intercuartílica estableceremos criterios para detectar valores que destaquen por alejarse sustancialmente del grupo mayoritario. Se trata de mediciones atípicas o excepcionalmente extremas, porque sean excesivamente grandes o excesivamente pequeñas. La identificación de estos valores es importante en la etapa exploratoria de los datos porque obliga a mirarlos en detalle. Puede tratarse de un error de medición o bien de un sujeto (o unos pocos) que se aparta de manera excepcional del grupo y que merece un análisis más detallado y particularizado. Tukey (1977) analiza la distancia de los casos a los cuartiles y sugiere tratar como “lejanas” a las observaciones que se encuentren a más de una amplitud intercuartílica y media (\\(1.5*AIQ\\)) por debajo del primer cuartil o por encima del tercero, pero a menos de tres veces la amplitud intercuartílica (\\(3*AIQ\\)). Además, aquellas observaciones que estén más allá de tres AIQ por debajo del primer cuartil o por encima del tercero se denominan “muy lejanas”. Este criterio determina entonces zonas en las que pueden hallarse las observaciones y según en cuál de ellas se encuentren, se las identifica como “cercanas”, “lejanas” o “muy lejanas”. Las zonas son las siguientes: Cercanas: Entre \\(Q_1\\) y \\(Q_1-1.5*AIQ\\) o bien entre \\(Q_3\\) y \\(Q_3+1.5*AIQ\\) Lejanas: Entre \\(Q_1-1.5*AIQ\\) y \\(Q_1-3*AIQ\\) o entre \\(Q_3+1.5*AIQ\\) y \\(Q_3+3*AIQ\\) Muy lejanas: Menores que \\(Q_1-3*AIQ\\) o mayores que \\(Q_3+3*AIQ\\) La división en zonas puede verse más claramente en un box-plot. En ese gráfico se toma la distancia entre los cuartiles tercero y primero (la amplitud intercuartílica) como unidad de medida, luego se calcula una vez y media esa medida (\\(1.5*AIQ\\)) y tres veces esa medida (\\(3*AIQ\\)) como puntos de corte para decidir cuándo una observación se aleja excepcionalmente del grupo. Los segmentos del box plot se cortan si se alcanza el máximo de la distribución (hacia arriba) o el mínimo (hacia abajo). Así, los segmentos tienen una longitud que es o bien \\(1.5*AIQ\\) o bien la distancia hasta el máximo o mínimo. 3.4.9 Medida de la dispersión cuando no hay distancias Todo lo indicado hasta el momento acerca de la variabilidad ha necesitado de la medición de la distancia entre las observaciones: desde el comienzo hablamos de cercanía o lejanía entre los datos. Por lo tanto estas medidas, desde el recorrido hasta el coeficiente de variación, solo tienen sentido si la variable es de nivel intervalar o proporcional. Si la variable tiene nivel nominal u ordinal habrá que medir su variabilidad de otra forma. En estos casos cambia un poco el significado de la variabilidad, ya que estaremos en presencia de una variable más dispersa cuanto más equitativamente se distribuya el total de observaciones entre las distintas categorías. Por ejemplo, si 100 individuos son clasificados según cómo sea su rendimiento en: muy bueno, bueno, regular, insatisfactorio; la distribución tendrá más dispersión si 25 de ellos se encuentran en cada categoría que si la gran mayoría está en una sola. La distribución: Rendimiento f f’ Muy bueno 25 0.25 Bueno 25 0.25 Regular 25 0.25 Insatisfactorio 25 0.25 Total 100 1.00 Tiene más dispersión que esta otra: Rendimiento f f’ Muy bueno 5 0.05 Bueno 80 0.80 Regular 5 0.05 Insatisfactorio 10 0.10 Total 100 1.00 ¿Por qué? Porque en la segunda, los casos están muy concentrados en una categoría (bueno), mientras que en la primera se dispersan entre todas. Notemos que ahora habrá más dispersión cuanto más parecidas sean las frecuencias entre sí. Esto puede parecer contradictorio con lo indicado para variables cuantitativas, pero allí la mayor dispersión viene dada por la mayor disparidad entre los valores de las variables, que no puede evaluarse con variables nominales u ordinales. Esta forma de considerar la dispersión equivale a la idea de incertidumbre. Supongamos que conocemos que la distribución del rendimiento es como lo muestra la primera tabla y que debemos “adivinar” cuál es el rendimiento de una persona elegida al azar. No tenemos ninguna razón para creer de manera preferencial que la persona sea de rendimiento muy bueno, bueno, regular o insatisfactorio; ya que todos son igualmente posibles. En esta situación, la incertidumbre es completa. Por el contrario, si supiéramos que la distribución es la que muestra la segunda tabla, tenderíamos con justa razón a creer que hay más chances que la persona elegida al azar tenga rendimiento bueno, ya que es bastante más probable que pertenezca a esa categoría que a otra. Diremos que aquí tenemos menos incertidumbre. La medida para expresar de manera sintética esta dispersión es: \\[H\\left( x \\right) = - \\sum_{i = 1}^{k}{{f&#39;}_{i}^{}*log{f&#39;}_{i}^{}}\\] El cálculo consiste en multiplicar cada frecuencia relativa por su propio logaritmo y sumar para todas las categorías. El resultado de la sumatoria siempre es negativo, por lo que la fórmula incluye un signo menos para volverlo positivo. Este coeficiente expresa en un solo número la magnitud de la dispersión. Cuanto más pequeña sea esta medida, tanto menos dispersa (o más concentrada) será la distribución de la variable que se analiza. Aplicado a las dos tablas de más arriba resulta, para la primera: \\[H\\left( x \\right) = - (0.25*log0.25 + 0.25*log0.25 + 0.25*log0.25 + 0.25*log0.25) = - \\left( - 0.60 \\right) = 0.60\\] Y, para la segunda: \\[H\\left( x \\right) = - (0.05*log0.05 + 0.80*log0.80 + 0.05*log0.05 + 0.10*log0.10) = - \\left( - 0.31 \\right) = 0.31\\] Así, a la distribución en la que las frecuencias están más concentradas, es decir la que tiene menor dispersión, le corresponde un menor valor de \\(H(x)\\). Cuando la variable tiene solo dos categorías, la proporción de casos en una de ellas es el complemento a uno de la otra, si en una categoría la proporción es \\(p\\) en la otra será \\(1-p\\). La máxima concentración se da cuando todos los casos están en una sola categoría, \\(p=1\\) y \\(1-p=0\\), allí la dispersión vale cero, porque se trata de una constante: a todos los individuos les corresponde el mismo valor de la variable. La máxima dispersión sucede cuando la distribución entre las dos categorías es equitativa, es decir cuando la mitad de los casos está en cada una: \\(p=0.5\\) y \\(1-p=0.5\\). La medida de esta variabilidad también se llama varianza, pero su cálculo es muy diferente del caso de variables cuantitativas. Para una variable nominal de dos categorías (dicotómica), la varianza es: \\[s^2 = p*(1-p)\\] La desviación estándar es: \\[s=\\sqrt(p*(1-p))\\] Que alcanza su mínimo en cero cuando todos los casos están en una sola categoría y su máximo en .25 cuando se distribuyen mitad en cada una. 3.5 El individuo en relación a su grupo Un uso muy frecuente de las medidas que acabamos de ver es que permiten decidir si un valor particular está cerca o lejos del promedio, o bien si se sitúa o no en los extremos de una distribución. Un valor particular en este caso se refiere al valor de la variable en un caso, en un individuo, por ejemplo, el puntaje que un sujeto obtiene en una prueba, el ingreso de un hogar, la PBI per cápita de un país. Así formulado el problema puede parecer muy elemental, porque puede “verse” si un número está cerca o lejos de otro. Si sabemos que una persona tiene dos metros de estatura, no necesitamos hacer cuentas para saber que es alto, más alto que la mayoría de las personas. Sin embargo, en el caso de medidas menos familiares, a veces resulta difícil hacer juicios de distancia sobre valores absolutos. Si un país tiene PBI per cápita de U$S20000, hace falta conocer más datos para evaluarlo como alto o bajo, Si sabemos que en una prueba de memoria con un puntaje máximo de 100 puntos, una persona logró 80 puntos, ¿estamos autorizados para decir que obtuvo un puntaje alto? La respuesta es no, porque no sabemos qué puntajes obtuvieron las demás personas que hicieron la prueba. Si la media del grupo completo hubiese sido 60 puntos, entonces 80 sería un valor elevado, pero si la media hubiese sido de 85, entonces el caso que estamos considerando se encontraría por debajo del promedio. Más aún, si el promedio fuese 60 y la mayoría de los evaluados hubiese obtenido puntajes cercanos a 60 (poca variabilidad), entonces el valor 80 podría considerarse como muy elevado. Solo conocer su puntaje individual no nos dice nada acerca de la posición de un sujeto particular. Dos ejemplos: Nos informan que un niño obtuvo un puntaje bruto de 85 en la escala de desarrollo infantil de Bayley ((???)), no tenemos, en principio ningún criterio para decidir si ese puntaje es alto o bajo. El Índice de Democracia ((???)) de un país es 7.5. ¿Dónde se ubica este país en el conjunto de democracias del mundo? ¿Es alto, medio…? Para situaciones como éstas, muy frecuentes en evaluaciones cuantitativas, será necesario conocer cuál es la posición relativa que un puntaje ocupa respecto del conjunto completo de observaciones. Supongamos que se aplica una prueba de ortografía a una muestra de alumnos de tercer grado y que el promedio de errores es 10 (\\(\\overline{x} = 10\\) errores) y que la desviación estándar es de 4 (\\(s = 4\\) errores). Si un alumno comete 6 errores (\\(x = 6\\) errores), podemos decir que cometió menos errores que el promedio del grupo. El cálculo de la diferencia entre \\(x\\) y \\(\\overline{x}\\) da \\(-4\\) errores (\\(x - \\overline{x} = 6 - 10 = - 4\\)), este resultado nos informa que este alumno se ubica a 4 errores por debajo del promedio (por debajo queda expresado en el signo menos el resultado). Ésta es una medida concreta, ya que expresa el número de errores que separan al alumno del comportamiento resumido del grupo (expresado en la media); dicho de otra manera, estamos considerando los valores absolutos. Si ahora a esta diferencia la dividimos por la desviación estándar obtenemos \\(-1\\) (procedente de \\(\\frac{- 4\\ }{\\ \\ 4\\ }\\)), que ya no tiene unidades, es un número abstracto. Como la desviación estándar es de 4 puntos y el alumno se encuentra a cuatro puntos de la media, esto equivale a decir que el alumno se encuentra “a una desviación estándar por debajo del promedio”. La operación que hemos hecho ha sido la de restar al valor particular (de ese alumno) la media y dividir el resultado en la desviación estándar, hemos calculado lo siguiente: \\[\\frac{x - \\overline{x}}{s}\\] Este número, que como dijimos no tiene unidades, es diferente para cada valor de \\(x\\), y mide la distancia a la que se encuentra una observación particular (\\(x\\)) de la media (\\(\\overline{x}\\)), expresada como fracción de la desviación estándar (\\(s\\)). Decimos que se trata de una medida estandarizada del alejamiento que tiene una observación particular del promedio del conjunto de observaciones. Hemos así expresado la posición del alumno respecto del grupo al que pertenece de manera relativa, en términos de desviaciones estándar. La variable que resulta de esta operación se llama desvío estándar, ya que se trata de un desvío (calculado en la diferencia \\(x - \\overline{x}\\)) expresado como cantidad de desviaciones estándar. Se utiliza la letra z para indicarla, así: \\[z = \\frac{x - \\overline{x}}{s}\\] Debido a que la letra z se utiliza de manera universal para indicar este o puntaje z o puntuación z. Esta nueva variable tiene media igual a cero y desviación estándar igual a uno19. Volvamos sobre el ejemplo del número de síntomas en que se basa el diagnóstico de depresión, cuya media fue de 7 y su desviación estándar de 1,55. Paciente \\(x_{i}\\) (número de síntomas) \\(x_{i} - \\overline{x}\\) (desvíos) \\(z\\) (desvíos estándar) 1 5 -2 -1.29 2 6 -1 -0.65 3 6 -1 -0.65 4 8 1 0.65 5 8 1 0.65 6 9 2 1.29 La última columna proviene de haber dividido cada desvío en la desviación estándar (1.55). Los desvíos indican a cuántas unidades de la variable (en este caso número de síntomas) se ubica cada caso del promedio. Los desvíos estándar indican a cuántas desviaciones estándar se encuentra cada caso del promedio. El primer paciente está 1.29 desviaciones estándar por debajo del promedio, el tercero está a 0.65 desviaciones estándar por debajo del promedio, etc. Para variables nominales, se procede de la misma manera, solo cambia el cálculo de la desviación estándar: Si en un país “A” se encuentra que el 12.5% de los ciudadanos cree que da lo mismo un gobierno autoritario que uno democrático (pregunta P8STGBS de Latinobarómetro) ¿es mucho o poco? Para saberlo necesitamos concer el porcentaje general de esta respuesta en el conjunto de países que se observaron: este valor es, para los países que participan del estudio, 27.6%. Ahora se sabe que en el país “A” la proporción de los que creen que da lo mismo el tipo de gobierno es más baja que en el conjunto de países de la región. ¿Cuánto más baja? Se requiere indicar su posición relativa, y eso se hace en términos de puntaje z. La varianza esta variable se calcula como \\(p*(1-p)=.276*(1-.276)=0.1998\\) y la desviación estándar como \\(\\sqrt(0.1998)=.447\\). Entonces \\(z = \\frac{0.125-0.276}{0.447}=-0.34\\). Que indica que ese país esta levemente por debajo del conjunto. En los próximos capítulos avanzaremos en el análisis de los puntajes z. Cuando se trata de variables de nivel ordinal también es posible ubicar de manera relativa cada valor de la variable, aunque no puedan medirse distancias. Es así porque en esas variables podemos calcular percentiles e indicar a qué percentil corresponde cada valor. Antes vimos el modo de señalar gráficamente la ubicación de los percentiles, allí buscamos de identificar el valor de la variable que corresponde, por ejemplo, al percentil 90 ó a cualquier otro. Podemos hacer también el recorrido inverso: dado un valor de la variable ¿a qué percentil corresponde? Consideremos los siguientes puntajes brutos obtenidos en una prueba psicológica administrada a una muestra de 310 personas: x f F F’ 20-29 0 0 0 30-39 10 10 0.03 40-49 30 40 0.13 50-59 50 90 0.29 60-69 70 160 0.52 70-79 90 250 0.81 80-89 40 290 0.94 90-99 10 300 0.97 100-109 5 305 0.98 110-119 5 310 1 Total 310 Algunos percentiles de esta distribución, por ejemplo, \\(P_{20}\\), \\(P_{60}\\) y \\(P_{90}\\), cuando se piden a R, dan: ## P20 P60 P90 ## 54.5 74.5 84.5 Procediendo del mismo modo, se realiza la siguiente correspondencia de puntajes brutos a percentiles: Percentil X 10 47.0 20 54.5 30 60.4 40 64.9 50 69.3 60 74.5 70 76.3 80 79.8 90 84.5 La tabla nos informa sobre los valores de la variable donde se divide cada 10% del total de casos. Usando la definición de los percentiles diremos que: El 10% de los sujetos obtuvo 47 puntos o menos. El 20% obtuvo 54.5 puntos o menos y así para el resto. Con esta información sabemos que si una persona obtuvo 50 puntos, tiene un puntaje muy bajo, porque supera a menos del 20% del grupo. O dicho de otra manera, más del 80% de las personas alcanzaron puntajes más altos que él. Por el contrario si alguien obtuvo 88 puntos, tiene un puntaje muy alto, ya que supera al percentil 90, con lo que menos del 10% del grupo lo supera. O bien, él supera a más del 90%. De este modo, la construcción de una tabla en la que se indica el valor de la variable (el puntaje en la prueba) correspondiente a cada percentil, permite conocer si un puntaje dado se ubica en algún extremo de la distribución (si es excepcionalmente elevado o bajo) o si es un valor intermedio. Estas tablas de correspondencia entre valores absolutos (o puntajes brutos) y los correspondientes valores relativos pueden también construirse a partir de los desvíos estándar, para lo que se debe transformar cada valor observado en su puntuación \\(z\\). Para el ejemplo anterior se debe calcular la media y la desviación estándar, que dan: \\(\\overline{x} = 68.4\\) y \\(s = 15.7\\). Con esto se indican los puntajes \\(z\\) que corresponden a cada puntaje bruto, con la transformación \\(z = \\frac{x - \\overline{x}}{s}\\). Para la marca de clase del primer puntaje bruto (25), el puntaje z que le corresponde es: \\(z = \\frac{25 - 68.4}{15.7} = - 2.8\\). Al repetir esta operación para cada puntaje bruto se obtiene la tabla de correspondencias: Intervalo de puntajes brutos Puntaje \\(z\\) 20-29 -2.8 30-39 -2.1 40-49 -1.5 50-59 -0.9 60-69 -0.2 70-79 0.4 80-89 1.1 90-99 1.7 100-109 2.3 110-119 3.0 Una tabla de ese tipo (ya sea construida a partir de los percentiles o bien de los puntajes \\(z\\)) se conoce como baremo y es absolutamente necesario para cualquier tipo de evaluación psicológica o educativa ya que posibilita decidir en qué lugar se encuentra un sujeto dado, respecto de su grupo de referencia, Esto se requiere porque, por ejemplo, para una prueba de inteligencia, un puntaje que es normal para la edad de 13 años, no lo es para los 16; los puntajes de alguien de 13 años se comparan con los puntajes de otras personas de 13 años. El baremo provee la transformación de puntajes absolutos en puntajes relativos. Un baremo es una tabla de valores transformados que permiten ubicar a un sujeto en relación a su grupo de referencia. El signo del puntaje z indica si un valor particular está por encima (si es positivo) o por debajo de la media (si negativo). El valor absoluto de z señala cuán lejos o cerca está la observación de la media. Para evaluar esta distancia, contamos con un resultado general, que es válido cualquiera sea la forma de la distribución. Ese resultado establece que a una distancia de hasta un número (\\(k\\)) determinado de desviaciones estándar se concentra no menos de \\(1-\\frac{1}{k^2}\\) de los casos. Si \\(k=2\\) este resultado indica que a una distancia de hasta dos desviaciones estándar de la media se concentra por lo menos la fracción \\(1-\\frac{1}{2^2}=1-\\frac{1}{4}=\\frac{3}{4}=.75\\) de las observaciones. Dicho de otra manera, el intervalo que va desde la media menos dos desviaciones estándar y la media más dos desviaciones estándar contiene al menos al 75% de los casos. Si \\(k=3\\), la proporción de casos que allí se encuentra es por lo menos 89% (que resulta de \\(1-\\frac{1}{3^2}\\). Ese resultado se conoce como desigualdad de Chebycheff \\[P(|x-media|&lt;k*s) \\geq 1-\\frac{1}{k^2}\\] En esta expresión leemos por ahora que la proporción de casos que se encuentran a una distancia de la media menor a \\(k\\) desviaciones estándar es mayor o igual a uno menos uno sobre \\(k\\) cuadrado. Cuando se asigna a \\(k\\) un valor, se puede calcular esa proporción para una distancia concreta a la media. Si se cumple que la distribución es unimodal y aproximadamente simétrica, esta regla se puede simplificar del siguiente modo: en el intervalo de una desviación estándar de la media se encuentra aproximadamente el 68% de los casos, a dos desviaciones el 95 y a tres, el 99%. Con estos criterios, podemos evaluar los valores de la variable como pertenecientes al conjunto más frecuente o a los extremos, menos frecuentes, de la distribución. Por ejemplo, si en una distribución simétrica, a un caso le corresponde un puntaje \\(z=3\\) se trata de un caso excepcionalmente elevado, porque pertenece a una distancia que solo es superada por el .5% del total de observaciones. Usaremos el criterio de considerar a los casos que estén a menos de dos desviaciones por encima o por debajo ed la media como “esperables”, porque están en la región de mayor frecuencia. Los casos que estén entre dos y tres desviaciones estándar serán valores “elevados” si \\(z&gt;0\\) y “bajos” si \\(z&lt;0\\). Los casos que se ubican a tres o más desviaciones estándar (\\(|z|\\geq 3\\)) serán considerados “excepcionalmente” altos o bajos según el signo de z. El gráfico siguiente muestra el intervalo de dos desviaciones estándar para una distribución no cumple los supuestos mencionados, a la que se aplica la desigualdad de Chebycheff. Mientras que la siguiente distribución es unimodal y aproximadamente simétrica, por lo que es válida la regla empírica. Volveremos sobre este tema con más detalle cuando tratemos una distribución teórica que se llama distribución normal. 3.6 Resumen de medidas descriptivas 3.6.1 Medidas de posición Nivel de medición mínimo requerido Centrales Modo Nominal Mediana Ordinal Media Intervalar No centrales Cuartiles Ordinal Quintiles Ordinal Percentiles Ordinal 3.6.2 Medidas de dispersión Nivel de medición mínimo requerido Entre extremos Recorrido Intervalar Basada en el orden Amplitud intercuartílica Intervalar Basadas enla media Varianza Intervalar Desviación estándar Intervalar Coeficiente de variación Intervalar De incertidumbre Coeficiente de incertidumbre Nominal Esta es la idea que transmite el lenguaje coloquial: cuando algo es &quot;la moda, es lo que más comúnmente (frecuentemente) se ve.↩ El manual DSM IV indica como síntomas característicos a dos (o más) de los siguientes, cada uno de ellos presente durante una parte significativa de un período de 1 mes: ideas delirantes, alucinaciones, lenguaje desorganizado (p. ej., descarrilamiento frecuente o incoherencia), comportamiento catatónico o gravemente desorganizado, síntomas negativos, por ejemplo, aplanamiento afectivo, alogia o abulia.↩ Propiedades que se agregan a las de las escalas de menor nivel, por lo que modo y mediana pueden calcularse e interpretarse también en las escalas métricas.↩ Otros coeficientes de asimetría son: el de Pearson, que compara la ubicación de la media y del modo, y el de Bowley, que compara los cuartiles y la mediana.↩ Para ver esto, comparemos con el caso de la serie: 3, 4, 6, 7, 23, 45 con media 14,7. Las diferencias entre cada observación y la media son las siguientes: x 3 4 6 7 23 45 \\[x_{i} - \\overline{x}\\] -11,7 -10,7 -8,7 -7,7 8,3 30,3 En este caso las diferencias no son simétricas, pero es igualmente cierto que su suma es igual a cero, es decir que están compensadas las diferencias por encima y por debajo de la media.↩ Puede verse que es así haciendo: \\(\\sum_{i = 1}^{n}{\\left( x_{i} - \\overline{x} \\right) = \\sum_{i = 1}^{n}x_{i} - \\sum_{i = 1}^{n}\\overline{x}}\\), como \\(\\overline{x}\\) es una constante, el segundo término es \\(n*\\overline{x}\\), igual que el primero, según la definición operativa de la media. Por lo tanto la diferencia es cero, cualquiera sea el conjunto de datos.↩ En este punto aparece la primera diferencia entre cálculos hechos sobre datos de una muestra o de una población. Si estuviésemos trabajando sobre toda la población, la varianza (a la que indicaríamos con otra letra) tendría denominador \\(n\\), en lugar de \\(n-1\\). No podemos explicar la razón de esto aún, habrá que esperar al capítulo de estimación. En algunos manuales, a la varianza calculada con denominador \\(n-1\\) se la llama cuasivarianza o también seudovarianza.↩ En este caso no hay variabilidad, y en consecuencia, no hay variable, porque el valor asumido es siempre el mismo. Se trata de una constante.↩ Presencia de cinco (o más) de los siguientes síntomas durante un período de 2 semanas, que representan un cambio respecto a la actividad previa; uno de los síntomas debe ser: 1. Estado de ánimo depresivo la mayor parte del día, casi cada día según lo indica el propio sujeto (p. ej., se siente triste o vacío) o la observación realizada por otros (p. ej., llanto). En los niños y adolescentes el estado de ánimo puede ser irritable 2. Disminución acusada del interés o de la capacidad para el placer en todas o casi todas las actividades, la mayor parte del día, casi cada día (según refiere el propio sujeto u observan los demás) 3. Pérdida importante de peso sin hacer régimen o aumento de peso ( p. ej., un cambio de más del 5% del peso corporal en 1 mes), o pérdida o aumento del apetito casi cada día. Nota: En niños hay que valorar el fracaso en lograr los aumentos de peso esperables 4. Insomnio o hipersomnia (sueño excesivo) casi cada día. 5. Agitación o enlentecimiento psicomotores casi cada día (observable por los demás, no meras sensaciones de inquietud o de estar enlentecido) 6. Fatiga o pérdida de energía casi cada día 7. Sentimientos de inutilidad o de culpa excesivos o inapropiados (que pueden ser delirantes) casi cada día (no los simples autorreproches o culpabilidad por el hecho de estar enfermo) 8. Disminución de la capacidad para pensar o concentrarse, o indecisión, casi cada día (ya sea una atribución subjetiva o una observación ajena) 9. Pensamientos recurrentes de muerte (no sólo temor a la muerte), ideación suicida recurrente sin un plan específico o una tentativa de suicidio o un plan específico para suicidarse↩ Dado que \\(\\overline{x}\\) y s son constantes, aplicando las propiedades de la media, resulta: \\[\\overline{z} = \\overline{\\left( \\frac{x - \\overline{x}}{s} \\right)} = \\frac{\\overline{x} - \\overline{x}}{s} = 0\\] También haciendo uso de las propiedades de la varianza, la de z es: \\[V\\left( z \\right) = V\\left( \\frac{x - \\overline{x}}{s} \\right) = \\frac{1}{s^{2}}\\left( V\\left( x \\right) - V\\left( \\overline{x} \\right) \\right) = \\frac{1}{s^{2}}\\left( V\\left( x \\right) - 0 \\right) = \\frac{1}{s^{2}}V\\left( x \\right) = 1\\] ya que la media es constante por lo que tiene varianza nula, y \\(V\\left( x \\right) = s^{2}\\).↩ "],
["relación-entre-variables-los-fundamentos.html", "Capítulo 4 Relación entre variables: los fundamentos 4.1 Tablas de contingencia 4.2 Frecuencias relativas 4.3 Una clasificación en referencia al tiempo 4.4 La dirección de la relación 4.5 Concepto de riesgo relativo 4.6 La intensidad 4.7 El concepto de independencia estadística 4.8 Hacerlo en R", " Capítulo 4 Relación entre variables: los fundamentos Hasta este punto se han descripto variables observadas o medidas a través de instrumentos de a una por vez. Ahora, el objetivo se acerca más al modo de hacer investigación en Ciencias Sociales. Es así porque en este capítulo y el siguiente se trata con relaciones entre variables: no ya describir cada variable por separado sino reunirlas en relaciones de dos como mínimo, pero que puede incluir a una gran cantidad. Buscar relaciones entre variables es comenzar a transitar el camino de la explicación de los fenómenos que observamos. Si nos preguntamos, por ejemplo: ¿por qué un tratamiento es exitoso con algunos pacientes diagnosticados de depresión y con otros no? A partir de antecedentes que existan sobre el tema, formularemos hipótesis sobre la respuesta: quizás la edad influya, puede suceder que con pacientes más jóvenes se obtenga mejor resultado que con los de más edad. Razonando así, introducimos otra variable, la edad, que aportaría a explicar la razón de los diferentes resultados del tratamiento. La hipótesis está formulada como una relación entre dos variables: se trata de indagar por el efecto que la edad (primera variable) tendría sobre el resultado del tratamiento (segunda variable). La edad podría ser un factor explicativo del resultado del tratamiento. Dentro del mismo ejemplo, también podemos sospechar que quienes han sido diagnosticados más precozmente pueden aprovechar el tratamiento mejor que quienes traen una dolencia de larga data. Aquí la variable que viene a explicar el resultado es el tiempo de evolución de la enfermedad. Ahora el tiempo de evolución de la enfermedad podría ser otro factor explicativo del resultado del tratamiento. Notemos el acento en “podría ser”: estas relaciones son hipotéticas, nuestro objetivo será analizar la evidencia que haya a su favor o en su contra. Esquemáticamente la relación se plantea de la siguiente manera: Figura 4.1: Relación hipotética entre dos factores explicativos y el resultado de un tratamiento para la depresión Estas dos variables son parte de la hipótesis para explicar las diferencias en los resultados que ofrece un determinado tratamiento sobre pacientes diagnosticados de depresión. Puede haber más variables: la gravedad de la depresión, el sexo del paciente (quizás el resultado no sea igual en mujeres que en hombres), el apoyo familiar que el paciente reciba, etc. Jamás agotaremos el conjunto de todos los factores explicativos de un fenómeno, porque en última instancia cada caso es único. Los fenómenos que observamos son multicausados, por lo que no puede decirse que una variable X sea la causa de otra variable Y20. Pero lo que sí puede hacerse es analizar la importancia relativa de los diferentes factores explicativos; saber en qué grado aporta cada uno a las diferencias que se observan. Ilustremos esto con otro ejemplo: el resultado escolar que alcanzan los alumnos. No hay dudas que cada niño tiene una trayectoria única, que depende de su historia, de su contexto familiar, etc. Supongamos que analizamos el resultado escolar obtenido en primer grado y observamos que algunos cursos tienen docentes tradicionales, que usan los mismos métodos estandarizados de enseñanza desde hace muchos años. Otros cursos tienen docentes que invitan a los alumnos participar, que innovan en los métodos de enseñanza. Luego comparamos el rendimiento de los alumnos en los dos cursos y vemos que los alumnos del primer grupo aprenden más lentamente que los del segundo y que además, los primeros dicen que se aburren yendo a la escuela y los otros no. Esto no sucede con todos los niños: habrá en el primer grupo algunos que aprenden más rápido y que se divierten, así como algunos del segundo grupo tardarán más en aprender. Pero, en general, en promedio, podríamos hallar mejores resultados entre los alumnos que tienen docentes innovadores. Esto nos lleva a indicar que hay evidencia para creer que los docentes innovadores obtienen con sus alumnos mejores resultados que los docentes tradicionales. Pero esto no es para todos los alumnos, sino para la mayoría de ellos. De eso se trata la búsqueda de factores explicativos: en este ejemplo diremos que, de los múltiples factores que explican por qué a algunos chicos les va bien en la escuela y a otros les va mal, el tipo de docente es parte de la explicación. Las hipótesis son respuestas tentativas a la pregunta formulada como problema de la investigación. Como tales, consisten en el planteamiento de una relación entre, al menos, dos variables. Recordemos que las hipótesis constituyen afirmaciones que se derivan del modelo de análisis que el investigador ha propuesto para explicar una situación dada. Las hipótesis son consecuencias deductivas de la teoría, cuya verificación no es suficiente para validar la teoría, aunque sí para “aportar evidencia en su favor”. Además, las hipótesis como tales, rara vez pueden ponerse a prueba de manera directa, son sus consecuencias observables las que permiten la verificación empírica. En cualquier modelo explicativo hipotético participa un número de variables mayor a dos, sin embargo de las hipótesis pueden deducirse relaciones más simples, inicialmente solo de dos variables. El siguiente esquema muestra la relación entre varias variables que aportarían (hipotéticamente) a explicar las diferencias en el rendimiento escolar, desde la perspectiva de las condiciones familiares (arrobaQuivy1992). Figura 4.2: Relación hipotética entre dos factores explicativos y el resultado de un tratamiento para la depresión El esquema muestra una hipótesis según la cual, los padres con más educación tienden a tener ocupaciones de mayor jerarquía, lo que implica de mejores ingresos y esto puede ayudar a crear condiciones adecuadas para el estudio, como disponer de un lugar para estudiar o tener acceso a otras fuentes de aprendizaje (visitas a museos, viajes, etc.). También los padres con mayor educación probablemente valoren más el estudio y así ofrezca mayor apoyo a sus hijos en la escuela. Por último, sería de esperar que los padres con más educación generen un ambiente con hábitos de lectura y discusiones que transmitan a sus hijos el valor de la educación. Esto es más cercano a la realidad, en la que las variables se relacionan de manera más compleja que la simple \\(x \\rightarrow y\\). Sin embargo la base para analizar estas relaciones complejas, son las relaciones bivariadas, es decir, entre solo dos variables. Establecer de manera hipotética una relación entre dos variables equivale a afirmar que, por alguna razón, los cambios de una de ellas van acompañados de cambios en la otra. Pero esto puede suceder de maneras muy diferentes, por ejemplo, el trueno sucede al relámpago, los síntomas de tuberculosis coinciden con la detección del bacilo de Koch, los movimientos sociales se incrementan en tiempos de deterioro económico, las personas abusadas en la infancia son más propensas a la depresión. En algunos de estos ejemplos puede identificarse una secuencia cronológica, señalando cuál de los dos eventos sucede primero, en otros esta distinción no es segura, a veces una variable es la que incide sobre la otra, otras veces es solo una contribución, por último, hay casos en que su ocurrencia conjunta o sucesiva se debe a otras razones. Evitaremos, por ahora hablar de relaciones de causalidad, llegaremos a este concepto hacia el final del capítulo y veremos que debe tratarse con suma cautela. Con el objetivo de ordenar la gran variedad de formas que pueden asumir las relaciones entre variables, estableceremos algunos criterios de clasificación que, sin ser exhaustivos, nos ayudarán a verlas desde diferentes ópticas. El modo más usado para observar relaciones entre dos variables consiste en presentar el comportamiento conjunto de ellas a través de tablas o gráficos. Las primeras son más adecuadas para variables con pocas categorías (usualmente nominales), mientras que los gráficos son más pertinentes para mostrar relaciones entre variables métricas. Veamos un ejemplo para ilustrar el primer modo de representación: creemos que los niños que han crecido en diferentes tipos de hogar (solo con su madre, solo con su padre, con ambos o con otros parientes) tienen diferentes formas de relacionarse con sus compañeros (con relaciones de liderazgo, sumisión o rebeldía). En el lenguaje de las relaciones entre variables, estaríamos proponiendo que existe asociación entre el tipo de hogar en que el niño crece (con las cuatro categorías mencionadas) y el tipo de relación que mantiene con sus pares. La presentación conjunta de esas dos variables es: Disposición de las variables y sus categorías para analizar la relación entre dos variables Relación con los pares Tipo de hogar Sumisión Rebeldía Liderazgo Monoparental materno Monoparental paterno Nuclear Extendido 4.1 Tablas de contingencia Cuando se distribuyen los datos en las celdas, se obtiene una tabla bivariada (porque contiene dos variables), que también se llama tabla de contingencia o tabla de distribución conjunta o también tabla de doble entrada. Las celdas del interior de la tabla llevarán, cuando los datos sean recolectados, la cantidad de niños que se encuentren en cada coincidencia de categorías. Si nuestra hipótesis afirmara que los niños provenientes de hogares nucleares son más propensos a ser líderes, esperaríamos una concentración relativa de casos en la celda correspondiente a “hogar nuclear” - “liderazgo”, hipótesis que luego deberemos confrontar con la información recogida. Una tabla bivariada o tabla de contingencia o tabla de distribución conjunta es un arreglo con tantas filas (horizontales) como categorías tenga una de las variables y tantas columnas (verticales) como categorías tenga la otra variable. Por oposición, las tablas que se mostraron en los capítulos anteriores, así como las medidas descriptivas que se calcularon, se denominan univariadas. A este arreglo se agrega una fila y una columna adicionales que corresponden a los totales de cada categoría. A los fines de usar un lenguaje común, en la tabla llamaremos filas a la líneas horizontales y columnas a las verticales e identificaremos la dimensión de la tabla indicando cuántas filas tiene y cuántas columnas, en este orden. En el ejemplo anterior, la dimensión de la tabla es cuatro por tres, porque tiene cuatro filas y tres columnas correspondientes a la cantidad de categorías de cada una de las dos variables. La dimensión de la tabla se indica como \\(f X c\\), donde \\(f\\) es el número de categorías de la variable que está en las filas y \\(c\\) es el número de categorías de la variable que está en las columnas. La celda en la que, bajo la hipótesis indicada, esperaríamos una mayor concentración relativa de casos corresponde entonces a la tercera fila y tercera columna. Con f indicaremos la frecuencia y con el subíndice la celda a que corresponde, así, \\(f_{ij}\\) será la cantidad de casos en la celda que corresponde a la fila i y a la columna j simultáneamente. La frecuencia de la celda de “nuclear-liderazgo” será indicada entonces como \\(f_{33}\\). Para aclarar la presentación de la tabla, se agregan una fila y una columna en la que se indica el total de casos de cada una de ellas, que se llaman marginales de fila y de columna. La notación será: \\(f_{i.}\\) (“efe i-punto”) para los marginales de fila \\(f_{.j}\\) (“efe punto-jota”) para los de columnas \\(f_{..}\\) (“efe punto-punto”) para el total general. Con esa notación, \\(f_{3.}\\)indica el total de niños que crecieron en hogares nucleares y \\(f_{.2}\\) el total de quienes se vinculan con rebeldía con sus compañeros, la tabla anterior resulta: Tabla 4.1: Disposición de las frecuencias para el análisis de la relación entre dos variables. Relación con los pares Tipo de hogar Sumisión Rebeldía Liderazgo Total Monoparental materno \\(f_{11}\\) \\(f_{12}\\) \\(f_{13}\\) \\(f_{1.}\\) Monoparental paterno \\(f_{21}\\) \\(f_{22}\\) \\(f_{23}\\) \\(f_{2.}\\) Nuclear \\(f_{31}\\) \\(f_{32}\\) \\(f_{33}\\) \\(f_{3.}\\) Extendido \\(f_{41}\\) \\(f_{42}\\) \\(f_{43}\\) \\(f_{4.}\\) Total \\(f_{.1}\\) \\(f_{.2}\\) \\(f_{.3}\\) \\(f_{..}\\) Si hemos recogido datos sobre estas características de los niños, la tabla podría quedar así: Tabla 4.2: Alumnos de escuelas primarias por relación con sus pares según tipo de hogar (organización de las frecuencias). Relación con los pares Tipo de hogar Sumisión Rebeldía Liderazgo Total Monoparental materno 20 30 50 100 Monoparental paterno 10 40 15 65 Nuclear 5 10 25 40 Extendido 30 20 10 60 Total 65 100 100 265 Esta tabla dice que se han observado un total de 265 niños y se ha registrado el tipo de hogar en que crecieron y la forma en que se relacionan con sus compañeros. De los 265: 100 provienen de hogares monoparentales maternos: \\(f_{1.}\\), 65 de monoparentales paternos: \\(f_{2.}\\), 40 de nucleares: \\(f_{3.}\\) y 60 de hogares extendidos: \\(f_{4.}\\). Los mismos niños se relacionan con sus compañeros: 65 de ellos con sumisión: \\(f_{.1}\\), 100 con rebeldía: \\(f_{.2}\\) y 100 con liderazgo: \\(f_{.3}\\). Todas estas son lecturas de las frecuencias marginales. Marginales de fila las del tipo de hogar y marginales de columna las de la forma de la relación. Se llama frecuencias marginales de fila a las frecuencias absolutas de las categorías de la variable que se ubica en las filas. Las frecuencias marginales de columna son las frecuencias absolutas de las categorías de la variable ubicada en las columnas.* Las frecuencias de las celdas, que se llaman frecuencias conjuntas se leen: 20 de los niños observados crecieron en hogares monoparentales maternos y se relacionan con sus compañeros con sumisión (\\(f_{11}\\)), 30 niños se relacionan con liderazgo y provienen de hogares monoparentales maternos (\\(f_{12}\\)), 10 se relacionan con rebeldía y provienen de hogares nucleares (\\(f_{32}\\)) y del mismo modo el resto de las frecuencias conjuntas. Ellas indican la cantidad de casos que reúnen al mismo tiempo las dos condiciones que se indican en la fila y en la columna. Las frecuencias conjuntas indican la cantidad de casos que corresponden simultáneamente a una determinada categoría de la variable de las filas y una categoría de la variable de columnas. 4.2 Frecuencias relativas Del mismo modo en que trabajamos con las tablas de distribución de frecuencia de una sola variable, podemos transformar todas estas frecuencias absolutas en relativas, por el simple procedimiento de dividirlas en el total general. Resulta así: Tabla 4.3: Alumnos de escuelas primarias por relación con sus pares según tipo de hogar, frecuencias relativas. Relación con los pares Tipo de hogar Sumisión Rebeldía Liderazgo Total Monoparental materno 0.08 0.11 0.19 0.38 Monoparental paterno 0.04 0.15 0.06 0.25 Nuclear 0.02 0.04 0.09 0.15 Extendido 0.11 0.08 0.04 0.23 Total 0.25 0.38 0.38 1 Leemos así las frecuencias que están destacadas en la tabla: El 15% del total de alumnos observados proviene de hogares monoparentales paternos y se relacionan con sus pares con rebeldía: Por ser una frecuencia relativa usamos la “prima” en la notación, entonces es \\(f&#39;_{22}\\) Un 25% del total se relaciona con sumisión, sin considerar el tipo de hogar del que provengan. Es \\(f&#39;_{1.}\\) Un 38% proviene de hogares monoparentales maternos, sin tener en cuenta de qué manera se relacionan con sus pares. Es \\(f&#39;_{.1}\\) La primera de estas frecuencias relativas es conjunta, las otras dos marginales. Verifique que queda bien clara la notación usada en cada caso y que pueden leerse las demás frecuencias relativas de la tabla. 4.3 Una clasificación en referencia al tiempo Como señalamos al principio hay relaciones en las que resulta posible identificar a una de las variables como previa a la presencia de la otra, o a un evento como anterior a la ocurrencia del otro. Así, el trueno siempre sucede luego del relámpago, si tenemos la oportunidad de oírlo. Aun cuando no podamos establecer la causa de la relación entre los dos eventos, no tenemos dudas en señalar a uno como anterior al otro. Los malos tratos sufridos durante la niñez son anteriores (en la historia del sujeto) a la eventual manifestación adulta de conductas antisociales. De modo que si nos interrogáramos sobre la existencia de una relación entre estos dos eventos, ubicaríamos a los malos tratos como variable anterior, aunque solo fuera porque su manifestación es temporalmente previa. Así sucede también al buscar una relación entre los resultados de un examen de ingreso a la universidad y el rendimiento posterior de los alumnos. Es importante indicar a esta altura que no estamos suponiendo que la relación exista, nos encontramos en el momento del planteo de las hipótesis; bien puede suceder que, luego del análisis de los datos, encontremos que la relación no es válida, que no se sostiene, en fin, que las observaciones no avalan una asociación entre malos tratos infantiles y conducta antisocial, o que el resultado de examen de ingreso no se relaciona con el desempeño posterior, pero esto no invalida que, en la relación que proponíamos, una variable sea tratada como anterior a la otra. Así como en ciertos casos es posible anticipar el orden (sea lógico o cronológico) en que se presentan las variables que constituyen una relación, hay algunas situaciones en que esto es muy difícil, o imposible y otras en las que no tiene ningún interés. Una relación que ilustra el primer caso es la relación entre el comportamiento infantil y el trato que recibe de sus padres. Puede interpretarse a los niños revoltosos como respondiendo a la escasa atención que le brindan sus padres, o leer la forma en que los padres tratan a sus hijos como consecuencia de la mala conducta de estos últimos. En este ejemplo se ve que el orden en que se establezcan las variables que se busca relacionar está influido por la posición teórica que el investigador asuma. Otros casos en los que no tiene interés mencionar qué variable es anterior y cual posterior son típicos de los estudios descriptivos, en los que interesa mostrar cómo se distribuyen ciertas variables, y no qué relación puede haber entre ellas. Así, una distribución de la población por sexo y edad como la de la tabla siguiente: Tabla 4.4: Departamento Capital, Provincia de Córdoba. Población por sexo según grupos de edad. Año 2001. Grupos de edad Varones Mujeres Total 0-4 56913 55053 111966 5-9 57471 56073 113544 10-14 55564 54394 109958 15-19 55581 55834 111415 20-24 67519 69727 137246 25-29 53736 54667 108403 30-34 42209 43852 86061 35-39 36910 39894 76804 40-44 34681 38243 72924 45-49 31879 36634 68513 50-54 30780 36187 66967 55-59 24485 29448 53933 60-64 19914 25038 44952 65-69 16485 22387 38872 70-74 13858 20831 34689 75-79 8816 15318 24134 80-84 4423 9471 13894 85-89 1827 5355 7182 90-94 600 1906 2506 95-99 120 448 568 100 y más 8 43 51 Total 613779 670803 1284582 Solo pretende describir a la población y no tiene sentido preguntar qué variable es prioritaria a la otra o cuál depende de cuál. Las relaciones en que no es posible o no interesa señalar qué variable es anterior, se llaman simétricas21 o de variación conjunta o de covariación, con ellas simplemente puede preguntarse si las variables están correlacionadas. Es decir si varían simultáneamente, sin preguntar cuál es la que podría preceder a la otra. Otro ejemplo de este tipo de relaciones es la que puede plantearse entre las calificaciones que los alumnos obtienen en dos materias que cursan simultáneamente; si encontramos que a aquellos alumnos que les va bien en Epistemología también obtienen buenas notas en Biología, no creeremos que un resultado incida en el otro, solamente describiremos que varían conjuntamente. Si luego nos interesamos por avanzar en un estudio explicativo iremos a buscar otras variables que den cuenta de esta covariación. Una relación entre dos variables es simétrica cuando es de variación conjunta y no puede identificarse a una variable como previa a la otra* Por el contrario, aquellas relaciones en las que puede identificarse a una variable como anterior a otra se denominan asimétricas, es decir, no es lo mismo planearlas en un sentido que en otro. Una de las variables (la anterior) se llama antecedente y la otra (posterior) consecuente. En el contexto del diseño experimental, estas variables se denominan, respectivamente independiente y dependiente. Puede observarse que una variable cambia a continuación de la otra (en sentido temporal) pero esto no nos autoriza a decir que cambia a causa de la otra, como resulta claro en el ejemplo del relámpago y el trueno. Que la relación sea asimétrica no implica que una variable sea ni la causa, ni un factor explicativo, de la otra. A la inversa, en los estudios explicativos la relación debe ser asimétrica, porque se busca identificar factores que anticipen determinados eventos. Por eso decimos que la asimetría es una condición necesaria de la causalidad, pero no suficiente. Una relación entre dos variables es asimétrica cuando una de las variables precede (lógica o cronológicamente) a la otra y puede identificarse a una como antecedente y a la otra como consecuente. 4.4 La dirección de la relación Cuando las variables que se ponen en juego en una relación tienen un nivel de medición superior al nominal, resulta posible hacer juicios de orden entre sus categorías, con lo que es posible indicar si los valores van creciendo o decreciendo. Ya sea que se trate de una relación simétrica o asimétrica, si las variables tienen nivel ordinal o superior, resulta de interés plantear la dirección de la relación. Se trata de otro criterio para clasificar relaciones entre variables: si a cambios ascendentes (crecientes) de una variable se siguen cambios ascendentes de la otra, llamamos a la relación directa. Si, por el contrario, un crecimiento de una de las variables va acompañado de una disminución en los valores de la otra, la denominaremos inversa22. Cuando se espera que la relación entre dos variables sea directa o inversa para toda la serie de categorías, decimos que la relación es monótona. Por ejemplo, puede plantearse, de manera hipotética, la relación entre los años de educación y el salario. Las personas que han asistido más años a instituciones educativas tienden, en promedio, a tener ingresos más altos que quienes asistieron menos tiempo. La hipótesis anticipa una relación directa entre la escolarización y los ingresos. Una relación entre dos variables medidas a nivel ordinal o superior es directa si cuando los valores de una de ella aumentan, también aumentan los de la otra. Análogamente: Se llama inversa a la relación entre dos variables de nivel ordinal o superior en la que los incrementos en los valores de una de ellas van acompañados de disminuciones en los valores de la otra. La clasificación solo tiene sentido si puede hablarse de aumento o disminución, es decir, si es factible realizar juicios de orden entre las categorías de las variables. Por eso es que este criterio requiere, para su aplicación, que ambas variables tengan por lo menos nivel ordinal. Por ejemplo, la calificación que se obtiene en un examen (variable consecuente, de nivel ordinal) puede tener relación directa con las horas dedicadas a estudiarla (variable antecedente, de nivel proporcional). Lo que equivale a decir que quienes estudian más horas tenderían a obtener calificaciones más altas. Si en otro ejemplo, se formula como hipótesis que el tipo de escuela secundaria (variable antecedente, de nivel nominal) a la que los alumnos asistieron tiene relación con el rendimiento que alcanzan en su carrera universitaria (variable consecuente, de nivel ordinal), no es posible establecer la dirección de esta relación, porque no se cumple que ambas variables sean al menos ordinales. Ejemplo (datos ficticios): la expresión “si los padres los ayudan con las tareas, a los chicos les va mucho mejor en la escuela” equivale a decir que la ayuda que los padres les dan a sus hijos está relacionada con mucha intensidad con el rendimiento en la escuela. La primera variable, la ayuda es la antecedente, que puede ser de nivel nominal, con categorías: ayuda, no ayuda; o bien ordinal, con categorías: ayuda siempre, casi siempre, pocas veces, nunca. La segunda variable, el rendimiento, es la consecuente, y sus categorías podrían ser: rendimiento alto, medio, bajo. El esquema de la relación será: Figura 4.3: Relación hipotética entre la ayuda de los padres y el rendimiento escolar Y la tabla que reúna los datos para verificar esta relación podrá tener dimensión \\(2 \\times 3\\), con forma: Disposición de las variables para analizar la relación entre la ayuda que los padres dan a sus hijos y el rendimiento que alcanzan en la escuela Rendimiento Ayuda Alto Medio Bajo Total Si No Total O bien, considerando a la ayuda como ordinal, en una tabla de \\(4 \\times 3\\) Disposición de las variables para analizar la relación entre la ayuda que los padres dan a sus hijos y el rendimiento que alcanzan en la escuela Rendimiento Ayuda Alto Medio Bajo Total Siempre Casi siempre Pocas veces Nunca Total Planteada de este modo, se trata de una relación asimétrica, ya que suponemos que es la ayuda (antecedente) la que incide sobre el resultado (consecuente). Si vemos el último esquema, puede considerarse la dirección (en el anterior no ¿por qué?) y la formularíamos como directa, es decir que, cuanto mayor sea ayuda que los padres aportan, tanto mejores serán los resultados. Esto está dentro de la hipótesis, aún no hemos recogido datos para avalarla o refutarla. Llegar a conocer si la ayuda de los padres contribuye en gran medida o escasamente a los resultados en la escuela, es un problema de la intensidad de la relación, que solo podrá responderse a posteriori, una vez que los datos están recolectados. 4.5 Concepto de riesgo relativo En las tablas de contingencia de dimensión \\(2\\times2\\), que plantean relaciones asimétricas se suele calcular una medida que resulta de muy accesible interpretación, denominada riesgo relativo. Se trata de un cociente entre la proporción de casos que se encuentran en una categoría de la variable consecuente bajo determinado escenario (una categoría de la variable antecedente) y la proporción de casos que se hallan en la misma, bajo el escenario complementario (la otra categoría de la variable antecedente). Es un término que tiene uso regular en epidemiología y tiene la ventaja de la claridad en la comunicación. Por ejemplo, un informe afirma que “El riesgo relativo de cardiopatía isquémica (CI) es 2,5 veces mayor en pacientes hipertensos.” Se interpreta que las personas que son hipertensas tienen dos veces y media mayores posibilidades de sufrir CI que quienes no lo son. El riesgo relativo se usa principalmente (pero no solo) en la relación entre dos variables dicotómicas; en este ejemplo las variables dicotómicas son: ser hipertenso y haber sufrido cardiopatía isquémica, ambas con categorías si - no, a las que denominamos: hip, nohip y card, nocard, respectivamente. La primera es el antecedente y la segunda el consecuente, porque interesa plantear el posible efecto de la hipertensión sobre la CI. A partir de los datos obtenidos en el estudio de arrobaRamonGonzalezJuanatey2001, la relación se plantea así: card nocard Total hip 4022 6555 10577 nohip 2068 19406 21474 Total 6090 25961 32051 Las frecuencias relativas son: card nocard Total hip 0.380 0.620 1 nohip 0.096 0.904 1 Total 0.190 0.810 1 La frecuencia relativa .380 es el riesgo de tener cardiopatía isquémica si se es hipertenso, mientras que .096 es el mismo riesgo para personas que no padecen hipertensión. La comparación de ellos es el riesgo relativo: \\[\\frac{.380}{.096}=3.96\\] Este cociente mide cuántas veces más grande es el numerador que el denominador, por lo que indica cuántas veces más riesgo hay de tener cardiopatía isquémica si se padece hipertensión, que si no es así. Ejemplo (datos del Operativo Nacional de Evaluación Argentina 2000): interesados en el efecto que podría tener el hábito de lectura de los alumnos sobre su rendimiento en Lengua, usamos una pregunta de un cuestionario aplicado a estudiantes del último año del secundario, que dice: “Durante los últimos dos meses ¿Leíste o estás leyendo algún libro, además de los que te pidieron en la escuela?” Con categorías de respuesta si - no. Nos interesa analizar la relación de esta variable con el resultado que los alumnos obtienen en la prueba de lengua, para lo cual cortamos los puntajes de esta prueba en dos categorías: altos (50 puntos o más) y bajos (menos de 50 puntos). Para la provincia de Córdoba, en el año 2000 resulta la siguiente tabla: Durante los últimos dos meses ¿Leíste o estás leyendo algún libro, además de los que te pidieron en la escuela? Puntaje prueba de de la Lengua Bajos Altos Total Si 2382 10299 12681 No 3530 9821 13351 Total 5912 20120 26032 A fin de comparar los puntajes que obtienen quienes leen con los que obtienen los que no leen (para ver si hay alguna diferencia), hacen falta frecuencias relativas. En este caso se calculan según las filas de la tabla: Durante los últimos dos meses ¿Leíste o estás leyendo algún libro, además de los que te pidieron en la escuela? Puntaje prueba de de la Lengua Bajos Altos Total Si 18,8% 81,2% 100% No 26,4% 73,6% 100% Total 22,7% 77,3% 100% En esta tabla se observa que menos de un cuarto (el 22,7%) obtuvo resultados bajos, pero que este porcentaje es diferente entre quienes lee y quienes no lo hacen: entre quienes dicen que leen, menos del 19% (el 18,8%) tiene bajo puntaje, mientras que entre quienes dicen que no leen, ese porcentaje sube a más del 26 (26,4%). Dado que el resultado bajo se considera como el evento desfavorable, puede hablarse del riesgo de obtenerlo. Así, el riesgo de obtener puntaje bajo en Lengua es 18,8% para quienes dicen que leen y de 26,4% para quienes dicen que no leen. Estos valores son los que se usan para calcular el riesgo relativo, el cociente entre 26,4 y 18,8 es 1,4, por lo que diremos que hay 1,4 veces más chances de obtener bajos resultados en Lengua entre alumnos que no leen que entre los que sí lo hacen. 4.6 La intensidad Sea que se trate de relaciones simétricas o asimétricas y que pueda o no decidirse sobre la dirección, siempre es posible (y tiene mucho interés hacerlo) evaluar la intensidad en que se manifiesta la relación entre las variables a partir de los datos de nuestras observaciones. Esta medida de la relación se corresponde con la idea intuitiva de “X tiene mucha influencia en Y”, la idea de mucha o poca influencia, es la de intensidad de la relación. Cuando hay muchos factores explicativos para un fenómeno, interesa saber qué factores inciden en mayor o menor medida en el fenómeno y a eso se responde indicando la intensidad de cada relación. La intensidad o grado de la relación puede también aplicarse a relaciones simétricas. En ese caso, la intensidad mide cuán a menudo los cambios de una de las variables se ven acompañados de cambios en la otra, y es un resultado descriptivo, no explicativo. La intensidad de una relación23 es una medida de la fuerza con que los cambios en una variable afectan los cambios en la otra (si es una relación asimétrica) o bien, de la frecuencia con que los cambios de una variable acompañan a los de la otra (si se trata de una relación simétrica). La evaluación de esta intensidad puede lograrse, en una primera aproximación, observando la distribución conjunta de las dos variables. En la medida que cierta combinación de categorías de una y otra variable concentren la mayor parte de los casos, estaremos en presencia de relaciones más fuertes o de mayor intensidad. Los siguientes son resultados de un estudio que relaciona el tipo de docente con el rendimiento de sus alumnos: Tabla 4.5: Alumnos primarios por rendimiento según tipo de docente, frecuencias absolutas rendimiento tipo de docente alto medio bajo Total Autoritario 5 35 50 90 Democrático 260 40 10 310 Total 265 75 60 400 Ejemplo: se compara la idea de emigrar entre quienes tienen diferente opinión sobre la evolución de su país. Para ellos se cruzan las siguientes variables de la edición 2017 de Latinobarómetro: S11. ¿Ud. y su familia han pensado en la posibilidad concreta de ir a vivir a otro país? Sí No P2ST. ¿Diría Ud. que este país…? Está progresando Está estancado Está en retroceso Tabla 4.6: Distrbibución conjunta de la opinión sobre la evolución de su país y la intención de emigrar. Frecuencias absolutas pensó emigrar nunca pensó emigrar Total progresando 1126 3914 5040 estancado 2324 7221 9545 en retroceso 1521 3543 5064 Total 4971 14678 19649 En la que, la opinión sobre la evolución del país (en las filas) y los proyectos migratorios (en las columnas) están codificados como las opciones de respuesta del cuestionario. Al pedir las frecuencias relativas al total obtenemos: Tabla 4.7: Distribución conjunta de la opinión sobre la evolución del propio país y la perspectiva de emigrar. Frecuencias relativas al total pensó emigrar nunca pensó emigrar Total progresando 5.7 19.9 25.7 estancado 11.8 36.7 48.6 en retroceso 7.7 18.0 25.8 Total 25.3 74.7 100.0 Leemos las frecuencias conjuntas y las marginales como en la tabla ref(tab:cual). Por ejemplo: El 36.7% de los encuestados considera que su país está estancado y no considera la posibilidad de emigrar. El 25.3% de los encuestados ha pensado en emigrar (sin importar su opinión sobre la evolución de su país). El 25.7% cree que su país está mejorando (sin tener en cuenta su proyecto migratorio). El análisis que se haga de la tabla depende del modo en que se formule la hipótesis sobre la relación. Si se plantea a la “opinón sobre la evolución del país” como uno de los posibles elementos que influiría a la decisión de emigrar, entonces, la opinión es antecedente de la decisión de migrar. Con esta formulación, el interés estaría en comparar la decisión de emigrar entre quienes tienen diferente opinión sobre la evolución del país. Para ello, generamos frecuencias relativas en dirección de la opinión (variable antecedente) y, por comodidad, expresamos esas frecuencias relativas como porcentajes: Tabla 4.8: Distribución conjunta de la opinión sobre la evolución del propio país y la perspectiva de emigrar. Frecuencias relativas por filas pensó emigrar nunca pensó emigrar Total progresando 22.3 77.7 100 estancado 24.3 75.7 100 en retroceso 30.0 70.0 100 Ahora la lectura es por las filas, es decir, por las categorías de la opinión. Entre quienes opinan que su pais está mejorando, hay un 22.3% que ha pensado en emigrar, mientras que entre quienes creen que está empeorando, el porcentaje sube al 30%. La ventaja de usar porcentajes (o frecuencias relativas) es que las comparaciones se hacen sobre los mismos totales, es “como si” hubiese 100 personas que opinan que el país está mejorando, 100 que está estancado y 100 que está empeorando. Que haya cierta relación entre la opinión acerca de la evolución del pais (antecedente) y la idea de emigrar (consecuente) no es equivalente a que la opinión sea “la causa” de las intenciones de emigrar. En la tabla se observa que la intención de emigrar es expresada por una minoría se los encuestados, solo que esa minoría es levemente mayor entre quienes opinan que el país está empeorando. Se puede afirmar que quienes opinan que el país está empeorando tienen “un poco más” de intenciones de emigrar que aquellos que opinan que está mejorado. La opinión sobre la evolución del país es uno de los muchos factores que pueden incidir en la intención de emigrar. Al comparar la tabla 4.6 con la 4.7 vemos que aunque ambas ofrecen frecuencias relativas, la primera las calcula respecto del total general (los 19649 casos) mientras que en la segunda los totales son las frecuencias marginales de cada fila. Son dos resultados muy diferentes, en efecto, la frecuencia de la celda 1,1 en la tabla 4.7 es 0,057 e indica que el 5.7% del total de encuestados cree que su país está mejorando y han pensado en emigrar. La misma celda en la tabla 4.8 tiene frecuencia de 0,223 y se lee: de los encuestados que creen que su país está mejorando, el 22.3% ha pensado en emigrar. Veamos que la primera de las frecuencias (relativa al total) contiene información simultanea sobre las dos variables, mientras que la segunda (relativa a los totales de fila), fija una categoría para una de las variables: al hablar de los encuestados que creen que su país está mejorando, estamos restringiendo el conjunto completo, ya no es un juicio sobre los 19649 encuestados del total, sino solo sobre los 5040 que cumplen con ese requisito. La frecuencia está condicionada por ese requisito. Esto equivale a decir que las frecuencias relativas cambian cuando se establece una condición como la mencionada. En general, la proporción de encuestados que piensa emigrar es 25.3% , pero si agregamos el dato que indica que estamos tratando solo con los que creen que el país está mejorando, entonces la proporción decae al 22.3%. La opinión sobre la evolución del país es una condición que imponemos cuando calculamos estas frecuencias relativas a los totales de fila. El modo en que se calcularon las frecuencias relativas (o los porcentajes) en la segunda tabla fue tomando como total al número de encuestados que dieron cada opinión sobre el país. No es ésta la única opción posible, ¿por qué no lo hicimos dividiendo por los totales de cada nivel de la otra variable, la intención de emigrar? Es decir ¿qué hizo que eligiéramos en esta tabla las filas y no las columnas como totales para el cálculo de los porcentajes? Es porque es trata de una relación asimétrica, y en esos casos siempre elegiremos como denominador a los totales de la variable antecedente, porque queremos ver qué diferencia hay entre los grupos que definen sus categorías. En el caso del ejemplo, el interés se centra en saber si la opinión sobre la evolución del país implica diferencia en la intención de emigrar. No es importante si la variable antecedente se ubica en las filas o en las columnas, aunque hay una práctica de ubicarla en las filas; en cualquier caso, son sus totales los que usaremos para el cálculo de los porcentajes. Con el paso de las frecuencias simples a las relativas, hemos avanzado en la detección de la relación entre las dos variables, pero aun no podemos cuantificar su intensidad. Para ello existe una gran cantidad de coeficientes que se usan para reconocer si se trata de relaciones fuertes, débiles o simplemente inexistentes. Estos coeficientes varían según el nivel de medición de las variables, según el número de categorías, la simetría de la relación y, en especial, en el aspecto que analizan de la relación y el modo en que se interpretan. En este capítulo solo nos detendremos en uno de ellos que es de utilidad para tratar relaciones entre variables que tienen dos categorías cada una, es decir entre dos variables dicotómicas. En los próximos capítulos trataremos con otros coeficientes. El coeficiente que usaremos para evaluar la intensidad de una relación entre dos variables dicotómicas se denomina Q de Kendall - Yule y en su cálculo tiene en cuenta el modo en que las frecuencias se distribuyen entre las cuatro celdas de la tabla. Para ejemplificar el uso de este coeficiente, transformaremos la relación del caso anterior, dejando de lado a quienes opinan que el pais está estancado. Es decir, conservamos las categorías extremas de la variable. Así, la tabla queda: Tabla 4.9: Distribución conjunta de la opinión sobre la evolución del propio país y la perspectiva de emigrar. Frecuencias absolutas, variables dicotomizadas pensó emigrar nunca pensó emigrar progresando 1126 3914 en retroceso 1521 3543 La concentración de la mayoría de los casos en las celdas de una de las diagonales de la tabla se considera como señal de la asociación existente entre las dos variables. El coeficiente Q se calcula operando con esas frecuencias del siguiente modo: \\[Q = \\frac{1126*3543 - 1521*3914}{1126*3543 + 1521*3914} = \\frac{-1963776}{9942612} = -0,198\\] En el numerador, hemos multiplicado las frecuencias de una de las diagonales y le hemos restado el producto de las frecuencias de la otra diagonal. En el denominador, hemos sumado los mismos dos productos. De manera simbólica, si representamos a las frecuencias de las celdas como A, B, C y D, tenemos A B C D \\[Q = \\frac{AD - CB}{AD + CB}\\] El cálculo de este coeficiente da un número que puede ser positivo o negativo pero que siempre se encuentra entre -1 y 1. \\[- 1 \\leq Q \\leq 1\\] En este coeficiente, el signo no tiene interpretación, se consideran iguales, por ejemplo, los valores 0,80 y -0,80. Esto se debe a que el signo que resulta depende del orden (arbitrariamente elegido) con que se hayan dispuesto las filas y las columnas. Cuanto más próximo a uno (1) o a menos uno (-1) sea el coeficiente, tanto más intensa es la relación entre las dos variables. Los valores del coeficiente cercanos a cero indican una relación entre las variables que es débil o inexistente. Por lo tanto, el valor obtenido en el ejemplo anterior señala una relación débil entre las dos variables, pudiendo llevarnos a afirmar que la opinión que se tenga sobre la evolución del país tiene, según estos datos, un efecto muy leve sobre la decisión de emigrar. Sin duda esta última es resultado de procesos complejos en los que intervienen muchos factores, entre ellos, la opinión que se tenga del país. En el caso extremo que el coeficiente sea igual a uno (o a menos uno) diremos que la relación es perfecta. Se trata de un caso ideal, no factible de ser observado en la realidad, pero que sirve para establecer el valor límite del coeficiente. Un ejemplo en que esto sucedería es si las frecuencias de la tabla anterior fueran como las siguientes: Tabla 4.10: Distribución ficticia de la opinión sobre la evolución del propio país y la perspectiva de emigrar. Caso de relación “perfecta” pensó emigrar nunca pensó emigrar progresando 0 5040 en retroceso 5064 0 Aquí resulta que ninguno de los que opinan que el país está progresando pensó en emigrar, mientras que todos los que creen que está empeorando sí pensaron emigrar. En esta tabla \\[Q = \\frac{0*0 - 5040*5064}{0*0+5040*5064} = \\frac{25522560}{25522560} = -1\\] El valor \\(-1\\) se interpreta entonces indicando que la relación entre la opinión y la intención de emigrar es perfecta. El caso contrario es aquél en el que no haya relación alguna entre las variables, allí es cuando el coeficiente alcanza (en valor absoluto) su mínimo valor posible, cero. Otra vez se trata de un caso ideal, porque muy improbablemente se encontrarán en la realidad observaciones que lleven a un coeficiente que sea exactamente cero. Modifiquemos nuevamente las frecuencias de nuestra tabla para ejemplificar esa situación ficticia: Tabla 4.11: Distribución ficticia de la opinión sobre la evolución del propio país y la perspectiva de emigrar. Caso de relación “nula” pensó emigrar nunca pensó emigrar progresando 1512 3528 en retroceso 1519 3545 En este caso los encuestados están distribuidos en las celdas del mismo modo si opinan que el país está ejorando o empeorando (verifique, calculando las frecuencias relativas por filas) Se encuentra que un 30% de los encuestados ha pensado en emigrar, tanto entre los que opinan que el país está mejorando como entre los que creen que empeora. El cálculo del coeficiente da ahora: \\[Q = \\frac{1512*3545-1519*3528}{1512*545+1519*3528} = 0.00016\\] Este valor indica que no hay relación entre las variables, es decir que, según estos datos, la opinión no haría diferencia alguna sobre la intención de emigrar. El coeficiente Q de Kendall - Yule mide la intensidad de la relación entre dos variables dicotómicas comparando la concentración de frecuencias en las diagonales. Alcanza su valor máximo cuando todos los casos se ubican sobre una diagonal y la relación es perfecta. Alcanza su mínimo valor cuando las frecuencias están distribuidas de manera proporcional entre las celdas y las variables son independientes. Una limitación importante de este coeficiente aparece cuando la distribución de las frecuencias es “rinconal”. Esto quiere decir que una de las frecuencias es cero, como sucedería si en las tablas anteriores, no se hubiesen encontrado casos de gente que opinara que el pais está mejorando y hubiesen pensado emigrar: Tabla 4.12: Distribución ficticia de la opinión sobre la evolución del propio país y la perspectiva de emigrar. Caso de distribución “rinconal” pensó emigrar nunca pensó emigrar progresando 0 5040 en retroceso 1519 3545 En este ejemplo -y siempre que una celda tenga frecuencia cero-, el coeficiente Q dará valor 1 (ó -1) y esto no debe interpretarse como una asociación perfecta, es una limitación del coeficiente, que no puede usarse en estos casos. Terminaremos esta introducción a la relación entre variables con una referencia al problema de la causalidad. El hecho de haber encontrado que, en una relación asimétrica, existe una asociación intensa entre las variables, no nos lleva inmediatamente a suponer que la antecedente sea causa del consecuente. En toda explicación de un fenómeno, en especial de los fenómenos sociales, la causalidad es múltiple, es casi siempre imposible atribuir una causa única a la explicación de un hecho. Desde el sentido común es frecuente enunciar que “todo tiene una causa”, pero en el dominio de la investigación que involucra a sujetos humanos, los hechos que nos interesa analizar tienen múltiples causas, las cuales compiten entre sí en la explicación. Por lo tanto, descubriendo relaciones entre variables podemos aportar a la inclusión o exclusión de variables como factores explicativos de un fenómeno dado, pero no a “determinar su causa”. Podremos afirmar qué factores hacen más probable la aparición de un fenómeno dado, bajo qué condiciones su ocurrencia es más frecuente, o inclusive indicar cuáles son las variables más importantes para que el fenómeno suceda, pero muy difícilmente lleguemos a afirmaciones del tipo X es la causa de Y. Pensemos por ejemplo en fenómenos psicosociales complejos, como la delincuencia juvenil. El tipo de hogar del que las personas provienen puede tener efecto, la relación con los padres, el abandono temprano de la escuela, la estructura familiar actual, y pueden seguir enumerándose factores que contribuirían a explicar que algunas personas desarrollen conductas delictivas y otras no. Pero no será posible alcanzar una explicación completa del fenómeno, en una expresión ingenua como “la causa de la delincuencia es…” 4.7 El concepto de independencia estadística Formulemos ahora el problema de manera inversa, interrogándonos por las condiciones en que puede decirse que dos variables son independientes. Intuitivamente la independencia entre dos eventos equivale a que la ocurrencia de uno de ellos no tiene efecto en el del otro. Así, las oportunidades que un evento ocurra serán iguales tanto si el otro evento sucedió como si no lo hizo. Cuando decimos que X no tiene efectos sobre Y, indicamos que Y sucede tanto si X está presente como si no lo está. La independencia de dos variables es equivalente a que no haya asociación entre ellas. Consideremos ahora la distribuión de la actividad económica por sexos según datos de la EPH. Tabla 4.13: Distribución de la condición laboral por sexos. Frecuencias absolutas varones mujeres Total ocupades 13202 10196 23398 desocupades 940 930 1870 inactives 8787 14380 23167 Total 22929 25506 48435 En este caso es más claro formular la pregunta sobre la relación entre variables, en términos de la diferencia entre grupos.¿Se distribuyen del mismo modo mujeres y varones entre las condiciones de ocupade, desocupade e inactive? La relación es, como en el ejemplo anterior, asimétrica, donde la variable sexo es antecedente y condición laboral, la consecuente. Por esa razón las frecuencias relativas es calculan por columnas, dode se encuuentra la variable antecedente. Tabla 4.14: Distribución de la condición laboral por sexos. Frecuencias relativas por columnas varones mujeres ocupades 57.6 40.0 desocupades 4.1 3.6 inactives 38.3 56.4 Total 100.0 100.0 Se lee aquí que del total de varones, el 57.6% está ocupado, mientras que, de las mujeres, el 40.0% lo está. Si la distribución de categorías laborales no tuviera ninguna relación con el hecho de ser hombre o mujer, se esperaría que haya igual proporción de personas ocupades, desocupades e inactives entre varones y mujeres. Si del total de personas, el 48.3% está ocupade, habría un 48.3% de varones ocupados y un 48.3% de mujeres ocupadas. De modo que, de los 22929 varones, 11077 (que constituyen aproximadamente el 48.3% de 22929) deberían estar ocupados. Análogamente, el 48.3% de 25506, (aproximadamente 12321 mujeres) son las que deberían estar ocupadas. Las frecuencias de las demás celdas se obtienen replicando la frecuencia marginal de desocupades e inactives sobre los totales de varones y mujeres. Puede entonces construirse una nueva tabla con las frecuencias que se esperaría encontrar si las dos variables fueran independientes, es decir si el hecho de ser varones o mujeres no tuviese ningún efecto sobre la actividad laboral. Dicho de otro modo, si la actividad laboral fuera independiente del sexo. Tabla 4.15: Frecuencias esperadas bajo la hipótesis de independencia correspondiente a la tabla anterior varones mujeres Total ocupades 11077 12321 23398 desocupades 885 985 1870 inactives 10967 12200 23167 Total 22929 25506 48435 Observemos algunos detalles de esta tabla. En primer lugar, las frecuencias marginales no han cambiado (salvo por elgún efecto de redondeo), los totales son los mismos y solo se trata de un reordenamiento de las frecuencias conjuntas bajo la hipótesis de independencia de las dos variables24. Tratemos ahora de formalizar las operaciones que condujeron a esta segunda tabla. Los valores 48.3%, 8.07% y 47.8% provienen de las proporciones de casos en cada una de las categorías de la variable condición de actividad, y se calcularon como \\(\\frac{23398}{48435}\\), \\(\\frac{1870}{48435}\\) y \\(\\frac{23167}{48435}\\) respectivamente. Luego esas proporciones se multiplicaron por los totales de casos de cada categoría de la variable sexo. De esa operación obtuvimos 11077 como \\(22929*.483\\) (salvo diferencias por redondeo), que daría lo mismo expresado como \\(22929*23398/48435\\). De mismo modo el resto de las celdas. De manera general entonces, obtenemos cada una de las frecuencias de la segunda tabla multiplicando la frecuencia marginal de su fila por la de su columna y dividiendo por el total general. En símbolos, las frecuencias esperadas son: \\[f_{\\text{ij}}^{e} = \\frac{f_{i}f_{j}}{n}\\] Si las dos variables fueran independientes (con más precisión se dice estadísticamente independientes), las frecuencias conjuntas que se esperaría encontrar serían como las que calculamos con este procedimiento. ¿Y qué sería en ese caso de las frecuencias relativas? Tabla 4.16: Frecuencias relativas por columnas esperadas bajo la hipótesis de independencia correspondiente a la tabla anterior varones mujeres Total ocupades 0.4831000 0.4830628 0.4830804 desocupades 0.0385974 0.0386184 0.0386084 inactives 0.4783026 0.4783188 0.4783111 Que habría idéntica proporción de ocupades, desocupades e inactives entre varones y mujeres, que es la condición de independencia que estamos proponiendo. La tabla de relativos respecto del total resulta así: Tabla 4.17: Frecuencias relativas por columnas esperadas bajo la hipótesis de independencia correspondiente a la tabla anterior varones mujeres Total ocupades 0.229 0.254 0.483 desocupades 0.018 0.020 0.039 inactives 0.226 0.252 0.478 Total 0.473 0.527 1.000 Puede llegarse directamente a las frecuencias relativas, porque la frecuencia absoluta de cada celda es: \\[f_{\\text{ij}} = \\frac{f_{i}f_{j}}{n}\\] Y relativa de esa celda: \\[f_{\\text{ij}}^{&#39;} = \\frac{f_{\\text{ij}}}{n}\\] Si reemplazamos, nos queda: \\[f_{\\text{ij}}^{&#39;} = \\frac{f_{\\text{ij}}}{n} = \\frac{\\left( \\frac{f_{i}f_{j}}{n} \\right)}{n} = \\frac{f_{i}}{n}\\frac{f_{j}}{n} = f_{i}^{&#39;}f_{j}^{&#39;}\\] Más brevemente: \\[f_{\\text{ij}}^{&#39;} = f_{i}^{&#39;}f_{j}^{&#39;}\\] Es decir que, si las variables fueran independientes, cada frecuencia relativa será producto de las correspondientes frecuencias relativas marginales. Ahora podemos dar una definición de independencia estadística. Dos variables son estadísticamente independientes si la frecuencia relativa de cada celda es igual al producto de las frecuencias relativas marginales de la fila y la columna a las que la celda pertenece. En efecto, cada frecuencia conjunta de la tabla 14 es el producto de las marginales correspondientes. En este capítulo solo se trató con variables nominales, y en un caso también ordinales, pero aún no se ha dicho nada sobre las variables intervalares y proporcionales. En las distribuciones univariadas se vio que una tabla de distribución de frecuencias no puede listar todas las categorías de una variable de estos niveles, sino que deben construirse intervalos de valores. Eso mismo puede hacerse para construir una tabla bivariada, cuando se analiza la relación entre variables intervalares y/o proporcionales. De ese modo resultaría la tabla que pone en relación la condición de actividad con la edad, categorizada en cuatro intervalos proporcionales: Tabla 4.18: Distribución conjunta de la condición de actividad y la edad en cuatro grupos (0,16] (16,32] (32,52] (52,101] Total ocupades 41 7163 11269 4925 23398 desocupades 8 1122 526 214 1870 inactives 6189 5975 2477 8526 23167 Total 6238 14260 14272 13665 48435 Pero en el próximo capítulo veremos que para variables de estos niveles de medición se cuenta con procedimientos más simples y más eficaces que permiten analizar con más detalle sus relaciones. 4.8 Hacerlo en R La elaboración de las tablas en R requiere del comando table aplicado sobre las variables de la matriz de datos que se quiera cruzar: table(eph.3.18$CH04, eph.3.18$ESTADO) ## ## 0 1 2 3 4 ## 1 34 13202 940 8787 4256 ## 2 26 10196 930 14380 4128 Los marginales deben pedirse explícitamente, con addmargins: addmargins(table(eph.3.18$CH04, eph.3.18$ESTADO)) ## ## 0 1 2 3 4 Sum ## 1 34 13202 940 8787 4256 27219 ## 2 26 10196 930 14380 4128 29660 ## Sum 60 23398 1870 23167 8384 56879 Así como las relativas, usando prop.table: prop.table(table(eph.3.18$CH04, eph.3.18$ESTADO)) ## ## 0 1 2 3 4 ## 1 0.0005977602 0.2321067529 0.0165263102 0.1544858384 0.0748255068 ## 2 0.0004571107 0.1792577225 0.0163504984 0.2528173843 0.0725751156 Para reducir los decimales, se solicita redondeo a solo tres: round(prop.table(table(eph.3.18$CH04, eph.3.18$ESTADO)), 3) ## ## 0 1 2 3 4 ## 1 0.001 0.232 0.017 0.154 0.075 ## 2 0.000 0.179 0.016 0.253 0.073 Y para expresarlos como porcentajes, lo multiplicamos por 100: round(prop.table(table(eph.3.18$CH04, eph.3.18$ESTADO)), 3) * 100 ## ## 0 1 2 3 4 ## 1 0.1 23.2 1.7 15.4 7.5 ## 2 0.0 17.9 1.6 25.3 7.3 Estas frecuencias relativas, lo son respecto del total, si se las quiere por filas, se indica en el argumento 1 round(prop.table(table(eph.3.18$CH04, eph.3.18$ESTADO), 1), 3) * 100 ## ## 0 1 2 3 4 ## 1 0.1 48.5 3.5 32.3 15.6 ## 2 0.1 34.4 3.1 48.5 13.9 Para obtenerlas por columnas, se indica 2 en el argumento de prop.table: round(prop.table(table(eph.3.18$CH04, eph.3.18$ESTADO), 2), 3) * 100 ## ## 0 1 2 3 4 ## 1 56.7 56.4 50.3 37.9 50.8 ## 2 43.3 43.6 49.7 62.1 49.2 Para darles formato, una opción es llevar la tabla a una hoja de cálculo y allí rotular, centrar, etc. De lo contrario, R ofrece un entorno llamado R Markdown con muchas posibilidades de formato y exportación a pdf o html. Salvo en el caso de diseños experimentales que permitan tener control sobre el conjunto de variables que participan en el resultado que se observa.↩ Atención, éste es un uso diferente de los términos simetría y asimetría. La simetría de una distribución (univariada) indica su forma, acá se refiere al tipo de relación entre dos variables. El primer uso caracteriza a una variable, el segundo a una relación.↩ No es directamente o inversamente proporcional. La proporcionalidad es otra cosa. Aquí solo se trata de que cambien en la misma dirección (ambas aumentan o ambas disminuyen) o en dirección inversa (una aumenta y la otra disminuye).↩ No es posible ofrecer una definición más precisa porque según el modo en que se mida la intensidad, es decir, según el coeficiente que se use, es diferente el aspecto de la relación que se tiene en cuenta.↩ Como consecuencia de ello, de las cuatro celdas solo es necesario calcular una frecuencia, ya que las demás pueden obtenerse restando de los totales de filas y de columnas. Una vez que sabemos que la frecuencia de la celda 1,1 es 120, podemos obtener 60 como lo que resta para llegar a 180 (de la primera fila), 80 como la diferencia con 200 (de la primera columna) y 40 como lo que le falta a 60 para llegar a 100 (segunda columna) o lo que le falta a 80 para alcanzar 120 (segunda fila).↩ "],
["relación-entre-variables-el-análisis.html", "Capítulo 5 Relación entre variables: el análisis 5.1 Variables nominales con más de dos categorías cada una 5.2 Variables de nivel ordinal 5.3 Nivel intervalar o proporcional 5.4 Dicotomías reales y artificiales 5.5 Niveles de medición combinados 5.6 Resumen de coeficientes de asociación 5.7 Matriz de correlaciones 5.8 La forma de la relación 5.9 La importancia de la visualización 5.10 Hacerlo en R", " Capítulo 5 Relación entre variables: el análisis En el capítulo anterior hemos tratado la relación entre dos variables en escalas nominales, y señalamos que si se trata de variables de nivel superior es posible crear categorías y tratarlas del mismo modo. En cuanto a la medida de la intensidad de la relación, nos hemos limitado al caso de dos variables dicotómicas, es decir, con dos categorías en cada una, con lo que la tabla resultante es de dos por dos y calculamos el coeficiente Q de Kendall - Yule. Ahora se amplía el dominio de nuestro análisis, incorporando herramientas que permiten poner a prueba la hipotética relación entre dos variables de nivel nominal con más de dos categorías cada una y variables de nivel superior (ordinales y métricas). 5.1 Variables nominales con más de dos categorías cada una 5.1.1 La distancia entre frecuencias esperadas y observadas Sobre el final del capítulo anterior presentamos el concepto de independencia estadística y vimos la manera de calcular las frecuencias de las celdas que se esperarían encontrar si las variables fueran independientes. Para hacer esto es suficiente multiplicar las frecuencias marginales correspondientes a cada celda y dividir el resultado por el total de casos. Sea el caso que interese analizar la relación del tipo de violencia25 con el lugar donde sucede. Aunque estadísticamente equivalente, no es adecuado preguntar si el lugar incide sobre el tipo de violencia, sino más bien si el tipo de violencia difiere según el lugar. Aquí es más pertinente el planteo del problema como una comparación de grupos (los definidos por los diferentes lugares) antes que como una relación entre variables. Lo mismo pasa cuando se comparan los resultados de un examen entre quienes cursan por la tarde o la mañana. Cuando hay control de variables, como en el diseño experimental o en la evaluación de impacto, el paralelismo entre las dos lecturas es más cercano. Así, preguntar si un grupo de niños que recibió un suplemento en su dieta, tiene mejor desarrollo que uno que no lo recibió (planteo en términos de comparación de grupos), equivale a preguntar si el suplemento dietario incide sobre el desarrollo (planteo en términos de relación entre variables). Las operaciones estadísticas que responden a las dos preguntas son las mismas, pero según el caso, una manera de formular el problema puede ser más adecuada que otra. La investigación social apela continuamente a las comparaciones: el pasado y el presente, mujeres y varones, sociedades industriales y agrarias (arrobaPescosolido1983), grupos minoritarios y población general, por eso es necesario contar con herramientas que permitan analizar la manera en que suceden estas diferencias y las relaciones entre variables que se asocian a ellas. Cuando se busca evaluar el impacto de una política pública dirigida a reducir enfermedades parasitarias en niños, una estrategia consiste en comparar la prevalencia de esas enfermedades entre niños que han sido destinatarios de esa política, con niños que no lo fueron. La pregunta por la diferencia entre los dos grupos equivale a indagar sobre el efecto de la política. Para el ejemplo de las diferencias en el tipo de violencia según área geográfica, una muestra de 500 casos provee la siguiente distribución conjunta: Tabla 5.1: Clasificación de diferentes tipos de violencia según área donde se manifiesta (datos ficticios) áreas rurales ciudades grandes ciudades pequeñas Total autoinfligida 15 100 35 150 colectiva 5 35 10 50 interpersonal 90 110 100 300 Total 110 245 145 500 Una primera aproximación consiste en calcular frecuencias relativas. Dado que nuestro interés está en comparar el tipo de violencia según las áreas, calcularemos los porcentajes según las columnas de la tabla 1 y resulta: Tabla 5.2: Frecuencia relativas por columnas de la clasificación de diferentes tipos de violencia según área donde se manifiesta áreas rurales ciudades grandes ciudades pequeñas Total autoinfligida 13.6 40.8 24.1 30 colectiva 4.5 14.3 6.9 10 interpersonal 81.8 44.9 69.0 60 Total 100.0 100.0 100.0 100 Si no consideramos el área, se ve (en la columna de los totales) que la violencia interpersonal es la más frecuente (60%), seguida de la autoinfligida con el 30%. Este patrón de distribución en las distintas formas de violencia se mantiene en las diferentes áreas, pero en más acentuado en las rurales, donde la categoría modal (que sigue siendo interpersonal) alcanza el 82% del total del área. Por el contrario, la violencia autoinfligida, que es el 30% del total, sube al 41% en grandes ciudades y solo representa el 14% de las formas de violencia que se observan en áreas rurales. Así, parecería que hay diferencia en la distribución de los tipos de violencia según las áreas que están considerándose. Buscaremos ahora de cuantificar la intensidad de esa relación, para lo que nos preguntaremos cuáles serían las frecuencias de las celdas si el tipo de violencia fuera independiente del área donde sucede, es decir, si se observara la misma proporción de los distintos tipos de violencia en todas las áreas. Usemos el concepto de independencia estadística para calcular las frecuencias esperadas correspondientes a la tabla 5.1. Tabla 5.3: Frecuencias esperadas bajo la hipótesis de independencia entre el tipo de violencia y el área donde se observa áreas rurales ciudades grandes ciudades pequeñas Total autoinfligida 33 74 44 151 colectiva 11 24 14 49 interpersonal 66 147 87 300 Total 110 245 145 500 Estas frecuencias están calculadas como indicamos en el capítulo anterior, haciendo: \\[f_{ij}^{e} = \\frac{f_{i}*f_{j}}{n}\\] Por ejemplo, la frecuencia de la celda 1,2 resultó de \\(f_{1 2}^{e} = \\frac{151*245}{500} = 73,99\\) que redondeamos a 74. La tabla 5.3 muestra las frecuencias que esperaríamos encontrar si no hubiera relación entre las variables, si éstas fueran independientes. A ellas debemos compararlas con las que realmente hemos encontrado, las que se denominan frecuencias observadas. Si halláramos que nuestras frecuencias observadas son muy similares a las que se esperan bajo la hipótesis de independencia, diríamos que las variables “están cerca” de ser independientes, o lo que es equivalente, que habría escasa relación entre ellas. Por el contrario, si las frecuencias observadas fueran muy diferentes de las esperadas, creeríamos que las variables “están lejos” de ser independientes, es decir, que habría alguna relación entre ellas. Para decidir, debemos comparar la tabla 5.1 con la 5.3. Una opción para medir la distancia entre los dos conjuntos de frecuencias es la de restar las correspondientes de cada celda; pero si hacemos eso nos encontraremos con un problema parecido al que tuvimos cuando intentamos observar la dispersión restando los valores de la media: la suma da cero. Por única vez realizaremos esta operación de manera manual: \\[(15 - 33) + (100 - 74) + (35 - 44) + (5 - 11) + (35 - 24) + (10 - 14) + (90 - 66) +\\] \\[(110 - 147) + (100 - 87) = 0\\] Obtenemos este resultado porque las frecuencias marginales son fijas y lo que una celda tiene de más, lo tiene otra de menos. Siempre sucederá así y por esa razón, no podemos saber si las observadas están cerca o lejos de las esperadas con el procedimiento directo de restarlas. Por el contrario, para medir la distancia entre los dos conjuntos de frecuencias (observadas y esperadas) se usa la siguiente expresión: \\[\\sum_{i=1; j=1}^{i=f; j=c}{\\frac{(f_{ij}^o - f_{ij}^e)^2}{f_{ij}^e}}\\] La expresión nos dice que deben restarse cada una de las frecuencias esperadas de cada observada correspondiente, elevar esa diferencia al cuadrado26 y dividir el resultado por cada una de las frecuencias esperadas. Los subíndices mantienen la notación del capítulo anterior: \\(i\\) es el índice de filas, que va desde la primera (\\(i=1\\)) hasta la última (\\(f\\) es el número total de filas); \\(j\\) es el índice de las columnas, que también empieza en 1 (\\(j=1\\)) y termina en \\(c\\), que es el número total de columnas27. Vamos a aplicarla una vez, solo para ver su funcionamiento, luego la pediremos al programa: \\[\\frac{(15 - 33)^{2}}{33} +\\frac{(100 - 74)^{2}}{74} + \\frac{(35 - 44)^{2}}{44} + \\frac{(5 - 11)^{2}}{11} + \\frac{(35 - 24)^{2}}{24} + \\frac{(10 - 14)^{2}}{14} +\\] \\[\\frac{(90 - 66)^{2}}{66} + \\frac{(110 - 147)^{2}}{147} + \\frac{(100 - 87)^{2}}{87} = 50,18\\] El número que resulta de esta operación se llama puntaje chi cuadrado (o también ji cuadrado), se indica con el símbolo \\(\\chi^{2}\\) y es una medida de la distancia a la que se encuentran las frecuencias observadas de las que se esperaría encontrar si las variables fueran independientes. El puntaje \\(\\chi^{2}\\) no puede ser negativo, ya que proviene de la suma de números elevados al cuadrado. Solo puede ser cero si todos los términos de la suma son cero, es decir, si cada frecuencia observada es exactamente igual a la esperada correspondiente. En ese caso no habría duda en decir que las variables son independientes, cumplirían exactamente con la definición de independencia estadística. El puntaje \\(\\chi^{2}\\) indica si las frecuencias observadas están cerca o lejos de las esperadas, pero ¿qué tan grande debe ser para que consideremos lejanas a las frecuencias? Dos problemas que tiene este puntaje son: puede ser indefinidamente grande su valor depende del número de casos que se evalúan y de la dimensión de la tabla. Así, por ejemplo, si multiplicamos por 10 todas las frecuencias de la tabla 5.1, obtenemos: Tabla 5.4: Ejemplo de expansión artificial del total de casos de la tabla de frecuencias observadas áreas rurales ciudades grandes ciudades pequeñas Total autoinfligida 150 1000 350 1500 colectiva 50 350 100 500 interpersonal 900 1100 1000 3000 Total 1100 2450 1450 5000 Aunque los valores absolutos son diez veces más grandes, no hubo cambios en las frecuencias relativas, por ejemplo, en la celda 1,1: \\(\\frac{150}{1100} = 0,14\\ (14\\%)\\) lo mismo que había dado esa celda en la tabla original. Cualquiera sea la intensidad de la relación entre estas dos variables, ésta no ha cambiado porque hayamos multiplicado todo por 10, sin embargo, si calculamos el puntaje \\(\\chi^{2}\\) en la tabla 5 obtenemos 501.9, es decir un número 10 veces más grande. Entonces el puntaje \\(\\chi^{2}\\) puede cambiar muy ampliamente sin que cambien las frecuencias relativas; esto nos dice que este puntaje no mide de manera directa la asociación entre dos variables, por ello: Para comparar la intensidad de la asociación, el puntaje \\(\\chi^{2}\\) solo en válido si las tablas tienen la misma dimensión y el mismo número de casos. 5.1.2 Coeficientes de asociación para variables nominales Para medir la asociación, debe eliminarse el efecto de la cantidad de casos y también de la dimensión de la tabla. Calcularemos tres coeficientes que nos permitan evaluar el grado o intensidad de la relación y que tengan un límite superior de modo que podamos juzgarlos como elevados o bajos. El primero de ellos es el coeficiente \\(\\varphi\\)28, válido para medir la asociación entre dos variables dicotómicas (o binarias), se calcula como: \\[\\varphi = \\sqrt{\\frac{\\chi^{2}}{n}}\\] Vale cero si las variables son independientes e indica mayor asociación cuando está más cerca de uno. Ejemplo (datos ficticios): en el análisis de la calidad de ítems de un examen, se observa las veces que una pregunta es correctamente respondida por los alumnos que aprobaron el examen y por quienes no lo aprobaron. Para el caso de una pregunta a la que se llama #7745, que fue respondida por 100 alumnos (a quienes les tocó por azar), la información se presenta en una tabla de \\(2 \\times 2\\): correcta incorrecta Total aprobó 50 15 65 no aprobó 10 25 35 Total 60 40 100 Para la que el puntaje \\(\\chi^{2}\\) vale 22.16, y el coeficiente resulta en: \\[\\varphi = \\sqrt{\\frac{22.16}{100}} = 0.47\\] Como el cálculo del puntaje \\(\\chi^{2}\\) es engorroso para hacer manualmente, existe una expresión alternativa para obtener el coeficiente \\(\\varphi\\), que solo usa las frecuencias observadas en la tabla. Si estas son: a b c d La fórmula de cálculo del coeficiente \\(\\varphi\\) es: \\[\\varphi = \\frac{(c*b) - (a*d)}{\\sqrt{(a + b)*(c + d)*(a + c)*(b + d)}}\\] Aplicado a los datos del ejemplo da: \\[\\varphi = \\frac{(10*15) - (50*25)}{\\sqrt{(50 + 15)*(10 + 25)*(50 + 10)*(15 + 25)}} = \\frac{1100}{2337} = 0.47\\] Otra forma de medir la asociación entre dos variables, cuando alguna de ellas o las dos, tienen más de dos categorías, es el coeficiente de contingencia, C de Pearson, se calcula del siguiente modo a partir del puntaje \\(\\chi^{2}\\): \\[C = \\sqrt{\\frac{\\chi^{2}}{\\chi^{2} + n}}\\] Al igual que \\(\\varphi\\), este coeficiente no puede ser menor que cero (0) y solo toma ese valor si las variables son independientes (es decir cuando \\(\\chi^{2} = 0\\)). Tampoco puede ser mayor que uno (1), pero su valor máximo depende de la dimensión de la tabla. Solo en el caso particular en que la tabla sea cuadrada (misma cantidad de filas que de columnas), el valor máximo del coeficiente es: \\(C_{\\max} = \\sqrt{\\frac{f - 1}{f}}\\) , o lo que es lo mismo : \\(C_{\\max} = \\sqrt{\\frac{c - 1}{c}}\\) Porque nos referimos a tablas cuadradas, en las que \\(f=c\\). Si la tabla no es cuadrada, sino de dimansión \\(f X c\\), el valor máximo es: \\[C_{\\max} = \\sqrt{\\frac{\\min(f,c) - 1}{min(f,c)}}\\] En la que \\(min(f,c)\\) es el más chico de los dos números \\(f\\) o \\(c\\). De este modo se obtiene un coeficiente que indica el grado de la asociación entre dos variables que es apto para tablas de cualquier dimensión, no solo para las de \\(2 \\times 2\\), por lo que mejora lo que mide el coeficiente Q de Kendall - Yule. Reemplacemos los valores para el ejemplo anterior: \\[C = \\sqrt{\\frac{\\chi^{2}}{\\chi^{2} + n}} = \\sqrt{\\frac{50,19}{50,19 + 500}} = 0,30\\] Para decidir si este resultado es alto o bajo, es decir, si la relación es fuerte o débil, calculemos el máximo que podría haber alcanzado para una tabla de 3X3: \\[C_{\\max} = \\sqrt{\\frac{f - 1}{f}} = \\sqrt{\\frac{3 - 1}{3}} = \\sqrt{\\frac{2}{3}} = 0,82\\] Entonces el valor que hemos encontrado es moderado, y nos indica que la relación entre el tipo de violencia y el tamaño de las ciudades no es intensa. El tercer (y último) coeficiente que calcularemos para variables nominales está también basado en el puntaje \\(\\chi^{2}\\) y tiene un valor máximo de 1 (uno). Se llama coeficiente V de Cramer y se calcula así: \\[V = \\sqrt{\\frac{\\chi^{2}}{n*min(f - 1, c - 1)}}\\] La expresión \\(min(f-1, c-1)\\), tiene el mismo significado que en \\(C_{max}\\), es mínimo entre el número de filas menos uno y el número de columnas menos uno. Para obtenerlo se resta 1 al número de filas, luego se resta 1 al número de columnas y se elige el menor de los dos. Si la tabla es de \\(3 \\times 2\\) se hace \\(3 - 1 = 2\\) y \\(2 - 1 = 1\\), entre 2 y 1 el mínimo es 1 y ése es el número que ubicamos en el denominador, multiplicando a \\(n\\). En este ejemplo, las filas y las columnas son tres, por lo que se toma el mínimo entre \\(3-1\\) y \\(3-1\\), el resultado es 2, y el coeficiente V de Cramer resulta: \\[V = \\sqrt{\\frac{\\chi^{2}}{n*min(f - 1,c - 1)}} = \\sqrt{\\frac{50,19}{500*min(3 - 1,\\ 3 - 1)}} = \\sqrt{\\frac{50,19}{500*2}} = 0,22\\] Como el valor máximo que puede alcanzar este coeficiente es 1 (uno), en este caso se trata de una relación moderada entre las dos variables. 5.2 Variables de nivel ordinal Si nuestro problema es el de describir la relación entre variables cuyas categorías están ordenadas, es decir variables ordinales, los coeficientes anteriores son válidos: pero como sucedió con las medidas descriptivas, el mayor nivel de medición permite calcular coeficientes más elaborados y que, por esa razón, informen más acerca de la relación entre las variables que se analizan. Un punto a tener en cuenta es que cuando se trata con dos variables, la del menor nivel de medición es la que manda. Así, para relacionar una ordinal y una nominal, debe usarse un coeficiente V o C, como si fueran las dos nominales. Si las dos variables son ordinales o si una es ordinal y la otra intervalar o proporcional, es posible calcular un coeficiente que tiene en cuenta los “rangos” es decir la posición de cada categoría respecto de las demás, su carácter de primera, segunda, etc., es decir, el orden. Sea el problema de indagar por la relación que podría haber entre el resultado que obtienen los alumnos al rendir un examen de ingreso a una carrera y el nivel de educación de sus madres, consideraremos como variables el nivel máximo de educación de la madre de cada uno y el orden de mérito alcanzado en el ingreso a esa carrera; ambas variables son ordinales. Tratemos solo la situación de pocos casos por ahora. Si para el orden de mérito codificamos como 1, 2, 3, …, el primer lugar en el ingreso, el segundo, etc. y para la educación de la madre usamos 1 = universitario completo, 2 = universitario incompleto, etc., entonces el fragmento de la matriz de datos para 8 observaciones tendría una forma como esta: OM educamadre 1 2 2 2 3 3 4 2 5 3 6 4 7 5 8 3 Que está ordenada según los valores de la primera variable (orden de mérito). A estos datos no conviene presentarlos en una tabla de doble entrada, porque cada orden de mérito corresponde a un único individuo, por lo que resultaría una tabla tan poco resumida como la siguiente: Tabla 5.5: Distribución conjunta de las frecuencias del orden de mérito en el ingreso a una carrera universitaria y el nivel de educación de la madre. 2 3 4 5 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 Esta tabla no es útil, ya que tiene tantas filas como la matriz de datos (porque cada orden de mérito corresponde a una sola persona), hay solo un caso en cada celda no vacía y hay muchas celdas vacías (con frecuencia cero). Por eso, cuando se trata de variables de este nivel de medición, no se usan tablas de doble entrada para representar los datos, solo se calcula un coeficiente que indique la intensidad de la relación. Este coeficiente se llama coeficiente de correlación por rangos, de Spearman y para calcularlo hay que transformar los valores de las variables en rangos, de mayor a menor, de manera que al máximo valor de cada variable corresponda el 1, al siguiente el 2 y así sucesivamente. En nuestro ejemplo, el orden de mérito ya está en rangos, uno para el primero, dos para el segundo y un rango para cada persona. No es así para el nivel de educación, ya que varias personas pueden tener el mismo, a esta variable la transformaremos en rangos. El mayor nivel de educación observado es 2 (universitario incompleto) a ese valor le correspondería el rango 1 (uno), pero hay tres madres con ese nivel de educación, ellas deberían llevar los rangos 1, 2 y 3, como están empatadas, les asignamos a todas el promedio de los tres rangos: 2. Luego sigue el nivel de educación 3 (secundario completo) a quien deberíamos asignar el rango 4, pero acá también hay empate entre tres casos, corresponderían los rangos 4, 5 y 6, nuevamente usamos el promedio de los tres rangos para asignar a los tres el mismo: 5. Sigue el nivel 4 (secundario incompleto), al que asignamos el rango siguiente: 7, ya que hay solo un caso aquí; y lo mismo pasa con el nivel 5 (primario completo) al que le toca rango 8. Resumiendo entonces, la transformación de los valores de las variables en rangos resulta así: Orden de mérito en el ingreso Rango del orden de mérito Educación de la madre Rango de la educación de la madre 1 1 2 2 2 2 2 2 3 3 3 5 4 4 2 2 5 5 3 5 6 6 4 7 7 7 5 8 8 8 3 5 No ha sido necesario transformar los valores del orden de mérito, porque ya correspondían uno a cada sujeto. Una vez construidos los rangos, se observa, para cada caso la diferencia entre el rango de una variable y de la otra, esas diferencias se llamarán \\(d\\). Tabla 5.6: Cálculo de las diferencias entre los rangos de dos variables ordinales Rango del orden de mérito Rango de la educación de la madre \\(d\\) 1 2 -1 2 2 0 3 5 -2 4 2 2 5 5 0 6 7 -1 7 8 -1 8 5 3 Estas diferencias indican la distancia que hay entre los dos ordenamientos, si fueran ambos iguales (si el máximo de uno coincidiera con el máximo del otro y así en todas las categorías), tendríamos una asociación perfecta entre las dos variables. Por el contrario si el orden estuviese exactamente invertido (si el rango máximo de una variable coincidiera con el rango mínimo de la otra y así en las demás) la relación también sería perfecta, pero inversa. La intensidad de la relación se mide entonces con el que hemos llamado coeficiente se Spearman, la expresión de su cálculo es la siguiente: \\[r_{s} = 1 - \\frac{6*\\sum_{i = 1}^{n}d_{i}^{2}}{n^{3} - n}\\] En la que: \\(d_{i}\\) son las diferencias de rangos (calculadas en la última columna de la tabla de arriba) que en la fórmula van elevadas al cuadrado. La sumatoria indica que ésta va desde la primera de las diferencias (\\(i=1\\)) hasta la última (\\(n\\)). \\(n\\) es el número total de observaciones. Este coeficiente puede ser positivo o negativo y tiene un campo de variación igual al del Q de Kendall - Yule, es decir, entre \\(-1\\) y 1, es decir: \\[- 1 \\leq r_{s} \\leq 1\\] Al igual que el coeficiente de Kendall - Yule, los valores próximos a 1 ó a \\(-1\\) se interpretan como propios de una asociación fuerte (intensa) y los cercanos a 0 (cero), sean positivos o negativos, corresponden a asociaciones débiles. Si un coeficiente vale 1 ó \\(-1\\) diremos que la asociación es perfecta, pero eso no es algo que suceda en la realidad, del mismo modo que si el coeficiente es exactamente 0 (cero), la asociación será nula y otra vez es muy poco común que eso suceda con datos reales. A diferencia de los coeficientes usados para variables nominales, ahora el signo importa: cuando es positivo da cuenta de una relación directa entre las dos variables, una relación en la que cuando una aumenta, la otra también lo hace. Si el coeficiente es negativo indica relación inversa, el crecimiento de una variable se acompaña del decrecimiento de la otra. En este nivel de medición (ordinal) podemos hacer estos juicios, podemos decir “aumenta” o “disminuye”, porque las categorías están ordenadas, por esa razón podemos analizar no solo la intensidad de la relación, sino también si se trata de una relación directa o inversa. Se trata de dos características independientes de cada relación: puede ser fuerte y directa; o fuerte e inversa; o bien débil y directa; o débil e inversa. Un error muy frecuente es creer que si el coeficiente es negativo, la relación es débil, no es así. Es débil si el coeficiente es cercano a 0 (cero), es igualmente débil si \\(r_s=0,03\\) como si \\(r_s=-0,03\\), el signo del coeficiente no aporta para saber si es fuerte o débil. Del mismo modo es igual de fuerte una relación en la que \\(r_s=0,96\\) como una en la que \\(r_s=-0,96\\). Para obtener el valor del coeficiente en nuestro ejemplo, vamos primero a calcular las \\({d_{i}}^{2}\\): Rango del orden de mérito Rango de la educación de la madre \\(d\\) \\(d_i^2\\) 1 2 -1 1 2 2 0 0 3 5 -2 4 4 2 2 4 5 5 0 0 6 7 -1 1 7 8 -1 1 8 5 3 9 Por lo que la suma de la última columna es 20. Al reemplazar los valores en la expresión de , obtenemos: \\[r_{s} = 1 - \\frac{6*\\sum_{i = 1}^{n}d_{i}^{2}}{n^{3} - n} = 1 - \\frac{6*20}{8^{3} - 8} = 1 - \\frac{120}{512 - 8} = 1 - \\frac{120}{504} = 0,76\\] Este valor de \\(r_{s} = 0,76\\), indica una asociación intensa y positiva entre la educación de la madre y los resultados del ingreso a la universidad. Que sea positiva quiere decir que los alumnos con madres de mayor educación obtienen mejores resultados en el ingreso a esa carrera. Como ya hemos señalado, esto no quiere decir causalidad, no significa que la causa del resultado en el ingreso sea la educación de la madre. El problema de la causalidad es teórico y depende del análisis que se hace de las relaciones entre los conceptos, en este ejemplo, la educación de la madre es uno de muchos de los factores interrelacionados, que inciden sobre el resultado que obtiene el alumno. Este coeficiente (como sucede con todos los coeficientes de asociación) no revelan la causalidad sino lo frecuente que resulta que los cambios de una variable se vean acompañados de cambios en la otra. Para ilustrar con otros ejemplos de relaciones entre variables ordinales, sea que se pone en correspondencia el ranking de temas musicales de una semana con la frecuencia con que cada tema es reproducido en la radio, esperamos hallar que la relación sea muy fuerte y directa: los temas de mayor posición en el ranking son también los que más frecuentemente se pasan en la radio. Al revés, en la relación entre el rating de los programas de televisión y el contenido cultural que ofrecen esperamos una relación también fuerte, pero ahora inversa: los de mayor rating son habitualmente lo que menos contenido cultural tienen. Este coeficiente es adecuado, no solo cuando las variables son ordinales, sino cuando son cuantitativas (intervalares o proporcionales) pero existen casos atípicos, que afectarían el cálculo de otro coeficiente que se verá a continuación. Para que la interpretación del coeficiente de Spearman sea correcta, es necesario de las variables guarden entre sí una relación directa o inversa, en todo su conjunto de valores, es decir, que la relación sea monótona creciente o decreciente. 5.3 Nivel intervalar o proporcional Si tratamos con variables intervalares o proporcionales, podríamos usar los procedimientos que referimos antes para el cálculo de la intensidad de las relaciones entre variables nominales. Para ello, deberíamos construir intervalos y tratarlos como las categorías de las dos variables. De ese modo, perderíamos la información que provee una variable cuantitativa. Por ejemplo, si disponemos de un conjunto de personas adultas de las que sabemos la edad a la que cada una se casó (o unió) por primera vez y los años de escolarización, y nos interesamos por la relación entre estas dos variables. La matriz de datos para estas dos variables en 13 casos es: edad.union escolarizacion edad.union.3 escolariz.3 18 10.0 (17,23] (9.99,13.3] 17 12.0 (17,23] (9.99,13.3] 25 10.5 (23,29] (9.99,13.3] 19 11.5 (17,23] (9.99,13.3] 23 18.0 (17,23] (16.7,20] 20 14.0 (17,23] (13.3,16.7] 18 15.5 (17,23] (13.3,16.7] 20 12.0 (17,23] (9.99,13.3] 24 13.0 (23,29] (9.99,13.3] 24 15.0 (23,29] (13.3,16.7] 26 16.0 (23,29] (13.3,16.7] 30 18.0 (29,35] (16.7,20] 35 20.0 (29,35] (16.7,20] Si se intenta construir una tabla de doble entrada para estas dos variables, el problema es aún mayor que con las ordinales, dado que habría un gran número de filas y de columnas, y resultaría casi imposible de leer. Además, muchas celdas estarían vacías y habría muy pocos casos en cada una de las restantes. Los trece datos de la matriz anterior quedarán, en una tabla de doble entrada, así: Tabla 5.7: Distribución conjunta de los años de escolarización y la edad a la que se realizó la primera unión conyugal 10 10.5 11.5 12 13 14 15 15.5 16 18 20 17 0 0 0 1 0 0 0 0 0 0 0 18 1 0 0 0 0 0 0 1 0 0 0 19 0 0 1 0 0 0 0 0 0 0 0 20 0 0 0 1 0 1 0 0 0 0 0 23 0 0 0 0 0 0 0 0 0 1 0 24 0 0 0 0 1 0 1 0 0 0 0 25 0 1 0 0 0 0 0 0 0 0 0 26 0 0 0 0 0 0 0 0 1 0 0 30 0 0 0 0 0 0 0 0 0 1 0 35 0 0 0 0 0 0 0 0 0 0 1 Nuevamente, esta no es una tabla adecuada para representar estos datos y sería más legible con las categorías agrupadas: Tabla 5.8: Distribución conjunta de los años de escolarización y la edad a la que se realizó la primera unión conyugal (categorías agrupadas) (9.99,13.3] (13.3,16.7] (16.7,20] (17,23] 4 2 1 (23,29] 2 2 0 (29,35] 0 0 2 Ahora la tabla se lee con más facilidad y podemos tratarla como hicimos antes, como si fueran nominales y calcular un puntaje chi cuadrado y coeficientes C de Pearson y V de Cramer, o bien, como los intervalos están ordenados, poner una ranking y calcular el coeficiente de Spearman. Sin embargo, al hacer esto, se trata como si se hubiesen unido a la misma edad todas las personas que están entre 18 y 23.7 años. Del mismo modo, se trata como iguales a quienes tienen escolariación entre 10 y 13 años, no se puede distinguir entre quienes estudiaron 11, 12, 13 años: al interior del intervalo todos son considerados iguales. Además de esto, se pierden las posibilidades de análisis que ofrecen las variables cuantitativas. Para poder mantener las variables con sus verdaderos valores (sin agrupar) y tener al mismo tiempo una representación abreviada de los datos, existe un recurso muy valioso: una representación gráfica de los valores que se denomina diagrama de dispersión. Figura 5.1: Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal Este gráfico usa los ejes cartesianos para indicar los valores de las dos variables que estamos analizando y representa con un punto cada concordancia de dos categorías que puede corresponder a un caso o a varios. Cada punto es un par ordenado: el primer número son los años de escolarización y el segundo la edad a la que se unió por primera vez. Los ceros de la tabla 5.7 ya no aparecen en este diagrama. El primer punto de la izquierda corresponde a alguien que alcanzó 10 años de escolarización y se unió a los 18 años de edad. Lo que eran filas y columnas en todas las tablas mostradas hasta aquí, son ahora ejes coordenados, porque ya no se trata con categorías separadas de cada variable sino con valores cuantitativos de las variables que ahora son intervalares o proporcionales. Estos ejes se llaman ordenadas el vertical y abscisas el horizontal. En el ejemplo están representados los valores de los años de escolarización en el eje de las abscisas (primer elemento de cada par ordenado) y la edad a la primera unión en el eje de las ordenadas (segundo elemento de cada par). La manera en que los puntos se distribuyen en el diagrama de dispersión nos da una primera aproximación a la relación entre las dos variables. Así, en el caso del ejemplo, hay una cierta tendencia creciente, en la que se vería que globalmente, las personas con más años de escolarización tenderían a unirse más tardíamente. Esta observación es equivalente a ver la concentración de casos en las celdas de la diagonal de una tabla bivariada. Por el contrario, si los datos se dispersan de este otro modo: Figura 5.2: Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal (relación débil) No hay ninguna razón para creer que las variables estén relacionadas: los puntos no muestran una tendencia clara. Una asociación más acentuada entre las mismas dos variables se observa en el siguiente diagrama de dispersión: Figura 5.3: Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal (relación intensa) En el que la tendencia lineal es más clara, por lo que resulta más definido el efecto de la escolarización sobre la edad a la que se produce la primera unión. Aquí, la nube de puntos está más aplanada que en el ejemplo anterior; en efecto, en el gráfico 5.2 la nube de puntos tiene forma más circular que en el 5.3, donde es más elíptica. El ejemplo que hemos mostrado hasta aquí corresponde a una relación directa: más años de escolarización parecen asociarse con edades más tardías para la primera unión. De manera equivalente pueden representarse relaciones inversas. Consideremos el caso de la ansiedad frente a los exámenes y la calificación que se obtiene. En un estudio realizado por el Laboratorio de Evaluación Psicológica y Educativa (LEPE, Facultad de Psicología UNC) se observó que a mayor puntaje en una prueba de ansiedad ante los exámenes, menor rendimiento académico (arrobafurlán2014), por lo que la relación entre las variables es inversa. Los esquemas siguientes muestran el achatamiento de la nube de puntos según la relación sea más fuerte o más débil y según sea directa o inversa. Figura 5.4: Comparación de la forma de las nubes de puntos según la intensidad de la relación La intensidad de la relación está vinculada al achatamiento de la elipse que rodea la nube de puntos y éste al grado de alineación que los puntos tengan. Luego volveremos sobre esta idea. Solo nos ocuparemos de relaciones como las que acabamos de ejemplificar: aquellas en las que la tendencia es creciente o decreciente, pero siempre siguiendo un camino parecido a una línea recta. Son las que llamaremos relaciones lineales. No son la únicas que existen; solo a modo de ilustración, veamos cómo se representa la relación entre la edad de las personas y la frecuencia con que consultan al médico. Estas dos variables son tales que, en términos muy generales y sin considerar situaciones específicas, para valores pequeños de la primera (en la infancia) las consultas son frecuentes, luego se reducen durante la adultez para volver a incrementarse en la vejez. Por eso el gráfico que las representa tiene la siguiente forma aproximada: Figura 5.5: Diagrama de dispersión del número medio de consultas médicas anuales y la edad. Este conjunto de puntos muestra una tendencia no lineal, eso no implica que las variables no estén relacionadas; por el contrario, la relación existe, pero no es lineal. Estos puntos, en lugar de ser aproximados por una línea recta, lo serían con una curva con forma de parábola. No nos ocuparemos aquí de relaciones no lineales. Limitaremos nuestro análisis a relaciones lineales, debido a que es muy frecuente usarlas como primera aproximación a la forma que tiene la relación entre dos variables y porque a menudo, cuando se trabaja con relaciones no lineales, es posible realizar transformaciones de las variables para lograr relaciones lineales. Para analizar la intensidad de la relación lineal entre dos variables (ambas medidas a nivel intervalar o proporcional) calcularemos un coeficiente comparable a los que hemos visto hasta aquí, que tendrá una interpretación similar a la del coeficiente de correlación por rangos de Spearman. Este coeficiente se llama coeficiente de correlación r de Pearson y es uno de los de mayor utilización cuando las variables que se analizan alcanzan el nivel de medición que autoriza su cálculo. Este coeficiente va a medir qué tan bien se puede aproximar el conjunto de puntos con una función lineal y va a depender de lo que antes llamamos el “achatamiento” de la elipse. Será grande (próximo a 1 ó a \\(-1\\)) si las variables están muy relacionadas linealmente, es decir, si la nube de puntos se elonga hacia una línea; y será pequeño (próximo a cero) si las variables guardan poca relación lineal, es decir si la nube de puntos tiene forma redondeada. Será positivo y elevado (próximo a 1) si valores pequeños de una variable están acompañados de valores pequeños de la otra y valores grandes de una siguen a valores grandes de la otra, como sucedió en el ejemplo del gráfico 5.3. Será negativo y elevado (próximo a \\(-1\\)) si los valores grandes de una de las variables acompañan a los pequeños de la otra y viceversa, como en el gráfico ref(fig:cual). La correlación será perfecta positiva (\\(r = 1\\)) si todos los puntos se ubican sobre una recta creciente: Figura 5.6: Ejemplo de situación ideal con todas las observaciones alineadas en una recta creciente, por lo que \\(r = 1\\) Y será perfecta negativa (\\(r = - 1\\)) si todos los puntos se ubican sobre una recta decreciente: Figura 5.7: Ejemplo de situación ideal con todas las observaciones alineadas en una recta decreciente, por lo que \\(r = - 1\\) Ambas son situaciones ideales que no se encuentran en la realidad, constituyen el límite de la intensidad que pueden alcanzar las relaciones lineales directas o inversas. Las unidades en que se miden las variables que se relacionan pueden ser muy diferentes, en el ejemplo de ansiedad y resultado de los exámenes, la primera se puede medir en una escala de cero a cien y la segunda de cero a diez, por lo que un valor elevado de la primera sería 95 y uno elevado de la segunda, 9. Esto impide que se comparen directamente los valores grandes con los grandes y los pequeños con los pequeños. Vamos a usar un recurso que ya fue presentado: las puntuaciones z, aquellas que indican a cuántas desviaciones estándar se encuentra cada observación de la media. Son los puntajes que permiten decidir si se trata de un valor grande (muy superior a la media) o pequeño (muy inferior a la media) o intermedio (semejante a la media), sin tener unidades, por lo que permite la comparación de elementos que pueden tener cualquier unidad de medida. Recordemos que para los valores bajos de la variable (menores a la media), el puntaje z es negativo y es positivo para los valores altos (superiores a la media). Si dos variables están correlacionadas positivamente (altos con altos y bajos con bajos), entonces sus puntajes z se corresponderán positivos con positivos y negativos con negativos. Si para cada sujeto multiplicamos los puntajes z de las dos variables que se relacionan, obtendremos siempre un resultado positivo, ya sea porque multiplicamos dos números positivos (\\(+\\times+=+\\)) o dos negativos (\\(-\\times-=+\\)). Si luego sumamos esos productos para todos los sujetos obtendremos un número alto positivo. A la inversa, si dos variables se correlacionan negativamente los productos de sus puntajes z serán negativos, porque los valores altos de una irán con los bajos de la otra (que equivale a z positivos con z negativos, y \\(+\\times-=-\\)) y bajos con altos (que es lo mismo que z negativos con z positivos y \\(-\\times+=-\\)). Cuando sumemos estos productos para todos los casos tendremos un número alto y negativo. Si las variables no estuvieran correlacionadas, habría casos en el que un valor alto de una variable se acompaña de uno alto de la otra y casos en que un valor alto va seguido de uno bajo, algunos productos de z serían positivos y otros negativos y entonces, al sumarlos, obtendríamos un número bajo, que puede ser positivo o negativo, pero será cercano a cero. Entonces el producto de las puntuaciones z ofrece un resultado que será: alto y positivo si las variables tienen una correlación fuerte y directa alto y negativo si la correlación es fuerte e inversa cercano a cero si no están correlacionadas Haciendo uso de este razonamiento, el coeficiente de correlación de Pearson se calcula como29: \\[r = \\frac{\\sum_{i = 1}^{n}{z_{x_{i}}*z_{y_{i}}}}{n - 1}\\] Donde \\(z\\) representan los desvíos estándar de las variables \\(x\\) e \\(y\\), \\(n\\) es el total de observaciones y los subíndices \\(i\\) corresponden a cada una de ellas. El signo de suma señala que ésta debe extenderse desde el primer caso (\\(i=1\\)) hasta el último (cuando \\(i=n\\)). Como en el caso del coeficiente de Spearman, el campo de variación del coeficiente de Pearson es el intervalo \\(-1\\), 1. Para el cálculo del coeficiente de Pearson, no es necesario que las dos variables tengan las mismas unidades, porque se usan los puntajes \\(z\\), que carecen de unidades. No hay inconveniente en correlacionar el peso (en kilogramos) con la talla (medida en centímetros). A continuación, se presenta un ejemplo de cómo calcular el coeficiente de correlación de Pearson para evaluar la relación entre dos variables. Las variables seleccionadas para el ejemplo son: 1) puntaje obtenido en una escala de inteligencia lógico-matemática y 2) cantidad de ejercicios correctamente realizados en una prueba de matemática. El fragmento de la matriz de datos correspondiente es el siguiente: puntaje.escala ejercic.corr 46 7 44 2 56 7 57 8 30 2 60 9 45 5 43 1 64 9 32 3 Una vez que se ha obtenido la media y desviación estándar de las medidas del puntaje en la escala de inteligencia lógico-matemática (\\(\\overline{x} = 47,7\\) \\(s_{x} = 11,44\\)) y de cantidad de ejercicios matemáticos correctamente realizados (\\(\\overline{y} = 5,3\\) \\(s_{y} = 3,09\\)), se deben convertir las observaciones brutas en puntuaciones z. Para ello se calcula la diferencia entre la puntuación bruta original y la media del grupo, y el resultado de esta operación se divide por la desviación estándar del grupo. La transformación a puntaje z se obtiene como vimos antes: Para el puntaje en inteligencia lógico - matemática (x), \\[z_{x} = \\frac{x - \\overline{x}}{s_{x}}\\] Para la cantidad de ejercicios correctamente realizados (y), \\[z_{y} = \\frac{y - \\overline{y}}{s_{y}}\\] Entonces, el puntaje z del sujeto 1 para cada escala se obtiene de la siguiente manera: \\[z_{x_{1}} = \\frac{46 - 47,7}{11,44} = - 0,15\\] \\[z_{y_{1}} = \\frac{7 - 5,3}{3,09} = 0,55\\] Y del mismo modo para cada uno de los sujetos observados, para obtener la siguiente tabla: Sujetos Puntaje escala inteligencia lógico-matemática \\(z_{x}\\) Ejercicios correctamente realizados \\(z_{y}\\) \\(z_{x}*z_{y}\\) 1 -0.15 0.55 -0.08 2 -0.32 -1.07 0.35 3 0.73 0.55 0.40 4 0.81 0.87 0.71 5 -1.55 -1.07 1.65 6 1.08 1.20 1.29 7 -0.24 -0.10 0.02 8 -0.41 -1.39 0.57 9 1.42 1.20 1.70 10 -1.37 -0.74 1.02 El numerador del coeficiente r de Pearson se obtiene sumando la última columna: \\[\\sum_{}^{}{z_{x}*z_{y} = 7,63}\\] y solo queda dividir este número por \\(n-1=10-1=9\\) para obtener \\(r = 0,85\\). El coeficiente dio positivo, lo que indica que la relación es directa. Como se habría esperado: las personas con mayor puntaje en la escala de inteligencia lógico-matemática, son quienes tienen una mayor cantidad de ejercicios correctamente realizados. Además, el valor \\(0,85\\) es elevado, lo que indica que la relación entre las dos variables es intensa. La decisión acerca de considerar como grande o pequeño al valor de un coeficiente de asociación o de correlación depende del tipo de variable con que se esté trabajando y en especial de la forma en que son medidas esas variables. En buena medida, el uso de estos coeficientes es comparativo y puede ser muy valioso saber si una variable se asocia (o se correlaciona) más con una que con otra. Cuando tratamos de explicar un fenómeno y formulamos hipótesis sobre varios factores, es útil saber cuáles de ellos se asocian más intensamente con ese fenómeno. Se han establecido algunos valores de referencia, según los cuales la correlación se considera nula si \\(r &lt; 0,10\\), pequeña si \\(0,10 \\leq r &lt; 0,30\\), media si \\(0,30 \\leq r \\leq 0,50\\) y grande si \\(r &gt; 0,50\\). Coincidimos con arrobaCohen(1988), en que estos criterios son un tanto arbitrarios y siempre debe considerarse al coeficiente de correlación en contexto. Para poder interpretar el coeficiente de Pearson, se requiere que las variables guarden entre sí una relación lineal, de lo contrario, la interpretación como intensidad de la relación es incorrecta. Además, este coeficiente se ve afectado por valores extremos, es decir aquellos que se apartan de la tendencia mayoritaria, por lo que si éstos existen convienen calcular el coeficiente de Spearman. Ambas situaciones, tendencia lineal o no, y existencia o no de casos atípicos pueden verse en el diagrama de dispersión. Cuando la relación entre dos variables es lineal, el coeficiente de Pearson da una interpretación más detallada de la incidencia de una variable sobre la otra. Cuando este coeficiente se eleva al cuadrado, se obtiene un número que se llama coeficiente general de determinación, que se indica como \\(R^{2}\\) y que mide la parte de la varianza que es compartida por las dos variables. Esta interpretación puede no ser clara en este momento, y volveremos sobre ella hacia el final del capítulo. Cuando la relación es asimétrica y una variable opera como antecedente y la otra como consecuente, el coeficiente general de determinación mide la parte de la varianza de la variable consecuente que se explica por la antecedente. O bien la parte de la variabilidad de la variable dependiente que puede atribuirse a la variable independiente. Así, en nuestro ejemplo: \\(R^{2} = {0,85}^{2} = 0,72\\), lo podemos indicar como 72% y quiere decir que el 72% de la variabilidad total que aparece en el número de ejercicios correctamente realizados, se explica por el puntaje alcanzado en la escala de inteligencia lógico matemática. Así, con este coeficiente identificamos la magnitud del aporte que una variable hace a explicar los cambios de la otra. Los hechos que se observan obedecen a una multiplicidad factores explicativos, por esa razón es muy valioso disponer de un coeficiente como \\(R^{2}\\), que mide qué parte de los cambios en lo observado pueden atribuirse a un determinado factor explicativo. En el apartado siguiente volveremos sobre el coeficiente general de determinación en una aplicación más general. 5.4 Dicotomías reales y artificiales Cuando se trabaja con variables dicotómicas, estas pueden tener dos orígenes diferentes; hay dicotomías reales y las hay artificiales. Las primeras son variables que por su construcción, solo admiten dos categorías, como turno (mañana - tarde), sexo (varón - mujer), grupo (experimental - control). Las segundas, provienen de haber recategorizado una variable continua en dos grupos, como puntaje (alto - bajo), ingresos medidos según línea de pobreza (pobre - no pobre), resultado de un examen (aprobado - no aprobado), posición política (izquierda - derecha). Esta situación es especialmente interesante en la medición de rasgos latentes a los que se considera continuos, pero que se miden de manera dicotómica. Por ejemplo, la actitud hacia la política, puede ir desde el desinterés completo hasta la participación activa, pudiendo identificarse graduaciones entre esos extremos. Si se usa la afiliación a un partido como indicador de participación, se toma una medida dicotómica (está afiliado - no está afiliado); esta dicotomización se considera artificial, porque se supone que es un punto de corte que define dos categorías en un continuo. La distición entre alumnos que promovieron y que no promovieron es una dicotomizacion sobre una variable originalmente continua: el promedio de las notas. Clasificar a los países en desarrollados y en vías de desarrollo, implica cortar en dos (dicotomizar) un conjunto de indicadores de desarrollo, que son continuos (PIB per cápita, educación, etc.). Lo cual es diferente de distinguir países con arsenal nuclear y sin arsenal nuclear, porque aquí no hay graduación entre las categorías, esta última es una dicotomía real. Cuando trata de dicotomías reales, el coeficiente \\(\\varphi\\) que ya se mencionó, es adecuado. Por el contrario, en los análisis de la intensidad de la asociación entre dos variables que han sido dicotomizadas de manera artificial a partir de una variable que se considera continua, se usa una estimación del coeficiente de Pearson que habría resultado si las variables no hubieran sido dicotomizadas y hubiese entre ellas una relación lineal. El coeficiente para este caso se denomina coeficiente de correlación tetracórica, su cálculo requiere procedimientos matemáticos complejos, pero hay fórmulas aproximadas. Una de ellas es la siguiente \\[r_{tet} = \\cos(\\frac{\\pi}{1 + \\sqrt{\\frac{a*d}{b*c}}})\\] En la que a, b, c y d son las frecuencias absolutas de una tabla de \\(2 \\times 2\\) dispuestas así: a b c d El resultado de \\(r_{tet}\\) puede variar entre \\(-1\\) y 1, los valores más cercanos a 1 o a \\(-1\\) indican mayor intensidad en la asociación. Respecto del signo, es más claro no considerarlo en el coeficiente y observar en qué sentido se da la relación a partir de las frecuencias relativas calculadas en la tabla. Ejemplo a partir de la base bayley: para analizar la relación entre los puntajes en las subescalas mental y motora de la prueba de Bayley, se dicotomizan las dos variables en la media, asignando el valor 0 a quienes tienen puntajes inferiores a la media en cada subescala y uno a quienes superan a la media. Resulta así la tabla: 0 1 Total 0 139 102 241 1 102 200 302 Total 241 302 543 El cálculo del coeficiente de correlación tetracórico para esa tabla es: \\[r_{tet} = \\cos(\\frac{\\pi}{1 + \\sqrt{\\frac{139*200}{102*102}}}) = \\cos{(\\frac{\\pi}{2.63}) = 0,37}\\] Que indica una correlación moderada entre las variables. Como en este caso sí se dispone de los valores originales y la dicotomización se hizo a fines de ilustración, es posible calcularlo, su valor es 0,35. Pero si solo se hubiese contado con la dicotomía, el tetracórico es el único que puede calcularse. El coeficiente de Kendall - Yule es otra aproximación al coeficiente tetracórico. En este caso da \\(0,45\\), que es de peor calidad que la que se obtiene con la expresión anterior. Esta fórmula es aproximada, el cálculo exacto no puede hacerse manualmente, por lo que hay que usar programas informáticos. 5.5 Niveles de medición combinados Las operaciones que pueden hacerse a un nivel de medición son también válidas para los niveles superiores, pero no a la inversa; Por eso cada vez que haya variables con niveles de medición diferente, habrá que tener en cuenta el nivel más bajo para decidir qué coeficiente corresponde usar. Por ejemplo, la correlación entre una variable ordinal y una continua debe hacerse con el coeficiente de Spearman, porque las operaciones que este requiere se puede realizar tanto con variables ordinales como con continuas. Por el contrario, el coeficiente de Pearson requiere operaciones que no son válidas cunado la variable es ordinal. Sin embargo, hay algunos casos particulares que merecen mención. 5.5.1 Una variable dicotómica real y una proporcional La comparación de los valores de una variable continua entre dos grupos se trata como la correlación entre una variable dicotómica real (que define los grupos) y una continua. Allí, los grupos se codifican como cero y uno, y se calcula el coeficiente de Pearson entre las dos variables. Sin embargo, para esta situación existe un coeficiente específico, que se denomina punto biserial (\\(r_{pb}\\)). Su fórmula de cálculo conduce al mismo resultado que el coeficiente de Pearson, pero tiene en cuenta las medias de la variable continua y la proporción de casos en cada grupo, junto con la desviación estándar de la variable continua: \\[r_{pb} = \\frac{{\\overline{x}}_{1} - {\\overline{x}}_{0}}{s}*\\sqrt{p*(1 - p)*\\frac{n}{n - 1}}\\] Donde: \\({\\overline{x}}_{1}\\) Es la media de la variable en el grupo codificado como uno \\({\\overline{x}}_{0}\\) Es la media de la variable en el grupo codificado como cero \\(p\\) Es la proporción de casos que hay en grupo codificado como uno \\(n\\) Es el número total de observaciones y \\(s\\) Es la desviación estándar de la variable continua El signo de este coeficiente indica el sentido de la diferencia; es positivo cuando el grupo codificado como uno tiene valores más altos y negativo en el caso contrario. Su valor absoluto mide la magnitud de la relación entre las dos variables. Infostat® carece de un comando para solicitar este coeficiente, por lo que deben codificarse las categorías de la variable dicotómica como cero y uno y solicitar el coeficiente de Pearson. Ejemplo (datos ficticios): se comparan los puntajes alcanzados en una prueba por los individuos pertenecientes a los grupos experimental y control, y se obtienen estos valores: grupo puntaje control 8.0 control 5.0 control 6.0 control 5.0 control 6.0 control 8.0 control 6.0 experimental 4.0 experimental 5.6 experimental 5.6 experimental 8.0 experimental 7.2 experimental 6.4 experimental 7.2 experimental 8.0 experimental 8.0 experimental 7.2 Se toma como grupo de referencia (grupo 1) al experimental y resulta: \\({\\overline{x}}_{1} = 6.7\\) \\({\\overline{x}}_{0} = 6.3\\) \\(p = 0.59\\) \\(n = 17\\) \\(s = 1.27\\) La fórmula da: \\[r_{pb} = \\frac{6.7 - 6.3}{1.27}*\\sqrt{0.59*(1 - 0.59)*\\frac{17}{17 - 1}} = 0.1734\\] Que sea positivo indica que el grupo al que se codificó uno (el experimental) tiene puntajes medios más altos. Su valor absoluto señala una correlación pequeña entre la pertenencia a los grupos y los puntajes de la prueba. 5.5.2 Una variable continua dicotomizada y una proporcional Si la variable dicotómica proviene de la recategorización de una continua que se dividió en dos categorías, es decir, si la dicotomía es artificial y se supone que hay una variable latente continua, entonces el coeficiente que corresponde calcular es el llamado biserial \\(r_{b}\\). Como sucedió con el coeficiente de correlación tetracórico, se trata de una estimación del valor que tendría el coeficiente de Pearson si la variable no hubiese sido dicotomizada. \\[r_{b} = \\frac{{\\overline{x}}_{1} - {\\overline{x}}_{0}}{s}*\\frac{p*(1 - p)}{y}\\] Con la misma notación que se usó para el coeficiente \\(r_{pb}\\). Lo diferente es la \\(y\\) en el denominador, cuyo cálculo depende de la distribución normal, que se verá más adelante30. 5.6 Resumen de coeficientes de asociación Nivel de medición de las variables Coeficiente Rango de variación Lectura Ambas dicotómicas reales \\(\\varphi\\) (phi) de Yule \\([-1; 1]\\) No importa el signo, la relación es fuerte si es cercano a 1 ó a -1 y débil si está cerca de 0 Ambas dicotómicas provenientes de dos continuas recategorizadas tetracórico \\(r_{tet}\\) o bien Q de Kendall - Yule \\([-1; 1]\\) No importa el signo, la relación es fuerte si es cercano a 1 ó a -1 y débil si está cerca de 0 Ambas nominales de contingencia, C \\([0; C_{max}]\\) depende de la dimensión de la tabla Más intensa si es próximo a \\(C_{max}\\) Ambas nominales V de Cramer \\([0; 1]\\) Más intensa si es próximo a 1 Ambas ordinales o una ordinal y una proporcional \\(r_s\\) de Spearman \\([-1; 1]\\) El signo indica la dirección, positivo es directa, negativo es inversa. Fuerte si es cercano a 1 ó a \\(-1\\) y débil si está cerca de 0 Ambas proporcionales \\(r\\) de Pearson \\([-1; 1]\\) El signo indica la dirección, positivo es directa, negativo es inversa. Fuerte si es cercano a 1 ó a \\(-1\\) y débil si está cerca de 0 Una dicotómica real y una proporcional \\(r_{pb}\\) punto biserial \\([-1; 1]\\) Más intensa si es próximo a 1 o a \\(-1\\) Una dicotómica proveniente de una continua recategorizada y otra proporcional \\(r_b\\) biserial \\([-1; 1]\\) Más intensa si es próximo a 1 o a \\(-1\\) 5.7 Matriz de correlaciones A menudo resulta de interés observar grados de asociación entre más de dos variables, para ello, una disposición adecuada es la matriz de correlaciones. Se trata de una organización de las variables que se correlacionan, en filas y columnas; las variables se repiten en la primera fila y la primera columna, por lo que la matriz de correlaciones es cuadrada. La diagonal de la matriz tiene unos (1s), que indican la correlación perfecta de cada variable consigo misma. Las celdas que se encuentran por encima y por debajo de la diagonal muestran los coeficientes de correlación entre cada par de variables. Porque esos valores son idénticos, la matriz se llama simétrica. La matriz permite advertir patrones de asociación entre variables, es decir cuáles tienden a variar de manera más semejante. El siguiente ejemplo correlaciona simultáneamente las siguientes preguntas de Latinobarómetro: Para cada uno de los grupos, instituciones o personas de la lista ¿cuánta confianza tiene usted en ellas: mucha (1), algo (2), poca (3), ninguna (4) confianza en…? P14STGBS.A Las Fuerzas Armadas P14STGBS.B La policía/ Carabineros P14ST.C La Iglesia P14ST.D Congreso P14ST.E Gobierno P14ST.F Poder Judicial P14ST.G Los partidos políticos P14STGBS.A P14STGBS.B P14ST.C P14ST.D P14ST.E P14ST.F P14ST.G P14STGBS.A 1.00 0.57 0.19 0.27 0.34 0.38 0.26 P14STGBS.B 0.57 1.00 0.18 0.35 0.42 0.44 0.35 P14ST.C 0.19 0.18 1.00 0.22 0.16 0.18 0.14 P14ST.D 0.27 0.35 0.22 1.00 0.54 0.49 0.49 P14ST.E 0.34 0.42 0.16 0.54 1.00 0.55 0.50 P14ST.F 0.38 0.44 0.18 0.49 0.55 1.00 0.48 P14ST.G 0.26 0.35 0.14 0.49 0.50 0.48 1.00 Esta matriz de correlaciones muestra simultáneamente los coeficientes de correlación entre las siete variables seleccionadas. De las 49 celdas de la matriz, 7 están ocupadas con los unos de la diagonal. Las 42 restantes muestran los 21 coeficientes de correlación, repetidos por encima y por debajo de la diagonal. El coeficiente que se pidió es el de Spearman, porque los números codifican categorías ordinales. Esta matriz no es explicativa, no se identifican variables antecedentes y consecuentes, por eso se trata de una descripción del modo en que las respuestas a estas preguntas varían conjuntamente. La lectura de la matriz puede empezar señalando que todos los coeficientes son posivos. Eso quiere decir que los encuestados tomaron posición similar respecto de las diferentes instituciones por las que se les consultó, o que dieron respuestas no opuestas a las diferentes preguntas; quienes dijeron tener mucha confianza en algunas instituciones también la tienen por otras y a la inversa, quienes no confían en algunas, tampoco lo hacen en otras. Por ser relaciones descriptivas, nos informan que el conjunto de encuestados se caracteriza porque algunas personas tienden a confiar en estas instituciones y otras tienden a desconfiar de ellas. Nótese que este es un patrón posible, pero no el único. por ejemplo podría haber coeficientes negativos que indicarían que algunos pares de instituciones gozan de confianza inversa: quienes confían en unas, desconfían de otras. En segundo lugar, puede leerse que el valor más elevado, que es 0.57 corresponde a la asociación entre las Fuerzas Armadas y Policía. La intensidad, comparativamente elevada, de esta asociación indica que la confianza en ambas “va pareja”, de manera gruesa, podríamos decir que quienes confían en una de las dos instituciones, tienden a confiar también en la otra e inversamente, quienes desconfían de una también lo hacen de la otra. De manera similar se pueden analizar los demás pares de variables. En el otro extremo, la más tenue de las relaciones, con coeficiente de 0.14 es la de La Iglesia y Los partidos políticos. En este caso hay poca relación entre la confianza que se tiene a una y a la otra de estas dos instituciones. Se podría decir que son “relativamente independientes”. mucha (1), algo (2), poca (3), ninguna (4) 5.8 La forma de la relación En este apartado vamos a concentrarnos en relaciones asimétricas: aquellas en las que es posible identificar a una de las variables como antecedente y a la otra como consecuente (o como independiente y dependiente, en el marco de un diseño experimental). Se trata de relaciones que se dirigen a explicar una variable (la consecuente) a partir de los valores de la otra (la antecedente). Por ejemplo, cuando preguntamos si una droga es efectiva para tratar la depresión, buscamos la relación entre las diferentes dosis de la droga y la reducción de síntomas de la depresión, por ejemplo a través del puntaje alcanzado en una prueba que la evalúa. O también, si preguntamos por el efecto del nivel de ansiedad (variable antecedente) sobre los resultados que se obtienen en un examen (variable consecuente, a explicar), o el impacto de una campaña de vacunación (variable antecedente) sobre la frecuencia de casos de gripe o el tamaño del arsenal de un país como factor explicativo del riesgo de conflictos. Cuando las variables tienen nivel de medición proporcional, es posible representar la relación con un diagrama de dispersión y, como hemos visto, cuanto más intensa es la relación (coeficiente de correlación de Pearson cercano a 1), tanto más se aplana la nube de puntos, yendo hacia una tendencia lineal, aproximándose a una alineación a lo largo de una recta. En este apartado avanzamos un paso más en el análisis de la relación entre variables: cuando los puntos del diagrama de dispersión tengan una disposición semejante a una recta (creciente, como en el gráfico 5.3 o decreciente, como en el ref(fig:cual)), podremos buscar la función lineal que mejor aproxima esos puntos. Usaremos a partir de aquí una notación general: llamaremos x a la variable antecedente (o independiente) e y a la consecuente (o dependiente). Porque la relación se supone asimétrica, esperamos que x tenga efectos sobre y (la dosis de droga sobre la depresión, o la ansiedad sobre los resultados del examen, la cobertura de la campaña de vacunación sobre la prevalencia de gripe, la cantidad de armas y el riesgo de conflicto, en los ejemplos mencionados). Se trata de modelar la nube de puntos a través de una recta, como en el gráfico siguiente: Figura 5.8: Ejemplo de función lineal que aproxima los puntos con una tendencia creciente Aquí, la recta que aproxima los puntos está trazada de modo que equilibre lo que los puntos se apartan de ella por encima y por debajo. La búsqueda de esa función lineal implica proponer un modelo para la forma de la relación entre las dos variables, veremos cuán realista resulta suponer que las dos variables se relacionan de manera lineal. Antes de eso será necesaria una breve referencia a esta función. La función lineal tiene una expresión matemática como la siguiente \\(y = b_{0} + b_{1}*x\\) en la que x e y son las variables cuya relación analizamos y los números \\(b_{0}\\) y \\(b_{1}\\)son valores fijos que determinan cuál es la recta de la que hablamos. Hallar la recta implica encontrar esos dos números \\(b_{0}\\) y \\(b_{1}\\). Una vez que están determinados, se conoce la recta y se la puede trazar. 5.8.1 Ordenada al origen El número \\(b_{0}\\) se llama ordenada al origen y representa el valor de y cuando x vale cero. Eso puede verse fácilmente en la expresión de la recta cuando se reemplaza a x por cero, así se obtiene: \\[y = b_{0} + b_{1}*x = b_{0} + b_{1}*0 = b_{0}\\] Entonces, si \\(x = 0\\), tendremos \\(y = b_0\\). Como los ejes tienen el cero en el punto en que se cortan, gráficamente esta ordenada al origen se ubica sobre el eje y (por ser una ordenada), como indican las diferentes rectas en el gráfico siguiente. Figura 5.9: Ejemplos de funciones lineales con diferentes valores de la ordenada al origen Las rectas R1 y R3 tienen ordenada al origen positiva (\\(b_{0} &gt; 0\\)). La ordenada al origen de R3 es mayor que la de R1, porque su \\(b_{0}\\) está más arriba en el eje de ordenadas. A los efectos de la ordenada al origen, no hay ninguna diferencia en que R1 vaya subiendo y R3 baje. La recta R2 pasa exactamente por el origen de coordenadas, por lo que su ordenada al origen es cero, \\(b_{0} = 0\\). La recta R4, si se prolona para llegar a cortar al eje de ordenadas, lo hace en un valor negativo (\\(b_{0} &lt; 0\\)). Según las variables con que se trabaje, a veces \\(b_{0}\\) no tiene interés, porque no se consideran los valores negativos o bien porque no tiene sentido que la variable antecedente sea cero (\\(x=0\\)). En los ejemplos que hemos mencionado hay diferentes situaciones con respecto al valor de \\(b_{0}\\). En la relación dosis droga-depresión, el valor cero para la dosis es la no-administración de la misma. Aquellos sujetos que tienen \\(x = 0\\) son quienes no recibieron la droga y la ordenada al origen será el valor que hallemos en la escala de depresión (variable y) para quienes no tomaron la droga (a dosis cero). Por el contrario, no es posible considerar un valor cero de la ansiedad en el segundo ejemplo, por lo que allí no nos interesamos por la ordenada al origen. 5.8.2 Pendiente El otro número que determina de qué función lineal se trata, es \\(b_{1}\\) que se llama pendiente y gráficamente indica la inclinación de la recta: su valor es responsable de que la recta “suba” o “baje”, siempre mirándola de izquierda a derecha. Las rectas R1, R2 y R4 son crecientes, van aumentando hacia la derecha (a medida que x crece), por eso la pendiente es positiva (\\(b_{1} &gt; 0\\)). La recta R3 desciende, es una función decreciente, porque a medida que x aumenta y disminuye y la pendiente es negativa (\\(b_{1} &lt; 0\\)). Vemos entonces que la pendiente depende de que sea una relación directa o inversa. Cuando es directa, x crece e y crece y la pendiente es positiva; cuando es inversa, x crece e y disminuye y la pendiente es negativa. Esto es lo mismo que sucede con el coeficiente de Pearson: positivo indica relación directa y negativo, inversa. Por esta razón, \\(b_{1}\\) (la pendiente de la recta) siempre tiene el mismo signo de r, porque en ambos casos el signo indica si se trata de una relación directa o inversa. Además del gráfico, el significado analítico de la pendiente es muy importante, porque indica en cuánto varía y por cada unidad que aumenta x. El número \\(b_{1}\\) mide cuánto cambia la variable consecuente (dependiente), cuando la variable antecedente (independiente) cambia en una unidad. Como \\(b_{1}\\) puede ser positivo o negativo, el cambio en y puede ser en dirección de aumentar cuando x aumenta o de reducirse. En el ejemplo de la relación dosis droga-depresión, se esperaría que el valor de \\(b_{1}\\) fuera negativo, porque mide en cuánto se reduce la depresión (medida con el puntaje correspondiente a la escala que se use) por cada unidad que se aumente la dosis. Del mismo modo con la ansiedad y el resultado del examen, se espera que los sujetos con mayor ansiedad alcancen resultados menores en el examen, por lo que la relación se espera que sea inversa, con pendiente negativa y que la recta sea decreciente. Por el contrario, si observamos la relación entre las horas dedicadas al estudio -como variable antecedente- y el resultado del examen -como consecuente-, esperaríamos una relación directa, una pendiente positiva (\\(b_{1} &gt; 0\\)), una recta creciente que indica cómo aumenta el resultado del examen a medida que se dedican más horas al estudio. 5.8.3 Obtención de la recta de regresión Para encontrar \\(b_{0}\\) y \\(b_{1}\\) y determinar así la función lineal que corresponde a nuestra recta de regresión, deben usarse los puntos del diagrama, es decir los pares ordenados correspondientes a cada caso. Para hacerlo usaremos las fórmulas que mostramos a continuación pero, solo será para ver el modo de usarlas, luego lo pediremos a R. Llamando \\(x_i\\) e \\(y_i\\) a cada valor de cada par ordenado y n al número total de observaciones, la expresión para calcular la pendiente de la recta es: \\[b_1=\\frac{n*\\sum_{i=1}^{n}{x_i*y_i}-(\\sum_{i=1}^{n}x_i)*(\\sum_{i=1}^{n}y_i)}{n*\\sum_{i=1}^{n}x_i^{2}-(\\sum_{i=1}^{n}x_i )^{2}}\\] Una vez que conocemos la pendiente, se puede hallar la ordenada al origen haciendo: \\[b_{0} = \\overline{y} - b_{1}*\\overline{x}\\] Donde \\(\\overline{x}\\) e \\(\\overline{y}\\) son las medias de x y de y respectivamente. Vamos a aplicar estas expresiones para encontrar la función lineal que mejor ajusta los puntos del ejemplo en el que relacionamos el puntaje en la escala de inteligencia lógico-matemática con el número de ejercicios correctamente realizados. Tratamos de manera asimétrica a esta relación y tomamos al puntaje de la escala de inteligencia lógico-matemática como antecedente (x) y al número de aciertos como consecuente (y). Es decir que en nuestro modelo estamos tratando de explicar el número de aciertos a partir del puntaje en la escala de inteligencia lógico-matemática. Para facilitar el uso de la expresión del cálculo de la pendiente, agregamos dos columnas adicionales a los valores de las dos variables: la de los productos de cada x por cada y, y la de las x al cuadrado, del siguiente modo: \\(x_i\\) \\(y_i\\) \\(x_i*y_i\\) \\(x_i^2\\) 46 7 322 2116 44 2 88 1936 56 7 392 3136 57 8 456 3249 30 2 60 900 60 9 540 3600 45 5 225 2025 43 1 43 1849 64 9 576 4096 32 3 96 1024 Sumas de las columnas 477 53 2798 23931 Tenemos entonces \\[\\sum_{i=1}^{10}x_i=477\\] \\[\\sum_{i=1}^{10}y_i=53\\] \\[\\sum_{i=1}^{10}x_i*yi=2789\\] \\[\\sum_{i=1}^{10}x_i^{2}=23931\\] Reemplazando, obtenemos la pendiente de la recta: \\[b_1=\\frac{n*\\sum_{i=1}^{n}{x_i*y_i}-(\\sum_{i=1}^{n}x_i)*(\\sum_{i=1}^{n}y_i)}{n*\\sum_{i=1}^{n}x_i^{2}-(\\sum_{i=1}^{n}x_i )^{2}}= \\frac{10*2798-477*53}{10*23931-477^{2}}=\\frac{2699}{11781}=0.23\\] Esta pendiente es positiva, como lo había sido \\(r\\), y eso indica que la relación es directa. La pendiente además nos informa que por cada punto adicional en la variable antecedente (puntaje escala inteligencia lógico-matemática) se espera que se incremente en 0,23 el número de ejercicios bien resueltos. Las medias de \\(x\\) y de \\(y\\) habían sido calculadas cuando las necesitamos para r: \\(\\overline{x} = 47,7\\) e \\(\\overline{y} = 5,3\\) por lo que la ordenada al origen de la recta es: \\[b_0=\\bar{y}-b_1*\\bar{x}=5.3-0.23*47.7=-5.63\\] El valor de la ordenada al origen no tiene interés en este ejemplo -salvo para el trazado de la recta-, porque sería el número de aciertos esperado (que resultan negativos, es decir sin interpretación posible) para alguien con puntaje cero en la escala de inteligencia, lo cual no está definido. Conociendo la pendiente y la ordenada al origen, podemos escribir la ecuación de la recta: \\(\\widehat{y} = - 5,63 + 0,23*x\\). Esta es la función lineal que describe los cambios de y a partir de los de x. Hemos escrito a y con una indicación especial, un circunflejo: \\(\\widehat{y}\\), vamos a llamarla “y estimada” y es la que vamos a usar para trazar la recta: Figura 5.10: Diagrama de dispersión de la relación entre el puntaje en la escala de inteligencia lógico-matemática y el número de ejercicios de matemática correctamente realizados y la recta de regresión que mejor ajusta los puntos La recta que hemos encontrado usando las fórmulas de arriba es la que hace mínimos los cuadrados de las distancias de cada punto a la recta31, por eso, a esta también se la llama recta de mínimos cuadrados. Además de mostrarnos la forma del modelo, la recta de regresión sirve para hacer estimaciones de valores no observados, porque nos ofrece valores de \\(\\widehat{y}\\) para cada x que reemplacemos. Por ejemplo, si preguntamos por la cantidad de ejercicios bien resueltos que se esperan en alguien que alcanzó 55 puntos en la escala de inteligencia lógico-matemática, respondemos reemplazando en la función el valor de \\(x=55\\) y resulta: \\[\\widehat{y} = - 5,63 + 0,23*x = - 5,63 + 0,23*55 = 7,02\\] Que puede redondearse a 7. Este es el valor estimado del número de aciertos para alguien con 55 puntos en la escala de inteligencia lógico matemática. Estas estimaciones son muy valiosas para hacer predicciones sobre valores que no han sido observados, por ejemplo hacia el futuro. Ejemplos muy útiles de esta aplicación son las proyecciones de población, y más específicamente las de proyección de matrícula escolar, que ofrecen estimaciones del volumen de alumnos que se prevé para años próximos. Si se conoce la relación entre el peso de la deuda como porcentaje del PBI y el riesgo de crisis económica, se puede predecir el riesgo de crisis conociendo el porcentaje del PBI que representa la deuda. Cundo se cuenta con un modelo que explica la relación entre el monto de una transferenbcia condicionada de renta (como la AUH, ) sobre la propensión a buscar empleo por parte de jefes y jefas de hogar, se puede estimar el monto que permite cumplir con la condición del programa (controles de salud, escolarización), pero no desincentiva la búsqueda de empleo. En general, si se tiene un modelo que explica el comportamiento de una variable en base a las variaciones de otra, entonces se puede predecir qué sucederá con la primera para diferentes valores de la segunda. Los modelos que relacionan variables son diferentes según: la forma de la relación la cantidad de variables involucradas La primera puede provenir de una teoría, o de la observación del diagrama de dispersión. La segunda depende de las hipótesis; de cuántas y cuáles son las variables que participan en la explicación del fenómeno o proceso bajo análisis (resumido en la variable consecuente). Aquí nos ocuparemos por solo una de las formas posibles: el modelo lineal y solo del caso en que hay una sola variable explicativa (antecedente). Cuando se reemplaza cada uno de los x observados en la función, se encuentran las estimaciones para cada uno de ellos. En la tabla siguiente indicamos cada uno de los pares ordenados como fueron observados y agregamos los valores de \\(\\widehat{y}\\) estimados a través de la función lineal32; por último, restamos los valores estimados de y, de los observados, para ver las diferencias entre los que la recta estima y los que hemos observado: \\(x\\) \\(y\\) \\(\\widehat{y}\\) \\(y - \\widehat{y}\\) 46 7 4.91 2.09 44 2 4.45 -2.45 56 7 7.20 -0.20 57 8 7.43 0.57 30 2 1.24 0.76 60 9 8.12 0.88 45 5 4.68 0.32 43 1 4.22 -3.22 64 9 9.03 -0.03 32 3 1.70 1.30 La última columna mide la distancia que hay entre cada punto y la recta. Es un indicador de la calidad del ajuste que hace la función lineal de los puntos. Cuando esas distancias son pequeñas tenemos una recta que ajusta mejor los puntos que cuando las distancias son grandes. Como vemos, en este ejemplo hay algunas positivas, que corresponden a los puntos que están encima de la recta, y otras negativas, las de los puntos por debajo de la recta. Veamos en el gráfico siguiente la ubicación de uno de estos puntos, por ejemplo el que corresponde al par observado \\((43; 1)\\), al que la recta estima con el valor \\(\\widehat{y} = 4,22\\): Figura 5.11: Ubicación gráfica de la diferencia entre el valor observado de \\(y\\) observado y su estimación \\(\\widehat{y}\\) Este desvío es negativo porque el punto está debajo de la recta, la estimación \\(\\widehat{y}\\) es mayor que el valor observado, y. La suma de todos estos desvíos es cero, por haber pedido a la recta la condición de equilibrar los puntos. Estas diferencias son los errores que se cometen al estimar a través de la función lineal. Para verlos como tales, observemos que si la correlación fuera perfecta (positiva o negativa) como en los gráficos 5.6 y 5.7 todos los puntos estarían sobre la recta y coincidirían los valores de y con los de \\(\\widehat{y}\\), por lo que las diferencias de la última columna serían todas cero, no habría error en una relación perfecta. Como hemos dicho, esa es una situación ideal, que no puede observarse en la realidad: en los casos reales siempre hay apartamientos de los puntos a la recta, que constituyen el error de estimación. Para llegar a una medida de la calidad de nuestro modelo, es decir una medida de qué tan bueno es el ajuste que la recta hace sobre los puntos realmente observados, trabajaremos sobre la dispersión, a través de la varianza. En primer lugar, la variable tiene su varianza, que mide lo que los valores se apartan de la media, vamos a llamarla \\(s_{y}^{2}\\) (la varianza de y). En segundo lugar, los \\(\\widehat{y}\\) también se apartan de la media y esas distancias pueden resumirse en otra varianza, la que mide las distancias desde los \\(\\widehat{y}\\) hasta la media de y, la llamaremos \\(s_{\\widehat{y}}^{2}\\) (la varianza de \\(\\widehat{y}\\)). Así entonces resumimos los desvíos de la variable hasta la media, con la varianza de y, y los desvíos de las estimaciones hasta la media, con la varianza de \\(\\widehat{y}\\). Si se traza una recta horizontal para ubicar a la media de y (\\(\\overline{y}\\) en \\(5,3\\)) y se recuerda que los valores de y son los que están en los puntos realmente observados, mientras que los de \\(\\widehat{y}\\) están sobre la recta de regresión, estos desvíos pueden verse gráficamente así: Figura 5.12: Ubicación gráfica de los alejamientos (desvíos) de \\(y\\) observada y de \\(\\widehat{y}\\) estimada, hasta la media de \\(y\\) (\\(\\overline{y}\\)) Lo que cada observación se aleja de la media es la diferencia \\(y - \\overline{y}\\). Cuando se consideran todas ellas, su medida es la varianza de y (indicada \\(s_{y}^{2}\\)). Lo que se desvía la estimación (ubicada sobre la recta de regresión) de la media es \\(\\widehat{y} - \\overline{y}\\), que cuando se extiende a todos los puntos se resume en la varianza de \\(\\widehat{y}\\) (que indicamos como \\(s_{\\widehat{y}}^{2}\\)). La calidad del ajuste se aprecia en la proximidad que la recta tiene a los puntos, en el caso ideal (si \\(r = 1\\) o \\(r = - 1\\)), las distancias son todas cero. En una situación real, el ajuste será tanto mejor cuanto más cerca estén los puntos de la recta; es decir, cuanto más pequeñas sean esas distancias. Para medir esta calidad se usa el cociente entre las dos varianzas anteriores, que resulta ser el ya mencionado coeficiente general de determinación: \\(R^{2} = \\frac{s_{\\widehat{y}}^{2}}{s_{y}^{2}}\\). Al que ahora calculamos como la varianza de \\(\\widehat{y}\\) sobre la varianza de y, por lo que mide qué porción de la variabilidad total de y (el denominador) representa la variabilidad de \\(\\widehat{y}\\), puede leerse como la parte de toda la variabilidad de la variable dependiente que es explicada por el modelo lineal. Este cociente no puede ser negativo ni mayor que 1, porque el numerador es menor o igual que el denominador. Solo vale 1 en el caso de una asociación perfecta, en que las varianzas son iguales -porque los puntos están sobre la recta-, \\(r = 1\\) \\(r = - 1\\) y, en consecuencia \\(R^2=1\\). El coeficiente general de determinación mide la proporción de los cambios de y (expresados con la varianza) que se explican a través de la función lineal. Por eso es muy valioso, porque cuantifica el peso relativo de la variable x (a través de la función lineal) en la explicación de y. Podemos así decir que, por ejemplo, el 30% de las diferencias en el rendimiento escolar de los alumnos de primaria se explica por la educación de sus padres, o que el 60% de la disminución del puntaje en una prueba que evalúa la depresión se puede atribuir a la administración de una determinada droga. Se aprecia con estos ejemplos la gran potencialidad explicativa de este coeficiente. Todo el análisis de regresión que hemos desarrollado hasta aquí puede hacerse de manera equivalente si la relación entre las variables no es lineal. En vez de obtener la ecuación de una recta, se obtendrá la de una parábola, una cúbica o cualquier otra función que aproxime adecuadamente los pares ordenados que se observan. La definición del coeficiente general de determinación que hemos dado: \\(R^{2} = \\frac{s_{\\widehat{y}}^{2}}{s_{y}^{2}}\\) no cambia, pero los \\(\\widehat{y}\\) se calcularán con la función adecuada, no con la lineal que vimos. Sobre el coeficiente de correlación de Pearson, debe recordarse que solo es adecuado para evaluar la intensidad de la relación entre dos variables si ésta es lineal. En presencia de una relación de otro tipo, como la del gráfico 5.5, el coeficiente de Pearson dará un valor muy bajo, pero eso no quiere decir que la relación sea débil o inexistente, sino que el modelo lineal no es adecuado para describirla. Por ello, si se encuentra un coeficiente de Pearson muy bajo, debe explorarse la existencia de una relación no lineal, esto puede hacerse fácilmente observando cómo se disponen los puntos en el diagrama de dispersión. Cuando la relación se modela con una función lineal -y solo en estos casos-, el coeficiente general de determinación (\\(R^2\\)) se calcula directamente elevando al cuadrado al coeficiente de Pearson. Hemos señalado que el coeficiente de Spearman es adecuado cuando una variable o ambas están medidas a nivel ordinal. Pero también es adecuado cuando no se puede suponer que las variables tengan, en la población, distribución normal, que es un requisito para el cálculo del coeficiente de Pearson. Una ventaja adicional del coeficiente de Spearman es que es poco sensible a valores extremos, es una situación similar a la relación entre la media y la mediana la que hay entre estos dos coeficientes. Cuando existen excepcionalmente altos o bajos, es conveniente calcular este coeficiente, aun cuando las variables sean ambas cuantitativas. Se dice que el coeficiente de Spearman es más “robusto” que es de Pearson, porque se afecta menos por valores atípicos de la variable. El siguiente ejemplo con datos ficticios ilustra la diferencia. Consideremos la siguiente relación Los coeficientes resultan: ## [1] &quot;coeficiente de Pearson: 0.662&quot; ## [1] &quot;coeficiente de Spearman: 0.694&quot; Se trata de una tendencia lineal, con un par de valores extremos que se apartan del grupo. Los coeficientes de Pearson y de Spearman dan 0.662 y 0.694 respectivamente. La diferencia se debe a que el coeficiente de Pearson tiene en cuenta cada uno de los valores de la variable, mientras que el de Spearman considera los “rangos”, el efecto de los valores aislados se detectado por el primero de los coeficientes y en menos medida por el segundo. El tratamiento de estas situaciones requiere atención. Por un lado, se debe repetir el análisis sin los valores extremos y comparar nuevamente los coeficientes; por el otro, observar qué hizo que esos casos tuvieran valores tan atípicos. La diferencia entre los dos coeficientes, da una señal para mirar más de cerca los datos. 5.9 La importancia de la visualización La medidas descriptivas que se mencionaron en los capítulos anteriores ofrecen un resumen de las variables individualmente; en estos dos últimos capítulos hemos recorrido un amplio conjunto de formas en que pueden suceder las relaciones entre dos variables y mucho de lo que se ha dicho, puede extrapolarse a modelos más complejos, con más de dos variables bajo análisis simultáneo y con relaciones que no son lineales. A modo de ilustración de la utilidad de las representaciones gráficas, existe un conjunto de datos producido a ese efecto por Francis Anscombe en la década de los setenta del siglo pasado (arrobaanscombe1973, arrobatufte1989). Su autor muestra por este medio, tanto la importancia de la visualización de los datos, como el impacto que pueden tener los casos atípicos sobre las medidas descriptivas. Más adelante se analiza en detalle ese conjunto de datos, lo importante es que muestra que el conocimiento de medidas resumen como los descriptivos univariados, los coeficientes de correlación y aun los coeficientes de un modelo que ajuste la relación, pueden dar una idea equivocada de la manera en que los datos se organizan y que la visualización permite apreciarla mejor. En la misma dirección, Steph Locke (arrobadatasaurus2018, arrobalocke2018) generó una matriz de datos, llamada “Datasaurus”, con 13 pares \\(x-y\\), cada uno de los cuales tiene medidas descriptivas (media y desviación estándar de \\(x\\) y de \\(y\\)), así como coeficientes de correlación entre \\(x\\) e \\(y\\), muy similares, pero los diagramas de dispersión muestran las grandes diferencias entre los pares de datos. La idea, en línea con la de Anscombe, es la de llamar la atención sobre la importancia de la visualización de los datos para tener una descripción completa y que las medidas descriptivas pueden engañar. 5.10 Hacerlo en R 5.10.1 Distancia \\(\\chi^{2}\\) En el paquete base de R existe una función que realiza operaciones relacionadas con el puntaje \\(\\chi^{2}\\); el comando es chi.test y se aplica sobre una tabla de contingencia. Estas operaciones contituyen lo que se denomina “prueba \\(\\chi^{2}\\)”, sobre la que trabajaremos más adelante. Por ahora, solo se usará una parte de los resultados de esta prueba. La aplicación de la prueba a una tabla de contingencia da como resultado un objeto de clase “htest”, de ello, nos van a interesar sus componentes. A continuación llamamos “tabla.viol” a la que cruza los tipos de violencia con el tamaño de las ciudades y aplicamos la prueba a esa tabla. Al resultado de la prueba lo guardamos con el nombre “jicu.viol”. Luego preguntamos cuáles son los atributos de este objeto: tabla.viol &lt;- table(violencia$tipo, violencia$ciudades) jicu.viol &lt;- chisq.test(tabla.viol) attributes(jicu.viol) ## $names ## [1] &quot;statistic&quot; &quot;parameter&quot; &quot;p.value&quot; &quot;method&quot; &quot;data.name&quot; &quot;observed&quot; ## [7] &quot;expected&quot; &quot;residuals&quot; &quot;stdres&quot; ## ## $class ## [1] &quot;htest&quot; Los “nombres” indican lo que este objeto contiene en su interior, la “clase” es el tipo de objeto. De los nombres, por ahora nos interesan: statistic que es el valor de la distancia \\(\\chi^{2}\\). observed es la tabla de frecuencias original, las frecuencias observadas expected es la tabla de frecuencias esperadas bajo la hipótesis de independencia Para llegar a ellos, se usa el mismo procedimiento que para referirse a las variables de una matriz de datos. Así, la distancia \\(\\chi^{2}\\) es: jicu.viol$statistic ## X-squared ## 50.18553 La tabla de frecuencias observadas: jicu.viol$observed ## ## áreas rurales ciudades grandes ciudades pequeñas ## autoinfligida 15 100 35 ## colectiva 5 35 10 ## interpersonal 90 110 100 Y la de esperadas: jicu.viol$expected ## ## áreas rurales ciudades grandes ciudades pequeñas ## autoinfligida 33 73.5 43.5 ## colectiva 11 24.5 14.5 ## interpersonal 66 147.0 87.0 Los decimales de la última pueden quitarse redondeando: round(jicu.viol$expected, 0) ## ## áreas rurales ciudades grandes ciudades pequeñas ## autoinfligida 33 74 44 ## colectiva 11 24 14 ## interpersonal 66 147 87 El número total de observaciones no es uno de los elementos que la prueba da directamente. Hay que pedirlo a partir de la suma de las frecuencias de la tabla de observadas (o de esperadas, que totaliza lo mismo). Definimos como “n” al ese valor, porque lo vamos a necesitar para calcular los coeficientes: n &lt;- sum(jicu.viol$observed) Del mismo modo, rotulamos el número de filas y de columnas: f &lt;- nrow(jicu.viol$observed) c &lt;- ncol(jicu.viol$observed) Una vez que se cuenta con el puntaje \\(\\chi^{2}\\), se pueden calcular los coeficientes. Para tenerlo disponible más fácilmente, le vamos a asignar un nombre: d.ji.cuad &lt;- jicu.viol$statistic Ahora d.ji.cuad es la distancia \\(\\chi^{2}\\) 5.10.2 Coeficientes 5.10.2.1 \\(\\varphi\\) Se calcula la raiz cuadrada de la distancia \\(\\chi^{2}\\) dividida en el número de casos: sqrt(d.ji.cuad / n) ## X-squared ## 0.3168139 5.10.2.2 C de Pearson Como el anterior, sumando \\(\\chi^{2}\\) a \\(n\\) en el denominador sqrt(d.ji.cuad / (d.ji.cuad + n)) ## X-squared ## 0.3020193 5.10.2.3 V de Cramer Incluye al mínimo entre el número de filas menos uno y el número de columnas menos uno. min es una función de biblioteca de R base. sqrt(d.ji.cuad / (n * min(c - 1, f - 1))) ## X-squared ## 0.2240213 5.10.2.4 Spearman El comando para calcular coeficientes de correlación en R es cor, al cual en este caso deberá indicársele que estamos trabajando con variables ordinales, por lo que queremos el coeficiente de Spearman; de lo contrario, por defecto calcula el coeficiente de Pearson. La matriz de datos del ejemplo se llama merito.educa.mad y las variables son OM (orden de mérito) y educamadre. Así definidas, el pedido del coeficiente se hace indicando cuáles son las dos variables que se correlacionan y qué método debe usarse, en base a su nivel de medición: cor(merito.educa.mad$OM, merito.educa.mad$educamadre, method = &quot;spearman&quot;) ## [1] 0.7509393 5.10.2.5 Pearson El comando cor devuelve, por defecto, el coeficiente de Pearson, por lo que no es necesario especificar el parámetro method. Para el ejemplo que correlaciona el puntaje en la escala de inteligencia lógico matemática y el puntaje en una prueba, el cálculo se pide así: cor(puntaje.escala, ejercic.corr) ## [1] 0.8474425 5.10.2.6 Dicotomías artificiales Las dicotomías sobre variables continuas pueden hacerse con la función cut que se usó antes para construir categorías de variables cuantitativas, solo que ahora el corte se da solo en dos grupos. Para el caso de los puntajes de la subescala motora de la prueba de Bayley, si se quienen dos categorías que tengan la misma amplitud en los valores de la variable, se indican dos cortes. En este ejemplo, primero leemos la base “bayley”, luego introducimos la variable dicotomizada como una columna más de la matriz de datos y visualizamos el resultado pidiendo una tabla: bayley &lt;- read.csv(&quot;bases/archivostxt/bayley.txt&quot;, sep = &quot;;&quot;) bayley$motor.dic &lt;- cut(bayley$baymotor, breaks = 2) table(bayley$motor.dic) ## ## (63.9,107] (107,150] ## 257 197 El corte se realizó en 107 que es el centro de los valores de la variable (promedio entre el mínimo y el máximo). Otra opción es cortar en la mediana, de modo que la cantidad de casos en las dos categorías sea similar. Para ello, hay que especificar todos los cortes que determinan los intervalos; el mínimo, la mediana y el máximo: bayley$motor.dic.2 &lt;- cut(bayley$baymotor, breaks = c( min(bayley$baymotor), median(bayley$baymotor), max(bayley$baymotor))) table(bayley$motor.dic.2) ## ## (64,105] (105,150] ## 231 222 Ahora el corte está en 105 y quedan cantidades más similares de casos en cada grupo. La decisión sobre el mejor modo de hacer el corte es teórica, y con ella presente, puede denominarse “grupo bajo” y “grupo alto” a los dos resultantes de la dicotomización. 5.10.2.7 Tetracórico El paquete psych (arroba Revelle2018) cuenta con la función tetrachoric, cuyo argumento es la matriz de datos original y no la tabla de contingencia. Aquí se aplica al análisis de la relación entre los puntajes de las subescalas motora y mental de la prueba de Bayley, dicotomizadas. Primero se carga el paquete library(&quot;psych&quot;) Y luego se aplica la función a la matriz de datos que solo contiene las dos variables dicotomizadas: tetrachoric(compara.escalas.dic) ## Call: tetrachoric(x = compara.escalas.dic) ## tetrachoric correlation ## sbscl.mt sbscl.mn ## subescala.motora 1.00 ## subescala.mental 0.37 1.00 ## ## with tau of ## subescala.motora subescala.mental ## -0.14 -0.14 La salida muestra varias cosas, nos interesa la tabla con las dos variables en filas y columnas, con “unos” en la diagonal (correlación de cada variable consigo misma) y en la celda \\((2; 1)\\) (inferior izquierda), está el coeficiente solicitado, 0.37. 5.10.2.8 Punto biserial Los grupos deben codificarse como cero y uno, para luego solicitar un coeficiente de Pearson. En este ejemplo, se crea la base de datos con siete casos en el grupo control y diez en el experimental. Se codifica a los grupos control y experimental como cero y uno respectivamente, y luego se solicita el coeficiente de correlación de Pearson entre la variable dicotómica que codifica los grupos, y los puntajes. grupo &lt;- c(rep(&quot;control&quot;, 7), rep(&quot;experimental&quot;, 10)) puntaje &lt;- c(8, 5, 6, 5, 6, 8, 6, 4, 5.6, 5.6, 8, 7.2, 6.4, 7.2, 8, 8, 7.2) grupo.cod &lt;- c(rep(0, 7), rep(1, 10)) compara.grupos &lt;- data.frame(grupo, puntaje, grupo.cod) cor(x = compara.grupos$puntaje, compara.grupos$grupo.cod) ## [1] 0.1734252 5.10.3 Modelo lineal El ajuste de una variable como función (lineal en el caso que nos interesa) de otra (u otras) constituye un objeto en R. Lo denominaremos “modelo.1”. El comando para construir ese objeto es lm (modelo lineal) y usaremos como argumento la variable consecuente (o dependiente o a explicar) relacionada por medio del signo ~ (alt + 126 en windows) con la variable antecedente (o independiente o factor explicativo). El orden entre estas dos variables es determinante para el modelo, por lo que debe cuidarse, si x es antecedente e y consecuente y la relación se plantea \\[X \\rightarrow Y\\] entonces el argumento de lm es \\[Y \\tilde{} X\\] El modelo se construye así: modelo.1 &lt;- lm(ejercic.corr ~ puntaje.escala) El objeto que resulta tiene como atributos: attributes(modelo.1) ## $names ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; ## [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; ## [9] &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; &quot;model&quot; ## ## $class ## [1] &quot;lm&quot; La clase es lm, modelo lineal, un tipo particular de objeto R. De los nombres, por ahora solo nos interesan los coeficientes, a los que evocamos del mismo modo que a las variables de una matriz de datos: modelo.1$coefficients ## (Intercept) puntaje.escala ## -5.6279603 0.2290977 Estos son: intercept: la intersección con el eje \\(y\\), es decir, la ordenada al origen. puntaje.escala: el nombre de la variable antecedente, es la pendiente de la recta. Cada uno de estos valores puede accederse separamente, así: modelo.1$coefficients[1] ## (Intercept) ## -5.62796 modelo.1$coefficients[2] ## puntaje.escala ## 0.2290977 Y luego usarse para calcular un valor de \\(y\\) (aciertos estimados) para un valor elegido de \\(x\\) (puntaje en la escala). El ejemplo hecho manualmente antes resulta ahora: modelo.1$coefficients[1] + modelo.1$coefficients[2] * 55 ## (Intercept) ## 6.972413 Que se diferencia del obtenido antes por el redondeo y sigue siendo un promedio de siete errores esperados para quienes tienen puntaje 55 en la escala. También es posible crear una función para que calcule automáticamente valores de \\(y\\) para cualquier \\(x\\) que se elija: yest &lt;- function(x) { modelo.1$coefficients[1] + modelo.1$coefficients[2] * x } Para usarla, damos a esta nueva función un valor de x: yest(55) ## (Intercept) ## 6.972413 yest(75) ## (Intercept) ## 11.55437 5.10.4 Cuarteto de Anscombe El cuarteto de Anscombe, es una matriz de datos de once casos en cuatro pares variables y viene cargado en R. Se lo puede ver, llamándolo por su nombre: anscombe ## x1 x2 x3 x4 y1 y2 y3 y4 ## 1 10 10 10 8 8.04 9.14 7.46 6.58 ## 2 8 8 8 8 6.95 8.14 6.77 5.76 ## 3 13 13 13 8 7.58 8.74 12.74 7.71 ## 4 9 9 9 8 8.81 8.77 7.11 8.84 ## 5 11 11 11 8 8.33 9.26 7.81 8.47 ## 6 14 14 14 8 9.96 8.10 8.84 7.04 ## 7 6 6 6 8 7.24 6.13 6.08 5.25 ## 8 4 4 4 19 4.26 3.10 5.39 12.50 ## 9 12 12 12 8 10.84 9.13 8.15 5.56 ## 10 7 7 7 8 4.82 7.26 6.42 7.91 ## 11 5 5 5 8 5.68 4.74 5.73 6.89 Para ver las medidas descriptivas, se solicita el resumen completo de la matriz de datos, ya que son pocas variables: # summary(anscombe) apply(anscombe, 2, summary) ## x1 x2 x3 x4 y1 y2 y3 y4 ## Min. 4.0 4.0 4.0 8 4.260000 3.100000 5.39 5.250000 ## 1st Qu. 6.5 6.5 6.5 8 6.315000 6.695000 6.25 6.170000 ## Median 9.0 9.0 9.0 8 7.580000 8.140000 7.11 7.040000 ## Mean 9.0 9.0 9.0 9 7.500909 7.500909 7.50 7.500909 ## 3rd Qu. 11.5 11.5 11.5 8 8.570000 8.950000 7.98 8.190000 ## Max. 14.0 14.0 14.0 19 10.840000 9.260000 12.74 12.500000 Se observa la similitud de las medidas resumen de x1, x2, x3, x4 por un lado y de y1, y2, y3, y4 por otro. Además, las correlaciones entre los pares son casi idénticas: cor(anscombe$x1, anscombe$y1) ## [1] 0.8164205 cor(anscombe$x2, anscombe$y2) ## [1] 0.8162365 cor(anscombe$x3, anscombe$y3) ## [1] 0.8162867 cor(anscombe$x4, anscombe$y4) ## [1] 0.8165214 Y también son muy similares los modelos lineales que ajustan cada relación. Las ordenadas al origen: lm(anscombe$y1 ~ anscombe$x1)$coefficients[1] ## (Intercept) ## 3.000091 lm(anscombe$y2 ~ anscombe$x2)$coefficients[1] ## (Intercept) ## 3.000909 lm(anscombe$y3 ~ anscombe$x3)$coefficients[1] ## (Intercept) ## 3.002455 lm(anscombe$y4 ~ anscombe$x4)$coefficients[1] ## (Intercept) ## 3.001727 Y las pendientes: lm(anscombe$y1 ~ anscombe$x1)$coefficients[2] ## anscombe$x1 ## 0.5000909 lm(anscombe$y2 ~ anscombe$x2)$coefficients[2] ## anscombe$x2 ## 0.5 lm(anscombe$y3 ~ anscombe$x3)$coefficients[2] ## anscombe$x3 ## 0.4997273 lm(anscombe$y4 ~ anscombe$x4)$coefficients[2] ## anscombe$x4 ## 0.4999091 Sin embargo, los diagramas de dispersión muestran que se trata de conjuntos muy diferentes entre sí: p1 &lt;- ggplot(anscombe) + geom_point(aes(x1, y1)) + geom_abline() + theme_tufte() p2 &lt;- ggplot(anscombe) + geom_point(aes(x2, y2)) + geom_abline() + theme_tufte() p3 &lt;- ggplot(anscombe) + geom_point(aes(x3, y3)) + geom_abline() + theme_tufte() p4 &lt;- ggplot(anscombe) + geom_point(aes(x4, y4)) + geom_abline() + theme_tufte() grid.arrange(p1, p2, p3, p4, nrow = 2, ncol = 2) Para usar el Datasaurus, se debe primero instalar el paquete y cargarlo en la sesión, la matriz de datos se llama datasaurus_dozen: ## # A tibble: 1,846 x 3 ## dataset x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 dino 55.4 97.2 ## 2 dino 51.5 96.0 ## 3 dino 46.2 94.5 ## 4 dino 42.8 91.4 ## 5 dino 40.8 88.3 ## 6 dino 38.7 84.9 ## 7 dino 35.6 79.9 ## 8 dino 33.1 77.6 ## 9 dino 29.0 74.5 ## 10 dino 26.2 71.4 ## # … with 1,836 more rows Los datos están organizados en tres columnas; la primera, que se llama dataset es el nombre del subconjunto, son 13 subconjuntos en total. Luego cargamos el paquete dplyr, que facilita hacer las operaciones por grupos con la función group_by library(&quot;dplyr&quot;) Y luego las aplicamos sucesivamente usando el operador %&gt;% “pipe” (sobre la matriz datasaurus_dozen, agrupe por dataset y resuma, calculando las medidas indicadas). datasaurus_dozen %&gt;% group_by(dataset) %&gt;% summarize( media_x = mean(x), media_y = mean(y), s_x = sd(x), s_y = sd(y), r_x_y = cor(x, y) ) ## # A tibble: 13 x 6 ## dataset media_x media_y s_x s_y r_x_y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 away 54.3 47.8 16.8 26.9 -0.0641 ## 2 bullseye 54.3 47.8 16.8 26.9 -0.0686 ## 3 circle 54.3 47.8 16.8 26.9 -0.0683 ## 4 dino 54.3 47.8 16.8 26.9 -0.0645 ## 5 dots 54.3 47.8 16.8 26.9 -0.0603 ## 6 h_lines 54.3 47.8 16.8 26.9 -0.0617 ## 7 high_lines 54.3 47.8 16.8 26.9 -0.0685 ## 8 slant_down 54.3 47.8 16.8 26.9 -0.0690 ## 9 slant_up 54.3 47.8 16.8 26.9 -0.0686 ## 10 star 54.3 47.8 16.8 26.9 -0.0630 ## 11 v_lines 54.3 47.8 16.8 26.9 -0.0694 ## 12 wide_lines 54.3 47.8 16.8 26.9 -0.0666 ## 13 x_shape 54.3 47.8 16.8 26.9 -0.0656 Cada fila corresponde a un subconjunto de datos. En la tabla se observa la similitud de las \\(x\\) y de las \\(y\\) y también de las correlaciones entre ellas. Para completar la idea que se tiene de los subconjuntos de datos, construimos un diagrama de dispersión para cada uno de ellos: ggplot(datasaurus_dozen) + # haremos un plot con los datos datasaurus_dozen geom_point(aes(x, y, col = dataset)) + # puntos x, y, con coloreados p/data geom_abline() + # agregamos una linea recta facet_wrap(~dataset, ncol = 3) + # separamos en subplots por data theme_tufte() + # fondo blanco theme(legend.position = &quot;none&quot;) # eliminamos el legend Aquí se mapeó el nombre de cada subconjunto al color de los puntos de los diagramas de dispersión y se agregó la función lineal que mejor los ajusta. Como con el cuarteto de Anscombe, los gráfcos aportan una visión muy diferente de los conjuntos de datos, comparada con la que se tenía a partir de la observación solo de sus medidas descriptivas. Según la clasificación sugerida por el Informe Mundial sobre la Violencia y la Salud, Organización Panamericana de la Salud, 2003.↩ El mismo recurso que se usó cuando se definió la varianza y no era posible usar la suma de los desvíos porque daba cero. Nuevamente aquí, usamos el exponente 2 para volver positivos a los números negativos.↩ Recordemos que, de manera general la dimensión de la tabla es \\(f X c\\), filas por columnas.↩ Ver Ekström, J. (2011) para las discusiones en torno a este coeficiente en el llamado “debate Pearson-Yule”.↩ Esta expresión puede encontrarse un poco diferente en algunos manuales. Si las desviaciones estándar, que se usan para calcular los puntajes z, se calcularan con denominador \\(n\\) (como si correspondieran a observaciones provenientes de toda la población), entonces la fórmula de \\(r\\) llevaría denominador \\(n\\) también. Aquí mantenemos el modo de cálculo de la desviación estándar muestral con denominador \\(n-1\\) y por eso esta fórmula lo lleva así también.↩ Es la ordenada correspondiente a un valor de z que deja a derecha e izquierda, en una distribución normal, proporciones del área bajo la curva iguales a \\(p\\) y \\(1-p\\) respectivamente.↩ No es posible poner como condición que la recta haga mínimas las distancias porque hay puntos por encima y por debajo, por lo que la suma de las distancias se hace cero (igual a lo que sucedió con la suma de los desvíos alrededor de la media y que llevó a usar sus cuadrados para definir la varianza). Por esa razón se usan los cuadrados de las distancias.↩ Para calcular los valores de \\(y\\) estimado (\\(\\widehat{y}\\)) hemos conservado más decimales en \\(b_0\\) y \\(b_1\\) que los mostrados.↩ "],
["obtención-de-la-muestra.html", "Capítulo 6 Obtención de la muestra 6.1 Población 6.2 Muestreos probabilísticos 6.3 Muestreos no probabilísticos 6.4 Resumen de técnicas de muestreo 6.5 Hacerlo en R", " Capítulo 6 Obtención de la muestra La estadística inferencial provee los procedimientos para estudiar un subconjunto de elementos y generalizar las conclusiones obtenidas un total; esto se debe a que estudiar uno o varios atributos o variables en todos los elementos, como se hace en los censos, requiere mucha inversión, de tiempo y de dinero. Por ello es que se procede estudiando tales variables en una muestra y se estiman por inferencia los valores de la población. Se reducen así los costos y se disminuye el tiempo necesario para llevar adelante las investigaciones, si se respetan los procedimientos de la estadística inferencial el error que proviene de trabajar sólo con una parte de la población puede ser conocido y controlado. El muestreo es un conjunto de procedimientos mediante los cuales se selecciona, de un universo determinado, llamado población, un subconjunto que recibe el nombre de muestra, con el objetivo de llegar al conocimiento de determinadas características de los elementos de la población a través de la observación y generalización de esas características presentes en los elementos de la muestra. Este recurso no es ajeno a la vida cotidiana, por ejemplo, cuando se considera a una persona “poco confiable” suele ser a partir de varias veces en que esa persona mintió. Al hacerlo, se extiende ese comportamiento (se generaliza) a situaciones que no han sido observadas, se espera que en el futuro, esa persona actúe de modo similar. Esta forma de generalizar tienen requisitos, ya que no es suficiente que haya mentido una vez para caracterizarlo como poco confiable, ni que haya mentido varias veces sobre un mismo asunto. Por el contrario, debe ser una conducta que se haya apreciado en diversidad de situaciones, la que permita hacer un juicio sobre la persona. Por la complejidad de los procesos que involucran a personas, el conocimiento que tengamos de ellos siempre será fragmentario, solo está a nuestro alcance conocer una porción de la infinidad de situaciones humanas posibles. Esos fragmentos constituyen nuestra experiencia cotidiana y necesitamos generalizar intuitivamente para orientarnos en el mundo, para tomar decisiones de todos los días. Pero cuando queremos dar a ese conocimiento un carácter tan validado como sea posible, debemos poner bajo análisis crítico nuestras observaciones y el modo en que han sido seleccionadas. De eso se trata el muestreo; de elegir algunas observaciones que permitan generalizar parcialmente. No lograremos afirmaciones universales, pero sabremos cuáles son los límites de esas afirmaciones. En la generalización estadística hay dos subprocesos. El primero es la selección, que consiste en operaciones mediante las cuales se incluyen algunos elementos de la población en la muestra. El segundo es la estimación, donde, a partir de lo observado en la muestra, ofrecemos una aproximación a los valores poblacionales. A su vez, la selección de la muestra implica decidir cuáles y cuántos casos seleccionar, es decir, la calidad del proceso de selección por un lado, y la cantidad de casos a seleccionar por otro. En este capítulo nos ocupamos de la primera de estas preguntas: de qué modo seleccionar individuos para que lo que se observe de ellos pueda extrapolarse a otros individuos no observados. El número de casos que deben seleccionarse, será tema de los capítulos posteriores. Destaquemos aquí un punto importante: la calidad de la muestra es un requisito de base. Si la muestra está correctamente elegida, los procedimientos de inferencia son válidos, de lo contrario no lo son, es una clasificación dicotómica, por sí o por no. Por el contrario, el tamaño de la muestra incide gradualmente, veremos que si las muestras son más grandes se detectan mejor las diferencias y se reduce el error de estimación. Pero esto es cierto a condición que se cumpla la primera condición. Si la muestra no es adecuada, el aumento en el número de casos no mejora la estimación, e inclusive puede empeorarla. 6.1 Población Utilizaremos la palabra población o, indistintamente, universo, para designar, de manera genérica, a un conjunto de unidades de análisis que son objeto de un estudio particular. Tal conjunto puede estar definido con precisión en el tiempo y el espacio o no, a él se referirán los resultados obtenidos en la investigación por muestreo. Ejemplos de estos son: los pacientes con trastornos alimenticios del hospital Misericordia de la ciudad de Córdoba en el año 2009, o los votantes en las elecciones para intendente de la ciudad de Río Cuarto en 2008, las escuelas primarias de la provincia de Córdoba, las carreras que se dictan en universidades en Argentina en 2017, los países representados en la ONU. Las unidades de análisis antes mencionadas constituyen los elementos de la población, son entidades de diferente naturaleza: personas, hogares, instituciones, ciudades, países, etc. El tamaño que tiene una población influye en el diseño de la muestra porque dependiendo de su tamaño, la población puede ser tratada como finita o infinita. Se dice que es finita si el número de elementos es limitado y se puede tener acceso a todos o casi todos los elementos, ejemplo de ello serían los alumnos de cuarto año del colegio Manuel Belgrano del ciclo lectivo 2020 o los pacientes admitidos en el Hospital de Clínicas en mayo de 2017 o el conjunto de países representados en la ONU en 2015, los senadores electos en un país en un año determinado. Se habla de población infinita33 cuando el número de elementos que integra la misma es elevado, por ejemplo, los automovilistas que circulan por rutas nacionales en una provincia, o alumnos de nivel inicial de la República Argentina. En ciertas ocasiones no se especifica con precisión el tiempo por lo que se habla de población hipotética, tal caso sería el de alumnos de primer año de la carrera de Psicología en UNC (sin especificar ciclo lectivo), por lo que no sólo se incluyen los elementos existentes hoy y en años anteriores, sino también los que en el futuro lo hagan. En este caso, la población no puede siquiera enumerarse. Así sucede también con estudios que plantean probar los efectos de un tipo de psicoterapia sobre pacientes diagnosticados como esquizofrénicos. En ese caso la “población” es la de las personas diagnosticadas como esquizofrénicas en la actualidad y también aquellas que lo serán en el futuro. Cuando se ensaya en una muestra una droga para la hipertensión, la generalización se espera válida para una población que no puede enumerarse: la de “los hipertensos”, tanto los ya diagnosticados como aquellos que lo serán en el futuro. En casos como estos no tenemos posibilidad de delimitar la población completa, decimos que se trata de poblaciones hipotéticas. Para analizar características de las unidades de análisis, puede creerse que lo mejor sería realizar un relevamiento exhaustivo de las mismas. Este relevamiento consistiría en observar dicha característica (variable) en cada uno de los individuos de la población. Tal modo de recolectar la información se conoce con el nombre de censo. Desde el punto de vista práctico, es frecuente realizar relevamientos exhaustivos cuando las poblaciones son de pequeño tamaño y están bien delimitadas en el tiempo y en el espacio. Un ejemplo de este caso sería la situación en que se pretende conocer la opinión de los alumnos de un curso acerca de su docente, aquí lo más adecuado es indagar (vía encuesta) a cada uno de ellos. Sin embargo, la mayoría de las poblaciones de interés para la investigación social tienen dimensiones considerables (todos los alumnos de primer grado del país) o son inaccesibles (los consumidores de una marca de gaseosa, los practicantes del budismo) o son hipotéticas (las personas diagnosticadas de depresión, los ciudadanos con ideología de derecha). Cuando se busca dar generalidad a los resultados alcanzados a través de experimentos, la población de referencia suele ser hipotética: los efectos de una droga sobre la depresión, la relación entre xenofobia y autoritarismo, la eficacia de una estrategia didáctica. Son casos que aspiran a generar resultados válidos para una población hipotética, por lo que el relevamiento completo es imposible y solo se puede observar a unos pocos casos. El modo en que seleccionemos esos pocos casos es de la máxima importancia para que los resultados también sean válidos para los casos que no son observados. Además de permitir economía de recursos, el muestreo permite profundizar los estudios que se realizan sobre los elementos de la muestra. En efecto, en los relevamientos exhaustivos de gran magnitud, como los censos nacionales o provinciales, no es posible profundizar con la indagación; por el contrario se deben hacer pocas preguntas a fin de alcanzar a una gran población en un tiempo aceptable. Si se trabaja con una muestra, se puede indagar con más detalle y profundidad, y luego, con los procedimientos adecuados, extender los hallazgos a la población de la cual la muestra proviene. 6.1.1 Muestra Se llama muestra a un subconjunto de una población que comparte sus características en los aspectos de interés para la investigación. El concepto de muestra va ligado al de representatividad, es decir a su capacidad de actuar como “representante” de los elementos de la población que no han sido seleccionados. Tal representatividad no implica una identidad en todos los aspectos, son solamente aquellas características que se encuentran bajo análisis las que deben ser compartidas por la muestra y la población. Población de quienes votan en una ciudad –&gt; muestra de votantes para consulta de opinión política. Población de docentes universitaries –&gt; muestra de docentes para analizar la distribución de tiempo entre docencia, investigación y extensión. Población de hogares existentes en una ciudad –&gt; muestra de hogares para conocer sus condiciones de vida Cuando se planifica la extracción de una muestra, no se conoce en detalle a la población, por lo que no es posible saber a priori cómo debe ser la muestra que la represente. Si se conoce algunas características de la población que estén relacionadas con el aspecto que se estudia, entonces corresponde reproducirlas en la muestra. En el primero de los ejemplos anteriores, la muestra de votantes debe respetar las proporciones de varones y mujeres que hay en la población, así como de los diferentes grupos de edad. Si se extrajera una muestra que solo tenga mujeres de 18 a 25 años sería una muestra sesgada, porque solo tomaría en cuenta un grupo que puede tener comportamiento electoral diferente al resto de la población. Una muestra así, sirve para estudiar el comportamiento de ese grupo particular (mujeres de 18 a 25 años), pero no se puede generalizar a la población. En el segundo ejemplo, si sabemos que en la población de docentes universitaries, hay 60% de mujeres, y se espera que las respuestas que den las mujeres sean diferentes a las de los varones, entonces debe respetarse ese porcentaje en la muestra. Pero si el 70% de les docentes va a trabajar en auto y esto no tiene ninguna relación con la distribución de tiempo en las diferentes actividades, entonces ese porcentaje es irrelevante para el muestreo. Por otro lado, si la dedicación (simple, semiexclusiva o exclusiva) incide en el tema de investigación, entonces, las diferentes categorías de dedicación deben estar representadas en la muestra. La posibilidad de extrapolar los resultados muestrales a la población completa está ligada a la posibilidad de asignar probabilidades a cada una de las muestras que podrían seleccionarse de una población. De manera que sólo será lícito utilizar los resultados muestrales como estimación de valores poblacionales cuando sea posible conocer a priori cuál es la probabilidad que cada individuo (cada unidad de análisis definida) de la población tiene de ser incluido en la muestra. Las técnicas de muestreo que permiten asegurar este requisito se denominan de carácter probabilístico. Otras técnicas que no cumplen esta condición se llaman muestreos no probabilísticos y muchas veces son utilizadas con el objetivo de reducir tiempos y costos, pero los resultados obtenidos de ellas no pueden utilizarse para extraer conclusiones acerca de la población. Son adecuados en estudios que no buscan generalidad de sus conclusiones sino profundidad en el análisis de los casos observados. Sin embargo, hay investigaciones que usan muestras no probabilísticas para dar carácter general a los resultados que se obtienen. Cuando se hace esto, nunca hay certeza del grado de generalidad de lo que se concluye y hasta qué punto no se trata de características específicas de los individuos a los que se observó, porque no puede conocerse el margen de error de lo que se estima. Cuando las limitaciones prácticas hacen imposible la obtención de una muestra probabilística, se deben tomar recaudos para que la muestra sea heterogénea y que la inclusión de casos dependa lo menos posible de la voluntad de los participantes. Para que sea posible asignar probabilidades a cada una de los individuos de formar parte de la muestra, el método por el cual los individuos son seleccionados debe excluir la elección voluntaria. Esto implica que el proceso de elección debe quedar estrictamente librado al azar, sin dejar margen para que se filtre la intencionalidad, no se trata de elegir a “cualquiera”. En consecuencia, caerán en la categoría de técnicas de muestreo no probabilísticas todos los procedimientos en que exista alguien que pueda tomar la decisión acerca de si una unidad va a ser o no incluida en una muestra. Muestreos probabilísticos: las muestras obtenidas por estos procedimientos permiten generalizar los resultados obtenidos en ellas a toda la población de referencia. El requisito para que una muestra sea probabilística es que sus elementos hayan sido elegidos al azar (aleatoriamente), sin la participación voluntaria que decida a quién incluir y a quién excluir de la muestra. Muestreos no probabilísticos: en estas muestras no se cumple el requisito de aleatoriedad en la selección de los elementos que la componen. Los resultados no se pueden generalizar de manera probabilística más allá de los casos observados. 6.2 Muestreos probabilísticos Cuando se pretende que los resultados obtenidos en una muestra puedan ser generalizados a la población de la cual ésta proviene, se hace necesario recurrir a muestreos de tipo probabilísticos. Se trata de diseños que requieren más cuidado en su elaboración y de manera concomitante son más costosos. Señalamos a continuación los tipos puros de muestreos probabilísticos y luego veremos algunas combinaciones de ellos que se usan a menudo. 6.2.1 Muestreo irrestricto aleatorio o aleatorio simple Se trata de una técnica que asigna igual probabilidad de pertenecer a la muestra a todos los individuos de la población. Para su realización se requiere contar con una lista de los elementos de la población. Este listado es lo que se denomina el marco de la muestra. Dicho marco debe cumplir con los requisitos de exhaustividad (es decir, que sea completo) y debe cuidarse que no existan duplicaciones. La tarea de depuración de un listado puede insumir bastante tiempo según el tamaño de la población y el tipo de marco muestral de que se trate. Es diferente el caso de un registro electoral, del total de historias clínicas de un gran hospital o del listado de todos los alumnos de una facultad, o los diputados de la cámara). Su realización consiste en numerar los elementos del listado y elegir aleatoriamente una cantidad \\(n\\) de ellos (el tamaño de la muestra). La aleatoriedad de la elección queda garantizada por el uso de una tabla de números aleatorios o de un generador electrónico de los mismos, algunas calculadoras de los teléfonos disponen de esta opción en la tecla #RAN (por random, aleatorio). La exigencia de contar con el listado de los elementos de la población es una limitación importante para este tipo de muestreo por lo que, como se verá más adelante, a menudo se lo utiliza en combinación con otros procedimientos. Además, puede ocurrir que los elementos elegidos en la muestra se encuentren dispersos geográficamente de manera que resulte notablemente costoso ubicar a cada uno de ellos para entrevistarlos. Una ventaja importante es que no exige que se conozca a priori ninguna característica de la población. Desde el punto de vista estrictamente estadístico, resulta más fácil acotar el error de muestreo ya que las distribuciones de probabilidad subyacentes son bien conocidas para este tipo de muestreo. 6.2.2 Muestreo sistemático Un procedimiento alternativo al muestreo irrestricto aleatorio lo constituye el muestreo sistemático. En este caso solo se selecciona un elemento aleatoriamente y, comenzando por él, se recorre el marco de la muestra tomando los elementos siguientes a intervalos regulares. El primer paso consiste en determinar el número de veces que se incluye la muestra en la población. Ese valor es el que resulta de dividir el tamaño de la población en el tamaño de la muestra: \\[r = \\frac{N}{n}\\] Donde: \\(r\\) representa a las veces que la población contiene a la muestra, \\(N\\): tamaño de la población, \\(n\\): tamaño de la muestra. Luego se genera un número aleatorio entre 1 y \\(r\\), éste constituye el primer elemento de la muestra al que llamaremos “a”. A continuación se selecciona el elemento que se encuentra \\(r\\) unidades más adelante en la lista (el elemento que ocupa el lugar \\(a+r\\)) y así sucesivamente hasta recorrer la lista completa, lo cual ocurrirá cuando se haya alcanzado al enésimo y último elemento de la muestra. El gráfico siguiente ilustra este procedimiento, las flechas a la derecha señalan los primeros elementos que constituyen la muestra; el procedimiento prosigue de idéntica manera hasta la última unidad de la muestra. 1 … → a … … → a+r … … → a+2r … … N Esta técnica tiene, en principio, los mismos requerimientos que el muestreo irrestricto aleatorio, en cuanto a la necesidad de disponer del marco de la muestra, pero puede adaptarse cuando no se cuenta con la lista. Su uso se justifica por dos razones. La primera es que si la lista no presenta ninguna tendencia especial, el muestreo sistemático facilita la extracción de la muestra, simplifica la operación, ya que la elección de todos los números aleatoriamente puede ser lenta por la aparición de elementos repetidos que deben descartarse. La segunda razón es que puede ocurrir que el listado este ordenado según algún criterio (por fechas, o por edades de los individuos, etc.), de ser así, existe el riesgo que una muestra irrestricta aleatoria concentre los elementos elegidos en alguna “zona” de la lista, sobre-representando de esta manera a los individuos que tienen alguna característica en común. En este caso el muestreo sistemático asegura que el marco de la muestra sea recorrido completamente a intervalos iguales. Por otra parte, existen situaciones en que el muestreo sistemático es desaconsejado: diremos que la población presenta un comportamiento cíclico si cierta característica se repite regularmente cada cierta cantidad fija de casos. Un ejemplo de esto es una muestra a lo largo del tiempo, en que algunos “momentos”, tales como inicios o finales de mes, determinados días de la semana, etc., se repiten periódicamente en el año. Sea que tratamos de estimar los ingresos a un hospital y elegimos, de manera sistemática, los días que constituirán la muestra. Si el valor de r fuera 7 ó un múltiplo de él, la muestra contendría siempre al mismo día de la semana y sería un sesgo grave, porque los ingresos al hospital pueden ser muy diferentes en los diferentes días de la semana. Aun cuando el ejemplo va más allá de lo realista, su utilidad está en alertar contra el uso de procedimientos sistemáticos cuando se sospecha de la existencia de una tendencia cíclica en el listado con que se cuenta. Por último, hay casos en que el muestreo sistemático se usa para prescindir del marco de la muestra. Es cuando se seleccionan casos a partir de poblaciones en movimiento: la cola para entrar al cine es un caso. Otro caso frecuente son las encuestas “boca de urna” en las que se pregunta por quién votó a personas que salen del lugar de votación. Allí no hay listado al que recurrir, es a la gente que está físicamente presente que debemos encuestar. El recurso consiste en elegir a una persona cada \\(r\\), buscando que la muestra incluya a personas que llegaron temprano y que llegaron tarde, que votaron a la mañana y a la tarde, es decir que recorramos la “fila” alcanzando a quienes están en los primeros lugares y también a quienes están al final. 6.2.3 Muestreo estratificado El procedimiento consiste en extraer muestras de subconjuntos de la población llamados estratos. Se espera que tales estratos sean homogéneos en su interior con respecto a alguna característica conocida a priori. Dicha característica se denomina criterio de estratificación. Figura 6.1: En el muestreo estratificado se eligen muestras diferentes de cada uno de los subconjuntos definidos en la población. Un ejemplo puede aclarar esta idea: supongamos que se requiere estimar el consumo de bebidas alcohólicas de los jóvenes. Como se supone que esa variable está influida por el nivel socioeconómico, puede utilizarse este último como criterio para estratificar a la población, dividiéndola en subconjuntos en los que el nivel socioeconómico sea homogéneo. La cantidad de estratos que puedan definirse de esta manera dependerá del grado de precisión con que pueda medirse el nivel socioeconómico. Si estratificamos con categorías nivel socioeconómico alto, medio y bajo, entonces será \\(k=3\\) y seleccionaremos jóvenes de cada uno de los tres estratos. Es de destacar que la división de la población en estratos demanda cierta información acerca de ella (en este ejemplo el nivel socioeconómico). Cuanta más precisión se pretenda lograr con la estratificación, tanto mayor será la información necesaria a priori. A veces los estratos están dados de manera más inmediata, como sucede con los alumnos de una carrera universitaria. Si se busca una muestra que represente a los estudiantes de la carrera, es conveniente estratificar por año de cursado, de modo de incluir en ella alumnos de todos los años. Este procedimiento de muestreo se utiliza cuando se busca aumentar la precisión de la estimación sobre la población total o bien para mejorar la precisión sobre los estratos individuales. Se obtendrá tanto mayor ganancia en la estimación cuanto más homogéneos sean los estratos en su interior y más diferentes (heterogéneos) sean entre ellos. Veremos en detalle las razones de esto cuando presentemos el error en la estimación por intervalo. 6.2.3.1 Muestreo estratificado con afijación igual o uniforme Se llama afijación a la modalidad que se utilice para distribuir la muestra sobre los estratos definidos. Según la información con que se cuente a priori, se podrán utilizar diferentes formas de afijar, la primera que tratamos es la afijación igual o uniforme. Ésta se aplica cuando no existe información alguna acerca de los estratos y no hay razón para ponderar especialmente alguno de ellos. El procedimiento es simplemente extraer la misma cantidad de casos de cada estrato. Las muestras tienen así el mismo tamaño que resulta: \\[n_{i} = \\frac{n}{k}\\] Donde: \\(n_{i}\\) es el tamaño de las muestras extraídas de cada estrato \\(n\\) es el tamaño de la muestra total. \\(k\\) representa el número de estratos en que fue dividida la población. En el ejemplo sobre el consumo de bebidas alcohólicas, si se trata de una muestra de 600 jóvenes, con este tipo de afijación, y como son tres estratos, extraeremos 200 casos de cada estrato. 6.2.3.2 Muestreo estratificado con afijación proporcional Consiste en extraer de cada estrato una muestra cuyo tamaño resulte proporcional al estrato del que proviene. Para ello, primero calculamos \\(f\\) que es la proporción de población que integra la muestra: \\[f = \\frac{n}{N}\\] Este cociente se llama fracción de muestreo, en su cálculo: \\(n\\) es el tamaño de la muestra total. \\(N\\) representa el tamaño de la población. Una vez que conocemos la fracción de muestreo, la aplicamos a cada uno de los estratos para obtener la cantidad de casos que deben extraerse de cada uno: \\[n_{i} = f*N_{i}\\] Donde: \\(N_{i}\\): es la cantidad de casos en el estrato i-ésimo (en la población), \\(n_{i}\\): es la cantidad de casos que se extraerán del estrato i-ésimo, \\(f\\): es la fracción de muestreo que calculamos antes. Para usar este tipo de afijación en el ejemplo del consumo de bebidas alcohólicas necesitaríamos conocer la cantidad de jóvenes que hay en cada estrato, es decir cuántos jóvenes de nivel socioeconómico alto, medio y bajo hay en la población. Este dato usualmente es desconocido. Veamos un ejemplo con datos reales: en el año 2008 en Psicología, la siguiente era la distribución de alumnos según el año en que habían ingresado a la carrera (considerando solo a los ingresados a partir del año 2000). Año de ingreso a la carrera Cantidad de alumnos 2008 1357 2007 1113 2006 1001 2005 807 2004 859 2003 764 2002 700 2001 483 2000 399 total 7483 Fuente: Anuario estadístico 2008, UNC. Si queremos una muestra de 200 alumnos de esa población, la fracción de muestreo será:\\(f = \\frac{200}{7483} = 0,027\\) que redondeamos a \\(0,03\\). Aplicaremos esta fracción a cada estrato, es decir multiplicamos por esa fracción a la cantidad de casos que hay en cada estrato y redondeamos al entero más próximo. Año de ingreso a la carrera Cantidad de alumnos Casos a seleccionar 2008 1357 41 2007 1113 33 2006 1001 30 2005 807 24 2004 859 26 2003 764 23 2002 700 21 2001 483 14 2000 399 12 total 7483 Entonces, para la muestra debemos elegir 41 alumnos que hayan ingresado en 2008, luego 33 del 2007 y así sucesivamente. A esa selección la hacemos aleatoria, ya que es posible contar con el marco de la muestra que es el registro de alumnos que tiene la facultad. Existen otras formas de afijación, más complejas, que tienen en cuenta más información acerca de la población. Por ejemplo, la afijación óptima tiene en cuenta la heterogeneidad de cada estrato para elegir la cantidad de casos que se extraen de cada uno. Ya que cuando los elementos son muy homogéneos, bastan unos pocos casos para tener una imagen adecuada del conjunto completo, por el contrario, cuanto más dispares (heterogéneos) sean los elementos de la población, tantas más observaciones serán necesarias para hacer estimaciones de buena calidad. Este es el criterio que se usa en el procedimiento llamado afijación óptima. Si se dispone de suficiente información, es posible incluir el costo de acceso a los casos pertenecientes a diferentes estratos y realizar una afijación que minimice el costo global del muestreo, para más detalles sugerimos arrobaMendenhall1971. Solo nos ocuparemos de las dos formas de afijación que hemos mencionado: igual y proporcional. Dos puntos que deben recordarse para decidir el uso del muestreo estratificado: Cada criterio de estratificación demanda información acerca de la población. Esa información debe provenir de un conocimiento anterior al muestreo. El muestreo estratificado implica un aumento de la calidad de la estimación bajo la condición que los elementos que están en un mismo estrato sean homogéneos entre sí y que los estratos sean diferentes unos de otros (heterogéneos entre sí). 6.2.4 Muestreo por conglomerados Se denomina conglomerado a una unidad de muestreo que está constituida, en su interior, por varios elementos de la población. Para un diseño por conglomerado deben definirse unidades primarias de muestreo (conocidas como PSU por sus siglas en inglés) que contengan en su interior a las unidades elementales. Un ejemplo clásico de este tipo de muestreo lo constituye el caso en que se requiere extraer una muestra de hogares en una ciudad. Se trata de una situación en la que resulta imposible contar con un listado de las unidades primarias (los hogares). Un muestreo por conglomerados permite resolver este problema tomando como unidad de selección a los radios censales. Numerando estas unidades sobre un plano de la ciudad (o del área que se pretenda relevar) se selecciona aleatoriamente un número \\(n\\) de ellas. Una vez identificadas las unidades primarias que constituirán la muestra (los radios censales) se relevan todos los hogares (unidades elementales) que residen en cada una de ellos. Figura 6.2: Radios censales 2010 de la ciudad de Río Cuarto, provincia de Córdoba, Argentina. Otro ejemplo es aquel en el que necesitamos una muestra de 100 alumnos de primer grado de escuelas municipales la ciudad de Córdoba. Tenemos dos problemas: el primero es que no hay una lista de estudiantes, no contamos con un marco muestral. El segundo es que, aunque la tuviéramos, tendríamos que ir a buscar a cada uno de los 100 alumnos muestreados al lugar donde viven, lo que tendría un costo muy elevado. En este caso, el conglomerado (o unidad primaria) que se elige es la escuela: en lugar de elegir 100 alumnos al azar, se eligen, por ejemplo 10 escuelas al azar del listado de ellas, que sí existe. Luego, en cada escuela elegimos 10 alumnos, también al azar, a partir del listado de alumnos de primer grado, que sí está disponible en cada escuela. Los requisitos para la efectividad de este tipo de muestreo pueden ser resumidos como sigue: Las unidades primarias de muestreo deben ser homogéneas entre sí, de tal manera que cada unidad sea intercambiable con otra. Cada unidad primaria debe contener, en su interior, la heterogeneidad propia de la población que se releva. Volviendo al ejemplo anterior en que las unidades primarias son los radios censales, se espera que cada radio sea similar a los vecinos en cuanto a su composición (dentro de un área geográfica dada, se trata de un supuesto válido). Además, cada radio dispondrá, en su interior, de la variedad que sea propia del área en cuestión (en términos de su composición: proporción de hogares particulares, comercios, escuelas, etc.). Además del ejemplo de los radios censales como unidad primaria previa a los hogares, otros conglomerados utilizados son: establecimientos educativos, para muestrear a su interior docentes o estudiantes, empresas, identificando luego trabajadores, organizaciones religiosas, etc. En general, todo conjunto que contenga en su interior a las unidades elementales, puede elegirse como conglomerado. 6.2.5 Método de Kish Es un procedimiento para seleccionar aleatoriamente un individuo entre los que residen en un hogar, que es independiente del método de muestreo utilizado para seleccionar los hogares. Solo depende de la composición del hogar y se usa para controlar el sesgo que se pueda producir si el encuestador elige quién encuestar o encuesta al que tiene más accesible. Se trata de ordenar a los integrantes del hogar, asignando un número a cada uno de acuerdo a su sexo y edad. El Centro de Control de Enfermedades de Estados Unidos sugiere asignar el número 1 a la persona de mayor edad y sucesivamente a los demás miembros. En el caso que hubiese dos personas de la misma edad, se puede usar la fecha de cumpleaños para decidir cuál va primero. Luego se consulta una planilla que el encuestador lleva consigo, donde tiene impresos números aleatorios entre 1 y el total de personas que habitan en el hogar. La planilla tiene cada fila para identificar el número de hogar al que se está encuestando, que es el número de cuestionario que se va a aplicar. Cada columna de la planilla tiene la cantidad de integrantes que hay en el hogar. Por ejemplo: si es el quinto hogar que el encuestador visita y en él viven seis personas adultas, luego de enumerarlas según edad, de acuerdo a la siguiente tabla, debe aplicar el cuestionario a la persona que tiene el número 3. hogar Cantidad de integrantes 1 2 3 4 5 6 7 8 9 10 12 1 1 1 3 4 4 4 4 4 8 3 7 2 1 2 2 4 5 3 3 7 4 7 8 3 1 2 1 4 5 1 1 5 6 5 1 4 1 1 1 2 4 2 5 3 9 6 6 5 1 1 3 4 4 3 7 3 5 7 9 6 1 1 3 4 2 2 2 3 5 4 7 7 1 2 2 1 3 5 3 7 3 6 10 8 1 2 1 1 2 3 5 2 5 9 4 Las encuestas de salud, como la Encuesta Nacional de Factores de Riesgo de Argentina, usan este método. Ver https://www.who.int/ncds/surveillance/steps/Parte2_Seccion2.pdf y https://www.cdc.gov/Spanish/EncuestasSR/disenoM/muestreo2.html para las recomendaciones de la Organización Mundial de la Salud y del Centro de Control de Enfermedades. 6.2.6 Uso combinado de técnicas de muestreo Las modalidades de muestreo presentadas pueden combinarse de varias formas para resolver problemas particulares. En el muestreo por conglomerados puede usarse una segunda etapa posterior a la selección de las unidades primarias consistente en la incorporación en la muestra sólo de algunas de las unidades elementales contenidas en ellas. Tal elección puede realizarse por un diseño aleatorio irrestricto o sistemático. Aplicando este concepto al ejemplo anterior, la situación consistirá en la elección de algunos hogares dentro de los radios seleccionadas (en lugar de relevarlos a todos). Para lograr esta muestra, se instruye a los encuestadores para que, recorriendo un circuito establecido de antemano, entrevisten a un hogar cada una cantidad dada (uno cada diez por ejemplo para contar con una muestra del 10% de los hogares del radio). O bien, en el ejemplo de los alumnos de primer grado, se trataría de seleccionar a 10 de ellos en cada escuela de manera aleatoria. Figura 6.3: Muestreo por conglomerados en dos etapas. La obtención de una muestra en una situación real implica la combinación de varios de estos procedimientos. Por ejemplo, para un sondeo de opinión sobre la población adulta de una ciudad, el primer paso es estratificar a la población (los adultos residentes en la ciudad), según nivel socioeconómico, porque esta es una variable que suele hacer diferencias marcadas en opinión política o en pautas de consumo. Un dato que puede tenerse sobre el nivel socioeconómico de los habitantes, es el provisto por el censo de población, que incluye preguntas que permiten hacer una caracterización de los hogares según esta variable. Sin embargo, el censo se hace cada diez años y se vuelve desactualizada al poco tiempo. Por eso suele usarse, como aproximación al nivel socioeconómico, el área de residencia. Si bien no es absoluta, la división puede aproximarse con barrios habitados mayoritariamente por hogares con nivel socioeconómico más alto y más bajo. Así, en un primer momento es posible dividir la ciudad en estratos, determinados por grandes áreas que aproximan el nivel socioeconómico. Con los datos del censo se conoce la cantidad de habitantes de cada una de esas áreas (según los cercano que sea el último censo, este dato será más o menos certero), por lo que el muestreo estratificado se puede hacer con estratificación proporcional. En la etapa siguiente, en lugar de seleccionar a las personas que responderán a la encuesta, se seleccionan unidades geográficas más pequeñas que los barrios: los radios censales. Éstos son enumerados dentro de cada estrato (barrio) y se selecciona aleatoriamente la cantidad de radios que sea necesaria para el tamaño de muestra establecido. Una vez seleccionados los radios, a cada encuestador se le indica que recorra el que le tocó según un circuito establecido de antemano y que llame a la puerta en un domicilio cada \\(k\\). En cada domicilio seleccionado se debe preguntar por las personas adultas que viven allí y se debe seleccionar aleatoriamente a una de ellas, por el método de Kish, quien será finalmente la que responda a nuestro cuestionario. A este esquema general deben agregarse precisiones para casos particulares, como el rechazo a responder o la falta de gente en el domicilio seleccionado. Lo usual es volver dos veces luego de un rechazo y si se fracasa las dos veces, entonces ese domicilio se reemplaza por otro, según una regla establecida de antemano. También hay que aclarar desde el principio qué hacer en los casos de edificios, barrios cerrados, etc. Para los sondeos de opinión, en una ciudad mediana, se estila usar 400 casos en 20 conglomerados de 20 casos cada uno. Como se ve, lo que se busca es dejar el menor margen posible para improvisar, para evitar que la selección sea voluntaria. Esto se hace para asegurar que la muestra sea aleatoria y por tanto probabilística. Si se busca una muestra de pacientes internados en centros de salud de una determinada región, se empezará por el listado de esos centros, a los cuales es posible estratificar según su dependencia pública o privada, según su tamaño, o según otra característica de interés. Una vez establecida la estratificación, se seleccionan al azar una cierta cantidad de centros de salud de cada estrato y, en cada centro será necesario contar con el registro de pacientes internados, aquí se introducirán las restricciones propias de cada investigación, el período durante el cual nos interesan los datos, las patologías que fueron motivo de la internación, etc. La selección de casos (historias clínicas de los pacientes internados) puede realizarse de manera irrestricta aleatoria si se dispone del listado. 6.3 Muestreos no probabilísticos Los procedimientos que pretenden estimar valores de la población a partir de resultados muestrales sólo pueden aplicarse cuando es posible asignar probabilidades a priori a los individuos de ser parte de la muestra. Aun cuando no cumplen con este requisito, las técnicas de muestreo no probabilísticas se utilizan en situaciones en que se pretende adquirir un conocimiento inicial de un problema que se encuentra escasamente delimitado, como sucede en los estudios de tipo exploratorio. También es frecuente su uso cuando no se pretende un conocimiento acabado sobre la población completa sino que el objetivo es profundizar sobre algunos casos en particular (estudios de casos) a través de entrevistas en profundidad que reconstruyan la historia de vida de algunas personas solamente. Un tercer uso es el de aproximar los resultados que se obtendrían con muestras probabilísticas. Como señalamos antes, deben tenerse recaudos con la generalidad de las conclusiones provenientes de este tipo de muestreo. Una clasificación útil para este tipo de muestreo toma en consideración su definición, esto es que la elección no depende del azar sino de la voluntad de alguien. De esta manera los muestreos no probabilísticos pueden clasificarse según quien sea el responsable de la elección en: muestreo por cuotas, de juicio o intencional, autoelegido y accidental. Una combinación de estos procedimientos es el muestro por bola de nieve. 6.3.1 Muestreo por cuotas En este muestreo se busca reproducir de la manera lo más ajustada posible las características de la población en la muestra. Se llama cuotas a las fracciones de la muestra con las distintas características. Este muestreo se usa cuando se conocen algunas características de la población y se busca reproducirlas en la muestra. Por ejemplo, si la muestra contiene una proporción de varones y mujeres igual a la que hay en la población y además respeta las proporciones de diferentes grupos de edad, decimos que usamos cuotas de sexo y edad. A estos criterios suele agregarse otros, según los objetivos de la investigación, por ejemplo, en las encuestas políticas, es frecuente establecer cuotas de acuerdo al voto en las elecciones pasadas. Los ejemplos que indicamos antes, como reproducir la proporción de varones y mujeres entre los docentes primarios, o de las diferentes proporciones de niveles educativos de la población en la muestra, son casos de muestreo por cuotas. En la práctica, se encarga a los encuestadores una cantidad especificada de casos a relevar, sin indicar quiénes serán esos casos ni cómo hallarlos, esto le da el carácter de no probabilístico, pero respetando las cantidades de casos en cada cuota. El entrevistador elige a “cualquiera”, según su comodidad o preferencias, es decir que no es posible conocer a priori qué probabilidad tienen los elementos de la población de caer en la muestra, pero esa elección está limitada por la exigencia que los elementos reúnan ciertas características. Un ejemplo es en el que se indica a un encuestador que complete 10 entrevistas a médicos que trabajen en relación de dependencia en la ciudad de Córdoba que tengan hasta diez años de egresados; a otro, que entreviste a 15 médicos también en relación de dependencia, pero que tengan más de diez años de egresados. Si bien en este caso los entrevistadores pueden elegir según su preferencia cuáles serán los médicos a los que entrevistará, sus posibilidades de elección están restringidas a cumplir la cuota asignada. En las encuestas políticas, el encuestador puede verse limitado a elegir personas de sexo femenino, de 45 años, que en las elecciones pasadas hayan votado por el partido X (mientras que a otros encuestadores se les encargarán otras cuotas). No hay azar, porque el encuestador elegirá a quienes prefiera o tenga más a su alcance, pero deberá respetar las cantidades que le fueron indicadas. Atención: una muestra construida por cuotas, es evidentemente representativa de los criterios correspondientes de las cuotas con los que fue elaborada (sexo, edad, ocupación, región, \\(\\ldots\\)). Pero no hay ningún medio para saber si es representativa de aquello para lo cual fue construida, es decir, el tema de la investigación: la opinión, los rendimientos académicos, las actitudes, etc. 6.3.2 Muestreo de juicio o intencional En este tipo de muestreo, conocido también como “selección experta”, es el investigador quien decide qué elementos son los más adecuados para realizar la investigación. La elección se basa en la apreciación subjetiva del investigador sobre la representatividad de los elementos que muestrea. En algunos ámbitos de la investigación, suele solicitarse a expertos que seleccionen los elementos de la población que consideren más adecuados para construir la muestra, esta selección se apoya en la experiencia de los consultados. Un primer uso de este tipo de muestreo es aquel en el que el interés no se centra en la representatividad sino en la riqueza de contenidos que pueden ofrecer algunos individuos a diferencia de otros. Si se pretende reconstruir la historia de un asentamiento urbano marginal, sería más adecuado elegir a personas que hayan residido en él por largo tiempo. Se espera que los pobladores más antiguos puedan dar mayor información acerca de la génesis y evolución que los que han arribado recientemente. En este caso, el investigador se preocupará primero por identificar a los residentes en el asentamiento y, a partir de ese conocimiento, decidirá a quiénes va a incluir en la muestra. Aquí no se pretende la generalización de los resultados, ni se busca encontrar una historia típica en el sentido de que, en mayor o menor grado, la mayoría de los pobladores la comparta. Lo que se busca es profundizar el análisis a partir del testimonio de aquellos a los que consideramos como informantes más idóneos. 6.3.3 Muestreo autoelegido Usado principalmente en razón de la reducción de costos que implica, cuando se usa este tipo de muestreo no se selecciona a los sujetos del estudio, sino que se solicita a las personas que participen voluntariamente. La decisión de formar parte o no de la muestra queda en manos de la persona invitada, por eso se llama autoelegido, es ella quien optará por participar o no hacerlo (por falta de interés, de tiempo, etc.). Supongamos que se pretende estudiar el gasto por familia en actividades de recreación y para reducir costos, en lugar de enviar encuestadores, se envían por correo formularios anónimos a los domicilios de los hogares seleccionados aleatoriamente. Podría suceder que aquellos hogares que tienen gastos en recreación muy bajos contesten en proporción menor que los que más gastan. De esta manera, las respuestas resultantes darían un valor promedio por encima del verdadero por el hecho que, inadvertidamente, la muestra estaría representando en mayor medida a los hogares que tienen los más altos gastos en recreación. En el estudio acerca del comportamiento sexual de las mujeres en Estados Unidos, el Informe Hite (1976) basó sus conclusiones sobre el 3% de mujeres que remitieron completos los cuestionarios que habían recibido por correo. Aun cuando el número de cuestionarios respondidos sea alto (gracias a una numerosa muestra inicial), resulta riesgoso extender las conclusiones a la población en general. Es así porque no se sabe si ese pequeño porcentaje de mujeres que respondieron tiene conductas semejantes o muy diferentes de aquellas que no lo hicieron. En la actualidad ya no se envían formularios por correo postal para que la gente responda, pero sí se hacen encuestas por mail o se invita a expresar la opinión en encuestas en sitios web. A esas encuestas responde una fracción muy específica de la población: la que accede a internet, que visita esa página, que tiene tiempo e interés por responder a las preguntas que allí se hacen. No es posible saber qué recorte de la población es representado por esa muestra y es completamente inválido extender los resultados a toda la población, como lo es generalizar a los visitantes de esa página, ya que no todos tienen el tiempo ni el interés para responder. Se trata de un dato imposible de adjudicar a alguna población identificable, es simplemente “la opinión de los que opinaron”. Sin embargo a veces se tratan equivocadamente esos resultados como si representaran una tendencia de opinión. El muestreo autoelegido tiene una aplicación en el campo de experimental cuando se trabaja con sujetos humanos. Allí, la selección de quienes participarán de los experimentos, muy raramente puede hacerse al azar, habitualmente resulta de la voluntad de personas que se prestan para los estudios. Sin embargo, es un requisito indispensable en los experimentos que se asignen las personas de manera aleatoria a los grupos experimental y control. Es decir, que se elija aleatoriamente a cuáles de las personas voluntarias se someterá a los tratamientos que se ponen a prueba y a cuáles se tomará como controles. También es frecuente usar cuotas en la asignación de sujetos a los dos grupos de modo que estén equilibrados respecto de algunas variables, cuya determinación depende del estudio particular. En este caso las cuotas indican qué proporción de casos se requieren en cada categoría de las variables de interés, la selección de los sujetos que constituirán el grupo experimental y el grupo control se hace aleatoriamente. Este tema se desarrolla con detalle en Metodología de la Investigación. 6.3.4 Muestreo accidental o según disponibilidad Esta modalidad cuenta con sustancial difusión, en particular por los medios de comunicación, y consiste en entrevistar a los individuos que se encuentran accidentalmente en determinado lugar. La expresión “accidental” se presta a equívocos ya que puede confundirse con “aleatorio”. Si bien no resulta posible identificar a quien toma la decisión por la selección de la muestra, nos encontramos en una situación en que múltiples factores son los responsables de la misma. Algunos de estos factores son: la voluntad de los encuestados para prestarse o no a participar de la entrevista, la elección (consciente o no) que el entrevistador hace entre las personas que transitan, el lugar donde se hace la entrevista (ciertas personas difícilmente transitan por determinadas áreas de una ciudad), etc. El hecho que se trate de la confluencia de múltiples factores fortuitos, lo que determina cuáles serán las personas que formarán parte de la muestra y quienes no, no puede considerarse sinónimo de aleatoriedad. Por lo tanto, no se trata de un muestreo probabilístico dado que no es posible asignar probabilidades a priori de pertenecer a la muestra a los elementos de la población. En consecuencia, las conclusiones obtenidas a través de este tipo de relevamiento (porcentaje de opiniones a favor o en contra de un tema cualquiera, etc.) sólo pueden ser válidas para aquellas personas que fueron parte integrante de la muestra, no pudiendo generalizarse los resultados más allá de la misma. Por el contrario cuando se lo utiliza en ámbitos académicos, suelen tomarse los resguardos mencionados antes para conseguir que sea tan representativo como sea posible. Para hacer esto se consideran en primer lugar las características conocidas de la población y se las reproduce en la muestra por ejemplo la proporción de varones y mujeres, los niveles de educación, como en el caso del muestreo por cuotas. Luego se busca la mayor heterogeneidad posible y un número elevado de casos. Con estos cuidados, este tipo de muestreo puede usarse, por ejemplo para la validación de escalas psicométricas. 6.3.5 Muestreo bola de nieve Esta técnica fue publicada por primera vez por Leo Goodman (1961), de la Universidad de Chicago. Es adecuada cuando se debe estudiar una población infrecuente, poco representada en el total general y no hay un marco disponible para el muestreo. Estas situaciones se presentan, por ejemplo, si se requiere entrevistar a consumidores de drogas ilegales, personas afectadas por alguna enfermedad rara, trabajadores inmigrantes. Comienza con la selección de una muestra inicial o básica de individuos y en cada entrevista se pregunta a qué otras personas de la población el entrevistado conoce. Luego se visita a esos casos referenciados por los primeros, repitiendo el procedimiento hasta que se completa la muestra. Así, al entrevistar a cada miembro de un grupo, se puede pedir que indique otros individuos en ese grupo que podrían dar información sobre el tema; o pedirle que mencione personas que compartan sus puntos de vista y a otras de opinión opuesta. De este modo se entrevistan nuevos individuos y se continúa del mismo modo hasta que no se encuentran nuevos puntos de vista. Cuando se llega a ese punto, se dice que se ha saturado el tema. Este es un buen método para recoger los distintos puntos de vista existentes en un grupo, o para alcanzar a persona que no son visibles en una comunidad, pero no ofrece información sobre la distribución de los casos en la población. Si es posible, la primera selección se hace en forma probabilística, y los casos siguientes quedan determinados por las referencias que se van encontrando. Lo más frecuente es que se carezca de datos iniciales, por lo que la primera muestra deberá seleccionarse en forma intencional o estar constituida por voluntarios. En cualquier caso se trata de un muestreo no probabilístico, cuya ventaja es que puede asegurar una amplia cobertura, porque permite llegar a través de contactos personales, a individuos que de otro modo permanecerían invisibles. El carácter no representativo viene dado porque la probabilidad de entrevistar a una determinada persona depende de sus conexiones: aquellas muy conectadas tendrán más probabilidad de ser entrevistadas que las que estén aisladas, o tengan pocos conocidos. Este método puede mejorarse para lograr que la muestra sea representativa de la población. Para eso se lo combina con un modelo matemático que da peso diferente a los casos teniendo en cuenta que han sido seleccionados de manera no aleatoria. La técnica que así resulta se llama “Muestreo Dirigido por el Respondente” y fue desarrollado por Douglas Heckathorn en 1997, como parte de un proyecto de investigación sobre prevención de VIH dirigido a consumidores de drogas inyectables en varias ciudades de Connecticut. Aplicando este procedimiento se logran muestras no sesgadas (representativas) aun cuando se haya partido, como generalmente sucede, con una muestra no probabilística. Para detalles sobre el modo de usarlo, puede consultarse http://www.respondentdrivensampling.org/, donde se encuentran abundantes ejemplos de aplicación. 6.4 Resumen de técnicas de muestreo 6.5 Hacerlo en R 6.5.1 Aleatorio simple Una muestra aleatoria de casos de una matriz de datos, es una selección aleatoria de un número determinado de filas, manteniendo todas las columnas igual. En primer lugar leeremos la base Encuesta Nacional de Factores de Riesgo con el nombre enfr y luego, extraeremos una submuestra aleatoria de 100 casos de ella a la que denominamos enfr100. El corchete se refiere a los elementos de enfr que se van a seleccionar. De las filas (primer componente dentro del corchete, antes dela coma) se elige una muestra de 100 filas de enfr.Luego de la coma no se indica nada, con lo que se dejan todas las columnas de la base original. En el panel superior derecho se observa la aparición del nuevo objeto enfr100, con 100 casos y 204 variables, las mismas que tenía enfr. 6.5.2 Estratificado 6.5.2.1 Afijación uniforme Es necesario instalar un paquete específico y cargarlo en la sesión Luego se define la nueva matriz muestra.estrat.eph, indicando la matriz de donde se extrae la muestra, el criterio de estratificación y la cantidad de casos. Pediremos 100 casos de cada nivel de educación: Para ver el resultado, se puede pedir cualquier tabla, con los márgenes a fin de ver el total de casos en cada categoría: ## ## 1 2 3 4 5 6 7 Sum ## 1 55 46 53 37 39 44 55 329 ## 2 45 54 47 63 61 56 45 371 ## Sum 100 100 100 100 100 100 100 700 La muestra tiene 700 casos que son 100 de cada nivel de educación. También se puede pedir más de un criterio de estratificación, por ejemplo, educación y sexo: ## ## 1 2 3 4 5 6 7 Sum ## 1 100 100 100 100 100 100 100 700 ## 2 100 100 100 100 100 100 100 700 ## Sum 200 200 200 200 200 200 200 1400 Ahora hay 1400 casos en total 100 en cada combinación de sexo y nivel de educación (2X7). 6.5.2.2 Afijación proporcional En lugar de especificar la cantidad de casos, se puede indicar la proporción de casos que se requieren de cada categoría, por ejemplo para el 10%: ## ## 1 2 3 4 5 6 7 Sum ## 1 404 337 620 536 298 270 264 2729 ## 2 428 391 559 561 344 407 270 2960 ## Sum 832 728 1179 1097 642 677 534 5689 La cantidad de casos en cada categoría depende de cuántos casos había en la matriz original. La idea de infinito no es la de la matemática, sino que se refiere a una relación pequeña entre la cantidad de casos de muestra y los de la de la población. Ver nota 48.↩ "],
["probabilidad-los-fundamentos.html", "Capítulo 7 Probabilidad: los fundamentos 7.1 El rol de la probabilidad en Estadística 7.2 Formas para asignar probabilidades 7.3 Operando con probabilidades 7.4 El teorema de Bayes 7.5 Variables aleatorias", " Capítulo 7 Probabilidad: los fundamentos 7.1 El rol de la probabilidad en Estadística Para hacer inferencias se requiere de la probabilidad porque se trabaja con situaciones inciertas, que no se conocen y que son difíciles de prever. Por eso se comienza aquí haciendo la distinción entre las preguntas que pueden responderse con certeza y las que no. De las primeras, son ejemplos: ¿cuándo será el próximo eclipse de sol? ¿Cómo varía el diámetro de la pupila luego del consumo de alcohol? Sobre estas preguntas tenemos, o bien un conocimiento profundo sobre el movimiento de los astros, o bien una gran cantidad de observaciones, que nos permiten dar una respuesta certera. Por el contrario, si preguntamos ¿cuál es el efecto sobre la personalidad, de haber tenido figuras parentales autoritarias en la niñez? ¿Qué determina que algunos alumnos tengan éxito en la escuela y otros no? ¿Cómo afecta la estabilidad económica a la intención de voto?, solo podemos ofrecer respuestas parciales, tentativas, aproximadas. Se trata de hechos que dependen de muchos factores a los que no conocemos en su totalidad, por lo que el resultado es variable: algunas personas criadas en ambientes autoritarios desarrollan una personalidad autoritaria, otras no. En algunos alumnos, el hecho que sus padres tengan estudios elevados los ayuda a tener éxito en la escuela, pero también hay hijos de personas muy educadas que fracasan en la escuela. La estabilidad económica que favorecería una reelección, puede estar acompañada de mucha pobreza, o de corrupción; también eventos inesperados antes de las elecciones pueden cambiar decisiones a último momento. Hay razones más allá de nuestro alcance que inciden en la personalidad o en el resultado de la escuela, o la intención de voto. En estas situaciones, cuando no tenemos toda la información que hace falta para predecir el resultado, recurriremos a la probabilidad. Ingresaremos al tema desde situaciones muy sencillas, desde el muy usado ejemplo de arrojar una moneda. Pero detengámonos un momento en él: si tuviéramos toda la información necesaria para predecir la trayectoria de la moneda en el aire (distancia desde donde se arroja, fuerza que se le aplica, el lugar de la moneda donde se aplica esa fuerza, eventuales corrientes de aire que puedan incidir en el desplazamiento de la moneda, etc.), podríamos predecir con certeza el resultado. Esa información no está disponible, el lado del que caiga la moneda está determinado por una multiplicidad de factores, por esa razón no podemos anticipar el resultado de la tirada. A esa ignorancia la resumimos diciendo que el resultado de la tirada de la moneda “depende del azar” y llamamos al experimento de tirar una moneda “experimento aleatorio”. Es un paso muy largo ir desde este ejemplo a decir que el modo en que se desarrolle la personalidad de alguien que ha sido criado en una familia autoritaria depende del azar o que la distribución de votos en las próximas elecciones depende del azar. Sabemos que esos resultados no dependen del azar, dependen de muchos factores que ignoramos, por eso usaremos probabilidades en las disciplinas que tratan con sujetos humanos, por la imposibilidad de predecir con certeza los resultados. Podremos decir que un alumno cuyos padres valoran la educación tiene una probabilidad mayor de tener éxito en la escuela, pero no podremos asegurar que lo tendrá. Es razonable creer que si un gobierno logró estabilidad económica, tendrá más posibilidades de ser reelegido, pero no hay certeza sobre que lo será. Los tratamientos más exitosos encuentran casos en los que no logran resultados, por lo que su efectividad no puede garantizarse completamente, hay una componente impredecible en la evolución de la patología. La probabilidad trata con la incertidumbre, con lo que hay entre la certeza en que algo ocurrirá y la certeza en que no ocurrirá. Los eventos que no son azarosos no tienen que ver con probabilidades: no asignamos probabilidad a un eclipse porque hay conocimiento suficiente como para saber cuándo ocurrirá; pero sí se asigna probabilidad a una tormenta, porque no se conocen simultáneamente todos los factores que la determinan. Se asignan probabilidades a hechos de cuya ocurrencia no se tiene certeza. Con la probabilidad se cuantifica (se le asigna un número) a la expectativa sobre el fenómeno. Intuitivamente, cuando decimos que algo tiene “mucha probabilidad de suceder” es porque estamos bastante seguros que sucederá. Esta es la posición conocida como “azar epistemológico”, que considera azarosos o aleatorios a los eventos cuya ocurrencia no puede anticiparse con certeza. Desde esta posición, que sea azaroso o no, depende el conocimiento que se tenga sobre los determinantes del evento. La cuantificación de la probabilidad implica que ésta se expresa con un número que está comprendido entre cero y uno. Que un evento tenga probabilidad cero significa que es imposible que suceda. Si un evento tiene probabilidad igual a uno, se llama “evento seguro”, y quiere decir que hay certeza en que sucederá. 7.2 Formas para asignar probabilidades 7.2.1 Asignación a priori Podemos partir de esa idea intuitiva de probabilidad, ligada a procesos cuya ocurrencia no nos es conocida con certeza. Para evocar esta idea, el ejemplo que más a menudo se cita es el del lanzamiento de una moneda, ¿cuál es la probabilidad de obtener “cara” al arrojar una moneda? Si la respuesta es \\(1/2\\) (o 0,50 ó 50 y 50), debe tenerse en cuenta que eso solo será cierto si la moneda está equilibrada, es decir si tiene iguales chances de salir de un lado que del otro. Si esto es cierto, efectivamente la probabilidad de obtener cara es \\(1/2\\) (ó 0,50). Con idéntica condición, la probabilidad de obtener un 5 al arrojar un dado es \\(1/6\\) (ó 0,17). Esta asignación de probabilidad a los resultados de un experimento es previa a su realización, no es necesario tirar realmente la moneda: es suficiente con que tengamos razones para suponer que está equilibrada, para poder afirmar que la probabilidad de cara es \\(1/2\\). Diremos en este caso que asignamos la probabilidad a priori, es decir, antes de hacer el experimento. De mismo modo sucede si el evento que nos interesa en un poco más complejo. Por ejemplo: ¿Cuál es la probabilidad de obtener un número mayor a cuatro si se tira un dado? Debido a que hay dos números mayores a cuatro (5 y 6), el evento tiene dos casos a su favor y hay seis resultados posibles, por lo que la probabilidad será: \\(2/6\\) (ó \\(1/3\\), si se simplifica la fracción). La expresión formal de esta asignación de probabilidades es. \\[P(A)=\\frac{\\#A}{\\#\\Omega}\\] En la que \\(\\#A\\) (que se lee “numeral de A”) indica el número de maneras enque puede suceder el evento A, y \\(\\#\\Omega\\) (numeral de omega) es el número total de resultados que se pueden obtener al realizar el experimento. \\(\\Omega\\) es el conjunto de resultados posibles, es llamado espacio muestral. En el caso del ejemplo, el experimento es el de tirar el dado y buscar un número mayor que cuatro, \\(\\#A\\) es 2 porque son las formas en que puede obtenerse un número mayor que cuatro, y \\(\\#\\Omega\\) es 6, que es el número total de resultados posibles al tirar un dado. Con este mismo razonamiento, la probabilidad de obtener un número par es \\(3/6\\) (\\(1/2\\) después de simplificar), porque hay tres números pares (2, 4 y 6) en un dado. Vamos a un caso más complejo: tiremos ahora dos dados y tomemos en cuenta la suma de los dos puntajes, a esa suma la llamaremos \\(S\\). El mínimo número que puede resultar es dos (que ambos dados salgan uno) y el máximo es doce (ambos seis), entonces hay once resultados posibles de esta variable (que son: \\(S = 2\\), \\(S = 3\\), \\(S = 4\\), \\(S = 5\\), \\(S = 6\\), \\(S = 7\\), \\(S = 8\\), \\(S = 9\\), \\(S = 10\\), \\(S = 11\\) y \\(S = 12\\)), algunos de los cuales pueden suceder de varias formas. Estos resultados posibles y sus formas de obtención se ven de manera esquemática a continuación: Tabla 7.1: Resultados posibles de la suma de los puntajes de dos dados. Primer dado 1 2 3 4 5 6 Segundo dado 1 2 3 4 5 6 7 2 3 4 5 6 7 8 3 4 5 6 7 8 9 4 5 6 7 8 9 10 5 6 7 8 9 10 11 6 7 8 9 10 11 12 Si bien los resultados posibles son 11, las formas en que estos pueden darse son 36; cada una de esas formas es un evento. El evento primer dado 5 y segundo dado 2 es diferente del evento primer dado 2 y segundo dado 5, aunque ambos conducen al mismo resultado de la suma: \\(S=7\\). Más precisamente, si indicamos los eventos con pares ordenados, los eventos \\((1,6)\\); \\((6,1)\\); \\((2,5)\\); \\((5,2)\\); \\((3,4)\\); \\((4,3)\\) son diferentes pero todos corresponden a \\(S=7\\). Son entonces 36 los resultados posibles del experimento, por lo que \\(\\#\\Omega\\) = 36. Ahora podemos calcular probabilidades para diferentes resultados. ¿Cuál es la probabilidad que la suma sea 12?, lo que puede expresarse como: ¿cuál es \\(P(S=12)\\)? Como esta suma solo puede lograrse si ambos dados salen 6, hay una sola manera en que se produzca el evento que nos interesa (suma doce), por lo que el \\(\\#A\\) es 1 y la probabilidad es entonces \\(1/36\\). \\(\\#A = 1, P(S = 12)=1/36\\) Primer dado 1 2 3 4 5 6 Segundo dado 1 2 3 4 5 6 7 2 3 4 5 6 7 8 3 4 5 6 7 8 9 4 5 6 7 8 9 10 5 6 7 8 9 10 11 6 7 8 9 10 11 12 En cambio, si la pregunta es por la probabilidad de obtener un tres, hay más de una manera de llegar a ese resultado (que \\(S = 3\\)). La suma 3 puede resultar de \\(2+1\\) ó de \\(1+2\\), es decir que, o bien el primer dado sale 2 y el segundo 1 ó bien el primero sale 1 y el segundo 2. Hay así dos formas posibles para el evento \\(S = 3\\), y \\(\\#A\\) es 2, por lo que la probabilidad es \\(P(S = 3) = 2/36\\). \\(\\#A = 2, P(S = 3)=2/36\\) Primer dado 1 2 3 4 5 6 Segundo dado 1 2 3 4 5 6 7 2 3 4 5 6 7 8 3 4 5 6 7 8 9 4 5 6 7 8 9 10 5 6 7 8 9 10 11 6 7 8 9 10 11 12 Otro ejemplo, sea \\(P(S=7)\\). La suma de siete puede obtenerse de muchas formas: \\(1+6\\), \\(2+5\\), \\(3+4\\), \\(4+3\\), \\(5+2\\) ó \\(6+1\\). Hay seis combinaciones que conducen a \\(S=7\\), en consecuencia, la probabilidad es \\(6/36\\). \\(\\#A = 6, P(S = 7)=6/36\\) Primer dado 1 2 3 4 5 6 Segundo dado 1 2 3 4 5 6 7 2 3 4 5 6 7 8 3 4 5 6 7 8 9 4 5 6 7 8 9 10 5 6 7 8 9 10 11 6 7 8 9 10 11 12 7.2.2 Asignación a posteriori Consideremos ahora una situación más cercana a la experiencia: supongamos que de un curso se selecciona un alumno al azar ¿Cuál es la probabilidad que sea mujer? Aquí el supuesto de equilibrio no es válido a priori, en gran medida depende de la carrera de que se trata, las hay con muchas mujeres y con pocas. Por lo tanto no podemos suponer que es igualmente probable que resulte un varón o una mujer y no podemos asignar probabilidad \\(1/2\\) a cada resultado. Aunque el experimento tenga dos resultados posibles, éstos no son igualmente probables. En otro ejemplo, si al alumno aleatoriamente seleccionado (por ejemplo, el que ocupa el lugar 98 en la lista de inscriptos) se le pregunta por el tipo de colegio del que egresó, con los resultados posibles: “público”, “privado laico”, “privado religioso”, el resultado que se obtenga también depende del azar, porque así fue elegido el alumno, la respuesta será una u otra según cuál sea el alumno elegido y esto depende del azar. Sin embargo, no podemos asignar una probabilidad igual a cada resultado, no es lícito decir que sea \\(1/3\\), ya que puede haber más estudiantes que provengan de colegios públicos que de privados y, en consecuencia, que sea más probable encontrar alumnos provenientes de esos colegios que de los otros. En este caso no podemos asignar de antemano probabilidades a los diferentes resultados, porque no tenemos suficientes razones para suponer la forma en que se distribuyen las probabilidades. Si supiéramos que hay el doble de alumnos que vienen de colegios públicos, podríamos decir que el alumno elegido al azar tiene el doble de probabilidad de provenir de un colegio público que de otro tipo. Encontramos así una relación entre la frecuencia y la probabilidad: si conocemos la distribución de frecuencias, tenemos razones para usarlas para asignar probabilidades a los resultados del experimento. Así, si una muestra de alumnos ofrece la siguiente distribución de frecuencias para el tipo de colegio del que provienen. Tabla 7.2: Distribución de frecuencias del tipo de colegio del que provienen alumnos que ingresan a la universidad f f’ Público 200 0,66 Privado laico 20 0,07 Privado religioso 80 0,27 Total 300 1,00 Fuente: datos ficticios para ejemplificación. Estamos autorizados a decir que la probabilidad que el alumno elegido al azar provenga de un colegio público es 0,67, que es su frecuencia relativa. Esto será válido en la medida que el número de casos sea elevado; no es posible transformar una frecuencia relativa en probabilidad si tenemos muy pocas observaciones. Más adelante volveremos sobre esta importante limitación. Cuando atribuimos probabilidades de este modo se trata de probabilidades a posteriori, es decir con posterioridad a haber hecho la experiencia, luego de la observación de los resultados reales obtenidos. También se llama a estas probabilidades empíricas, para destacar que provienen de la experiencia. ¿Cuál es el significado del 1.00 que corresponde al total? Sin dudas, como frecuencia significa el 100% de los casos, pero como probabilidad indica que el conjunto completo de alternativas (público, privado laico, privado religioso) tiene probabilidad 1.00; o bien que es un evento seguro. La expresión coloquial para este valor es que cuando se selecciona un alumno al azar, éste debe provenir de alguno de los tres tipos de colegio indicados, entonces el valor uno responde a la pregunta “¿cuál es la probabilidad de encontrar un alumno que provenga de un colegio que sea público, privado laico o privado religioso?”, la respuesta es que es seguro que de alguno de esos tipos de colegio provendrá el alumno, porque no hay otras alternativas, es decir que las categorías son exhaustivas, como debe ser. En este caso, \\[\\mathrm{\\Omega} = \\{ publico,\\ privado\\ laico,\\ privado\\ religioso\\}\\] Como vimos más arriba, el evento seguro es el que tiene probabilidad 1, por lo que la expresión formal de este enunciado es: \\(P(\\Omega) = 1\\) Donde \\(\\Omega\\) indica el conjunto de todos los resultados posibles de un experimento aleatorio, o el conjunto de todas las categorías de un variable, al que hemos llamado espacio muestral. 7.2.3 La relación entre asignación a priori y a posteriori Volvamos al experimento simple de arrojar la moneda: si ésta se encuentra equilibrada será entonces correcto asignar probabilidad \\(1/2\\) (ó 0,50) a cada lado, lo que indica que esperamos que a la larga la moneda caiga la mitad de las veces cara y la mitad cruz. Destaquemos la expresión “a la larga”, que quiere decir “si se arroja muchas veces”. Hagamos el experimento realmente, busque usted una moneda y arrójela, digamos 10 veces. Yo lo hice y obtuve la siguiente secuencia de resultados: CXXXCCCXXC. Elijamos nuestro lado favorito, que sea “cara” (C) y calculemos la frecuencia relativa de ese lado en cada tirada, presentamos los resultados resumidamente en la tabla . Cuando solo la he tirado una vez y como el primer resultado fue C, la frecuencia es 1 (una cara de un total de un resultado). A la segunda tirada, que es X, se obtiene \\(1/2\\) (una cara de dos tiradas). A la tercera, que otra vez sale X, la frecuencia de cara es \\(1/3\\) (una cara de tres tiradas) y así sigue: Tabla 7.3: Frecuencias relativas correspondientes a una secuencia de diez lanzamientos de una moneda. Tirada Cantidad de tiradas Resultado Cantidad de caras acumuladas Frecuencia relativa del evento “cara” Primera 1 C 1 1/1 = 1,00 Segunda 2 X 1 1/2 = 0,50 Tercera 3 X 1 1/3 = 0,33 Cuarta 4 X 1 1/4 = 0,25 Quinta 5 C 2 2/5 = 0,40 Sexta 6 C 3 3/6 = 0,50 Séptima 7 C 4 4/7 = 0,57 Octava 8 X 4 4/8 = 0,50 Novena 9 X 4 4/9 = 0,44 Décima 10 C 5 5/10 = 0,50 En la distribución vemos que la frecuencia relativa de C toma valores alrededor de 0,50; al principio más lejos y luego “se va acercando” a ese número cuando hemos hecho más tiradas. La representación gráfica de este proceso es la siguiente: Donde hemos agregado una línea que muestra el valor 0,50 que es el que habíamos calculado antes de hacer el experimento. Se aprecia que la sucesión de frecuencias relativas es tal que éstas se van acercando a la probabilidad predicha. Si la moneda se hubiese tirado una cantidad mayor de veces (cien veces, por ejemplo), el gráfico tendría una forma como la siguiente: Resulta entonces que, si se cumple que la moneda está equilibrada, entonces las frecuencias relativas de un resultado se irán acercando a la probabilidad asignada. Dicho de otra manera, la probabilidad a posteriori converge a la probabilidad a priori. Mucha atención a esto: solo en el caso que el supuesto inicial se cumpla, es decir que la moneda se comporte como esperamos (cayendo parejo de un lado y del otro). Si por el contrario, la moneda estuviese desequilibrada -y que fuera más frecuente el lado X que el lado C-, podríamos obtener, en 500 tiradas, por ejemplo, 350 veces X y la probabilidad a posteriori será entonces \\(P(C) = 350/500 = 0,70\\) y no 0,50 como sería si estuviera equilibrada. En ese caso el supuesto inicial de moneda equilibrada se muestra falso, decimos que “el modelo no se sostiene”, en un momento veremos con más detalle el significado de esta expresión. 7.3 Operando con probabilidades Cualquiera sea el modo a través del que se hayan asignado probabilidades a eventos, las probabilidades cumplen con ciertas propiedades generales, que trataremos a continuación y que permiten hacer operaciones con ellas. En primer lugar, y con carácter de axiomas, las siguientes características son condición para que un número \\(P(A)\\) pueda ser considerado una probabilidad: La probabilidad es un número comprendido entre cero y uno: \\(0 \\leq P(A) \\leq 1\\) La probabilidad del conjunto completo de resultados posibles (del espacio muestral) es uno: \\(P(\\Omega) = 1\\) La probabilidad de la unión de dos eventos que se excluyen mutuamente es la suma de las probabilidades de cada uno de ellos: \\(P(A \\cup B) = P(A) + P(B)\\) La definición frecuencial (a posteriori), así como todos los modelos de asignación de probabilidad a priori que mencionamos cumplen con estas condiciones. 7.3.1 Con probabilidades frecuenciales Sea una distribución conjunta de dos variables con asignación de probabilidades frecuenciales, es decir empíricas. Se trata de la relación entre la ciudad donde se vive y la intención de voto. Las categorías de la ciudad son: Córdoba, Rosario y Mendoza. Los partidos políticos son cuatro y los llamaremos Q, R, S y T. Supongamos que las siguientes son las frecuencias observadas luego de recoger los datos: Tabla 7.4: Distribución del partido al que declara que va a votar y la ciudad de residencia. Ciudad Partido al que dice que votará Total Q R S T Córdoba 200 300 100 50 650 Rosario 100 150 60 70 380 Mendoza 50 150 100 200 500 Total 350 600 260 320 1530 Calculemos algunas probabilidades a partir de las frecuencias relativas. 7.3.1.1 Probabilidades marginales Cuando se consideran las categorías de una variable sin tener en cuenta a la otra, usamos las frecuencias de los márgenes de la tabla, esas son las llamadas frecuencias marginales. La probabilidad que una persona elegida al azar viva en Córdoba (sin importar a qué partido piense votar) es \\(650/1530\\). De manera equivalente, la probabilidad de encontrar por azar a alguien que piense votar al partido \\(S\\) (cualquiera sea su ciudad) es \\(260/1530\\). Las escribimos simplemente \\(P(Córdoba)\\) y \\(P(S)\\) respectivamente. En las tablas singuientes están destacadas las frecuencias que participan en el cálculo de estas probabilidades. Tabla 7.5: Distribución del partido al que declara que va a votar y la ciudad de residencia. Esquema para el cálculo de la probabilidad marginal \\(P(Córdoba)\\). Ciudad Partido al que dice que votará Total Q R S T Córdoba 200 300 100 50 650 Rosario 100 150 60 70 380 Mendoza 50 150 100 200 500 Total 350 600 260 320 1530 Tabla 7.6: Distribución del partido al que declara que va a votar y la ciudad de residencia. Esquema para el cálculo de la probabilidad marginal \\(P(S)\\). Ciudad Partido al que dice que votará Total Q R S T Córdoba 200 300 100 50 650 Rosario 100 150 60 70 380 Mendoza 50 150 100 200 500 Total 350 600 260 320 1530 7.3.1.2 Probabilidades conjuntas o de la intersección de eventos Las usamos para hallar la probabilidad de ocurrencia simultánea de una categoría de cada variable. Por ejemplo ¿Cuál es la probabilidad de encontrar por azar a alguien que viva en Rosario años y que piense votar al partido R? La cantidad de individuos que cumplen simultáneamente las dos condiciones es de 150, por lo que la probabilidad se calcula como \\(150/1530\\). Hemos destacado la conjunción “y”, junto al “simultáneamente” porque en este caso se piden dos condiciones juntas. Por eso estas son llamadas probabilidades conjuntas. En teoría de conjuntos, corresponden a la intersección de dos conjuntos, que se indica con el signo \\(\\cap\\), por lo que el evento “vivir en Rosario” y al mismo tiempo “decir que se va a votar a R”, se escribe “\\(Rosario \\cap R\\)”. Esa intersección puede verse gráficamente en el cruce de la fila con la columna correspondiente. Tabla 7.7: Distribución del partido al que declara que va a votar y la ciudad de residencia. Esquema para el cálculo de la probabilidad conjunta \\(P(Rosario y R)\\). Ciudad Partido al que dice que votará Total Q R S T Córdoba 200 300 100 50 650 Rosario 100 150 60 70 380 Mendoza 50 150 100 200 500 Total 350 600 260 320 1530 ¿Qué sucede si aplicamos esta operación a dos eventos que corresponden a dos categorías de la misma variable?, por ejemplo, ¿cuál es la probabilidad de encontrar a alguien que diga que votará a Q y a R? Esos eventos no pueden suceder juntos porque son incompatibles: solo uno de los dos puede suceder. La intersección entre ellos es imposible, por lo que la probabilidad es cero. Es el mismo caso de buscar a alguien que viva en Córdoba y también en Mendoza, es claro que no hay intersección entre estos conjuntos; dicho de otra forma, la intersección es el conjunto vacío. A estos eventos que no pueden suceder simultáneamente, los llamaremos mutuamente excluyentes. Como recordamos, esa es la condición que deben cumplir las categorías de cualquier variable. Si dos eventos son mutuamente excluyentes entonces, su probabilidad conjunta es cero. En lenguaje de conjuntos: \\[si\\ A \\cap B = \\varnothing\\ entonces\\ P(A \\cap B) = 0\\] 7.3.1.3 Probabilidad de la unión de eventos mutuamente excluyentes Estas probabilidades sirven para analizar la ocurrencia de uno u otro de dos eventos, cuando éstos no pueden suceder simultáneamente. Por ejemplo: ¿qué probabilidad hay de encontrar a alguien que piense votar a Q o a R? Esto quiere decir “una cosa o la otra”, se trata de una disyunción, es decir, la unión de los dos eventos. En el lenguaje de la teoría de conjuntos la unión de dos conjuntos se indica con el símbolo \\(\\cup\\), por lo que decir “A o B” equivale a decir “\\(A\\cup B\\)”. El total de quienes cumplen con la condición de votar a Q o a R (sin tener en cuenta la ciudad) es de \\(950 (350 + 600)\\), por lo que la probabilidad es de \\(950/1530\\). Tabla 7.8: Distribución del partido al que declara que va a votar y la ciudad de residencia. Esquema para el cálculo de la probabilidad \\(P(Q o R)\\) (eventos disjuntos). Ciudad Partido al que dice que votará Total Q R S T Córdoba 200 300 100 50 650 Rosario 100 150 60 70 380 Mendoza 50 150 100 200 500 Total 350 600 260 320 1530 De modo equivalente, la probabilidad de seleccionar al azar a alguien que viva en Córdoba o en Rosario es de \\(1030/1530\\), donde hemos sumado las dos primeras categorías (Córdoba y Rosario). Tabla 7.9: Distribución del partido al que declara que va a votar y la ciudad de residencia. Esquema para el cálculo de la probabilidad \\(P(Córdoba o Rosario)\\) (eventos disjuntos). Ciudad Partido al que dice que votará Total Q R S T Córdoba 200 300 100 50 650 Rosario 100 150 60 70 380 Mendoza 50 150 100 200 500 Total 350 600 260 320 1530 En estas probabilidades, admitimos que se cumpla cualquiera de las dos condiciones (Q o R en el primer caso, Córdoba o Rosario en el segundo). En los dos ejemplos se trata de eventos que no pueden suceder simultáneamente, por ser categorías de una de las variables, son mutuamente excluyentes, por lo que la probabilidad de su ocurrencia conjunta es cero. En estos casos, la probabilidad de la unión es simplemente la suma de las probabilidades de los dos eventos: \\(P(A \\cup B) = P(A) + P(B)\\) Aplicada a los ejemplos: \\[P(Q \\cup R) = P(Q) + P(R)\\] \\[P(Córdoba \\cup Rosario) = P(Córdoba) + P(Rosario)\\] 7.3.1.4 Probabilidad de la unión de eventos no mutuamente excluyentes Vamos ahora a incluir en la operación de unión de eventos, aquellos que no se excluyan mutuamente. Para el ejemplo con el que venimos trabajando, cambiamos las condiciones de esta unión de eventos: Ahora preguntamos: ¿Cuál es la probabilidad de hallar por azar a alguien que viva en Córdoba o que piense votar al partido T? Otra vez es una disyunción, por lo que admitimos cualquiera de los dos eventos: que viva en Córdoba (sin importar a quién piense votar) o que piense votar a T (cualquiera sea su ciudad). Si intentamos el mismo procedimiento que en el caso anterior, deberíamos sumar las probabilidades: \\(650/1530 + 320/1530\\), con solo observar la Tabla 8, vemos que los 50 individuos que cumplen las dos condiciones (viven en Córdoba y votarán a T), han sido contados dos veces: en los 650 y en los 320, por lo que deben descontarse del resultado haciendo \\(650/1530 + 320/1530 - 50/1530\\). ¿Por qué sucedió esto?, porque los eventos cuya unión estamos considerando pueden ocurrir simultáneamente, tienen intersección y es esa intersección justamente la que aparece en el cálculo de las dos probabilidades que se suman. Esta última expresión tiene forma: \\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\] Y es la expresión más general para el cálculo de la probabilidad de la unión de conjuntos. Esta fórmula toma la forma simplificada que usamos antes \\(P(A \\cup B) = P(A) + P(B)\\) solo cuando A y B son disjuntos, es decir cuando se excluyen mutuamente como lo indica el tercer axioma. Aplicada al ejemplo, el cálculo es: \\[P(Córdoba \\cup T) = P(Córdoba) + P(T) - P(Córdoba \\cap T) =\\] \\[\\frac{650}{1530} + \\frac{320}{1530} - \\frac{50}{1350} = \\frac{920}{1530} = 0,60\\] Tabla 7.10: Distribución del partido al que declara que va a votar y la ciudad de residencia. Esquema para el cálculo de la probabilidad \\(P(Córdoba o T)\\) (eventos no disjuntos). Ciudad Partido al que dice que votará Total Q R S T Córdoba 200 300 100 50 650 Rosario 100 150 60 70 380 Mendoza 50 150 100 200 500 Total 350 600 260 320 1530 7.3.1.5 Probabilidad condicional Este es el caso en que necesitamos calcular una probabilidad bajo una condición, que restringe el conjunto de resultado posibles. Se aplica cuando se cuenta con información adicional antes de calcular una probabilidad, por ejemplo que se sepa que la persona seleccionada al azar vive en Córdoba. ¿Cuál es la probabilidad que piense votar al partido S? El planteo es tal que preguntamos cuál es la probabilidad de votar a S si se sabe que vive en Córdoba. Vivir en Córdoba es la condición y se escribe: \\(S/Córdoba\\), y lo leemos “S, dado que vive en Córdoba”. En este caso, el dato “vive en Córdoba” es una restricción sobre el conjunto total, ya no debemos tener en cuenta a las 1530 personas del total, sino solo a los que cumplen con la condición de vivir en Córdoba. Entonces ahora, el nuevo total es de solo 650 personas, los que viven en Córdoba. De ellos, 100 piensan votar a S, por lo que la probabilidad que nos interesa es \\(100/650\\). Entonces: \\(P(S/Córdoba) = \\frac{100}{650} = 0,15\\). Tabla 7.11: Distribución del partido al que declara que va a votar y la ciudad de residencia. Esquema para el cálculo de la probabilidad condicional \\(P(S/Córdoba)\\). Ciudad Partido al que dice que votará Total Q R S T Córdoba 200 300 100 50 650 Rosario 100 150 60 70 380 Mendoza 50 150 100 200 500 Total 350 600 260 320 1530 Razonando del mismo modo, si se sabe que la persona elegida piensa votar a R, el total queda restringido a 600 casos (los que cumplen con esa condición). Si nos interesa la probabilidad que viva en Mendoza, bajo esa restricción resulta: \\(150/600\\). Entonces: \\(P(Mendoza/R) = \\frac{150}{600} = 0,25\\) Tabla 7.12: Distribución del partido al que declara que va a votar y la ciudad de residencia. Esquema para el cálculo de la probabilidad condicional \\(P(Mendoza/R)\\). Ciudad Partido al que dice que votará Total Q R S T Córdoba 200 300 100 50 650 Rosario 100 150 60 70 380 Mendoza 50 150 100 200 500 Total 350 600 260 320 1530 En estos dos últimos ejemplos, el cambio respecto de todos los anteriores es que el denominador de las probabilidades ya no es 1530 sino un número menor, que resulta de haber impuesto previamente una condición: que viva en Córdoba en el primer caso y que haya votado a R en el segundo. Como se ve, estas probabilidades condicionales no son conmutativas: Se selecciona una persona al azar entre quienes votarán a R, ¿Cuál es la probabilidad que viva en Mendoza? Se escribe \\(P(Mendoza/R)\\) y vale \\(150/600\\). Se selecciona una persona al azar entre los que viven en Mendoza, ¿Cuál es la probabilidad que vaya a votar a R? Se escribe \\(P(R/Mendoza)\\) y vale \\(150/500\\). 7.3.1.6 Relación entre probabilidades condicionales y conjuntas Compararemos ahora la probabilidad de hallar alguien que vaya a votar a Q y que viva en Córdoba (\\(P(Q \\cap Córdoba)\\)) con la probabilidad que vaya a votarlo si se sabe que vive en Córdoba (\\(P(Q/Córdoba)\\)). \\[P(Q \\cap Córdoba) = \\frac{200}{1503}\\] \\[P(Q/Córdoba) = \\frac{200}{650}\\] Si dividimos entre sí estas dos expresiones obtenemos: \\[\\frac{P(Q \\cap Córdoba)}{P(Q/Córdoba)} = \\frac{\\frac{200}{1503}}{\\frac{200}{650}} = \\frac{650}{1503}\\] El último cociente es la probabilidad marginal correspondiente a Córdoba, por lo que: \\[\\frac{P(Q \\cap Córdoba)}{P(Q/Córdoba)} = P(Córdoba)\\] Esta expresión, que es general, nos ofrece una relación muy útil entre las probabilidades condicional y conjunta. Una forma más frecuente de escribir esta relación, para dos eventos cualesquiera A y B es: \\[P(A \\cap B) = P(B)*P(A/B)\\] Si escribimos la intersección en orden inverso34, tenemos: \\[P(B \\cap A) = P(A)*P(B/A)\\] Como son iguales los primeros miembros de las dos expresiones anteriores, igualamos los segundos miembros, para obtener: \\[P(B)*P(A/B) = P(A)*P(B/A)\\] Esta igualdad relaciona las probabilidades condicionales en un orden o en el otro. Conociendo las probabilidades de A y B, esa igualdad nos permite pasar de \\(P(A/B)\\) a \\(P(B/A)\\), veremos más adelante que se trata de un resultado muy valioso. 7.3.2 Con probabilidades a priori Veamos el uso de estas operaciones con probabilidades usando ahora un experimento en el que asignamos probabilidades a priori. Sea una caja que contiene 4 fichas rojas y 3 azules. ¿Cuál es la probabilidad de sacar una roja en la primera extracción? Como \\(\\#Roja\\) es 4 y \\(\\#\\Omega\\) es 7, la probabilidad vale \\(4/7\\). De mismo modo, la probabilidad de una azul es \\(3/7\\). Hagamos ahora dos extracciones sucesivas de modo tal que no reponemos la primera ficha antes de sacar la segunda, este tipo de extracción se llama sin reposición. Saco la primera, veo su color y saco la segunda sin devolver la primera. ¿Cuál es la probabilidad que salga la segunda azul si la primera fue roja? En este caso, a la segunda extracción hay 3 azules sobre un total de 6 fichas (porque ya sacamos una), entonces \\(\\#Azul = 3\\) y \\(\\#\\Omega = 6\\) y la probabilidad es \\(P(A_{2}/R_{1}) = 3/6\\) (ó \\(1/2\\)). Otro caso: ¿Cuál es la probabilidad que la segunda sea azul si la primera fue azul? Ahora quedan 2 azules, porque ya sacamos una, sobre un total de 6 fichas, por lo que la probabilidad es \\(P(A_{2}/A_{1}) = 2/6\\) (ó \\(1/3\\)). Sucede entonces que la probabilidad de obtener una ficha azul a la segunda extracción depende de lo que haya resultado en la primera. Otro problema: ¿cuál es la probabilidad de sacar dos rojas en dos extracciones sin reposición? Lo escribimos: \\(P(R_{1}R_{2}) = P(R_{1}\\cap R_{2})\\) Y aplicamos la relación que encontramos al final del apartado anterior: \\[P(R_{1}\\cap R_{2}) = P(R_{1})*P(R_{2}/R_{1})=4/7*3/6=2/7\\] Que es la probabilidad que salga roja la primera multiplicada por la probabilidad que salga roja la segunda condicionada a que ya haya salido roja la primera (es decir, con el espacio muestral restringido) . Del mismo modo, la probabilidad de sacar dos azules es: \\[P(A_{1}\\cap A_{2}) = P(A_{1})*P(A_{2}/A_{1})=3/7*2/6=1/7\\] Nuevamente, es la probabilidad de azul la primera por la probabilidad de azul la segunda condicionada a que ya haya salido azul la primera. Ahora preguntamos por la probabilidad de obtener una azul y una roja, en cualquier orden. Esto equivale a pedir azul la primera y roja la segunda o bien roja la primera y azul la segunda, por lo que: \\[P((A_{1}\\cap R_{2})\\cup(R_{1}\\cap A_{2}))=P(A_{1} \\cap R_{2})+P(R_{1} \\cap A_{2}) =\\] \\[P(A_{1})*P(R_{2}/A_{1})+P(R_{1})*P(A_{2}/R_{1})\\] Si cambiamos el experimento reponiendo ahora la primera ficha antes de extraer la segunda, llamamos al experimento extracción con reposición. De este modo se restaura el espacio muestral al estado inicial. Por esta razón, la probabilidad de la segunda extracción será la misma que la de la primera para cualquier evento. Por ejemplo, \\(P(A_{2}/A_{1})\\) es \\(3/7\\), como lo es también \\(P(A_{2}/R_{1})\\). Que la primera haya sido azul o roja no afecta la probabilidad de la segunda extracción, ya que se la repone: la segunda extracción no depende de la primera. En el caso de extracciones con reposición -en que la segunda extracción no se ve afectada por el resultado que haya dado la primera-, decimos que los eventos son independientes y resulta que, para dos eventos cualesquiera A y B: \\[P(A/B) = P(A)\\] Lo cual, dicho en lenguaje cotidiano nos indica que, para la ocurrencia del evento \\(A\\), no importa que haya sucedido o no el evento \\(B\\). Debido a esto, en nuestro ejemplo, la probabilidad de obtener dos rojas es: \\[P(R_{1} \\cap R_{2})=P(R_{1})*P(R_{2})\\] Figura 7.1: Efectos de extraer una ficha sin reponerla o reponiéndola, en las condiciones que quedan para la segunda extracción. Este concepto de independencia entre eventos en muy valioso para analizar uno de nuestros más importantes problemas: las relaciones entre variables. Veamos su aplicación a la Tabla 2. Si la intención de voto fuera independiente de la ciudad donde se vive (quiere decir si votaran del mismo modo personas de las diferentes ciudades) la probabilidad de encontrar una persona que vote a R si vive en Córdoba sería simplemente la probabilidad de votar a R, es decir \\(P(R/Córdoba)=P(R)\\) y del mismo modo para los demás eventos. En nuestro ejemplo no se obtiene esa igualdad, ya que: \\(P(R/Córdoba)=300/650=0,46\\), mientras que: \\(P(R)=600/1530=0,39\\) Por lo que estos eventos no son independientes en sentido estadístico. Cuando se trataron las relaciones entre variables, se discutió este problema, al calcular las frecuencias que se esperarían si las variables fueran independientes. Se concluyó que dos variables son independientes si la frecuencia relativa de cada celda resulta del producto de las frecuencias relativas marginales que le corresponden. En el lenguaje de las probabilidades, encontramos ahora el mismo resultado y lo expresamos diciendo que si los eventos A y B son independientes, entonces \\[P(A\\cap B)=P(A)*P(B)\\] 7.4 El teorema de Bayes La aplicación que presentamos en este último apartado usa probabilidades condicionales para deducir la probabilidad que tiene un evento observado de provenir de diferentes eventos previos. Por esta razón se denomina también “teorema de las causas”35. Nos interesa porque es un resultado que permite “aprender de la experiencia”, lo que quiere decir que da los medios para usar la información disponible para modificar las probabilidades de determinados eventos. Tiene mucho valor en Ciencias de la Salud, porque es frecuente conocer cuál es la probabilidad a priori que un paciente tenga determinada patología (la prevalencia de la enfermedad) pero, una vez que se dispone de indicadores clínicos, esa probabilidad cambia. De manera equivalente, si se conoce cuál es la probabilidad que un alumno termine una carrera universitaria, esa probabilidad puede modificarse, una vez que se cuenta con información adicional, como el número de materias que ya ha aprobado. De manera general, si \\(B_{1}, B_{2}, \\ldots, B_{k}\\) son eventos mutuamente excluyentes que completan el espacio muestral (es decir que la unión de todos esos eventos es \\(\\Omega\\)), y un evento A puede suceder en intersección con cualquiera de ellos (es decir que A puede suceder en intersección con \\(B_{1}\\), o con \\(B_{2}\\), etc.), lo esquematizaremos así: Por ejemplo, los eventos \\(B\\) pueden ser los diferentes tipos de escuela secundaria de la que provienen los alumnos y el evento \\(A\\) es “terminar la carrera”. Hay quienes terminan la carrera (quienes están dentro de la elipse) y quienes no lo hacen (dentro del rectángulo pero fuera de la elipse), y tanto unos como otros pueden provenir de escuelas de cualquiera de los tipos \\(B_{1}, B_{2}\\) etc. La primera de las intersecciones (la grisada más oscura) representa a alumnos que cumplen simultáneamente \\(A\\) (haber terminado la carrera) y \\(B_{1}\\) (provenir de una escuela del tipo que ese grupo define). Otro ejemplo es que los eventos \\(B\\) sean solo dos: \\(B_{1}\\): tener una determinada enfermedad \\(B_{2}\\): no tener esa enfermedad Si el evento \\(A\\) es “una prueba diagnóstica dio positiva”, aparecen intersecciones entre el resultado de la prueba y la condición de las personas a quienes se aplica. La primera es la zona dentro del círculo a la izquierda: (\\(A \\cap B_{1}\\)), son los casos correctamente diagnosticados. Los que quedan fuera del círculo a la izquierda representa casos en los que la prueba no indicó la enfermedad aun cuando se trataba de personas enfermas, se llaman “falsos negativos”. A la derecha, la pequeña parte de círculo es (\\(A \\cap B_{2}\\)) e indica los casos en que la prueba dio positiva cuando fue aplicada a personas que no tenían la enfermedad, se llaman “falsos positivos”. Por último, la parte blanca del rectángulo a la derecha son los casos en que dio correctamente negativa en personas que no tenían la enfermedad. Con esta notación y esa relación entre los eventos \\(B_{1}, B_{2}, \\ldots, B_{k}\\) y \\(A\\), el teorema de Bayes se expresa de la siguiente manera: \\[P(B_{j}/A) = \\frac{P(B_{j})*P(A/B_{j})}{\\sum_{i = 1}^{k}{P(B_{i})*P(A/B_{i})}}\\] El valor de este teorema es que permite pasar de la probabilidad simple de uno de los eventos \\(B\\) (en general, del que llamamos \\(B_{j}\\), a la probabilidad “corregida”, a partir de la información que aporta el evento \\(A\\). Si se conoce inicialmente la probabilidad del evento \\(B_{j}\\), el teorema permite calcular la probabilidad de \\(B_{j}\\), luego de haber agregado la condición \\(A\\). Veamos un ejemplo sencillo: se dispone de dos frascos, el primero de ellos tiene 20 fichas azules y 10 rojas, el segundo contiene 20 azules y 20 rojas. Se elige un frasco al azar y luego se extrae de él una ficha, que resulta ser azul, nos preguntamos por la probabilidad que la ficha provenga del primer frasco. En ausencia de toda información, los dos frascos son igualmente probables, por lo que la probabilidad de cada uno es 0,50: \\(P(F1)=0,50\\) y \\(P(F2)=0,50\\). Si la ficha fue extraída del primer frasco, la probabilidad de que sea azul es: \\(P(A/F1)=20/30=0,67\\), mientras que si proviene del segundo frasco es \\(P(A/F2)=20/40=0,50\\). La pregunta es por \\(P(F1/A)\\), debemos invertir una probabilidad condicional, por lo que usaremos el teorema de Bayes: \\[P(F_{1}/A) = \\frac{P(A/F_{1})*P(F_{1})}{P(A/F_{1})*P(F_{1}) + P(A/F_{2})*P(F_{2})}\\] Reemplazando, tenemos: \\[P(F_{1}/A) = \\frac{0,67*0,50}{0,67*0,50 + 0,50*0,50} = \\frac{0,33}{0,58} = 0,57\\] Este resultado dice que, con el dato que la ficha extraída es azul, corregimos la probabilidad de provenir del primer frasco, que a priori era de 0,50; a 0,57. En este sentido la fórmula de Bayes nos permite usar la información para corregir probabilidades a priori. En el ejemplo sobre la enfermedad y su diagnóstico, se dispone inicialmente de la probabilidad que tiene una persona cualquiera de padecer la enfermedad, esa es \\(P(B_{1})\\), luego esa probabilidad cambia cuando se agrega el dato que dice que a la persona la prueba le dio positiva. Veamos un ejemplo que presentó Cohen (1994) en un artículo crítico hacia los procedimientos tradicionales de análisis estadístico. La aplicación ilustra el aporte del teorema a las interpretaciones de los resultados que arrojan las pruebas diagnósticas. La prevalencia de esquizofrenia en adultos es de aproximadamente el 2%, que indica que aproximadamente 2 de cada 100 personas en la población general de adultos padece la enfermedad. Se dispone de un conjunto de pruebas diagnósticas del que se estima que tiene al menos un 95% de precisión al hacer diagnósticos positivos (sensibilidad) y aproximadamente 97% de precisión al declarar normalidad (especificidad). Para expresar formalmente estos datos, tratamos por un lado, la situación real, la de ser esquizofrénico o no serlo. Llamamos \\(E\\) al evento “el paciente es esquizofrénico” y \\(noE\\) al evento “el paciente no es esquizofrénico”. Por lo que, elegida una persona al azar, y en ausencia de cualquier otra información, su probabilidad de ser esquizofrénico es \\(P(E)=0,02\\), la probabilidad que no lo sea es \\(P(noE)=0,98\\). Por otro lado tenemos el resultado del conjunto de pruebas, que pueden dar positivas o negativas. La sensibilidad se escribe así: \\(P(+/E)=0,95\\), que quiere decir que, aplicada a sujetos esquizofrénicos, el 95% de las veces la prueba dará un resltado positivo, que conducirá al diagnóstico correcto de la enfermedad. El complemento de esa probabilidad, 5%, es la probabilidad de dar un resultado negativo ante un caso de alguien que sí es esquizofrénico, se denomina resultado “falso negativo” y solo puede identificarse ante pruebas posteriores más sensibles o por el desarrollo de otros síntomas, que dan más elementos para realizar el diagnóstico. Escribimos entonces que \\(P(-/E)=0,05\\). Ante personas que no son esquizofrénicas, la prueba da, en el 97% de los casos resultado negativo (correctamente), es decir: \\(P(-/noE)=0,97\\). Su complemento, del 3%, es la probabilidad de hallar un resultado positivo en alguien que no es esquizofrénico36, se denomina “falso positivo” y su probabilidad se escribe: \\(P(+/noE)=0,03\\). Dado un sujeto cuyas pruebas dan un resultado positivo, nos preguntamos por la probabilidad que efectivamente sea esquizofrénico. Antes de conocer la respuesta al problema piénselo un momento por su cuenta y ofrezca un valor aproximado para esa probabilidad. Este es un problema que requiere que se invierta una probabilidad condicional, ya que conocemos la probabilidad de obtener un resultado positivo si el individuo es esquizofrénico \\(P(+/E)\\), y queremos saber la probabilidad que sea esquizofrénico dado que la prueba dio positiva, que es \\(P(E/+)\\). En la aplicación del teorema de Bayes, el universo está compuesto por un 98% de no esquizofrénicos y un 2% de esquizofrénicos y la prueba puede dar positiva tratándose de alguien enfermo (muy frecuentemente) o estando sano (con poca probabilidad). Reemplazamos en la expresión del teorema de Bayes y tenemos: \\[P(E/+) = \\frac{P(+/E)*P(E)}{P(+/E)*P(E) + P(+/noE)*P(noE)} =\\] \\[\\frac{0,95*0,02}{0,95*0,02 + 0,03*0,98} = \\frac{0,019}{0,019 + 0,029} = 0,396\\] Entonces, si a una persona estas pruebas le han dado resultado positivo, la probabilidad que efectivamente sea esquizofrénico es menos del 40%, que es mucho mayor que la prevalencia en la población general, del 2%, pero que no resulta concluyente para el diagnóstico, el cual debe completarse con otros procedimientos. Es posible que este resultado no esté cerca de la estimación intuitiva que uno haría y nos pone muy en alerta sobre la interpretación de pruebas de este tipo. El razonamiento intuitivo quizás nos habría llevado a creer que alguien a quien la prueba da positiva tiene muchas posibilidades de tener la enfermedad, pero no debemos confundir la probabilidad que la prueba de positiva si se tiene la enfermedad (\\(P(+/E)\\)) con la probabilidad de tener la enfermedad si la prueba da positiva (\\(P(E/+)\\)). Si una persona es esquizofrénica, la prueba le da positiva en el 95% de las veces; pero si da positiva, la probabilidad que sea esquizofrénica es menor al 40%. Este resultado no debe conducir a creer que la prueba no sirva para el diagnóstico. Por el contrario, ante una persona de la que no se tiene ninguna información, la probabilidad que sea esquizofrénico es 0,02; cuando se agrega el dato que dice que el test dio positivo, la probabilidad que sea esquizofrénico asciende a 0,39. Nuevamente, se ve con claridad cómo este teorema permite usar los resultados de la experiencia para corregir probabilidades asignadas a priori. En este ejemplo, la probabilidad de ser esquizofrénico para alguien que obtuvo resultado positivo en las pruebas es tan baja debido a la baja frecuencia de la esquizofrenia en la población general (prevalencia), pero demuestra lo equivocado que puede estarse si no se tienen en cuenta resultados falso positivo y falso negativo asociados a las pruebas diagnósticas. Un abordaje alternativo a este problema es usando una tabla de contingencia. Suponiendo que aplicamos el conjunto de pruebas a un universo de un millón de personas y usando las probabilidades enunciadas antes: Condición Resultado de las pruebas Total Positivo Negativo Esquizofrénicos 19000 1000 20000 No esquizofrénicos 29400 950600 980000 Total 48400 951600 1000000 Queremos responder ¿cuál es la probabilidad que el sujeto sea esquizofrénico, si sabemos que la prueba le dio positiva? Para ello: \\[P(E/+) = \\frac{19.000}{48.400} = 0,39\\] Que es el mismo resultado que obtuvimos aplicando el teorema de Bayes. La ventaja de la presentación a través de una tabla de doble entrada es que permite distinguir dos conjuntos de eventos sobre los que tenemos diferente conocimiento: Un estado de realidad, que es la condición de esquizofrénico o no esquizofrénico del sujeto. Este estado nos es desconocido. La evidencia observable, que está dada por el resultado de la prueba que aplicamos, que conocemos. Como las pruebas no son perfectas, los resultados deben leerse en términos probabilísticos y no determinísticos. Cuando ingresemos a inferencia estadística veremos que ésta es la situación más frecuente: que dispongamos de cierta evidencia y debemos usarla para tomar una decisión acerca de un estado de realidad al que no conocemos. El de Bayes es un teorema de gran importancia, por las consecuencias que tiene para muchas pruebas diagnósticas que se usan a menudo. Lo que hemos encontrado también implica el cuidado con que deben leerse los resultados de pruebas de cualquier tipo: diagnósticos, dosaje de productos prohibidos en deportistas, pruebas genéticas, etc. Para una correcta interpretación de los resultados de esas pruebas se deben conocer cuáles son los errores de tipo “falso positivo” y “falso negativo” que las acompañan. 7.5 Variables aleatorias Es necesario hacer más explícita una parte del vocabulario que hemos usado. Al tratar con eventos aleatorios (resultados de experimentos aleatorios), en algunos hemos usado una notación más textual, como “que la moneda salga cara” y en otros una más numérica, por ejemplo “\\(S=4\\)”. De aquí en adelante trabajaremos con la segunda notación que tiene muchas ventajas. La razón es que pasamos a tratar a los experimentos como observación de variables, cuyas categorías (o valores) son los resultados del experimento. En la tirada de la moneda, no es difícil cuantificar los eventos, podemos elegir cara como lado preferido y definir la variable X = “número de caras que se obtienen al lanzar una moneda equilibrada”, los valores posibles son 0 (si sale cruz) y 1 (si sale cara). En la suma de los puntos de los dos dados, S asume valores discretos del 2 al 12. La descripción como distribución de frecuencias que hacíamos antes, se transforma ahora en distribución de probabilidades y, para los dos ejemplos citados, toma la forma: X = número de caras \\(P(X)\\) 0 1/2 1 1/2 Total 1 S = suma de puntos de dos dados \\(P(S)\\) 2 0.028 3 0.056 4 0.083 5 0.111 6 0.139 7 0.167 8 0.139 9 0.111 10 0.083 11 0.056 12 0.028 Total 1.000 Estas variables se denominan variables aleatorias, porque sus valores dependen del azar y serán muy necesarias en todo lo que sigue de la materia. El aspecto de estas tablas de distribución de probabilidades es en un todo equivalente al de las de distribución de frecuencias: el total igual a uno indica la probabilidad del espacio muestral (\\(P(\\Omega) = 1\\)). Sobre ellas pueden hacerse operaciones similares a las descripciones de variables ya vistas. Cuando la variable aleatoria puede asumir valores continuos, ya no es posible asignar probabilidades individualmente y debe hacerse a través de intervalos. Es el mismo problema que hallamos en las distribuciones de frecuencia, y lo resolvemos del mismo modo. Se usan probabilidades acumuladas, ya sea entre valores de la variable o desde ciertos valores hacia los mayores o desde ciertos valores hacia los menores37. También es posible, sobre distribuciones de probabilidad, calcular algunas medidas descriptivas, veamos en qué se transforma la media. El procedimiento para calcularla que hemos visto consiste en multiplicar cada valor de la variable por su frecuencia y dividir por el total de casos; para las variables aleatorias eso se hace de una sola vez, multiplicando cada valor por la probabilidad y se obtiene: \\[E(x) = \\sum_{i = 1}^{n}x_{i}*{P(x}_{i})\\] Que se llama esperanza matemática, la indicaremos \\(E(x)\\). Aunque esta expresión proviene del cálculo de la media38, tiene una diferencia conceptual importante: la media es una medida resumen, por lo que describe hechos que han sido observados, puede decirse que hace referencia a algo que ya sucedió. Por el contrario la esperanza se refiere a eventos que pueden llegar a suceder, por eso tiene ese nombre, es la expectativa que tenemos sobre el devenir futuro de un experimento. Uno de los usos más difundidos de este concepto es la esperanza de vida, que mide el número promedio de años que viviría un conjunto de personas si a lo largo de toda su vida se mantuvieran las mismas tasas de mortalidad que en la actualidad (las tasas de mortalidad se usan para estimar las probabilidades de morir a cada edad). Un “promedio a futuro” es una descripción sobre algo que aún no sucedió, por eso se llama esperanza. De manera análoga puede calcularse la varianza de una variable aleatoria, su fórmula es: \\[V(x)=\\sum_{i=1}^{n}(x_i-E(x))^{2}*P(x_i)\\] Al referirse a una variable aleatoria, la interpretación de la varianza difiere levemente de aquella que se usó como medida descriptiva de la dispersión. Aquí indica el modo en que se alcanzará el valor de la esperanza. Una varianza grande indica un proceso aleatorio muy variable, con valores dispares que convergen lentamente al valor de la esperanza. Por el contrario, un valor pequeño de la varianza indica un proceso más estable en el que los valores difieren poco de un paso al siguiente y rápidamente se aproximan a la esperanza. Un ejemplo común que ilustra el uso de estas medidas es el juego de la ruleta. En este juego, por cada ficha que se apuesta a un color se obtiene una de premio si sale ese color y, por cada ficha que se apuesta a un solo número, se obtienen 35 como premio. En ambos tipos de apuesta, la ganancia esperada39 vale -0,027. Esto significa que, jugando indefinidamente, se espera perder (porque es negativa) 0,027 pesos por cada peso que se apueste; esa es la ganancia esperada del organizador del juego. Sin embargo, las varianzas son diferentes; para las apuestas a color, vale poco menos de 1 y para la apuesta a número único es más de 34. Esto describe la dinámica del juego; mientras con la primera modalidad se gana y se pierde a menudo, con la segunda forma de apostar, se pierde muchas veces y cuando se gana es grande la recompensa. De todos modos en ambos tipos de apuesta, el balance entre ganancias y pérdidas es negativo, como lo indica la esperanza. La intersección de dos eventos es conmutativa: \\(P(A \\cap B)=P(B \\cap A)\\)↩ Fue enunciado por Thomas Bayes (1702-1761), matemático inglés.↩ Nuevamente en este caso, esto puede conocerse a posteriori, luego de otras pruebas o del seguimiento del sujeto.↩ Sin embargo hay algo importante que cambia; porque en lugar de sumar un número finito de valores discretos, cuando se trata de variables continuas se debe sumar una cantidad infinita de valores infinitesimales, ese cambio se refleja en que la operación de suma se transforma en otra operación que se llama integral. No disponemos de los elementos matemáticos suficientes para ir más allá de esta mención imprecisa del concepto, pero tampoco es necesario a los fines de este curso.↩ Puede deducirse esto a partir del cálculo de la media, si se reemplazan las frecuencias relativas por las probabilidades de cada valor de la variable, tenemos: \\[\\overline{x} = \\frac{\\sum_{i = 1}^{n}{x_{i}*f_{i}}}{n} = \\sum_{i = 1}^{n}x_{i}*\\frac{f_{i}}{n} = \\sum_{i = 1}^{n}x_{i}*f_{i}^{&#39;} = \\sum_{i = 1}^{n}x_{i}*{P(x}_{i}) = E(x)\\]↩ Para el caso de ruletas con un solo cero, existen algunas que tienen además del cero el doble cero, en esos casos la esperanza de pérdida es mayor.↩ "],
["probabilidad-los-modelos.html", "Capítulo 8 Probabilidad: los modelos 8.1 Concepto de modelización 8.2 Distribución binomial 8.3 Distribución normal 8.4 La idea de grados de libertad 8.5 La distribución ji cuadrado (\\(\\chi^{2}\\)) 8.6 La distribución t de Student 8.7 Hacerlo en R", " Capítulo 8 Probabilidad: los modelos 8.1 Concepto de modelización La asignación a priori de probabilidades, presentada con los ejemplos elementales de la moneda o el dado es parte de una forma muy general de tratar con los fenómenos que dependen del azar. El supuesto inicial de probabilidad \\(1/2\\) a cada lado, constituye un modelo de probabilidad, es una anticipación acerca de lo que se espera que suceda. No es arbitrario, ya que deben tenerse razones para suponer que el modelo se sostiene, pero en todos los casos es una aproximación a lo que sucede en la realidad. Tratamos de modelar (o modelizar) lo que observamos a fin de simplificarlo, pero un modelo puede ser más o menos adecuado a la realidad, por eso dijimos que cabe la posibilidad que “el modelo no se sostenga”. La idea de simplificar está aquí utilizada en el sentido de elegir algunos aspectos de la realidad para construir un modelo que luego se usa para asignar probabilidades a los diferentes resultados posibles. La riqueza y complejidad de los fenómenos sociales no se menoscaba porque se usen modelos, salvo si se comete el error de confundir el modelo con la realidad. Disponer de un modelo de probabilidad permite calcular probabilidades de manera sencilla bajo ciertos supuestos, que deben explicitarse. Para seguir con nuestra moneda, digamos que el modelo que resume el supuesto de iguales chances para todos los resultados, se llama distribución uniforme, es válido también para un dado, si está equilibrado, o para cualquier fenómeno aleatorio en el que se pueda suponer que los resultados son igualmente probables. La expresión formal de ese modelo es la siguiente: “Si un experimento aleatorio tiene distribución uniforme y k resultados posibles, entonces \\(P(A_{i}) = \\frac{1}{k}\\), donde \\(A_{i}\\) es uno cualquiera de los \\(k\\) resultados” Por lo tanto si se trata de una moneda (2 caras) la probabilidad de cualesquiera de sus caras será \\(1/2\\), si es un dado, cada lado tiene probabilidad \\(1/6\\), y si es un icosaedro regular (veinte caras iguales, parecido a un globo de espejos) cada cara tendrá probabilidad 1/20 de salir. La representación gráfica de este modelo, es para cada uno de los ejemplos, la siguiente: En estos gráficos, la idea de uniformidad (para todos los eventos la misma probabilidad) se transmite en la igual altura de todas las columnas. Además de este modelo uniforme, en este capítulo presentaremos cinco modelos de probabilidad que serán necesarios para lo que sigue de nuestros contenidos; el primero para variables discretas y los demás para continuas. Hay una gran cantidad de modelos que permiten asignar probabilidades a priori a diferentes fenómenos observables. El tratamiento que haremos a continuación será de carácter utilitario, es decir estará centrado en el uso que podemos hacer de cada distribución teórica. Haremos las referencias matemáticas mínimas que sean necesarias para comprender las propiedades y condiciones de aplicación de los modelos. 8.2 Distribución binomial Esta distribución se usa para modelar fenómenos aleatorios que pueden dar solo dos resultados, a los que se llama “éxito” y “fracaso”. La elección de cuál es éxito es arbitraria y corresponde a la categoría que el investigador toma como de interés. La variable aleatoria que se considera es el número de veces que se obtienen éxitos, o simplemente el número de éxitos que resultan luego de una cierta cantidad de repeticiones de la experiencia. La condición para que este modelo sea válido es que cada repetición sea independiente de las anteriores, es decir, que cada realización del experimento no incida sobre la siguiente. Nuevamente con la moneda equilibrada que hemos tratado, este modelo va a facilitar el cálculo de, por ejemplo, qué probabilidad hay de obtener 3 caras en 4 tiradas de la moneda. Resolvamos primero el problema de manera manual. En la tabla siguiente mostramos los resultados posibles de ese experimento (lanzar cuatro veces una moneda equilibrada) y el valor que corresponde a la variable aleatoria “número de caras”, a la que llamaremos x40. Resultado del experimento Valor de la variable “número de caras” x XXXX 0 XXXC 1 XXCX 1 XXCC 2 XCXX 1 XCXC 2 XCCX 2 XCCC 3 CXXX 1 CXXC 2 CXCX 2 CXCC 3 CCXX 2 CCXC 3 CCCX 3 CCCC 4 Como estos 16 resultados son igualmente probables, le corresponde una probabilidad de 1/16 (0,0625) a cada uno, por lo que podemos calcular las probabilidades de cada valor sumando los que corresponden a las formas en que pueden lograrse. Por ejemplo, tres caras (x=3) puede ser consecuencia de cualquiera de los eventos XCCC, CXCC, CCXC, CCCX, por lo que hay cuatro eventos a su favor y su probabilidad es 4/16. Resumiendo entonces la tabla anterior, tenemos: \\(x\\) \\(P(x)\\) 0 1/16 (0,0625) 1 4/16 (0,25) 2 6/16 (0,375) 3 4/16 (0,25) 4 1/16 (0,0625) Total 1 Como esperábamos, “lo más probable” es obtener dos caras, porque se espera que la moneda caiga cara la mitad de las veces, ahora sabemos también cuán probable es que caiga una cantidad diferente de veces cara. La respuesta a la pregunta que formulamos arriba es 0,25 y lo expresamos simplemente: \\[P(x = 3) = 0,25\\] Para construir la tabla y responder a la pregunta hemos usado como información: la cantidad de repeticiones del experimento (\\(n=4\\)) la probabilidad del evento cada vez que se lo repite (\\(p=0,5\\)) el número de veces cuya probabilidad calculamos (el número de éxitos) (\\(x=3\\)) Esta información es suficiente para aplicar el modelo binomial, que se va a escribir formalmente como \\[B(n, p, x)\\]. En la que la $B $es por binomial, \\(n\\) es el número de repeticiones, \\(p\\) es la probabilidad de éxito a cada repetición y \\(x\\) el número de éxitos cuya probabilidad se calcula. Cuando se trata de variables discretas como en este ejemplo, los modelos admiten el cálculo de la probabilidad: de un valor particular de la variable, es decir un determinado número de éxitos: \\(P(X=x)\\) O bien de un conjunto de valores por debajo de un valor dado, es decir, la probabilidad acumulada: \\(P(X\\leq x)\\) Si se requiere la probabilidad de los valores mayores a uno dado \\(P(X&gt;x)\\), se complementa (se resta de 1) la probabilidad acumulada. Cuando se trata de variables continuas, las probabilidades exactas son cero, por lo que solo pueden calcularse la acumuladas: \\(P(X\\leq x)\\) y su complemento a uno: \\(P(X&gt;x)\\) Resulta claro que la realización manual de estas operaciones es larga y engorrosa, sobre todo en situaciones reales donde hay más observaciones que en la moneda. Por ejemplo, un examen consiste de 20 preguntas de opción múltiple con cinco opciones de respuesta cada una, una sola de las cuales es correcta. Para aprobar el examen es necesario contestar bien al menos 12 de ellas (el 60%). Se pregunta: ¿Qué probabilidad tiene un alumno de aprobar solo por azar? Es decir si responde a cada pregunta por sorteo. Es una problema de distribución binomial: hay 20 repeticiones (una por cada pregunta) de un experimento que tiene 0.20 (1/5) de probabilidad de éxito. Para aprobar se necesitan al menos 12 éxitos. La resolución manual de este problema requiere considerar que para aprobar los éxitos pueden ser 12, 13, 14, etc. Y que cada cantidad de éxitos puede lograrse de varias formas. Doce aciertos pueden provenir de las doce primeras preguntas, o de las diez primeras y las dos últimas, o muchas otras combinaciones posibles. Si bien existen fórmulas para simplificar estas operaciones, usaremos directamente el software para calcular la probabilidad bajo modelos dados, a condición que el modelo se adapte al problema y que se cumplan los supuestos del modelo. En este caso, la expresión, para 12 éxitos exactamente es \\[B(20, .20, 12)\\] Pero para aprobar, 12 es el número mínimo de aciertos que se requieren, por lo que hará falta la probabilidad de 12 y de todos los valores siguientes, hasta 20. En R disponemos de las rutinas para calcular probabilidades simples y acumuladas bajo diferentes modelos. Para la binomial, el comando dbinom, tiene como argumentos: el número de éxitos cuya probabilidad se solicita, el número de repeticiones y la probabilidad de éxito a cada repetición. La probabilidad de obtener una cara al lanzar una moneda equilibrada (\\(p=0.5\\)), dos veces es: ## [1] 0.5 Y la probabilidad de tres caras en cuatro lanzamientos de una moneda equilibrada (\\(P(X=3)\\)) es: ## [1] 0.25 El la que hemos pedido un redondeo a cuatro decimales. Para pedir la probabilidad acumulada, como por ejemplo la de obtener tres caras o menos (\\(P(X\\leq 3)\\)) en cuatro lanzamientos, el comando es pbinom, con los mismos argumentos: ## [1] 0.9375 La respuesta al problema del examen se resuelve en dos pasos, porque para aprobar hacen falta 12 aciertos o más. Entonces, primero calculamos la probabilidad acumulada de 11 (\\(P(X\\leq 11)\\)), que es la probabilidad de no aprobar (obtener 11 aciertos o menos): ## [1] 0.9999 Y luego complementamos el resultado para obtener la probabilidad de superar los 11 aciertos 1010^{-5}. $P(X&gt;11)=$1010^{-5}. Otro ejemplo es aquel en el que se elige una muestra aleatoria de 15 estudiantes de primer año de la carrera de Biología para un experimento. Si se sabe que la proporción de mujeres de primer año de esa carrera es del 70%, ¿Cuál es la probabilidad que en la muestra resulten todas mujeres?. Cada persona que se selecciona aleatoriamente es una repetición, en la que la probabilidad que esa persona sea mujer es 0.70, y se pregunta por la probabilidad de hallar 15 éxitos. Entonces, la pregunta se formula así: ## [1] 0.004747562 Y el resutado se expresa así: \\[P(X=15)=B(15,15,.7)=0.0047\\] 8.2.1 Esperanza y varianza En este modelo de probabilidad, la esperanza es \\(n*p\\), que representa el número esperado de casos favorables a obtener en n repeticiones. En el primer ejemplo, la esperanza es \\(4*0,50=2\\), que quiere decir que en 4 tiradas de la moneda equilibrada, esperaríamos obtener 2 caras, como sabemos, esto es lo que sucede luego de un gran número de repeticiones del experimento. En el ejemplo de la selección de estudiantes, la esperanza es \\(0,70*15=10,5\\), aunque este número decimal no es una cantidad posible de casos favorables (mujeres) a obtener en la muestra, es el promedio a futuro, luego de la realización reiterada de este experimento muchas veces. Es decir qu esi el experimento de muestrear 15 estudiantes se repitiena muchas veces, en promedio se encontrarían entre 10 y 11 mujeres en cada muestra. En el ejemplo del examen, la esperanza \\(20*.20=4\\) indica que el número medio de aciertos que se espera lograr por puro azar es de 4. La varianza de la distribución binomial es \\(n*p*(1-p)\\), que es una medida de la variabilidad del proceso. Más adelante volveremos sobre este tema. El gráfico de esta distribución se construye calculando las probabilidades de los diferentes valores de \\(x\\), que puede ir desde 0 hasta el número total de repeticiones del experimento. El siguiente es el correspondiente a 20 repeticiones con diferentes valores de p: Observemos la forma en que aparece representada la diferencia entre las varianzas de las distribuciones41. 8.3 Distribución normal La mayoría de los fenómenos naturales, sociales, psicológicos no tienen distribución uniforme, es decir, no es igualmente probable que resulte cualquiera de los resultados. Por ejemplo, para una determinada población, el peso de los niños al nacer tiene un valor promedio y cuando un niño nace se espera que tenga un peso cercano a ese valor medio. No es igualmente probable que un niño nazca con que con 5800. Son menos frecuentes los niños que nacen con pesos muy por encima o muy por debajo del promedio. De modo similar sucede con medidas psicológicas como el Cociente intelectual (CI); se hallan con mayor frecuencia valores cercanos al promedio y la probabilidad de encontrar personas muy por encima o muy por debajo de ese promedio es menor. Para este tipo de fenómeno, hay un modelo que suele ajustar bien las probabilidades, se llama distribución normal42 y su representación gráfica, una curva unimodal, simétrica, de forma acampanada es llamada “campana de Gauss”43 en referencia a Johann Carl Friedrich Gauss44. Un primer elemento a tener en cuenta es que, a diferencia de los gráficos anteriores, ahora se trata de una curva con trazado continuo. Esto se debe a que esta distribución es adecuada para modelar variables continuas. Recordemos que cuando se construyeron las distribuciones de frecuencia, resultaba imposible enumerar todas las categorías de una variable de este tipo, ya que son infinitas. Dijimos en ese momento que no es posible indicar la frecuencia de un valor único de una variable continua. Lo mismo vale ahora para las probabilidades: no calculamos probabilidades para valores simples de variables continuas, sí calculamos probabilidades acumuladas y, como sucedía con las frecuencias acumuladas, éstas están representadas gráficamente en el área bajo la curva, pero en lugar de sumar las frecuencias de valores discretos, se realiza una operación que se llama integración45. Dado que la curva que describe la distribución normal es unimodal y simétrica; el modo, la media y la mediana coinciden, el coeficiente de asimetría es cero (\\(g_{1}=0\\)) y la distribución es mesocúrtica (\\(g_{2}=0\\)). El cálculo de las probabilidades bajo el modelo normal -o, lo que es lo mismo, de las áreas bajo la curva-, es muy complejo, por lo que se encuentra tabulado, es decir, precalculado para algunos valores de la variable. ¿De qué variable?, hemos mencionado el peso al nacer, el IQ, ¿con qué método calcularemos probabilidades para fenómenos tan disímiles? Antes que se difundiera el uso de la computadora personal, se usaban tablas, ahora usamos cualquier hoja de cálculo, donde se indica la probabilidad acumulada para diferentes valores de una variable abstracta, sin unidades, adaptable a una diversidad de fenómenos. Se trata de la variable \\(z\\), que ya fue definida y que mide el número de desviaciones estándar -contadas desde la media-, a las que se encuentra un caso individual. Una de las aplicaciones prácticas de esta variable es que permite comparar variables que miden cualidades muy diferentes. Sabemos ya que la cantidad de desviaciones estándar (\\(z\\)) es una medida de lo cerca o lejos que un caso se encuentra del promedio. Si la variable en estudio es adecuadamente modelada con la distribución normal, entonces podremos conocer la probabilidad de hallar casos, por ejemplo a más de dos desviaciones estándar de la media y eso tendrá una inmediata traducción a valores de la variable. Recordemos que la variable \\(z\\) está definida, para un valor particular de \\(x\\) como: \\[z = \\frac{x - \\overline{x}}{s}\\] Y que tiene media igual a cero y desviación estándar igual a uno. Si \\(x\\) tiene una distribución normal con una media \\(\\overline{x}\\) y una desviación estándar \\(s\\), entonces \\(z\\) tiene distribución que se llama normal estándar. Su gráfico está centrado en cero: Cualquier hoja de cálculo (como OpenOfficeCalc o Excel) calcula las probabilidades (o áreas) bajo la curva normal. En R es muy directo, porque del mismo modo en que dispusimos de una función para la binomial acumulada (pbinom), tenemos ahora el comando pnorm para obtener probabilidades acumuladas (\\(P(Z\\leq z)\\)) bajo un modelo de distribución normal estándar. Y, al igual que con cualquier otra distribución, el valor de \\(P(Z&gt;z)\\) se logra restando de 1, que es el área completa bajo la curva. Por ejemplo, el área acumulada por debajo de \\(z=0\\) es la mitad de la campana, \\(P(Z\\leq 0)=0.5\\), por lo que \\(P(Z&gt;z)=0.5\\). Si lo pedimos a R: ## [1] 0.5 Cuyo gráfico es: El área sombreada vale 0.50. Para el área por debajo de \\(Z=2\\), redondeado a cuatro decimales: ## [1] 0.9772 Y su representación: Queda delimitada por debajo de \\(z=2\\) un área de 0.9772. \\(P(z\\leq2)=0.9772\\). Si solicitamos las probabilidades acumuladas por debajo de diferentes valores de \\(z\\), empezando con los negativos, pasando por el cero y siguiendo por los positivos, obtenemos lo siguiente: z P(&lt;z) Ubicación z *P(&lt;z) * Ubicación -3,0 0,00135 {width=“0.8188976377952756in” height=&quot;0.3937007874015748in &quot;} 0 ,0 0,50000 -2,0 0,02275 {width=“0.8188976377952756in” height=&quot;0.3937007874015748in &quot;} 1 ,0 0,84134 -1,0 0,15866 {width=“0.8188976377952756in” height=&quot;0.3937007874015748in &quot;} 2 ,0 0,97725 3,0 0,99865 Las probabilidades acumuladas (es decir, las áreas a la izquierda) van creciendo desde casi cero en el valor más pequeño que pusimos (\\(z = -4\\)) y llegan hasta casi uno en el máximo valor (\\(z = 4\\)). En el modelo matemático, \\(z\\) tiene como campo de variación todos los valores, es decir, desde menos infinito hasta más infinito (\\(-\\infty\\); \\(\\infty\\)), pero como vemos, en la realidad, los valores -4 y 4 son muy extremos, en el sentido que las probabilidades acumuladas son casi cero y casi uno respectivamente. Aunque el modelo teórico tiene un comportamiento asintótico respecto del eje horizontal, en el gráfico, la curva se confunde con el eje para valores cercanos a 4. La notación para estos resultados es la siguiente (usando hasta cuatro decimales que es lo más frecuente), por ejemplo: \\(P(z\\leq-2)= 0.0227\\) ó también \\(P(z\\leq1) = 0,8413\\). Las representaciones gráficas de estas probabilidades son las siguientes: A continuación vemos la representación gráfica de la relación entre las probabilidades “por encima” y “por debajo” de \\(z=1\\), sabiendo que \\(P(z\\leq1)+P(z&gt;1)=1\\). También se pueden identificar probabilidades entre valores de z, por ejemplo cuál es el área entre -1 y 1 (es decir cuál es la probabilidad de encontrar a z entre esos valores). Esto se escribe así: \\(P(-1&lt;z&lt;1)\\). Para calcularla solo usaremos la información sobre la probabilidad acumulada: el área por debajo de \\(-1\\) vale \\(0,1587\\) y el área por debajo de \\(1\\) es \\(0,8413\\), si restamos esas dos áreas tendremos lo que queda entremedio: \\(0,8413 - 0,1587 = 0,6835\\), gráficamente: El área comprendida entre -2 y 2 se calcula del mismo modo, ya que ## [1] 0.0228 ## [1] 0.9772 ## [1] 0.9544 \\[P(- 2 &lt; z &lt; 2) = P(z &lt; 2) - P(z &lt; - 2) = 0,9772 - 0,0228 = 0,9544\\] Y los valores \\(\\pm3\\) delimitan: ## [1] 0.9973002 ## [1] 0.9973 Es decir que: \\[P(- 3 &lt; z &lt; 3) = P(z &lt; 3) - P(z &lt; - 3) = 0,9986 - 0,0013 = 0,9973\\] La regla empírica que se mencionó en el capítulo , tiene aquí su origen. Ya que si la distribución es similar a la normal (unimodal y simétrica), entonces aproximadamente el 68% estará a menos de una desviación estándar de la media, el 95% a menos de dos, y el 99,7 a una distancia no mayor a tres desviaciones estándar. Son los valores de \\(z\\), que mide distancia a la media en términos de desviaciones estándar. 8.3.1 Percentiles De mismo modo que con las distribuciones de frecuencia, los valores de la variable que acumulan una determinada probabilidad son los percentiles. El valor \\(z=-1\\) es el percentil \\(.1587\\) de la variable y \\(z=2\\) es el percentil \\(.9772\\). Para determinar ahora los valores de \\(z\\) que acumulan cierta probabilidad, se necesita la operación inversa a la que se realizó hasta aquí, porque hay que hallar cuál es el valor de la variable (\\(z\\)) que deja por debajo una determinada probabilidad. Según la definición de percentiles, el percentil \\(P_{r}\\) de la variable es el valor por debajo del cual la probabilidad de hallarla es \\(r\\%\\). Gráficamente, se trataría de fijar el área (\\(r\\%\\)) y determinar cuál es el \\(z\\) que la acumula. Nuevamente, recurrimos a R para solicitar este valor, el comando es qnorm, que a partir de la probabilidad acumulada, devuelve el valor de \\(z\\). Por ejemplo, el percentil \\(95\\) (\\(P_{95}\\)) de la distribución normal es: ## [1] 1.644854 ## [1] 1.6449 El valor 1.6449 acumula el 95% o bien \\(P(z\\leq1.6449=.95)\\). Y del mismo modo el percentil 99 es: ## [1] 2.3263 \\[P_{99}=1.6449\\] Por la simetría de la distribución, los percentiles complementarios son valores opuestos de la variable: ## [1] -1.6449 ## [1] -2.3263 Con los que, bajo el modelo normal estándar: \\(P_{5}=-1.6449\\) y \\(P_{1}=-2.3263\\) Por el uso que haremos de la distribución normal hay algunos prcentiles de mucha importancia y conviene recordar: son los que delimitan áreas centrales de probabilidad .90, .95 y .99. Para determinarlos, hay que identificar a qué percentiles corresponden. Para el área central de .90, el área de .10 que queda fuera se reparte de manera simétrica en las dos colas de la distribución, a razón de .05 en cada una: Entonces, hay que determinar los valores de \\(z\\) que acumulan \\(.05\\) y \\(.95\\), dicho de otro modo, hay que calcular \\(P_{5}\\) y \\(P_{95}\\), que son: ## [1] -1.644854 ## [1] 1.644854 Redondeados a dos decimales: ## [1] -1.64 ## [1] 1.64 Con lo que los valores \\(\\pm1.64\\) delimitan un área central en la que hay una probabilidad .90 de encontrar a la variable normal estándar. \\[P(- 1.64 &lt; z &lt; 1.64) = 0,90\\] Del mismo modo, para el área central de \\(.95\\), el área complementaria de \\(.05\\) se reparte en dos, y los percentiles que se requieren son: \\(P_{2.5}\\) y \\(P_{97.5}\\), que son: ## [1] -1.96 ## [1] 1.96 Así: \\[P(- 1.96 &lt; z &lt; 1.96) = 0,95\\] Y para \\(.99\\), el \\(.01\\) restante se divide en dos, por lo que los \\(z\\) que se buscan son los valores que acumulan \\(.005\\) y \\(.995\\), es decir: \\(P_{.5}\\) y \\(P_{99.5}\\), que resultan: ## [1] -2.58 ## [1] 2.58 Entonces: \\[P(- 2.58 &lt; z &lt; 2.58) = 0,99\\] 8.3.1.1 Usos de la distribución normal La distribución normal es muy valiosa, por muchas razones, de las cuales nos interesan dos. La primera es que es adecuada para modelar muchos fenómenos observables, en especial variables biológicas como el peso de los niños al nacer, la talla para diferentes edades. Hay variables psicológicas como el coeficiente intelectual, para las que se elaboran instrumentos de medición cuyos puntajes se distribuyen de manera normal. Otras variables, como el rendimiento en la escuela, o las actitudes medidas con escalas numéricas, a menudo, pueden aproximarse de manera adecuada con un modelo normal. La segunda razón es que cuando se extraen muestras aleatorias de una población, algunas medidas que se calculan sobre esas muestras tienen una distribución que se aproxima a la normal a medida que las muestras tienen mayor tamaño. Eso será lo que nos permita realizar nuestras primeras estimaciones de valores poblacionales a partir de muestras. Hasta este punto trabajamos con la distribución normal de una variable abstracta, sin unidades, a la que llamamos \\(z\\), a cuyos valores pudimos asignar probabilidades. La función que describe la curva acampanada está expresada en términos de \\(z\\). Pero cuando vamos a trabajar con una variable real, como las que mencionamos, por ejemplo, el peso de los niños cuando nacen o el CI, es necesario disponer de una variable concreta, a la que llamamos \\(x\\). ¿Qué relación tiene esa variable, cuya distribución podría modelarse bien con una curva normal, con la \\(z\\), que nos permite hallar las probabilidades bajo el modelo normal? Es decir, ¿qué relación tiene \\(x\\) con \\(z\\)? Ya la conocemos, porque \\(z\\) es el desvío estándar que definimos en el capítulo , es: \\[z = \\frac{x - \\overline{x}}{s}\\] Que cuenta la cantidad de desviaciones estándar (\\(s\\)) a que se encuentra un valor (\\(x\\)) de la media (\\(\\overline{x})\\). Para encontrar probabilidades correspondientes a valores reales de una variable y no solo los \\(z\\) abstractos, debemos transformar esos valores en puntajes \\(z\\), con la expresión de arriba. Veamos esto en un ejemplo: a partir de las historias clínicas de varios años de un hospital materno infantil, conocemos que el peso medio en el momento de nacer (de niños varones, a término, con madre entre 20 y 29 años) es de 3300 gramos y que la desviación estándar es de 800 gramos. Además sabemos que la distribución normal es adecuada para describir la variable peso al nacer. Entonces podemos calcular la probabilidad que un niño al nacer tenga un peso por debajo de los 1500 gramos. El problema es averiguar el área sombreada en el siguiente gráfico: Para calcular el área marcada -que corresponde a la probabilidad solicitada-, vamos a transformar el valor de \\(x\\) (1500) a puntaje \\(z\\), haciendo: \\[z = \\frac{x - \\overline{x}}{s} = \\frac{1500 - 3300}{800} = - 2.25\\] Ahora es equivalente solicitar la probabilidad de \\(x\\) menor que 1500 que la de \\(z\\) menor que -2,25, en símbolos: \\[P(x &lt; 1500) = P(z &lt; - 2.25)\\] Y el gráfico anterior expresado en términos de \\(z\\) resulta: A esta probabilidad sabemos cómo solicitarla: ## [1] 0.01222447 Ésta es la probabilidad de hallar niños que al nacer tengan pesos inferiores a los 1500 gramos. Del mismo modo podemos operar si nos interesa conocer la probabilidad de hallar niños que nazcan con peso comprendido entre 3500 y . Transformando cada uno de los valores se obtiene: \\[x = 3500arrow z = \\frac{3500 - 3300}{800} = 0,25\\] \\[x = 4500arrow z = \\frac{4500 - 3300}{800} = 1,50\\] Entonces, que \\(x\\) (el peso de los niños al nacer) esté entre 3500 y , equivale a que \\(z\\) (cantidad de desviaciones estándar) se encuentre entre 0,25 y 1,50. Esto se expresa simbólicamente así: \\[P(3500 &lt; x &lt; 4500) = P(0,25 &lt; z &lt; 1,50)\\] Y se representa gráficamente así: En términos de: Para calcular el área comprendida entre los dos puntos, es decir la probabilidad de hallar a \\(x\\) entre 3500 y 4500, restamos, a la probabilidad acumulada hasta \\(z=1.50\\), la acumulada hasta \\(z=0.25\\): \\[P(3500 &lt; x &lt; 4500) = P(0,25 &lt; z &lt; 1,50) = P(z &lt; 1,50) - P(z &lt; 0,25)\\] La última operación la solicitamos a R: ## [1] 0.3344865 Leemos el resultado diciendo que la probabilidad de hallar a un niño que haya nacido con un peso comprendido entre los 3500 y los 4500 gramos es de \\(0.3345\\). Toda variable que puede modelarse con una distribución normal puede transformarse a puntaje \\(z\\) y así hallar la probabilidad asociada a diferentes intervalos. Hemos realizado las operaciones de este modo hasta aquí, porque es importante tener clara la relación entre las variable concreta que se mide u observa, con la variable abstracta, \\(z\\). Sin embargo, es posible ingresar al comando de R directamente con los valores de la variable original e informar la media y la desviación estándar, para obtener las probabilidades correspondientes. Veamos el modo de obtener el resultado de manera directa, sin pasar por \\(z\\). La probabilidad que nos interesa es, como antes: \\[P(3500 &lt; x &lt; 4500)\\] Que se calcula como la diferencia entre la probabilidad acumulada hasta 4500 menos la acumulada hasta 3500. \\[P(3500 &lt; x &lt; 4500) = P(x &lt; 4500) - P(x &lt; 3500)\\] Al comando pnorm en R ahora le agregamos los valores de la media y la desviación estándar, para que calcule la probabilidad directamente sobre \\(x\\): ## [1] 0.3344865 Es el mismo resultado al que habíamos llegado a través de la transformación a puntaje \\(z\\), pero ahora pidiéndola directamente desde \\(x\\). Aunque éste sea el procedimiento más cómodo para calcular probabilidades, es necesario estar familiarizado con la distribución normal estándar (en \\(z\\)), por los usos que haremos en los próximos capítulos. La distribución normal tiene un uso muy amplio y varios campos de aplicación. Más adelante veremos que para aplicar algunos procedimientos de análisis, es necesario que los datos provengan de una distribución normal, y existen pruebas para verificar que esto se cumpla. Una primera aproximación para ver si un conjunto de datos tiene distribución cercana a la normal es observar el histograma y evaluar si su forma se aproxima a la normalidad: si es unimodal y aproximadamente simétrica, es decir si la mediana es semejante a la media. Luego se calculan los coeficientes de curtosis y asimetría y, si éstos están entre \\(-0,50\\) y \\(+0,50\\), puede aceptarse, en primera instancia, la normalidad de los datos. 8.4 La idea de grados de libertad Antes de avanzar hacia los otros modelos de probabilidad que presentaremos en este capítulo, es necesario tener una idea aproximada de un concepto que juega un papel de importancia en esas distribuciones, el de “grados de libertad”, un número que, como veremos enseguida, determina la forma de algunas distribuciones. Se trata de un concepto matemático complejo, al que vamos a definir como el número de observaciones linealmente independientes que existen en una suma de cuadrados46, pero del que haremos un uso exclusivamente instrumental. Su denominación es gl o bien df en inglés (degrees of freedom). Consideremos el caso del cálculo de la varianza, cuyo numerador es: \\(\\sum_{i = 1}^{n}(x_{i} - \\overline{x})^{2}\\). Que es la suma de \\(n\\) términos, cada uno de ellos elevado al cuadrado. Identificar los grados de libertad de esa expresión equivale a responder a ¿cuántos términos de esa suma no dependen del valor que asumen los demás? Supongamos que se conoce la media muestral; esto establece un número fijo para la suma de las \\(n\\) observaciones: \\(x_{1}, x_{2}, \\ldots, x_{n}\\), por lo que solo \\(n-1\\) de ellas pueden elegirse “libremente”, la última observación queda determinada. Por ejemplo, si se trata de cuatro observaciones de las que sabemos que su media es cinco, entonces la suma de los cuatro números debe ser 20 ¿Cuáles son los valores posibles para las cuatro observaciones \\(x_{1}, x_{2}, x_{3}, x_{4}\\)? Hay infinitas combinaciones posibles que darían suma igual a 20, fijemos arbitrariamente algunos de los valores: \\(x_{1}=3, x_{2}=4, x_{3}=4\\), estos tres números suman 11, por lo que el cuarto solo puede ser 9 (para lograr la suma de 20 y que entonces la media sea 5). Otra combinación posible de valores es \\(x_{1}=4, x_{2}=5, x_{3}=10\\), con lo que \\(x_{4}=1\\) necesariamente. Cualquiera sea la elección que se haga, siempre serán tres de los cuatro valores los que puedan elegirse libremente; decimos entonces que los grados de libertad son tres. En general, para este problema, los grados de libertad se calcularán como \\(n-1\\), donde \\(n\\) es el número de observaciones, diremos así que, de \\(n\\) observaciones, \\(n-1\\) son independientes, si se fija el resultado de la suma. Una situación diferente es cuando se trata con una tabla de doble entrada con frecuencias marginales fijas; allí los grados de libertad se interpretan de modo distinto. No están relacionados con el número de observaciones sino con la dimensión de la tabla. Veamos la siguiente tabla de dos por tres, con frecuencias marginales fijadas: A B C Total R 10 S 30 Total 5 10 25 40 En ella se relacionan dos variables cuyas categorías son \\(A\\), \\(B\\) y \\(C\\) para la de las columnas y \\(R\\) y \\(S\\) para la de las filas. En la tabla, hemos fijado las frecuencias marginales. No hay dudas que hay infinitos valores posibles para las frecuencias conjuntas que podrían sumar lo que piden las marginales. Nos preguntamos ¿Cuántas de las frecuencias de las celdas (frecuencias conjuntas) pueden elegirse libremente? Si elegimos el valor 2 para la celda \\(RA\\), queda determinado un 3 en la celda \\(SA\\) (para que cumpla con sumar 5 verticalmente). Si luego elegimos un 4 en la celda \\(RB\\), la \\(SB\\) queda determinada a ser 6 (para sumar 10 en la segunda columna). Al mismo tiempo, la celda \\(RC\\) debe ser también 4 para sumar 10 en la primera fila y también se determina la celda \\(SC\\), que no puede ser sino 21, para sumar 30 en la segunda fila y 25 en la tercera columna. La tabla queda así completada, solo las celdas \\(RA\\) y \\(RB\\) fueron elegidas, las demás quedaron determinadas por la exigencia de respetar las frecuencias marginales. A B C Total R 2 4 4 10 S 3 6 21 30 Total 5 10 25 40 ¿Cuántos serán los grados de libertad en este ejemplo?, de las seis celdas que debían completarse con frecuencias, solo 2 pudieron elegirse libremente. Éstos últimos son los grados de libertad: 2. De manera general, para una tabla de dimensión \\(f X c\\) (donde \\(f\\) es la cantidad de filas y \\(c\\) la de columnas, como antes), los grados de libertad se calculan multiplicando \\((f-1)\\) por \\((c-1)\\). En la tabla que acabamos de usar como ejemplo, la dimensión es 2 por 3, por lo que los grados de libertad son \\((2-1)*(3-1)= 1*2=2\\), que son las dos celdas cuyas frecuencias pudimos fijar “libremente”. A los fines de nuestro curso, esta introducción a la idea de grados de libertad es suficiente, el concepto es amplio y su tratamiento más profundo exigiría algunos conocimientos de álgebra lineal, que no necesitamos desarrollar aquí. 8.5 La distribución ji cuadrado (\\(\\chi^{2}\\)) Esta distribución es el primer modelo que veremos con forma asimétrica47. Una de sus aplicaciones es la estimación de la varianza, nosotros la utilizaremos más adelante, cuando tratemos sobre estadística no paramétrica, en especial para probar si una variable puede modelarse con cierta distribución (pruebas de bondad de ajuste) y también para analizar la independencia entre variables nominales. Del mismo modo en que tratamos a la distribución normal, no haremos uso de la fórmula para calcular probabilidades, sino que las buscaremos en una tabla disponible en cualquier hoja de cálculo. Además de la forma asimétrica, hay otra diferencia con la distribución normal, la \\(\\chi^{2}\\) no es una distribución única: no es suficiente especificar un valor de la variable para conocer su probabilidad acumulada sino que la forma que tenga dependerá de los recientemente mencionados “grados de libertad”, los cuales en una primera aproximación tomaremos como \\(n-1\\), donde \\(n\\)es el tamaño de la muestra. Las siguientes son las formas diferentes que tiene la distribución \\(\\chi^{2}\\) para diferentes valores de los \\(gl\\), el eje horizontal indica los valores de la variable \\(\\chi^{2}\\). Como en la normal, las probabilidades se representan como áreas bajo la curva: Figura 8.1: distribución \\(chi^{2}\\) con diferentes grados de libertad (df). Figura 8.2: distribución \\(chi^{2}\\) con diferentes grados de libertad (df). Figura 8.3: distribución \\(chi^{2}\\) con diferentes grados de libertad (df). Los gráficos muestran que a medida que se incrementan los grados de libertad, la forma de la distribución gana en simetría y se asemeja a la distribución normal. Para hallar las probabilidades correspondientes a valores de la variable, usaremos nuevamente el comando de R que provee probabilidades bajo modelos especificados; el que provee los acumulados de la distribución chi cuadrado es pchisq. Para hallar la probabilidad acumulada hasta el valor 8 bajo un modelo \\(\\chi^{2}\\) con \\(10\\) grados de libertad, lo pedimos así: ## [1] 0.3711631 Cuyos argumentos son el valor de la variable (\\(8\\)) y los grados de libertad del modelo (\\(10\\)). Gráficamente se ubica en: Y se escribe: \\[P(\\chi_{10}^{2} \\leq 8) = 0.3712\\] Para el área superior a 8, se complementa la probabilidad acumulada. \\[P(\\chi_{10}^{2} &gt; 8) = 1-P(\\chi_{10}^2 \\leq 8)= 1-0.3712=0,6288\\] Que es la superficie sombreada en el gráfico siguiente. Para encontrar percentiles bajo este modelo, el comando es qchisq, que tiene como argumentos: la probabilidad acumulada y los grados de libertad, y devuelve el valor de la variable \\(\\chi^{2}\\). Por ejemplo, el percentil 95 de una distribución \\(\\chi^{2}\\) con 15 grados de libertad es: ## [1] 24.99579 \\[P_{95}=24.99\\] Dicho de otra manera, el 5% de los valores de la variable \\(\\chi^{2}\\) con 15 grados de libertad, supera al valor 24.99. O también, los valores superiores a 24.99 tienen probabilidad menor a 5% de obtenerse bajo este modelo. La distribución \\(\\chi^{2}\\) tiene muchas aplicaciones, una de las más frecuentes es para poner a prueba la independencia entre dos variables nominales. El vínculo entre esta distribución y el puntaje \\(\\chi^{2}\\) que ya se mencionó, se verá más adelante. 8.6 La distribución t de Student El tercer modelo especial de probabilidades para variables continuas que nos interesa describir es la distribución t, conocida como “de Student”, por el seudónimo que utilizaba quien la aplicó por primera vez, William Gosset48. Se trata de una distribución que, como la normal es simétrica y como la \\(\\chi^{2}\\) depende de los grados de libertad49. Su forma es la siguiente, dependiendo de los grados de libertad: Distribución t de Student con diferentes grados de libertad: A partir de 30 grados de libertad, la distribución toma una forma que va haciéndose más similar a la normal. Las probabilidades acumuladas se buscan con R, con el comando dt, que tiene como argumentos el valor de la variable y los grados de libertad. La probabilidad que una variable con distribución \\(t\\) con \\(un\\) grado de libertad, esté por debajo del valor \\(2\\) se escribe: \\[P(t_{1} \\leq 2)\\] Y se solicita: ## [1] 0.8524164 Que dice que \\[P(t_{1} \\leq 2)=0.8524\\] Su ubicación gráfica es: Como en las otras distribuciones, el área superior se calcula como el complemento: \\[P(t_{1} &gt; 2)=1-P(t_{1}\\leq2)=1-0.8524=0.1476\\] Para ver los efectos del cambio en los grados de libertad, vamos a comparar la probabilidad que una variable t con 30 grados de libertad supere a 2, es decir: \\[P(t_{30} &gt; 2)\\] Lo solicitamos directamente como: ## [1] 0.02731252 Los dos resultados tienen estas representaciones gráficas; En los gráficos y en los valores de las probabilidades se ve que el aumento de los grados de libertad en la distribución t tiene el efecto de reducir la probabilidad de los valores extremos. Los percentiles de la distribución t se solicitan con qt, por ejemplo, el percentil 95 bajo un modelo t con 1 grado de libertad es: ## [1] 6.313752 Y el mismo percentil, si la distribución tiene 30 grados de libertad es: ## [1] 1.697261 Esto quiere decir que un valor t como por ejemplo 3, se considerará extremo bajo una distribución con 30 grados de libertad, pero será un valor esperable si la distribución tiene 1 grado de libertad. Cuando trabajemos con inferencia, veremos que la distribución t se aplica en reemplazo de la normal, cuando se trabaja con muestras pequeñas y que se va volviendo más equivalente a ella a medida que las muestras son de mayor tamaño. 8.6.1 La distribución F El último de los modelos de probabilidad que necesitamos para usar en los próximos capítulos en la realización de inferencias, es la distribución F de Fisher. Es una distribución asimétrica, no negativa y su forma depende de los valores de los grados de libertad del numerador y del denominador50. Es una curva muy asimétrica a la derecha cuando los grados de libertad son pocos y tiende a la normalidad a medida que aumentan los \\(gl\\). Veamos dos casos de combinaciones de grados de libertad en el numerador y en el denominador: En el cálculo de las probabilidades, ahora debemos informar los grados de libertad del numerador y del denominador separadamente. Para solicitar, por ejemplo, la \\(P(F_{3,2} \\leq 4)\\), se usa el comando pf, indicando el valor de la variable y los grados de libertad del numerador y el denominador en ese orden: ## [1] 0.7935601 Es decir: \\(P(F_{3,2} \\leq 4)=0.7936\\) Cuyo gráfico es: El área superior es la diferencia a uno: ## [1] 0.2064399 De modo que \\(P(F_{3,2} &gt; 4) = 0,2064\\). El percentil 95 de una distrindución F con 3 grados de libertad en el numerador y dos en el denominador es: ## [1] 19.16429 Que se lee indicando que el 5% de los valores de la variable \\(F_{3,2}\\) superan a \\(19.16\\). \\(P(F_{3,2}&gt;19.16)=.05\\) Cuando pedimos el mismo percentil de otra variable que tenga distribución \\(F_{5,10}\\), se obtiene: ## [1] 3.325835 Los gráficos del \\(P_{95}\\) en las dos distribuciones son los siguientes: También en esta distribución vemos que el aumento de los \\(gl\\) tiene el efecto de reducir la probabilidad de los valores extremos. La distribución F es usada para comparar la dispersión de dos distribuciones, a través del cociente de las varianzas. 8.7 Hacerlo en R 8.7.1 Probabilidades Para solicitar las probabilidades acumuladas hasta determinado valor (\\(x\\)) de la variable, bajo diferentes modelos, los comandos llevan una \\(p\\) delante del nombre de la distribución: pbinom, pnorm, pchisq, pt, pf. Y según la distribución, deben indicarse los parámetros que la especifican: Binomial: pbinom(x, “cantidad de ensayos”, “probabilidad de éxito a cada ensayo”) Normal estándar: pnorm (z), la media vale cero y la desviación estándar, uno. No hace falta indicarlo. Normal: pnorm(x, “media”, “desviación estándar” ) Ji cuadrado: pchisq(x, “grados de libertad”) t de Student: pt(x, “grados de libertad”) F de Fisher: pf(x, “grados de libertad del numerador”, “grados de libertad del denominador”) 8.7.2 Percentiles Para hallar percentiles, los comandos tienen una \\(q\\) delante del nombre del modelo: qbinom, qnorm, qchisq, qt, qf. Y debe indicarse el percentil que se busca, junto a los parámetros que corresponden a cada distribución. Llamando r al percentil que interesa encontrar, la solicitud a R para cada modelo es: Binomial: qbinom(\\(r/100\\), “cantidad de ensayos”, “probabilidad de éxito a cada ensayo”) Normal estándar: qnorm (\\(r/100\\)), la media vale cero y la desviación estándar, uno. No hace falta indicarlo. Normal: qnorm(\\(r/100\\), “media”, “desviación estándar” ) Ji cuadrado: qchisq(\\(r/100\\), “grados de libertad”) t de Student: qt(\\(r/100\\), “grados de libertad”) F de Fisher: qf(\\(r/100\\), “grados de libertad del numerador”, “grados de libertad del denominador”) 8.7.3 Áreas centrales En lo que sigue será frecuente que se necesiten percetiles de la variable que dellimitan determinadas áreas centrales de la distribución. Cuanquiera se el modelo de probabilidad que se use, suele denominarse \\(1-\\alpha\\) al área central, con lo que \\(\\alpha\\) es el área que queda por fuera de la zona central, dividida en dos. Los percentiles que delimitan esa área central de \\(1-\\alpha\\) son \\(\\frac{\\alpha}{2}\\) y \\(1-\\frac{\\alpha}{2}\\). Por ejemplo, para determinar cuáles son los valores de una distribución \\(\\chi^2\\) con 13 grados delibertad que delimitan un 90% de área central, calculamos \\(\\alpha\\), que es el 10% restante y los percentiles son: 5 (\\(\\frac{\\alpha}{2}\\)) y 95 (\\(1-\\frac{\\alpha}{2}\\)). ## [1] 5.891864 ## [1] 22.36203 Que gráficamente se ve así: "]
]
