<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 9 Distribuciones en el muestreo | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R</title>
  <meta name="description" content="Capítulo 9 Distribuciones en el muestreo | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 9 Distribuciones en el muestreo | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/imagenes/cover.jpg" />
  
  <meta name="github-repo" content="jcrodriguez1989/EstadisticaParaCienciasSocialesConR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 9 Distribuciones en el muestreo | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  
  
  <meta name="twitter:image" content="/imagenes/cover.jpg" />

<meta name="author" content="Eduardo Bologna" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probabilidad-los-modelos.html"/>
<link rel="next" href="estimación-por-intervalo.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística para Ciencias Sociales con R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Colaboradores</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#comit%C3%A9-editorial"><i class="fa fa-check"></i>Comité Editorial</a></li>
<li class="chapter" data-level="" data-path=""><a href="#edici%C3%B3n-en-bookdown"><i class="fa fa-check"></i>Edición en bookdown</a></li>
<li class="chapter" data-level="" data-path=""><a href="#revisi%C3%B3n-de-lenguaje-incluyente"><i class="fa fa-check"></i>Revisión de lenguaje incluyente</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#presentaci%C3%B3n"><i class="fa fa-check"></i>Presentación</a>
<ul>
<li class="chapter" data-level="" data-path="presentación.html"><a href="presentación.html"><i class="fa fa-check"></i>Recorridos posibles</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#introducci%C3%B3n"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html"><i class="fa fa-check"></i>Antes de empezar</a>
<ul>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#materiales"><i class="fa fa-check"></i>Materiales</a>
<ul>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#encuesta-permanente-de-hogares"><i class="fa fa-check"></i>Encuesta Permanente de Hogares</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#encuesta-nacional-de-factores-de-riesgo"><i class="fa fa-check"></i>Encuesta Nacional de Factores de Riesgo</a></li>
<li class="chapter" data-level="" data-path=""><a href="#latinobar%C3%B3metro"><i class="fa fa-check"></i>Latinobarómetro</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#encuesta-nacional-sobre-prevalencias-de-consumo-de-sustancias-psicoactivas"><i class="fa fa-check"></i>Encuesta Nacional sobre Prevalencias de Consumo de Sustancias Psicoactivas</a></li>
<li class="chapter" data-level="" data-path=""><a href="#aplicaci%C3%B3n-de-la-escala-de-bayley"><i class="fa fa-check"></i>Aplicación de la escala de Bayley</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#tercera-edad"><i class="fa fa-check"></i>Tercera edad</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#herramientas"><i class="fa fa-check"></i>Herramientas</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#la-elecci%C3%B3n-de-r"><i class="fa fa-check"></i>La elección de R</a></li>
<li class="chapter" data-level="" data-path=""><a href="#instalaci%C3%B3n-de-r-y-rstudio"><i class="fa fa-check"></i>Instalación de R y RStudio</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#los-componentes-de-rstudio"><i class="fa fa-check"></i>Los componentes de RStudio</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#operaciones-en-el-script"><i class="fa fa-check"></i>Operaciones en el script</a></li>
<li class="chapter" data-level="" data-path=""><a href="#instalaci%C3%B3n-de-paquetes"><i class="fa fa-check"></i>Instalación de paquetes</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Estadística Descriptiva</b></span></li>
<li class="chapter" data-level="1" data-path="10-capitulo9.html"><a href="#los-datos-estad%C3%ADsticos"><i class="fa fa-check"></i><b>1</b> Los datos estadísticos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="10-capitulo9.html"><a href="#la-selecci%C3%B3n-de-la-informaci%C3%B3n-pertinente"><i class="fa fa-check"></i><b>1.1</b> La selección de la información pertinente</a></li>
<li class="chapter" data-level="1.2" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html"><i class="fa fa-check"></i><b>1.2</b> Las entidades</a></li>
<li class="chapter" data-level="1.3" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-variables"><i class="fa fa-check"></i><b>1.3</b> Las variables</a></li>
<li class="chapter" data-level="1.4" data-path="10-capitulo9.html"><a href="#las-categor%C3%ADas"><i class="fa fa-check"></i><b>1.4</b> Las categorías</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="10-capitulo9.html"><a href="#requisitos-de-las-categor%C3%ADas"><i class="fa fa-check"></i><b>1.4.1</b> Requisitos de las categorías</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="10-capitulo9.html"><a href="#los-s%C3%ADmbolos-num%C3%A9ricos"><i class="fa fa-check"></i><b>1.5</b> Los símbolos numéricos</a></li>
<li class="chapter" data-level="1.6" data-path="10-capitulo9.html"><a href="#la-medici%C3%B3n"><i class="fa fa-check"></i><b>1.6</b> La medición</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="10-capitulo9.html"><a href="#niveles-de-medici%C3%B3n"><i class="fa fa-check"></i><b>1.6.1</b> Niveles de medición</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="10-capitulo9.html"><a href="#resumen-de-los-niveles-de-medici%C3%B3n"><i class="fa fa-check"></i><b>1.7</b> Resumen de los niveles de medición</a></li>
<li class="chapter" data-level="1.8" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#hacerlo-en-r"><i class="fa fa-check"></i><b>1.8</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#lectura-de-la-base"><i class="fa fa-check"></i><b>1.8.1</b> Lectura de la base</a></li>
<li class="chapter" data-level="1.8.2" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-variables-1"><i class="fa fa-check"></i><b>1.8.2</b> Las variables</a></li>
<li class="chapter" data-level="1.8.3" data-path="10-capitulo9.html"><a href="#los-niveles-de-medici%C3%B3n-en-r"><i class="fa fa-check"></i><b>1.8.3</b> Los niveles de medición en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html"><i class="fa fa-check"></i><b>2</b> Distribuciones de frecuencia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="10-capitulo9.html"><a href="#tablas-de-distribuci%C3%B3n-de-frecuencia"><i class="fa fa-check"></i><b>2.1</b> Tablas de distribución de frecuencia</a></li>
<li class="chapter" data-level="2.2" data-path="10-capitulo9.html"><a href="#recategorizaci%C3%B3n"><i class="fa fa-check"></i><b>2.2</b> Recategorización</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="10-capitulo9.html"><a href="#variable-discreta-con-muchas-categor%C3%ADas"><i class="fa fa-check"></i><b>2.2.1</b> Variable discreta con muchas categorías</a></li>
<li class="chapter" data-level="2.2.2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#variable-continua"><i class="fa fa-check"></i><b>2.2.2</b> Variable continua</a></li>
<li class="chapter" data-level="2.2.3" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#formas-de-recategorizar"><i class="fa fa-check"></i><b>2.2.3</b> Formas de recategorizar</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="10-capitulo9.html"><a href="#la-presentaci%C3%B3n-gr%C3%A1fica-de-los-resultados"><i class="fa fa-check"></i><b>2.3</b> La presentación gráfica de los resultados</a></li>
<li class="chapter" data-level="2.4" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#hacerlo-en-r-1"><i class="fa fa-check"></i><b>2.4</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#tablas-univariadas"><i class="fa fa-check"></i><b>2.4.1</b> Tablas univariadas</a></li>
<li class="chapter" data-level="2.4.2" data-path="10-capitulo9.html"><a href="#recategorizaci%C3%B3n-1"><i class="fa fa-check"></i><b>2.4.2</b> Recategorización</a></li>
<li class="chapter" data-level="2.4.3" data-path="10-capitulo9.html"><a href="#representaciones-gr%C3%A1ficas"><i class="fa fa-check"></i><b>2.4.3</b> Representaciones gráficas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="10-capitulo9.html"><a href="#la-expresi%C3%B3n-resumida-de-la-informaci%C3%B3n"><i class="fa fa-check"></i><b>3</b> La expresión resumida de la información</a>
<ul>
<li class="chapter" data-level="3.1" data-path="10-capitulo9.html"><a href="#medidas-de-posici%C3%B3n"><i class="fa fa-check"></i><b>3.1</b> Medidas de posición</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html"><i class="fa fa-check"></i><b>3.1.1</b> Variables nominales: proporciones</a></li>
<li class="chapter" data-level="3.1.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-tasas"><i class="fa fa-check"></i><b>3.1.2</b> Variables nominales: tasas</a></li>
<li class="chapter" data-level="3.1.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-razones"><i class="fa fa-check"></i><b>3.1.3</b> Variables nominales: razones</a></li>
<li class="chapter" data-level="3.1.4" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-el-modo"><i class="fa fa-check"></i><b>3.1.4</b> Variables nominales: el modo</a></li>
<li class="chapter" data-level="3.1.5" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-ordinales-cuantiles"><i class="fa fa-check"></i><b>3.1.5</b> Variables ordinales: cuantiles</a></li>
<li class="chapter" data-level="3.1.6" data-path="10-capitulo9.html"><a href="#variables-m%C3%A9tricas-la-media-o-promedio"><i class="fa fa-check"></i><b>3.1.6</b> Variables métricas: la media o promedio</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="10-capitulo9.html"><a href="#la-forma-de-la-distribuci%C3%B3n"><i class="fa fa-check"></i><b>3.2</b> La forma de la distribución</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="10-capitulo9.html"><a href="#asimetr%C3%ADa"><i class="fa fa-check"></i><b>3.2.1</b> Asimetría</a></li>
<li class="chapter" data-level="3.2.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#curtosis"><i class="fa fa-check"></i><b>3.2.2</b> Curtosis</a></li>
<li class="chapter" data-level="3.2.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#box-plots"><i class="fa fa-check"></i><b>3.2.3</b> Box-plots</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="10-capitulo9.html"><a href="#medidas-de-dispersi%C3%B3n"><i class="fa fa-check"></i><b>3.3</b> Medidas de dispersión</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#recorrido"><i class="fa fa-check"></i><b>3.3.1</b> Recorrido</a></li>
<li class="chapter" data-level="3.3.2" data-path="10-capitulo9.html"><a href="#amplitud-intercuart%C3%ADlica"><i class="fa fa-check"></i><b>3.3.2</b> Amplitud intercuartílica</a></li>
<li class="chapter" data-level="3.3.3" data-path="10-capitulo9.html"><a href="#medidas-de-dispersi%C3%B3n-basadas-en-la-media"><i class="fa fa-check"></i><b>3.3.3</b> Medidas de dispersión basadas en la media</a></li>
<li class="chapter" data-level="3.3.4" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#varianza"><i class="fa fa-check"></i><b>3.3.4</b> Varianza</a></li>
<li class="chapter" data-level="3.3.5" data-path="10-capitulo9.html"><a href="#desviaci%C3%B3n-est%C3%A1ndar"><i class="fa fa-check"></i><b>3.3.5</b> Desviación estándar</a></li>
<li class="chapter" data-level="3.3.6" data-path="10-capitulo9.html"><a href="#coeficiente-de-variaci%C3%B3n"><i class="fa fa-check"></i><b>3.3.6</b> Coeficiente de variación</a></li>
<li class="chapter" data-level="3.3.7" data-path="10-capitulo9.html"><a href="#box-plots-y-dispersi%C3%B3n"><i class="fa fa-check"></i><b>3.3.7</b> Box-plots y dispersión</a></li>
<li class="chapter" data-level="3.3.8" data-path="10-capitulo9.html"><a href="#medida-de-la-dispersi%C3%B3n-cuando-no-hay-distancias"><i class="fa fa-check"></i><b>3.3.8</b> Medida de la dispersión cuando no hay distancias</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="10-capitulo9.html"><a href="#el-individuo-en-relaci%C3%B3n-a-su-grupo"><i class="fa fa-check"></i><b>3.4</b> El individuo en relación a su grupo</a></li>
<li class="chapter" data-level="3.5" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#resumen-de-medidas-descriptivas"><i class="fa fa-check"></i><b>3.5</b> Resumen de medidas descriptivas</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="10-capitulo9.html"><a href="#medidas-de-posici%C3%B3n-1"><i class="fa fa-check"></i><b>3.5.1</b> Medidas de posición</a></li>
<li class="chapter" data-level="3.5.2" data-path="10-capitulo9.html"><a href="#medidas-de-dispersi%C3%B3n-1"><i class="fa fa-check"></i><b>3.5.2</b> Medidas de dispersión</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#hacerlo-en-r-2"><i class="fa fa-check"></i><b>3.6</b> Hacerlo en R</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="10-capitulo9.html"><a href="#relaci%C3%B3n-entre-variables-los-fundamentos"><i class="fa fa-check"></i><b>4</b> Relación entre variables: los fundamentos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html"><i class="fa fa-check"></i><b>4.1</b> Tablas de contingencia</a></li>
<li class="chapter" data-level="4.2" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#frecuencias-relativas"><i class="fa fa-check"></i><b>4.2</b> Frecuencias relativas</a></li>
<li class="chapter" data-level="4.3" data-path="10-capitulo9.html"><a href="#una-clasificaci%C3%B3n-en-referencia-al-tiempo"><i class="fa fa-check"></i><b>4.3</b> Una clasificación en referencia al tiempo</a></li>
<li class="chapter" data-level="4.4" data-path="10-capitulo9.html"><a href="#la-direcci%C3%B3n-de-la-relaci%C3%B3n"><i class="fa fa-check"></i><b>4.4</b> La dirección de la relación</a></li>
<li class="chapter" data-level="4.5" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#concepto-de-riesgo-relativo"><i class="fa fa-check"></i><b>4.5</b> Concepto de riesgo relativo</a></li>
<li class="chapter" data-level="4.6" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#la-intensidad"><i class="fa fa-check"></i><b>4.6</b> La intensidad</a></li>
<li class="chapter" data-level="4.7" data-path="10-capitulo9.html"><a href="#el-concepto-de-independencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>4.7</b> El concepto de independencia estadística</a></li>
<li class="chapter" data-level="4.8" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#hacerlo-en-r-3"><i class="fa fa-check"></i><b>4.8</b> Hacerlo en R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="10-capitulo9.html"><a href="#relaci%C3%B3n-entre-variables-el-an%C3%A1lisis"><i class="fa fa-check"></i><b>5</b> Relación entre variables: el análisis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="10-capitulo9.html"><a href="#relaciones-entre-variables-vs.-comparaci%C3%B3n-de-grupos"><i class="fa fa-check"></i><b>5.1</b> Relaciones entre variables vs. comparación de grupos</a></li>
<li class="chapter" data-level="5.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html"><i class="fa fa-check"></i><b>5.2</b> Variables nominales</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="10-capitulo9.html"><a href="#coeficientes-de-asociaci%C3%B3n-para-variables-nominales"><i class="fa fa-check"></i><b>5.2.1</b> Coeficientes de asociación para variables nominales</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#variables-de-nivel-ordinal"><i class="fa fa-check"></i><b>5.3</b> Variables de nivel ordinal</a></li>
<li class="chapter" data-level="5.4" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#nivel-intervalar-o-proporcional"><i class="fa fa-check"></i><b>5.4</b> Nivel intervalar o proporcional</a></li>
<li class="chapter" data-level="5.5" data-path="10-capitulo9.html"><a href="#dicotom%C3%ADas-reales-y-artificiales"><i class="fa fa-check"></i><b>5.5</b> Dicotomías reales y artificiales</a></li>
<li class="chapter" data-level="5.6" data-path="10-capitulo9.html"><a href="#niveles-de-medici%C3%B3n-combinados"><i class="fa fa-check"></i><b>5.6</b> Niveles de medición combinados</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="10-capitulo9.html"><a href="#una-variable-dicot%C3%B3mica-real-y-una-proporcional"><i class="fa fa-check"></i><b>5.6.1</b> Una variable dicotómica real y una proporcional</a></li>
<li class="chapter" data-level="5.6.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#una-variable-continua-dicotomizada-y-una-proporcional"><i class="fa fa-check"></i><b>5.6.2</b> Una variable continua dicotomizada y una proporcional</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="10-capitulo9.html"><a href="#resumen-de-coeficientes-de-asociaci%C3%B3n"><i class="fa fa-check"></i><b>5.7</b> Resumen de coeficientes de asociación</a></li>
<li class="chapter" data-level="5.8" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#matriz-de-correlaciones"><i class="fa fa-check"></i><b>5.8</b> Matriz de correlaciones</a></li>
<li class="chapter" data-level="5.9" data-path="10-capitulo9.html"><a href="#la-forma-de-la-relaci%C3%B3n"><i class="fa fa-check"></i><b>5.9</b> La forma de la relación</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#ordenada-al-origen"><i class="fa fa-check"></i><b>5.9.1</b> Ordenada al origen</a></li>
<li class="chapter" data-level="5.9.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#pendiente"><i class="fa fa-check"></i><b>5.9.2</b> Pendiente</a></li>
<li class="chapter" data-level="5.9.3" data-path="10-capitulo9.html"><a href="#obtenci%C3%B3n-de-la-recta-de-regresi%C3%B3n"><i class="fa fa-check"></i><b>5.9.3</b> Obtención de la recta de regresión</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="10-capitulo9.html"><a href="#la-visualizaci%C3%B3n-de-los-datos"><i class="fa fa-check"></i><b>5.10</b> La visualización de los datos</a></li>
<li class="chapter" data-level="5.11" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#hacerlo-en-r-4"><i class="fa fa-check"></i><b>5.11</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#distancia-chi2"><i class="fa fa-check"></i><b>5.11.1</b> Distancia <span class="math inline">\(\chi^{2}\)</span></a></li>
<li class="chapter" data-level="5.11.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#coeficientes"><i class="fa fa-check"></i><b>5.11.2</b> Coeficientes</a></li>
<li class="chapter" data-level="5.11.3" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#modelo-lineal"><i class="fa fa-check"></i><b>5.11.3</b> Modelo lineal</a></li>
<li class="chapter" data-level="5.11.4" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#cuarteto-de-anscombe"><i class="fa fa-check"></i><b>5.11.4</b> Cuarteto de Anscombe</a></li>
<li class="chapter" data-level="5.11.5" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#datasaurus"><i class="fa fa-check"></i><b>5.11.5</b> Datasaurus</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II De la descripción a la inferencia</b></span></li>
<li class="chapter" data-level="6" data-path="10-capitulo9.html"><a href="#obtenci%C3%B3n-de-la-muestra"><i class="fa fa-check"></i><b>6</b> Obtención de la muestra</a>
<ul>
<li class="chapter" data-level="6.1" data-path="10-capitulo9.html"><a href="#poblaci%C3%B3n"><i class="fa fa-check"></i><b>6.1</b> Población</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html"><i class="fa fa-check"></i><b>6.1.1</b> Muestra</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="10-capitulo9.html"><a href="#muestreos-probabil%C3%ADsticos"><i class="fa fa-check"></i><b>6.2</b> Muestreos probabilísticos</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-irrestricto-aleatorio-o-aleatorio-simple"><i class="fa fa-check"></i><b>6.2.1</b> Muestreo irrestricto aleatorio o aleatorio simple</a></li>
<li class="chapter" data-level="6.2.2" data-path="10-capitulo9.html"><a href="#muestreo-sistem%C3%A1tico"><i class="fa fa-check"></i><b>6.2.2</b> Muestreo sistemático</a></li>
<li class="chapter" data-level="6.2.3" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-estratificado"><i class="fa fa-check"></i><b>6.2.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="6.2.4" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-por-conglomerados"><i class="fa fa-check"></i><b>6.2.4</b> Muestreo por conglomerados</a></li>
<li class="chapter" data-level="6.2.5" data-path="10-capitulo9.html"><a href="#m%C3%A9todo-de-kish"><i class="fa fa-check"></i><b>6.2.5</b> Método de Kish</a></li>
<li class="chapter" data-level="6.2.6" data-path="10-capitulo9.html"><a href="#uso-combinado-de-t%C3%A9cnicas-de-muestreo"><i class="fa fa-check"></i><b>6.2.6</b> Uso combinado de técnicas de muestreo</a></li>
<li class="chapter" data-level="6.2.7" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-de-panel"><i class="fa fa-check"></i><b>6.2.7</b> Muestreo de panel</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="10-capitulo9.html"><a href="#muestreos-no-probabil%C3%ADsticos"><i class="fa fa-check"></i><b>6.3</b> Muestreos no probabilísticos</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-por-cuotas"><i class="fa fa-check"></i><b>6.3.1</b> Muestreo por cuotas</a></li>
<li class="chapter" data-level="6.3.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-de-juicio-o-intencional"><i class="fa fa-check"></i><b>6.3.2</b> Muestreo de juicio o intencional</a></li>
<li class="chapter" data-level="6.3.3" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-autoelegido"><i class="fa fa-check"></i><b>6.3.3</b> Muestreo autoelegido</a></li>
<li class="chapter" data-level="6.3.4" data-path="10-capitulo9.html"><a href="#muestreo-accidental-o-seg%C3%BAn-disponibilidad"><i class="fa fa-check"></i><b>6.3.4</b> Muestreo accidental o según disponibilidad</a></li>
<li class="chapter" data-level="6.3.5" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-bola-de-nieve"><i class="fa fa-check"></i><b>6.3.5</b> Muestreo bola de nieve</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#hacerlo-en-r-5"><i class="fa fa-check"></i><b>6.4</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#aleatorio-simple"><i class="fa fa-check"></i><b>6.4.1</b> Aleatorio simple</a></li>
<li class="chapter" data-level="6.4.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#estratificado"><i class="fa fa-check"></i><b>6.4.2</b> Estratificado</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html"><i class="fa fa-check"></i><b>7</b> Probabilidad: los fundamentos</a>
<ul>
<li class="chapter" data-level="7.1" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#formas-para-asignar-probabilidades"><i class="fa fa-check"></i><b>7.1</b> Formas para asignar probabilidades</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="10-capitulo9.html"><a href="#asignaci%C3%B3n-a-priori"><i class="fa fa-check"></i><b>7.1.1</b> Asignación a priori</a></li>
<li class="chapter" data-level="7.1.2" data-path="10-capitulo9.html"><a href="#asignaci%C3%B3n-a-posteriori"><i class="fa fa-check"></i><b>7.1.2</b> Asignación a posteriori</a></li>
<li class="chapter" data-level="7.1.3" data-path="10-capitulo9.html"><a href="#la-relaci%C3%B3n-entre-asignaci%C3%B3n-a-priori-y-a-posteriori"><i class="fa fa-check"></i><b>7.1.3</b> La relación entre asignación a priori y a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#operando-con-probabilidades"><i class="fa fa-check"></i><b>7.2</b> Operando con probabilidades</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#con-probabilidades-frecuenciales"><i class="fa fa-check"></i><b>7.2.1</b> Con probabilidades frecuenciales</a></li>
<li class="chapter" data-level="7.2.2" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#con-probabilidades-a-priori"><i class="fa fa-check"></i><b>7.2.2</b> Con probabilidades a priori</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#el-teorema-de-bayes"><i class="fa fa-check"></i><b>7.3</b> El teorema de Bayes</a></li>
<li class="chapter" data-level="7.4" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#variables-aleatorias"><i class="fa fa-check"></i><b>7.4</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html"><i class="fa fa-check"></i><b>8</b> Probabilidad: los modelos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="10-capitulo9.html"><a href="#concepto-de-modelizaci%C3%B3n"><i class="fa fa-check"></i><b>8.1</b> Concepto de modelización</a></li>
<li class="chapter" data-level="8.2" data-path="10-capitulo9.html"><a href="#distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>8.2</b> Distribución binomial</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#esperanza-y-varianza"><i class="fa fa-check"></i><b>8.2.1</b> Esperanza y varianza</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="10-capitulo9.html"><a href="#distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.3</b> Distribución normal</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#cuantiles"><i class="fa fa-check"></i><b>8.3.1</b> Cuantiles</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#la-idea-de-grados-de-libertad"><i class="fa fa-check"></i><b>8.4</b> La idea de grados de libertad</a></li>
<li class="chapter" data-level="8.5" data-path="10-capitulo9.html"><a href="#la-distribuci%C3%B3n-ji-cuadrado-chi2"><i class="fa fa-check"></i><b>8.5</b> La distribución ji cuadrado (<span class="math inline">\(\chi^{2}\)</span>)</a></li>
<li class="chapter" data-level="8.6" data-path="10-capitulo9.html"><a href="#la-distribuci%C3%B3n-t-de-student"><i class="fa fa-check"></i><b>8.6</b> La distribución t de Student</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="10-capitulo9.html"><a href="#la-distribuci%C3%B3n-f"><i class="fa fa-check"></i><b>8.6.1</b> La distribución F</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#hacerlo-en-r-6"><i class="fa fa-check"></i><b>8.7</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#probabilidades-exactas"><i class="fa fa-check"></i><b>8.7.1</b> Probabilidades exactas</a></li>
<li class="chapter" data-level="8.7.2" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#probabilidades-acumuladas"><i class="fa fa-check"></i><b>8.7.2</b> Probabilidades acumuladas</a></li>
<li class="chapter" data-level="8.7.3" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#cuantiles-1"><i class="fa fa-check"></i><b>8.7.3</b> Cuantiles</a></li>
<li class="chapter" data-level="8.7.4" data-path="10-capitulo9.html"><a href="#%C3%A1reas-centrales"><i class="fa fa-check"></i><b>8.7.4</b> Áreas centrales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html"><i class="fa fa-check"></i><b>9</b> Distribuciones en el muestreo</a>
<ul>
<li class="chapter" data-level="9.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#variabilidad-muestral"><i class="fa fa-check"></i><b>9.1</b> Variabilidad muestral</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#dos-aspectos-importantes-para-recordar-cuando-se-usan-muestras"><i class="fa fa-check"></i><b>9.1.1</b> Dos aspectos importantes para recordar cuando se usan muestras:</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="10-capitulo9.html"><a href="#caracter%C3%ADsticas-de-los-estimadores"><i class="fa fa-check"></i><b>9.2</b> Características de los estimadores</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#insesgabilidad"><i class="fa fa-check"></i><b>9.2.1</b> Insesgabilidad</a></li>
<li class="chapter" data-level="9.2.2" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#consistencia"><i class="fa fa-check"></i><b>9.2.2</b> Consistencia</a></li>
<li class="chapter" data-level="9.2.3" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#eficiencia"><i class="fa fa-check"></i><b>9.2.3</b> Eficiencia</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#distribuciones-de-probabilidad-de-los-estimadores"><i class="fa fa-check"></i><b>9.3</b> Distribuciones de probabilidad de los estimadores</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="10-capitulo9.html"><a href="#primera-aproximaci%C3%B3n"><i class="fa fa-check"></i><b>9.3.1</b> Primera aproximación</a></li>
<li class="chapter" data-level="9.3.2" data-path="10-capitulo9.html"><a href="#distribuci%C3%B3n-de-la-media-muestral"><i class="fa fa-check"></i><b>9.3.2</b> Distribución de la media muestral</a></li>
<li class="chapter" data-level="9.3.3" data-path="10-capitulo9.html"><a href="#distribuci%C3%B3n-de-la-proporci%C3%B3n-muestral"><i class="fa fa-check"></i><b>9.3.3</b> Distribución de la proporción muestral</a></li>
<li class="chapter" data-level="9.3.4" data-path="10-capitulo9.html"><a href="#muestras-peque%C3%B1as"><i class="fa fa-check"></i><b>9.3.4</b> Muestras pequeñas</a></li>
<li class="chapter" data-level="9.3.5" data-path="10-capitulo9.html"><a href="#distribuci%C3%B3n-de-la-varianza"><i class="fa fa-check"></i><b>9.3.5</b> Distribución de la varianza</a></li>
<li class="chapter" data-level="9.3.6" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#muestreo-desde-dos-poblaciones"><i class="fa fa-check"></i><b>9.3.6</b> Muestreo desde dos poblaciones</a></li>
<li class="chapter" data-level="9.3.7" data-path="10-capitulo9.html"><a href="#distribuci%C3%B3n-del-cociente-de-varianzas"><i class="fa fa-check"></i><b>9.3.7</b> Distribución del cociente de varianzas</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="10-capitulo9.html"><a href="#resumen-de-la-relaci%C3%B3n-entre-estimadores-y-par%C3%A1metros"><i class="fa fa-check"></i><b>9.4</b> Resumen de la relación entre estimadores y parámetros</a></li>
<li class="chapter" data-level="9.5" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#hacerlo-en-r-7"><i class="fa fa-check"></i><b>9.5</b> Hacerlo en R</a></li>
</ul></li>
<li class="part"><span><b>III Estadística inferencial</b></span></li>
<li class="chapter" data-level="10" data-path="10-capitulo9.html"><a href="#estimaci%C3%B3n-por-intervalo"><i class="fa fa-check"></i><b>10</b> Estimación por intervalo</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10-capitulo9.html"><a href="#estimaci%C3%B3n-puntual"><i class="fa fa-check"></i><b>10.1</b> Estimación puntual</a></li>
<li class="chapter" data-level="10.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html"><i class="fa fa-check"></i><b>10.2</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="10.3" data-path="10-capitulo9.html"><a href="#estimaci%C3%B3n-de-la-media"><i class="fa fa-check"></i><b>10.3</b> Estimación de la media</a></li>
<li class="chapter" data-level="10.4" data-path="10-capitulo9.html"><a href="#estimaci%C3%B3n-de-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.4</b> Estimación de la proporción</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-clopper-pearson"><i class="fa fa-check"></i><b>10.4.1</b> Intervalo de Clopper-Pearson</a></li>
<li class="chapter" data-level="10.4.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-wald"><i class="fa fa-check"></i><b>10.4.2</b> Intervalo de Wald</a></li>
<li class="chapter" data-level="10.4.3" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-wilson"><i class="fa fa-check"></i><b>10.4.3</b> Intervalo de Wilson</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#la-calidad-de-las-estimaciones-por-intervalo"><i class="fa fa-check"></i><b>10.5</b> La calidad de las estimaciones por intervalo</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="10-capitulo9.html"><a href="#el-error-de-estimaci%C3%B3n-en-la-media"><i class="fa fa-check"></i><b>10.5.1</b> El error de estimación en la media</a></li>
<li class="chapter" data-level="10.5.2" data-path="10-capitulo9.html"><a href="#el-error-de-estimaci%C3%B3n-en-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.5.2</b> El error de estimación en la proporción</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#probabilidad-de-cobertura"><i class="fa fa-check"></i><b>10.6</b> Probabilidad de cobertura</a></li>
<li class="chapter" data-level="10.7" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#hacerlo-en-r-8"><i class="fa fa-check"></i><b>10.7</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-para-la-media"><i class="fa fa-check"></i><b>10.7.1</b> Intervalo para la media</a></li>
<li class="chapter" data-level="10.7.2" data-path="10-capitulo9.html"><a href="#intervalo-para-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.7.2</b> Intervalo para la proporción</a></li>
<li class="chapter" data-level="10.7.3" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#cobertura"><i class="fa fa-check"></i><b>10.7.3</b> Cobertura</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="10-capitulo9.html"><a href="#prueba-de-hip%C3%B3tesis-la-l%C3%B3gica"><i class="fa fa-check"></i><b>11</b> Prueba de hipótesis: la lógica</a>
<ul>
<li class="chapter" data-level="11.1" data-path="10-capitulo9.html"><a href="#el-razonamiento-de-la-prueba-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>11.1</b> El razonamiento de la prueba de hipótesis</a></li>
<li class="chapter" data-level="11.2" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html"><i class="fa fa-check"></i><b>11.2</b> Prueba sobre la media</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="10-capitulo9.html"><a href="#la-toma-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>11.2.1</b> La toma de decisión</a></li>
<li class="chapter" data-level="11.2.2" data-path="10-capitulo9.html"><a href="#los-puntos-cr%C3%ADticos-en-t%C3%A9rminos-del-estimador"><i class="fa fa-check"></i><b>11.2.2</b> Los puntos críticos en términos del estimador</a></li>
<li class="chapter" data-level="11.2.3" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#pruebas-unilaterales"><i class="fa fa-check"></i><b>11.2.3</b> Pruebas unilaterales</a></li>
<li class="chapter" data-level="11.2.4" data-path="10-capitulo9.html"><a href="#otros-ejemplos-de-prueba-de-hip%C3%B3tesis-sobre-la-media"><i class="fa fa-check"></i><b>11.2.4</b> Otros ejemplos de prueba de hipótesis sobre la media</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="10-capitulo9.html"><a href="#prueba-sobre-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>11.3</b> Prueba sobre la proporción</a></li>
<li class="chapter" data-level="11.4" data-path="10-capitulo9.html"><a href="#tipos-de-error-en-las-pruebas-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>11.4</b> Tipos de error en las pruebas de hipótesis</a></li>
<li class="chapter" data-level="11.5" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#etii-mu-alpha-y-n"><i class="fa fa-check"></i><b>11.5</b> <em>ETII:</em> <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(n\)</span></a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#curva-de-potencia"><i class="fa fa-check"></i><b>11.5.1</b> Curva de potencia</a></li>
<li class="chapter" data-level="11.5.2" data-path="10-capitulo9.html"><a href="#significaci%C3%B3n-estad%C3%ADstica-y-valor-p"><i class="fa fa-check"></i><b>11.5.2</b> Significación estadística y valor <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="10-capitulo9.html"><a href="#muestras-peque%C3%B1as-y-pruebas-t"><i class="fa fa-check"></i><b>11.6</b> Muestras pequeñas y pruebas <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="11.7" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#hacerlo-en-r-9"><i class="fa fa-check"></i><b>11.7</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#prueba-sobre-la-media-1"><i class="fa fa-check"></i><b>11.7.1</b> Prueba sobre la media</a></li>
<li class="chapter" data-level="11.7.2" data-path="10-capitulo9.html"><a href="#prueba-sobre-la-proporci%C3%B3n-1"><i class="fa fa-check"></i><b>11.7.2</b> Prueba sobre la proporción</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#resumen-de-pruebas-sobre-una-muestra"><i class="fa fa-check"></i><b>11.8</b> Resumen de pruebas sobre una muestra</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="10-capitulo9.html"><a href="#prueba-de-hip%C3%B3tesis-las-aplicaciones"><i class="fa fa-check"></i><b>12</b> Prueba de hipótesis: las aplicaciones</a>
<ul>
<li class="chapter" data-level="12.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html"><i class="fa fa-check"></i><b>12.1</b> Muestras independientes</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-de-diferencia-de-medias"><i class="fa fa-check"></i><b>12.1.1</b> Prueba de diferencia de medias</a></li>
<li class="chapter" data-level="12.1.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#muestras-apareadas"><i class="fa fa-check"></i><b>12.1.2</b> Muestras apareadas</a></li>
<li class="chapter" data-level="12.1.3" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#coeficiente-r-de-pearson"><i class="fa fa-check"></i><b>12.1.3</b> Coeficiente r de Pearson</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#hacerlo-en-r-10"><i class="fa fa-check"></i><b>12.2</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-1."><i class="fa fa-check"></i><b>12.2.1</b> Ejemplo 1.</a></li>
<li class="chapter" data-level="12.2.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-2."><i class="fa fa-check"></i><b>12.2.2</b> Ejemplo 2.</a></li>
<li class="chapter" data-level="12.2.3" data-path="10-capitulo9.html"><a href="#aplicaci%C3%B3n-a-los-datos-de-poblaci%C3%B3n-adulta-mayor"><i class="fa fa-check"></i><b>12.2.3</b> Aplicación a los datos de Población Adulta Mayor</a></li>
<li class="chapter" data-level="12.2.4" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-apareada"><i class="fa fa-check"></i><b>12.2.4</b> Prueba apareada</a></li>
<li class="chapter" data-level="12.2.5" data-path="10-capitulo9.html"><a href="#coeficiente-de-correlaci%C3%B3n"><i class="fa fa-check"></i><b>12.2.5</b> Coeficiente de correlación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html"><i class="fa fa-check"></i><b>13</b> Cuando los supuestos no se cumplen</a>
<ul>
<li class="chapter" data-level="13.0.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#las-pruebas-ji-cuadrado-o-chi-cuadrado"><i class="fa fa-check"></i><b>13.0.1</b> Las pruebas ji cuadrado (o chi cuadrado)</a></li>
<li class="chapter" data-level="13.0.2" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#coeficiente-r_s-de-spearman"><i class="fa fa-check"></i><b>13.0.2</b> Coeficiente <span class="math inline">\(r_s\)</span> de Spearman</a></li>
<li class="chapter" data-level="13.0.3" data-path="10-capitulo9.html"><a href="#alternativas-no-param%C3%A9tricas-a-las-pruebas-t"><i class="fa fa-check"></i><b>13.0.3</b> Alternativas no paramétricas a las pruebas t</a></li>
<li class="chapter" data-level="13.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#hacerlo-en-r-11"><i class="fa fa-check"></i><b>13.1</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#ejemplo-1"><i class="fa fa-check"></i><b>13.1.1</b> Ejemplo 1</a></li>
<li class="chapter" data-level="13.1.2" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#ejemplo-2"><i class="fa fa-check"></i><b>13.1.2</b> Ejemplo 2</a></li>
<li class="chapter" data-level="13.1.3" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#prueba-de-la-mediana-1"><i class="fa fa-check"></i><b>13.1.3</b> Prueba de la mediana</a></li>
<li class="chapter" data-level="13.1.4" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#prueba-de-wilcoxon"><i class="fa fa-check"></i><b>13.1.4</b> Prueba de Wilcoxon</a></li>
<li class="chapter" data-level="13.1.5" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#muestras-apareadas-1"><i class="fa fa-check"></i><b>13.1.5</b> Muestras apareadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="10-capitulo9.html"><a href="#tama%C3%B1o-del-efecto"><i class="fa fa-check"></i><b>14</b> Tamaño del efecto</a>
<ul>
<li class="chapter" data-level="14.1" data-path="10-capitulo9.html"><a href="#significaci%C3%B3n-estad%C3%ADstica-y-significaci%C3%B3n-pr%C3%A1ctica"><i class="fa fa-check"></i><b>14.1</b> Significación estadística y significación práctica</a></li>
<li class="chapter" data-level="14.2" data-path="10-capitulo9.html"><a href="#medidas-de-tama%C3%B1o-del-efecto"><i class="fa fa-check"></i><b>14.2</b> Medidas de tamaño del efecto</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html"><i class="fa fa-check"></i><b>14.2.1</b> Prueba t para diferencia de medias</a></li>
<li class="chapter" data-level="14.2.2" data-path="10-capitulo9.html"><a href="#an%C3%A1lisis-de-la-varianza"><i class="fa fa-check"></i><b>14.2.2</b> Análisis de la varianza</a></li>
<li class="chapter" data-level="14.2.3" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#correlaciones"><i class="fa fa-check"></i><b>14.2.3</b> Correlaciones</a></li>
<li class="chapter" data-level="14.2.4" data-path="10-capitulo9.html"><a href="#regresi%C3%B3n-lineal"><i class="fa fa-check"></i><b>14.2.4</b> Regresión lineal</a></li>
<li class="chapter" data-level="14.2.5" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#pruebas-ji-cuadrado"><i class="fa fa-check"></i><b>14.2.5</b> Pruebas ji cuadrado</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="10-capitulo9.html"><a href="#an%C3%A1lisis-de-la-potencia"><i class="fa fa-check"></i><b>14.3</b> Análisis de la potencia</a></li>
<li class="chapter" data-level="14.4" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#hacerlo-en-r-12"><i class="fa fa-check"></i><b>14.4</b> Hacerlo en R</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Generado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="distribuciones-en-el-muestreo" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Capítulo 9</span> Distribuciones en el muestreo<a href="distribuciones-en-el-muestreo.html#distribuciones-en-el-muestreo" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En este capítulo se ligan los conceptos de muestreo y de probabilidad
para establecer las bases de los procedimientos de inferencia
estadística. La parte III tratará con datos que provienen de muestras
probabilísticas, es decir, unidades de análisis que habrán sido
seleccionadas usando alguno de los procedimientos de muestreo
probabilístico. En consecuencia, las medidas que se calculen a partir de esos datos dependerán del azar<a href="#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a>.</p>
<div id="variabilidad-muestral" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Variabilidad muestral<a href="distribuciones-en-el-muestreo.html#variabilidad-muestral" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El concepto que desarrollamos en este capítulo es el de <em>variabilidad muestral</em>. La idea central es que cuando se extraen muestras aleatorias de una población, los resultados que se obtienen en esas muestras, son aleatorios. Dos ejemplos de ello:<br />
- Según el <span class="citation">Estadísticas Universitarias (<a href="#ref-anuariounc2014">2015</a>)</span>, el conjunto completo de estudiantes de Psicología en 2014 tenía una edad promedio de 26.8 años. Si ese año se hubiese extraído una muestra aleatoria de tamaño 20, la edad promedio podría haber sido un número muy diferente de 26.8 años. Una posible muestra es la que tiene a 20 estudiantes muy jóvenes, por lo que la edad promedio de esa muestra va a ser menos de 26.8. Otra muestra podría tener estudiantes de más edad, por lo que promedio de esa muestra sería superior al de la población completa.<br />
- En las elecciones a gobernador de 2019 en la provincia de Córdoba, el partido que ganó, obtuvo 57% de los votos. Si se selecciona aleatoriamente una muestra de 50 personas que hayan votado ese año, el porcentaje de quienes optaron por ese partido pordría ser diferente a 57%. Alguna muestra podría dar cero, es decir no contener a ningún votante de ese partido; y otra dar 100%, que todos lo hayan votado.</p>
<p>Recordemos que los casos que “cayeron” en la muestra provienen de un proceso de selección aleatoria, no podemos asegurar que la variable que estamos estudiando se asemeje en la muestra al valor que tiene en la población. Por eso, el resultado que obtengamos en la muestra depende del azar: se trata de una variable aleatoria. Tanto la media muestral, en el ejemplo de las edades de estudiantes, como la proporción muestral, en el ejemplo de las elecciones, son medidas calculadas sobre los valores obtenidos en muestras aleatorias, son variables aleatorias, sus valores dependen de cuáles sean los casos que constituyen la muestra y esto depende del azar, que es lo que hemos pedido como requisito al procedimiento de muestreo.</p>
<p>Estamos entonces refiriéndonos a entidades diferentes cuando hablamos de la media poblacional y la media muestral, o cuando se distingue a la proporción muestral o poblacional. Aunque el procedimiento de cálculo sea el mismo, el valor poblacional es un valor que puede ser conocido, si hemos observado a toda la población por medio de un censo o si ya han sucedido las elecciones, o bien desconocido. Cuando hacemos estimaciones no sabemos cuánto vale la media o la proporción poblacionales, pero sí sabemos que es un número estable, fijo<a href="#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a>.
Por el contrario, la media y la proporción muestrales - porque dependen de los casos que hayan sido aleatoriamente seleccionados para constituir la muestra- dependen finalmente del azar, por eso son variables aleatorias.</p>
<p>Las medidas que se refieren a la población se denominan <strong>parámetros</strong>
también llamados <strong>parámetros poblacionales</strong>, para acentuar que se
trata de la población. Por ejemplo, el valor de 26,8 años que
mencionamos más arriba es la media paramétrica o también media
poblacional, porque fue calculada sobre el conjunto completo de estudiantes de Psicología (publicado en el anuario de la UNC). El 57% de votos que obtuvo el partido ganador en Córdoba es la proporción paramétrica, porque proviene del recuento de todos los votos emitidos.
Además de la media y la proporción, en los capítulos siguientes es harán estimaciones de la varianza, la desviación estándar, y de coeficientes de correlación (Pearson, Spearman). Todas las medidas que hemos mencionado hasta aquí pueden calcularse sobre la población completa si se hace un relevamiento completo (censo, elecciones), o bien sobre una muestra que debe ser aleatoria si se quiere luego hacer inferencias. En todos los casos que se trate de medidas que se refieran a la población completa, las llamaremos paramétricas. Solo podrían ser conocidas en aquellos casos en que la población íntegra fuera observada, es decir, si se hiciera un relevamiento exhaustivo; allí no hay inferencia.</p>
<p>Por eso, lo que interesa en estadística inferencial son las situaciones en que no conocemos los parámetros de una población, porque entonces deberemos <strong>estimarlos</strong> desde la muestra. Diremos que buscamos estimar diferentes parámetros. Ese es el tema que tratará el próximo capítulo: “Estimación de Parámetros”. También puede suceder que haya algún valor hipotético para un parámetro, al que necesitemos poner a prueba. En ese caso usaremos los datos de la muestra para <strong>probar una hipótesis</strong>, de eso trata un amplio campo que trataremos más adelante llamado “Pruebas de Hipótesis”.</p>
<p>Las medidas calculadas sobre los datos de la muestra se denominan
<strong>estadísticos</strong> también llamadas <strong>estadísticos muestrales</strong>,
nuevamente para acentuar de dónde provienen. Hablaremos entonces de la
media muestral, la proporción, la varianza o el coeficiente de
correlación muestral. Los valores que de ellos obtengamos en la muestra
permitirán estimar los correspondientes valores paramétricos. Por eso
decimos que la media muestral es el estimador de la media poblacional y
del mismo modo con la proporción, la varianza, la desviación estándar o
los coeficientes de correlación. La media muestral es el promedio de la
variable (cuantitativa) que se observa en la muestra de <span class="math inline">\(n\)</span> casos
seleccionados. Para calcular la proporción, se debe contar con una
variable categórica (o categorizada) y seleccionar las categorías de
interés, los que hemos llamado éxitos en la distribución binomial. Si se trata de varones y mujeres, puede elegirse la proporción de mujeres, si se hizo una encuesta de valores, puede estimarse la proporción de personas con ideología autoritaria, o con inclinaciones progresistas, o de religión católica,etc.
La proporción es como sabemos, el cociente entre los casos que resultan
en la categoría de interés y la cantidad total de casos, o sea, su frecuencia relativa.</p>
<p>Para distinguir entre las medidas calculadas sobre toda la población y
las de la muestra usaremos diferentes símbolos. De manera general, las
letras latinas se usarán para identificar medidas descriptivas obtenidas
sobre datos muestrales, mientras que usaremos letras griegas para
referirnos a los valores de la población. Pero esto no es siempre así,
por razones de tradición en el uso, en el caso de la proporción se
distingue la poblacional de la muestral usando P (mayúscula) para la
primera y p (minúscula) para la segunda<a href="#fn54" class="footnote-ref" id="fnref54"><sup>54</sup></a>. La siguiente es la
notación que usamos y la correspondencia entre valores poblacionales y
muestrales.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
En la población
</th>
<th style="text-align:center;">
En la muestra
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Cantidad de casos
</td>
<td style="text-align:center;">
<span class="math inline">\(N\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Media
</td>
<td style="text-align:center;">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\overline{x}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(mu)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Proporción
</td>
<td style="text-align:center;">
<span class="math inline">\(P\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Varianza
</td>
<td style="text-align:center;">
<span class="math inline">\(\sigma^{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(s^2\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(sigma cuadrado)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Desviación Standard
</td>
<td style="text-align:center;">
<span class="math inline">\(\sigma\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(s\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(sigma)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Diferencia de medias
</td>
<td style="text-align:center;">
<span class="math inline">\(\mu_{1} - \mu_{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\({\overline{x}}_{1} - {\overline{x}}_{2}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Diferencia de proporciones
</td>
<td style="text-align:center;">
<span class="math inline">\(P_{1} - P_{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\({\widehat{p}}_{1} - {\widehat{p}}_{2}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Cociente de varianzas
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{s_{1}^{2}}{s_{2}^{2}}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Coeficiente de correlación de Pearson
</td>
<td style="text-align:center;">
<span class="math inline">\(\rho\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(r\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(rho)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Coeficiente de correlación de Spearman
</td>
<td style="text-align:center;">
<span class="math inline">\(\rho_{s}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(r_s\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(rho ese)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Pendiente de la recta de regresión
</td>
<td style="text-align:center;">
<span class="math inline">\(\beta_{1}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(b_1\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(beta uno)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Ordenada al origen de la recta de regresión
</td>
<td style="text-align:center;">
<span class="math inline">\(\beta_{0}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(b_0\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(beta cero)
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>Las operaciones que se realizan para calcular los estadísticos que hemos
tratado hasta aquí son las mismas que para los parámetros, solo difieren
los nombres de cada elemento. Así, para calcular µ debemos hacer como
con <span class="math inline">\(\overline{x}\)</span>; sumar todos los valores y dividir por el total de
casos, pero en lugar de:</p>
<p><span class="math display">\[\overline{x} = \frac{\sum_{i = 1}^{n}{x_{i}*f_{i}}}{n}\]</span></p>
<p>Escribiremos:</p>
<p><span class="math display">\[\mu = \frac{\sum_{i = 1}^{N}{x_{i}*f_{i}}}{N}\]</span></p>
<p>Que solo difiere en el nombre de la media y la cantidad de casos.</p>
<p>Para la proporción, llamamos <span class="math inline">\(x\)</span> a la cantidad de casos que se
encuentran en la categoría de interés (la cantidad de éxitos):</p>
<p><span class="math display">\[\widehat{p} = \frac{x}{n}\]</span></p>
<p>Mientras que en la población, si <span class="math inline">\(X\)</span> es la cantidad de éxitos:</p>
<p><span class="math display">\[P = \frac{X}{N}\]</span></p>
<p>Una excepción a esto es la varianza, porque el modo de
calcularla es levemente distinto si se trabaja con datos muestrales o
poblacionales. Cuando es calculada sobre los elementos de la muestra, recordemos que la varianza muestral es:</p>
<p><span class="math display">\[s^{2} = \frac{\sum_{i = 1}^{n}{{(x}_{i} - \overline{x})}^{2}}{n - 1}\]</span></p>
<p>Pero cuando la varianza se calcula sobre los elementos de la población,
su cálculo se realiza con la expresión:</p>
<p><span class="math display">\[\sigma^{2} = \frac{\sum_{i = 1}^{N}{{(x}_{i} - \mu)}^{2}}{N}\]</span></p>
<p>En esta última expresión cambiaron los nombres de los elementos con los
que se opera (<span class="math inline">\(\mu\)</span> en lugar de <span class="math inline">\(\overline{x}\)</span>, <span class="math inline">\(N\)</span> en lugar de <span class="math inline">\(n\)</span>), y
además se ha eliminado el <span class="math inline">\(-1\)</span> del denominador. Ya no es el total de casos menos uno, sino el total de casos. El origen de esto es que esta última expresión (con denominador <span class="math inline">\(N\)</span>) es la definición original de la varianza, mientras que la que usada en la muestra (<span class="math inline">\(s^2\)</span> con denominador <span class="math inline">\(n-1\)</span>) es una corrección, que se hace para que sea un buen estimador de la varianza poblacional.<a href="#fn55" class="footnote-ref" id="fnref55"><sup>55</sup></a></p>
<p>Así, la característica poblacional que pretende conocerse se llama
<strong>parámetro</strong> y a través del proceso de muestreo se seleccionan algunas
unidades del universo que actuarán como representantes de la población
completa. Esta muestra será toda la información disponible para realizar
estimaciones acerca de los parámetros poblacionales. Los valores
calculados sobre los datos muestrales son los que se utilizarán para
realizar aproximaciones a los valores poblacionales; tales valores son
denominados <strong>estimadores puntuales</strong>, o simplemente <strong>estimadores.</strong></p>
<p>De una población se pueden obtener un número muy grande de muestras,
dependiendo de su tamaño y del universo de donde se extraen, pero en un
proceso de muestreo se toma una sola muestra de todas las posibles. Dado
que las muestras se extraen al azar, cada una de ellas proveerá de una
estimación diferente del parámetro. Para un parámetro elegido, habrá
tantos valores estimados como muestras puedan extraerse de la población
(con algunos resultados repetidos). Esta variación (casi) impredecible
de los estimadores, hace que se comporten como variables aleatorias.</p>
<p>Es posible (aunque esperamos que sea poco probable) que el estimador se
aleje notablemente del valor poblacional al que se pretende estimar.
Así, si se busca estimar la edad promedio de estudiantes de cierta
carrera universitaria y no se cuenta con un registro de ellos, puede
usarse una estimación a partir de una muestra. El promedio calculado sobre esos datos se tomará como
estimación de la edad del conjunto completo; pero puede ocurrir que
la muestra contenga, por azar, al grupo de mayor edad de toda la
población, con lo cual el resultado así obtenido será una
sobreestimación del verdadero valor poblacional. En un sondeo de opinión preelectoral, suponiendo que la verdadera proporción de personas que votaría a un partido es 45%, puede suceder que, de las muchas muestras, alguna de ellas se aleje tanto del 45% como que en ella, la intención de voto llegue a 65%. Por tratarse de una muestra, es un resultado posible, pero veremos que es poco probable. Debe destacarse que estos hechos (que los valores muestrales se alejen mucho de los poblacionales) resultan completamente inadvertidos para el investigador. Con respecto a la ocurrencia de estos eventos que conducen a resultados engañosos, sólo será posible -bajo ciertas condiciones-, calcular sus probabilidades.</p>
<div id="dos-aspectos-importantes-para-recordar-cuando-se-usan-muestras" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Dos aspectos importantes para recordar cuando se usan muestras:<a href="distribuciones-en-el-muestreo.html#dos-aspectos-importantes-para-recordar-cuando-se-usan-muestras" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>La variabilidad de las muestras: las muestras difieren entre sí. Varias muestras extraídas de la misma población dan resultados diferentes.</p></li>
<li><p>La representatividad de la muestra: No indica la similitud entre la
muestra y la población, sino su obtención por un procedimiento adecuado
que permita estimar valores de la población a partir de lo que se halle
en la muestra.</p></li>
</ul>
</div>
</div>
<div id="características-de-los-estimadores" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Características de los estimadores<a href="#caracter%C3%ADsticas-de-los-estimadores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Se describen tres propiedades de los estimadores, que se requieren para poder hacer inerencias de buena calidad: insesganilidad, consistencia y eficiencia.</p>
<div id="insesgabilidad" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Insesgabilidad<a href="distribuciones-en-el-muestreo.html#insesgabilidad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si fuera posible extraer todas las muestras de una población, se
contaría con todos los estimadores de un parámetro dado. Cuando el
promedio de todos los valores obtenidos en todas las muestras de un
determinado tamaño para cierto parámetro es igual al valor de esa
característica en la población, se dice que el estimador muestral es
<strong>insesgado</strong>. Se denomina sesgo de un estimador a la diferencia entre
el promedio que alcanzaría sobre todas las muestras posibles y el
verdadero valor del parámetro poblacional. En el caso de un estimador
insesgado esta diferencia es igual a cero (sin sesgo).</p>
</div>
<div id="consistencia" class="section level3 hasAnchor" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Consistencia<a href="distribuciones-en-el-muestreo.html#consistencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Intuitivamente puede pensarse que el aumento en el tamaño de la muestra
(número de elementos que la componen) mejora la calidad de la
estimación. Esta característica, que se cumple para algunos estimadores,
es denominada <strong>consistencia</strong>. Un aumento en el tamaño de la muestra no
garantiza que se obtendrán resultados más próximos a los valores
poblacionales: por grande que sea la muestra no resulta imposible que a
ella pertenezcan los valores más extremos de la población.<br />
Veamos esto
con un ejemplo. Supongamos que se quiere estimar la calificación
promedio con que se termina una carrera dada y que se toma
una muestra de 30 personas que han egresado. Puede ocurrir que la muestra (por azar)
contenga a los treinta mejores promedios de la carrera, con lo que se
obtendría una sobreestimación del verdadero promedio de toda la
población. El concepto de consistencia expresa que si la muestra, en
lugar de 30 elementos, contiene 100, la probabilidad de obtener una
sobreestimación igualmente extrema es menor. Intuitivamente podemos ver
que resulta más factible encontrar a los 30 mejores que a los 100
mejores.</p>
<p>No debe entenderse que el estimador alcance valores más próximos a los
paramétricos a medida que la muestra aumenta de tamaño, sino que
disminuye la probabilidad de obtener resultados muy lejos de los
paramétricos a medida que la muestra crece. Esta idea parece un poco
abstracta ahora, se aclarará cuando la usemos en casos aplicados.</p>
</div>
<div id="eficiencia" class="section level3 hasAnchor" number="9.2.3">
<h3><span class="header-section-number">9.2.3</span> Eficiencia<a href="distribuciones-en-el-muestreo.html#eficiencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Esta es una característica relativa, es decir que sirve para comparar
estimadores. La eficiencia será mayor cuanto más pequeña sea la varianza
del estimador. Por ejemplo, la media es un estimador más eficiente que
la mediana porque, extraídas en todas las muestras posibles de un tamaño
dado, la varianza de las medias es menor que la de las medianas.</p>
</div>
</div>
<div id="distribuciones-de-probabilidad-de-los-estimadores" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Distribuciones de probabilidad de los estimadores<a href="distribuciones-en-el-muestreo.html#distribuciones-de-probabilidad-de-los-estimadores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una vez acordados los elementos con los que trabajaremos en este
capítulo, debemos volver sobre el problema del carácter aleatorio de los
estimadores (los estadísticos muestrales). Como variables aleatorias que
son, tienen distribuciones de probabilidad asociadas y eso es lo que
permite calcular la probabilidad de ocurrencia de sus diferentes
valores. Conocer las distribuciones de probabilidad de los estadísticos
muestrales sirve para ponerlos en relación con los parámetros a los que
estiman: se usarán las distribuciones de probabilidad ya mencionadas
para relacionar los estimadores (conocidos) con los parámetros
(desconocidos). A fin de presentar el tema, haremos “como si” se
conocieran los valores poblacionales, y veremos qué sucede con los
estimadores.</p>
<div id="primera-aproximación" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Primera aproximación<a href="#primera-aproximaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El problema de las distribuciones muestrales se presenta aquí a través
de un ejemplo que trata sobre una muy pequeña población ficticia.
Supongamos que sea la población de tres pacientes de un hospital
psiquiátrico del que son su única población en internación<a href="#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a>. Llamaremos A, B
y C a quienes componen esta población y consideraremos dos variables: el <em>tiempo que llevan desde su ingreso</em> (expresado en meses) y el <em>sexo</em>. La
primera variable es cuantitativa, la segunda cualitativa. La siguiente
es la matriz de datos para esta población ficticia y las variables
indicadas.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Caso
</th>
<th style="text-align:center;">
Paciente
</th>
<th style="text-align:center;">
Meses desde el ingreso
</th>
<th style="text-align:center;">
Sexo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
Varón
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
Mujer
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
C
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
Varón
</td>
</tr>
</tbody>
</table>
<p>Para describir esta población mostramos su (elemental) distribución de
frecuencia e indicaremos la media y la varianza de la variable
cuantitativa (meses desde el ingreso):</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(x\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
Total (<span class="math inline">\(N\)</span>)
</td>
<td style="text-align:center;">
3
</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\mu = \frac{3 + 4 + 5}{3} = 4\]</span></p>
<p><span class="math display">\[\sigma^{2} = \frac{3 - 4^{2} + 4 - 4^{2} + 5 - 4^{2}}{3} = \frac{2}{3} = 0.67\]</span></p>
<p>Además, calcularemos -también sobre datos de la población completa- la
proporción de mujeres<a href="#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a>, codificando como <span class="math inline">\(1\)</span> la presencia de un
“éxito” y <span class="math inline">\(0\)</span> su ausencia:</p>
<p><span class="math display">\[P = \frac{0 + 1 + 0}{3} = \frac{1}{3} = 0.33\]</span></p>
<p>Estos valores (<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^{2}\)</span> y <span class="math inline">\(P\)</span>)$ son los que llamamos parámetros y caracterizan a las dos variables para la población completa.</p>
<p>Ahora veremos qué sucede cuando se muestrea. Para ello vamos a sacar
todas las muestras posibles de tamaño dos (podrían haber sido de otro
tamaño, lo elegimos para este ejemplo), y las muestras que extraigamos
serán con reposición<a href="#fn58" class="footnote-ref" id="fnref58"><sup>58</sup></a>. Así resultan las siguientes nueve muestras posibles: <span class="math inline">\(AA\)</span>, <span class="math inline">\(AB\)</span>, <span class="math inline">\(AC\)</span>, <span class="math inline">\(BA\)</span>, <span class="math inline">\(BC\)</span>, <span class="math inline">\(BB\)</span>, <span class="math inline">\(CA\)</span>, <span class="math inline">\(CB\)</span>, <span class="math inline">\(CC\)</span>. Como todas tienen la misma oportunidad, cada una tiene probabilidad <span class="math inline">\(1/9\)</span> de ser seleccionada aleatoriamente.</p>
<p>En cada una de las muestras calcularemos la media del tiempo de
internación (<span class="math inline">\(\overline{x}\)</span>) y la proporción de mujeres (<span class="math inline">\(\widehat{p})\)</span>.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Muestra
</th>
<th style="text-align:center;">
Meses de internación
</th>
<th style="text-align:center;">
<span class="math inline">\(\overline{x}\)</span>
</th>
<th style="text-align:center;">
Cantidad de mujeres
</th>
<th style="text-align:center;">
<span class="math inline">\(\widehat{p}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
AA
</td>
<td style="text-align:center;">
3-3
</td>
<td style="text-align:center;">
3.0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0,0
</td>
</tr>
<tr>
<td style="text-align:center;">
AB
</td>
<td style="text-align:center;">
3-4
</td>
<td style="text-align:center;">
3.5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
<tr>
<td style="text-align:center;">
AC
</td>
<td style="text-align:center;">
3-5
</td>
<td style="text-align:center;">
4.0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0.0
</td>
</tr>
<tr>
<td style="text-align:center;">
BA
</td>
<td style="text-align:center;">
4-3
</td>
<td style="text-align:center;">
3.5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
<tr>
<td style="text-align:center;">
BB
</td>
<td style="text-align:center;">
4-4
</td>
<td style="text-align:center;">
4.0
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
1.0
</td>
</tr>
<tr>
<td style="text-align:center;">
BC
</td>
<td style="text-align:center;">
4-5
</td>
<td style="text-align:center;">
4.5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
<tr>
<td style="text-align:center;">
CA
</td>
<td style="text-align:center;">
5-3
</td>
<td style="text-align:center;">
4.0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0.0
</td>
</tr>
<tr>
<td style="text-align:center;">
CB
</td>
<td style="text-align:center;">
5-4
</td>
<td style="text-align:center;">
4.5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
<tr>
<td style="text-align:center;">
CC
</td>
<td style="text-align:center;">
5-5
</td>
<td style="text-align:center;">
5.0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0.0
</td>
</tr>
</tbody>
</table>
<p>Antes de analizar estos resultados, los organizaremos mejor, presentando las distribuciones de frecuencia de las <span class="math inline">\(\overline{x}\)</span> y de las <span class="math inline">\(\widehat{p}\)</span>:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(\overline{x}\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f&#39;\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\widehat{p}\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f&#39;\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
3,0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0.11
</td>
<td style="text-align:center;">
0,0
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
0.44
</td>
</tr>
<tr>
<td style="text-align:center;">
3,5
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0.22
</td>
<td style="text-align:center;">
0,5
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
0.44
</td>
</tr>
<tr>
<td style="text-align:center;">
4,0
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
0.33
</td>
<td style="text-align:center;">
1,0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0.11
</td>
</tr>
<tr>
<td style="text-align:center;">
4,5
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0.22
</td>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
1.00
</td>
</tr>
<tr>
<td style="text-align:center;">
5,0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0.11
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
1.00
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
</div>
<div id="distribución-de-la-media-muestral" class="section level3 hasAnchor" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Distribución de la media muestral<a href="#distribuci%C3%B3n-de-la-media-muestral" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vamos a concentrarnos inicialmente en la distribución de <span class="math inline">\(\overline{x}\)</span>.
Lo primero que se observa en la tabla de distribución de frecuencias de
<span class="math inline">\(\overline{x}\)</span> es lo que significa que <span class="math inline">\(\overline{x}\)</span> sea una variable:
quiere decir que las diferentes muestras ofrecen valores diferentes de
<span class="math inline">\(\overline{x}\)</span>; o bien, que el valor de <span class="math inline">\(\overline{x}\)</span> varía dependiendo
de cuál haya sido la muestra que se seleccionó al azar. En segundo
lugar, estos valores no se refieren a casos individuales sino a
promedios obtenidos en muestras de tamaño dos.</p>
<p>Si se usan las frecuencias relativas como aproximaciones a la
probabilidad, leemos en la tabla que la probabilidad de obtener una
muestra en la que el promedio sea de tres meses de internación es de
0.11. Expresamos estos simbólicamente así:</p>
<p><span class="math display">\[P(\overline{x} = 3 )= 0.11\]</span></p>
<p>Comparando las probabilidades de los diferentes valores de
<span class="math inline">\(\overline{x}\)</span>, se puede ver que resulta más probable hallar una media
de <span class="math inline">\(4\)</span> que de <span class="math inline">\(3.5\)</span> ó de <span class="math inline">\(3\)</span>; porque <span class="math inline">\(P(\overline{x} = 4 )= 0.33\)</span>
mientras que <span class="math inline">\(P(\overline{x} = 3) = 0.11\)</span>. Se trata de un resultado
importante, porque la media de la población es <span class="math inline">\(4\)</span>, por lo que vemos que es más probable encontrar una media muestral cerca de la media
poblacional que lejos de ella.</p>
<p>La representación gráfica de la distribución que es la figura <a href="distribuciones-en-el-muestreo.html#fig:distrXBarra">9.1</a> también nos aporta
información sobre la relación entre <span class="math inline">\(\overline{x}\)</span> y <span class="math inline">\(\mu\)</span>.</p>
<div class="figure"><span style="display:block;" id="fig:distrXBarra"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/distrXBarra-1.svg" alt="Distribución de probabilidades de $\overline{x}$" width="672" />
<p class="caption">
Figura 9.1: Distribución de probabilidades de <span class="math inline">\(\overline{x}\)</span>
</p>
</div>
<p>Se observa que <span class="math inline">\(\overline{x}\)</span> asume valores cuya distribución es
simétrica alrededor de <span class="math inline">\(4\)</span>, que es la media poblacional (<span class="math inline">\(\mu\)</span>). Resulta interesante comparar esta distribución con la que tiene la variable original, el número de meses de internación de cada paciente, <span class="math inline">\(x\)</span> en la figura <a href="distribuciones-en-el-muestreo.html#fig:distrX">9.2</a>:</p>
<div class="figure"><span style="display:block;" id="fig:distrX"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/distrX-1.svg" alt="Distribución de probabilidades de $x$" width="672" />
<p class="caption">
Figura 9.2: Distribución de probabilidades de <span class="math inline">\(x\)</span>
</p>
</div>
<p>Observemos primero el nombre de los ejes:<br />
- el gráfico <a href="distribuciones-en-el-muestreo.html#fig:distrX">9.2</a>, representa los valores de <span class="math inline">\(x\)</span>: los tiempos de internación de cada paciente individualmente. Son tres casos, cada uno es un paciente. Esos son los valores que se ubican en el eje horizontal, las probabilidades del eje vertical son <span class="math inline">\(P(x)\)</span>.<br />
- el gráfico <a href="distribuciones-en-el-muestreo.html#fig:distrXBarra">9.1</a> muestra la
distribución de las <span class="math inline">\(\overline{x}\)</span>: el promedio de los tiempos de
internación de muestras de dos pacientes. Son nueve casos, cada uno es
una muestra de tamaño <span class="math inline">\(2\)</span>. Sus valores están en el eje horizontal y sus
probabilidades se indican como <span class="math inline">\(P(\overline{x})\)</span> en el eje vertical.</p>
<p>Luego la forma:<br />
- la del gráfico <a href="distribuciones-en-el-muestreo.html#fig:distrX">9.2</a> es la distribución en la población, en este caso es uniforme, pero podría tener cualquier otra forma.<br />
- Por el contrario, la del gráfico <a href="distribuciones-en-el-muestreo.html#fig:distrXBarra">9.1</a> es la distribución de las medias muestrales; es simétrica
y va a tender a tener esta forma a medida que las muestras sean de mayor tamaño, independientemente de cuál sea la distribución que la variable tenga en la población. Luego volveremos sobre esta importante
observación.</p>
<p>Vamos ahora a describir esta nueva variable <span class="math inline">\(\overline{x}\)</span>, a través de
su esperanza y su varianza. Calculemos primero la esperanza de <span class="math inline">\(\overline{x}\)</span>, aunque, por la forma de la distribución, puede anticiparse:</p>
<p><span class="math display">\[E(\overline{x}) = 3*0.11 + 3.5*0.22 + 4*0.33 + 4.5*0.22 + 5*0.11 = 4\]</span></p>
<p>Se verifica que el valor esperado para las medias muestrales coincide
con la media de la población. Este es el primer resultado que nos
interesa retener de la relación entre <span class="math inline">\(\overline{x}\)</span> y <span class="math inline">\(\mu\)</span>; la expresamos como:</p>
<p><span class="math display">\[E(\overline{x}) = \mu\]</span></p>
<p>Que puede escribirse:</p>
<p><span class="math display">\[\mu_{\overline{x}} = \mu\]</span></p>
<p>Esto implica que, si de una población se extraen todas las muestras
posibles de un determinado tamaño, y en cada una de ellas se calcula la
media, el promedio de esas medias muestrales coincide con la media de la
población completa. Esta cualidad según la cual la esperanza del
estimador es igual al parámetro, como ya hemos dicho, se llama
insesgabilidad. Cuando un estimador cumple con esa condición (como
sucede con <span class="math inline">\(\overline{x}\)</span> como estimador de <span class="math inline">\(\mu\)</span>) se dice de él que es
insesgado.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">La media muestral <span class="math inline">\((\overline{x})\)</span> es un estimador <strong>insesgado</strong> de la media poblacional (<span class="math inline">\(\mu\)</span>).</td>
</tr>
</tbody>
</table>
<p>Ahora vamos a calcular la varianza de <span class="math inline">\(\overline{x}\)</span>:</p>
<p><span class="math display">\[V(\overline{x}) = 3 - 4^{2}*0.11 + 3.5 - 4^{2}*0.22 + 4 - 4^{2}*0.33 + 4.5 - 4^{2}*0.22 + 5 - 4^{2}*0.11 = 0.33\]</span>
Este valor no es el mismo que el de <span class="math inline">\(\sigma^{2}\)</span>, sino que es la mitad.
Se trata nuevamente de un resultado que podemos generalizar y que
depende del tamaño de la muestra. En el caso de este ejemplo, las
muestras son de tamaño dos y por esa razón la varianza de la media
muestral es la varianza poblacional dividida por dos. Si las muestras
fuesen de tamaño tres, la varianza habría quedado reducida a la tercera
parte. Para otro tamaño de muestra, la varianza de <span class="math inline">\(\overline{x}\)</span> será
diferente.</p>
<p>De modo general, la varianza de <span class="math inline">\(\overline{x}\)</span> se relaciona
con la varianza de <span class="math inline">\(x\)</span> <span class="math inline">\({(\sigma}^{2}\)</span>) a través de:</p>
<p><span class="math display">\[V(\overline{x}) = \frac{\sigma^{2}}{n}\]</span></p>
<p>De manera alternativa, indicamos a esta varianza como
<span class="math inline">\(\sigma_{\overline{x}}^{2}\)</span>, con lo que:</p>
<p><span class="math display">\[\sigma_{\overline{x}}^{2} = \frac{\sigma^{2}}{n}\]</span></p>
<p>Esta fórmula indica que la varianza de las <span class="math inline">\(\overline{x}\)</span> varía
inversamente con el tamaño de la muestra.</p>
<p>Este también es un resultado muy importante: nos dice que cuanto más
grande sea la muestra, tanto más pequeña será la varianza de las medias
muestrales. Recordemos que la varianza mide la dispersión de los valores
de una variable, por lo que esta varianza mide la dispersión entre los
valores de las diferentes medias muestrales. El hecho que disminuya
cuando aumenta el tamaño de la muestra significa que para muestras más
grandes, las medias muestrales tendrán menos dispersión, es decir que
menos probables los valores muy elejados. Esta propiedad se denomina
consistencia, entonces este resultado puede expresarse indicando que la
media muestral es un estimador consistente de la media poblacional,
porque su varianza se reduce a medida que aumenta el tamaño de la
muestra.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">La media muestral (<span class="math inline">\(\overline{x}\)</span>) es un estimador <strong>consistente</strong> de la media poblacional (<span class="math inline">\(\mu\)</span>).</td>
</tr>
</tbody>
</table>
<p>De la varianza surge inmediatamente la desviación estándar de
<span class="math inline">\(\overline{x}\)</span> es:</p>
<p><span class="math display">\[\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}\]</span>.</p>
<p>Es común referirse a ella como el <strong>error estándar de la media</strong>.</p>
<p>Este es el segundo resultado de importancia sobre la relación entre
<span class="math inline">\(\overline{x}\)</span> y <span class="math inline">\(\mu\)</span>.</p>
<p>En la práctica, fuera de este ejemplo simplificado, solo extraemos una
muestra y en ella calculamos la media. Lo que hemos visto hasta aquí nos
dice que la media muestral que se obtenga tiene más chances de estar
cerca de la media poblacional cuanto más grande sea la muestra que
tomemos. Esto es así porque a medida que aumenta el número de casos en
la muestra (<span class="math inline">\(n\)</span>), disminuye la varianza y en consecuencia las medias
muestrales tienen más probabilidad de estar cerca de la media
poblacional. Por eso, será más probable que la única media que se
obtiene en la muestra sea próxima al parámetro que se estima. No es
seguro que la media muestral sea cercana a la poblacional, lo que se
sabe es que es menos probable que esté lejos cuando la muestra es más
grande.</p>
<p>La tercera característica de la distribución de la media muestral se
refiere a su forma. En el gráfico <a href="distribuciones-en-el-muestreo.html#fig:distrXBarra">9.1</a> se ve que las <span class="math inline">\(\overline{x}\)</span> del
ejemplo alcanzan una distribución unimodal y simétrica, sin importar que
en la población la variable hubiese tenido una distribución uniforme.
Este resultado también es general y es más amplio aun: a medida que
aumenta el tamaño de las muestras, la distribución de las medias
muestrales tiende a ser normal. La prueba de esta afirmación constituye
el Teorema Central del Límite, cuyo enunciado puede resumirse como: una
suma de <span class="math inline">\(n\)</span> variables aleatorias tiende a tener distribución normal a
medida que aumenta <span class="math inline">\(n\)</span>, independientemente del modo en que esté
distribuida esa variable. Para nuestro uso, la media es una suma de
valores de una variable aleatoria (porque esos valores provienen de una
muestra aleatoria) dividida en el total de casos. Por eso el teorema nos dice que si se trata de muestras grandes, puede tratarse a
<span class="math inline">\(\overline{x}\)</span> como teniendo una distribución normal.</p>
<p>Anteriormente se presentó el experimento de tirar un dado dos veces,
contar la suma de los puntos obtenidos y definir la variable aleatoria
<span class="math inline">\(S\)</span> que resulta de la suma de dos variables aleatorias, porque cada
tirada del dado da lugar a un resultado entre 1 y 6 que depende del
azar. La variable que resulta de tirar una sola vez el dado tiene
distribución uniforme: todos los números tienen la misma probabilidad
<span class="math inline">\(1/6\)</span>. La suma de puntos de los dos dados, <span class="math inline">\(S\)</span>, ya no tiene distribución uniforme, porque es más probable obtener <span class="math inline">\(7\)</span> (que puede resultar de <span class="math inline">\(6+1\)</span>, <span class="math inline">\(5+2\)</span>, <span class="math inline">\(4+3\)</span>, <span class="math inline">\(3+4\)</span>, <span class="math inline">\(2+5\)</span> ó <span class="math inline">\(1+6\)</span>) que <span class="math inline">\(12\)</span> (que solo puede obtenerse con <span class="math inline">\(6+6\)</span>).</p>
<div class="figure"><span style="display:block;" id="fig:puntosdado"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/puntosdado-1.svg" alt="Distribución de probabilidades de la variable *x = puntaje obtenido al tirar un dado*" width="672" />
<p class="caption">
Figura 9.3: Distribución de probabilidades de la variable <em>x = puntaje obtenido al tirar un dado</em>
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:puntosdosdados"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/puntosdosdados-1.svg" alt="Distribución de probabilidades de *S = suma de puntajes obtenidos al tirar dos veces un dado*" width="672" />
<p class="caption">
Figura 9.4: Distribución de probabilidades de <em>S = suma de puntajes obtenidos al tirar dos veces un dado</em>
</p>
</div>
<p>Los gráficos <a href="distribuciones-en-el-muestreo.html#fig:puntosdado">9.3</a> y <a href="distribuciones-en-el-muestreo.html#fig:puntosdosdados">9.4</a> ilustran la diferencia.</p>
<p>Si bien la distribución de <span class="math inline">\(S\)</span> no es normal, se aprecia la
tendencia, “va camino a ser normal”. En este caso la muestra tiene solo
dos casos (las dos tiradas del dado); cuando son más casos, la
distribución va volviéndose más cercana a la normal.</p>
<p>Esto es lo que sucede cuando se extraen muestras de una población: la
distribución de la variable en la población puede tener cualquier
distribución (en el caso del dado es uniforme), pero a las medias
muestrales les sucede lo mismo que a <span class="math inline">\(S\)</span>, van tendiendo a tener una
distribución normal a medida que se toman muestras de mayor tamaño. Éste
es el tercer resultado que necesitamos para relacionar a la media
muestral con la poblacional y poder hacer las primeras inferencias.</p>
<div id="resumen-de-la-relación-entre-la-media-muestral-y-la-paramétrica" class="section level4 hasAnchor" number="9.3.2.1">
<h4><span class="header-section-number">9.3.2.1</span> Resumen de la relación entre la media muestral y la paramétrica:<a href="#resumen-de-la-relaci%C3%B3n-entre-la-media-muestral-y-la-param%C3%A9trica" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><span class="math inline">\(E(\overline{x})=\mu\)</span> o <span class="math inline">\(\mu_{\overline{x}}=\mu\)</span></li>
<li><span class="math inline">\(V(\overline{x})=\frac{\sigma^2}{n}\)</span></li>
<li><span class="math inline">\(\overline{x} \rightarrow N(\mu, \frac{\sigma^2}{n})\)</span></li>
</ul>
<p>La última expresión sintetiza las anteriores y agrega que la
distribución de <span class="math inline">\(\overline{x}\)</span> es normal.</p>
<p>Entonces, de lo anterior se lee que:</p>
<ul>
<li><p>La esperanza de <span class="math inline">\(\overline{x}\)</span> es la media de la población (insesgabilidad).</p></li>
<li><p>La varianza de <span class="math inline">\(\overline{x}\)</span> es la varianza de la población dividida en el tamaño de la muestra<a href="#fn59" class="footnote-ref" id="fnref59"><sup>59</sup></a> (consistencia).</p></li>
<li><p>La media muestral tiende a tener una distribución normal con media <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(\frac{\sigma^{2}}{n}\)</span>, cuando el tamaño de la muestra aumenta.</p></li>
</ul>
</div>
<div id="ejemplo-con-datos-ficticios" class="section level4 hasAnchor" number="9.3.2.2">
<h4><span class="header-section-number">9.3.2.2</span> Ejemplo con datos ficticios<a href="distribuciones-en-el-muestreo.html#ejemplo-con-datos-ficticios" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Supongamos que en la población de personas adultas la media de horas diarias de
sueño es de 6.5 hs (<span class="math inline">\(\mu = 6.5\)</span>) con varianza de 9
<span class="math inline">\(hs^{2}\)</span> (<span class="math inline">\(\sigma^{2} = 9\)</span>). Si eligiéramos al azar muestras
de 200 personas (<span class="math inline">\(n=200\)</span>) y registráramos el número promedio de horas de sueño en cada muestra, encontraríamos que la distribución de esas horas
promedio sería como la siguiente:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-428-1.svg" width="672" /></p>
<p>En el eje horizontal están graficados los valores de las posibles
<span class="math inline">\(\overline{x}\)</span> que resultarían si sacáramos muestras aleatorias de esa
población. La distribución normal está centrada en <span class="math inline">\(6.50\)</span>, que es la media de la población. El gráfico muestra con claridad que “lo más probable” es encontrar a <span class="math inline">\(\overline{x}\)</span> en los alrededores de <span class="math inline">\(6.50\)</span> y que, muestras de 200 personas que promedien valores superiores a <span class="math inline">\(7\)</span> tendrían pocas posibilidades de ser seleccionadas.</p>
<p>Con la media y la desviación estándar de esta variable <span class="math inline">\(\overline{x}\)</span>
podemos calcular un puntaje <span class="math inline">\(z\)</span>, lo que conocíamos como desvío estándar.
Para llegar a la forma que tiene ahora <span class="math inline">\(z\)</span>, recordemos que lo definimos
como el número de desviaciones estándar a las que la variable se
encuentra de la media, por eso era la diferencia entre el valor de la
variable y el de la media, dividida en la desviación estándar:</p>
<p><span class="math display">\[z = \frac{x - \overline{x}}{s}\]</span></p>
<p>La diferencia ahora es que nuestra variable es <span class="math inline">\(\overline{x}\)</span>, su media
es <span class="math inline">\(\mu\)</span> y su desviación estándar es el que hemos llamado error estándar de la media: <span class="math inline">\(\sigma_{\overline{x}}\)</span>. Con lo que el puntaje <span class="math inline">\(z\)</span> asociado a cada valor de <span class="math inline">\(\overline{x}\)</span>, tiene ahora la forma:</p>
<p><span class="math display">\[z = \frac{\overline{x} - \mu}{\sigma_{\overline{x}}}\]</span></p>
<p>Si se reemplaza el error estándar de la media por su valor, se obtiene:</p>
<p><span class="math display">\[z = \frac{\overline{x} - \mu}{\frac{\sigma}{\sqrt{n}}}\]</span></p>
<p>Si ahora nos preguntamos por la probabilidad de encontrar muestras de
200 personas cuyos promedios de horas de sueño superen las 7 horas, la
representación gráfica será:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-429-1.svg" width="672" /></p>
<p>Y el valor de esa probabilidad se calcula observando a cuántas
desviaciones estándar se encuentra de la media, es decir, calculando el
puntaje <span class="math inline">\(z\)</span> correspondiente a la media de 7 horas:</p>
<p><span class="math display">\[z = \frac{7 - 6.5}{\frac{3}{\sqrt{200}}} = \frac{0.5}{0.21} = 2.38\]</span></p>
<p>Calculamos la probabilidad de superar este valor como el complemento de la acumulada<a href="#fn60" class="footnote-ref" id="fnref60"><sup>60</sup></a>: <span class="math inline">\(1-P(z\leq 2.38)\)</span></p>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb481-1"><a href="distribuciones-en-el-muestreo.html#cb481-1" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">2.38</span>)</span></code></pre></div>
<pre><code>## [1] 0.008656319</code></pre>
<p>La lectura de este resultado es que solo el 0.9% de las muestras de tamaño 200 darán media muestral mayor a 7 horas.</p>
<p>Para ver el efecto del tamaño de la muestra repitamos el cálculo con
muestras de 30 casos<a href="#fn61" class="footnote-ref" id="fnref61"><sup>61</sup></a>, cuyo gráfico es:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-431-1.svg" width="672" />
En el que se observa la mayor varianza de las <span class="math inline">\(\overline{x}\)</span>, debido al menor tamaño de muestra.</p>
<p>El puntaje <span class="math inline">\(z\)</span> es ahora:</p>
<p><span class="math display">\[z = \frac{7 - 6.5}{\frac{3}{\sqrt{30}}} = \frac{0.5}{0.55} = 0.91\]</span>
Y la probabilidad de superarlo:</p>
<div class="sourceCode" id="cb483"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb483-1"><a href="distribuciones-en-el-muestreo.html#cb483-1" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(.<span class="dv">91</span>)</span></code></pre></div>
<pre><code>## [1] 0.1814113</code></pre>
<p>Es decir que el 18% de las muestras de tamaño 30 darán media que supere a 7 hs. Esto indica que cuando las muestras son de mayor tamaño es menor la probabilidad de encontrar valores en los extremos de la distribución.</p>
<p>Para aclarar la relación entre valores poblacionales y muestrales, supongamos que la variable <em>horas de sueño</em> tiene distribución normal en la población y calculemos la probabilidad de encontrar personas que
duerman más de 7 horas. Antes destaquemos la diferencia entre esta
pregunta y las dos anteriores: las probabilidades que calculamos antes
son las de hallar <em>muestras</em> de 200 personas o de 30 personas con
promedio superior a 7 horas de sueño, ahora preguntamos por la
probabilidad de encontrar <em>personas individuales</em> que tengan más horas de sueño que esa cifra. El puntaje <span class="math inline">\(z\)</span> es ahora:</p>
<p><span class="math display">\[z = \frac{7 - 6.5}{3} = \frac{0.5}{3} = 0.17\]</span></p>
<p>La fórmula cambia porque la pregunta no es por medias muestrales sino
por valores individuales, por eso no hay <span class="math inline">\(n\)</span><a href="#fn62" class="footnote-ref" id="fnref62"><sup>62</sup></a>. La probabilidad es
ahora:</p>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb485-1"><a href="distribuciones-en-el-muestreo.html#cb485-1" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(.<span class="dv">17</span>)</span></code></pre></div>
<pre><code>## [1] 0.4325051</code></pre>
<p><span class="math display">\[P(z &gt; 0.17) = 0.432\]</span></p>
<p>Que leemos diciendo que el 43% de los individuos duerme 7 horas o más.
Esto indica que es mucho más probable encontrar individuos que se alejen
de la media, que grupos de 30 ó de 200 individuos cuyo promedio se aleje
de la media. Cuando las muestras son de mayor tamaño, tanto más
improbable resulta encontrarlas lejos de la media, eso es lo que está
expresado cuando <span class="math inline">\(n\)</span> aparece en el denominador de la desviación
estándar: mayor <span class="math inline">\(n\)</span> implica menor dispersión, y de ello se sigue que son menos probables los casos extremos.</p>
</div>
<div id="ejemplo-con-datos-reales" class="section level4 hasAnchor" number="9.3.2.3">
<h4><span class="header-section-number">9.3.2.3</span> Ejemplo con datos reales<a href="distribuciones-en-el-muestreo.html#ejemplo-con-datos-reales" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Ahora trabajaremos sobre una base que contiene las notas de los tres
parciales de Psicoestadística en 2009. En primer lugar damos una breve
descripción de la población de las notas del tercer parcial:</p>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   1.000   4.000   6.000   5.779   7.000  10.000     265</code></pre>
<p>Estas medidas están calculadas sobre la población completa, que es el
total que estudiantes que en 2009 hizo alguno de los tres parciales, como se ve, de ese total, hubo 265 que no hicieron el tercero.
Por ser la población completa, se trata de parámetros, así:</p>
<p><span class="math display">\[\mu = 5.779\]</span></p>
<p><span class="math display">\[\sigma^{2} = 4.12\]</span></p>
<p>El histograma de las notas del tercer parcial es:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-435-1.svg" width="672" /></p>
<p>Ahora extraemos 200 muestras de 80 casos cada una y producimos una nueva matriz de datos que tiene 80 filas y 200 columnas. Cada columna corresponde a una muestra, por lo que podemos solicitar la media y la varianza en cada una. No son “todas las muestras posibles de tamaño 80”, sino solo 200 por lo que tendremos una <em>aproximación</em> a la relación entre estimadores y parámetros. Con las medias y varianzas de cada muestra, resulta una nueva matriz de datos, que contiene una media muestral y una varianza muestral para cada una de las 200 muestras calculadas, y cuyas primeras seis filas son:</p>
<pre><code>##      Media Varianza
## 1 5.523077 4.253365
## 2 5.728571 4.780331
## 3 5.692308 3.747596
## 4 5.967742 3.539926
## 5 5.344262 4.229508
## 6 5.666667 4.967742</code></pre>
<p>Cuando solicitamos un resumen de las medias muestrales obtenemos:</p>
<pre><code>##      Media          Varianza    
##  Min.   :5.083   Min.   :2.578  
##  1st Qu.:5.594   1st Qu.:3.685  
##  Median :5.759   Median :4.179  
##  Mean   :5.764   Mean   :4.136  
##  3rd Qu.:5.952   3rd Qu.:4.531  
##  Max.   :6.532   Max.   :6.554</code></pre>
<p>Este resumen se refiere a las variables que están en la matriz de datos que contiene un resultado muestral en cada fila, por eso <span class="math inline">\(n=200\)</span> es la cantidad de muestras que se extrajeron (y no el tamaño de cada muestra), ahora cada muestra
representa un caso y las variables que se consideran son la media y la
varianza de la nota de los 80 casos seleccionados en cada muestra. Se
aprecia que el campo de variación de la variable original (nota del
tercer parcial) iba de 1 a 10, mientras que la nueva variable (promedio
de notas del tercer parcial de muestras de 80 casos cada una) varía entre 5.03
y 6.54, es decir, es notablemente más restringido, tiene menos
variabilidad.</p>
<p>El valor 5.79 es la media de todas las medias muestrales y como vemos
es muy cercana a la media poblacional, como lo es la media de todas las
varianzas muestrales comparada con la varianza poblacional. estos números no son idénticos, porque no se extrajeron todas las muestras, sino solo 200, pero la aproximación en adecuada. Eso quiere decir que la media y la varianza muestrales, son estimadores insesgados de la media y la varianza poblacionales.</p>
<p>Además, puede calcularse la varianza de las medias muestrales, que da:</p>
<pre><code>## [1] 0.07254758</code></pre>
<p>La relación teórica de esta varianza con la varianza poblacional es:
<span class="math inline">\(\sigma_{\overline{x}}^{2} = \frac{\sigma^{2}}{n}\)</span>, en la que <span class="math inline">\(n\)</span>
representa el tamaño de las muestras y no la cantidad de muestras
solicitadas. Con los datos del tercer parcial es:
<span class="math inline">\(\sigma_{\overline{x}}^{2} = \frac{4.12}{80} = 0.05\)</span>. El resultado que obtuvimos con nuestro muestreo es una buena aproximación a lo que prevé la teoría.</p>
<p>El histograma de las medias muestrales es:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-439-1.svg" width="672" /></p>
<p>En el que hemos usado la misma escala de 1 a 10 para que se vea con
claridad la reducción en la dispersión de esta nueva variable.</p>
</div>
</div>
<div id="distribución-de-la-proporción-muestral" class="section level3 hasAnchor" number="9.3.3">
<h3><span class="header-section-number">9.3.3</span> Distribución de la proporción muestral<a href="#distribuci%C3%B3n-de-la-proporci%C3%B3n-muestral" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El razonamiento para llegar a la relación que hay entre el estimador
<span class="math inline">\(\widehat{p}\)</span> y el parámetro correspondiente, <span class="math inline">\(P\)</span> es completamente
análogo al de la media, por lo que no recorreremos nuevamente los mismos pasos que llevaron a establecer la relación entre <span class="math inline">\(\overline{x}\)</span> y <span class="math inline">\(\mu\)</span>.</p>
<p>En primer lugar, y como sucede en el caso de la media, <span class="math inline">\(\widehat{p}\)</span> es
un estimador insesgado de <span class="math inline">\(P\)</span>.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">La proporción muestral <span class="math inline">\(\widehat{p}\)</span> es un estimador <strong>insesgado</strong> de la proporción poblacional <span class="math inline">\(P\)</span>.</td>
</tr>
</tbody>
</table>
<p>Si extrajéramos todas las muestras posibles de una población y
calculáramos en cada una la proporción de casos en una categoría de una
variable, el promedio de todas esas proporciones muestrales, daría como
resultado la proporción de casos que hay en esa categoría en la
población. Por lo que podemos escribir que:</p>
<p><span class="math display">\[E(\widehat{p}) = P\]</span></p>
<p>O de manera equivalente:</p>
<p><span class="math display">\[\mu_{\widehat{p}} = P\]</span></p>
<p>Acerca de la dispersión que alcanzan las diferentes <span class="math inline">\(\widehat{p}\)</span> en las
muestras, hay más diferencia con la media. En efecto, cuando se trata
con variables cualitativas (nominales u ordinales) no hay distancias y
en consecuencia no se puede usar una desviación estándar. La dispersión
de una variable de este nivel se aprecia a través de la idea de
incertidumbre: habrá tanto menos dispersión cuanto mayor sea la
concentración de casos en una categoría de la variable. Así, la
distribución:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
partido al que votará
</th>
<th style="text-align:center;">
<span class="math inline">\(f\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.09
</td>
</tr>
<tr>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.74
</td>
</tr>
<tr>
<td style="text-align:center;">
C
</td>
<td style="text-align:center;">
0.11
</td>
</tr>
<tr>
<td style="text-align:center;">
D
</td>
<td style="text-align:center;">
0.06
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
1.00
</td>
</tr>
</tbody>
</table>
<p>Tiene menos dispersión que:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
partido al que votará
</th>
<th style="text-align:center;">
<span class="math inline">\(f\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.23
</td>
</tr>
<tr>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.31
</td>
</tr>
<tr>
<td style="text-align:center;">
C
</td>
<td style="text-align:center;">
0.26
</td>
</tr>
<tr>
<td style="text-align:center;">
D
</td>
<td style="text-align:center;">
0.20
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
1.00
</td>
</tr>
</tbody>
</table>
<p>Porque si tuviéramos que “adivinar” quién va a ganar las elecciones, en
el primer caso estaríamos más seguros de inclinarnos por el partido B,
que en el segundo. Aunque en ambas distribuciones el modo es el
partido B, en la primera la concentración es mayor y menor es la
incertidumbre, por lo que tenemos mayor certeza, hay menos dispersión.</p>
<p>Así es como hemos tratado antes el problema de la variabilidad en variables que no
admiten la medición de distancias, en el capítulo. Pero en este caso, se está calculando
<span class="math inline">\(\widehat{p}\)</span> como la proporción de una categoría, sin considerar cómo
se distribuyen las otras, es decir que se trabaja con variables
dicotómicas. Si se considera solo al partido A, las dos tablas
anteriores se reducen a:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
partido al que votará
</th>
<th style="text-align:center;">
<span class="math inline">\(f\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.09
</td>
</tr>
<tr>
<td style="text-align:center;">
otro partido
</td>
<td style="text-align:center;">
0.91
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
1.00
</td>
</tr>
</tbody>
</table>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
partido al que votará
</th>
<th style="text-align:center;">
<span class="math inline">\(f\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.23
</td>
</tr>
<tr>
<td style="text-align:center;">
otro partido
</td>
<td style="text-align:center;">
0.77
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
1.00
</td>
</tr>
</tbody>
</table>
<p>¿Cuál de las dos distribuciones tiene mayor dispersión? La primera tiene una mayor concentración en la categoría “otro partido” que la segunda, por lo que tiene menor dispersión. Por eso, en variables dicotómicas, la mayor diferencia entre las dos proporciones indica la mayor concentración y por ello, la menor dispersión.</p>
<p>Como vimos antes, la forma operativa de evaluar esto es multiplicando las dos frecuencias
relativas: <span class="math inline">\(0.09*0.91\)</span> en el primer caso, y <span class="math inline">\(0.23*0.77\)</span> en el segundo.
Esos productos dan <span class="math inline">\(0.08\)</span> y <span class="math inline">\(0.18\)</span> respectivamente; estos valores son
indicadores de la menor dispersión de la primera distribución.</p>
<p>La operación de multiplicar a la proporción de casos de una categoría
por la de la otra, que se escribe como <span class="math inline">\(P*(1-P)\)</span>, es la medida de la
dispersión en variables nominales, que reemplaza a la varianza de las
variables cuantitativas. Como sucedió con la media, la varianza de la
proporción muestral es la varianza dividida el tamaño de la muestra:</p>
<p><span class="math display">\[V\widehat{p} = \frac{P*(1 - P)}{n}\]</span></p>
<p>Como antes, muestras de mayor tamaño dan lugar a menor variabilidad.
También puede expresarse la varianza de <span class="math inline">\(\widehat{p}\)</span> como
<span class="math inline">\(\sigma_{\widehat{p}}^{2}\)</span>, con lo que:</p>
<p><span class="math display">\[\sigma_{\widehat{p}}^{2} = \frac{P*(1 - P)}{n}\]</span></p>
<p>La desviación estándar de <span class="math inline">\(\widehat{p}\)</span> será:</p>
<p><span class="math display">\[\sigma_{\widehat{p}} = \sqrt{\frac{P*(1 - P)}{n}}\]</span></p>
<p>Esta expresión también se conoce como <strong>error estándar de la proporción</strong>.</p>
<p>Los dos últimos resultados (la esperanza y la varianza de <span class="math inline">\(\widehat{p}\)</span>) se derivan de la distribución que rige el experimento de extraer <span class="math inline">\(n\)</span> observaciones y contar la cantidad de casos que allí aparecen: se trata de la distribución binomial. Como vimos, si <span class="math inline">\(\widehat{x}\)</span> es la cantidad de casos en la categoría de interés en la muestra, entonces:</p>
<p><span class="math display">\[\widehat{p} = \frac{\widehat{x}}{n}\]</span></p>
<p>Y, en consecuencia:</p>
<p><span class="math display">\[\widehat{x} = n*\widehat{p}\]</span></p>
<p>En el modelo binomial, la esperanza y la varianza de <span class="math inline">\(x\)</span> (cantidad de
casos en la categoría de interés) son:</p>
<p><span class="math display">\[\begin{equation}
  \label{eq:1}
    E(\widehat{x}) = n*P
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  \label{eq:2}
    V(\widehat{x}) = n*P*(1 - P)
\end{equation}\]</span></p>
<p>Remplazando <span class="math inline">\(x\)</span> por su relación con <span class="math inline">\(\widehat{p}\)</span> y usando las propiedades de la esperanza y la varianza hallamos:</p>
<p>Para la esperanza de <span class="math inline">\(\widehat{p}\)</span> en <a href="#eq:1">(<strong>??</strong>)</a>:</p>
<p><span class="math display">\[E(n*\widehat{p}) = n*P\]</span></p>
<p><span class="math display">\[n*E(\widehat{p}) = n*P\]</span></p>
<p><span class="math display">\[E(\widehat{p}) = P\]</span></p>
<p>Esta última igualdad muestra que, efectivamente <span class="math inline">\(\widehat{p}\)</span> es un
estimador insesgado de P.</p>
<p>Para la varianza de <span class="math inline">\(\widehat{p}\)</span>, reemplazamos en <a href="#eq:2">(<strong>??</strong>)</a>:</p>
<p><span class="math display">\[V(n*\widehat{p}) = n*P*(1 - P)\]</span></p>
<p><span class="math display">\[n^{2}*V(\widehat{p}) = n*P*(1 - P)\]</span></p>
<p><span class="math display">\[V\widehat{p} = \frac{P*(1 - P)}{n}\]</span></p>
<p>Y vemos que <span class="math inline">\(\widehat{p}\)</span> es un estimador consistente de P, porque a
medida que aumenta el tamaño de la muestra, disminuye su varianza.</p>
<p>Para calcular la probabilidad de diferentes valores de <span class="math inline">\(\widehat{p}\)</span>, a
partir de P y de un determinado tamaño de muestra, usamos la
distribución binomial, en la que cambiamos la variable <span class="math inline">\(\widehat{x}\)</span>
(número de casos en la categoría de interés) por <span class="math inline">\(\widehat{p}\)</span>
(proporción de casos en esa categoría). Así, volviendo al último ejemplo que se vio en la distribución binomial, si en la población de estudiantes de Biología la proporción de mujeres es de 0.70; allí se preguntó por la probabilidad que, en una muestra de 15, fueran todas mujeres o bien, que <span class="math inline">\(\widehat{x} = 15\)</span> ahora puede plantearse en términos de proporciones: ¿Cuál es la probabilidad que, en una muestra de 15 estudiantes, el 100% sean mujeres? Aquí:</p>
<p><span class="math display">\[P = 0.70\]</span></p>
<p><span class="math display">\[n = 15\]</span></p>
<p><span class="math display">\[\widehat{p} = 1\]</span></p>
<p>Usando el valor de <span class="math inline">\(\widehat{p}\)</span> y de <span class="math inline">\(n\)</span>, calculamos <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[\widehat{x} = n*\widehat{p} = 15*1 = 15\]</span></p>
<p>Esto quiere decir que pedir que la proporción muestral (<span class="math inline">\(\widehat{p}\)</span>) sea 1 (100%) equivale a pedir 15 éxitos (mujeres) en la muestra, por lo que la probabilidad es:</p>
<p><span class="math display">\[P(\widehat{p} = 1) = B( 15;15;0.70)\]</span></p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="distribuciones-en-el-muestreo.html#cb491-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">dbinom</span>(<span class="dv">15</span>, <span class="dv">15</span>, .<span class="dv">7</span>), <span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0.0047</code></pre>
<p>Es el mismo resultado obtenido antes, ahora ubicado en el contexto del
muestreo.</p>
<p>Si la pregunta fuera ¿Cuál es la probabilidad que, si en la población la proporción es 0.70; en una muestra de 15 observaciones ésta sea 0.40? Respondemos del mismo modo, primero calculamos <span class="math inline">\(\widehat{x}\)</span>:</p>
<p><span class="math display">\[\widehat{x} = n*\widehat{p} = 15*0.40 = 6\]</span></p>
<p>Ahora la probabilidad es:</p>
<p><span class="math display">\[P(\widehat{p} = 0.40) = B(6;15;0.70)\]</span></p>
<pre><code>## [1] 0.0116</code></pre>
<p>De manera general, expresada en base a <span class="math inline">\(n\)</span>, <span class="math inline">\(\widehat{p}\)</span> y <span class="math inline">\(P\)</span>, la
probabilidad es:</p>
<p><span class="math display">\[P\widehat{p} = B(n*\widehat{p};n;P)\]</span></p>
<p>Es posible, y se hace a menudo, aproximar estas probabilidades
binomiales a través de un modelo normal. El fundamento de esta
aproximación es el teorema de Laplace - De Moivre que dice que si <span class="math inline">\(x\)</span> es una variable con distribución binomial, con esperanza <span class="math inline">\(n*P\)</span> y varianza <span class="math inline">\(n*P*(1-P)\)</span>, entonces, cuando <span class="math inline">\(n\)</span> tiende a infinito, la distribución de <span class="math inline">\(x\)</span> tiende a ser normal, con la misma media (esperanza) y varianza. Por la condición “<span class="math inline">\(n\)</span> tiende a infinito”, resulta claro que esto solo es válido<a href="#fn63" class="footnote-ref" id="fnref63"><sup>63</sup></a> cuando <span class="math inline">\(n\)</span> es grande y también debe cumplirse que <span class="math inline">\(P\)</span> no está muy cerca de <span class="math inline">\(0\)</span> ó de <span class="math inline">\(1\)</span>. La condición se solicita de manera sencilla exigiendo que <span class="math inline">\(n*P\)</span> y <span class="math inline">\(n*(1-P)\)</span> sean ambas mayores o iguales a 5. Si la variable sobre la que trabajamos no es <span class="math inline">\(x\)</span> sino <span class="math inline">\(n*\widehat{p}\)</span>, entonces la esperanza y la varianza serán:</p>
<p><span class="math inline">\(E(\widehat{p}) = P\)</span> y
<span class="math inline">\(V(\widehat{p}) = \frac{P*(1 - P)}{n}\)</span>.</p>
<p>Si la condición de <span class="math inline">\(n*p\)</span> y <span class="math inline">\(n*(1-P)\)</span> mayores o iguales a 5 se cumple,
puede usarse esta aproximación y obtener un resultado análogo al de la
media, que se resume así:</p>
<ul>
<li><span class="math inline">\(\widehat{p} \rightarrow  N(P, \frac{P*(1-P)}{n})\)</span></li>
</ul>
<p>Si <span class="math inline">\(n\)</span> tiende a <span class="math inline">\(\infty\)</span> y <span class="math inline">\(n*P\)</span> y <span class="math inline">\(n*(1-P)\)</span> son mayores a <span class="math inline">\(5\)</span>.</p>
<div id="ejemplo-con-datos-ficticios-1" class="section level4 hasAnchor" number="9.3.3.1">
<h4><span class="header-section-number">9.3.3.1</span> Ejemplo con datos ficticios<a href="distribuciones-en-el-muestreo.html#ejemplo-con-datos-ficticios-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Sea que para una localidad determinada, el 20% de la población adulta consultó al centro de salud municipal durante el año pasado. Si extraemos muestras de tamaño 100 y en cada una de ellas observamos la proporción de personas que consultaron a ese centro de salud durante el año pasado, el gráfico de la distribución binomial de la cantidad de consultantes en cada muestra será:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-446-1.svg" width="672" /></p>
<p>Este gráfico tiene un trazado continuo aunque se trata de una variable
discreta. Eso se debe a que es un gran número de observaciones y la
distancia entre ellas es pequeña. Cuantas más sean las observaciones,
tanto más cercana a la continuidad será la sucesión de puntos.</p>
<p>El gráfico muestra las probabilidades asociadas a cada cantidad
<span class="math inline">\(\widehat{x}\)</span> de éxitos que pueden resultar en la muestra, y cada valor
de <span class="math inline">\(\widehat{x}\)</span> se corresponde con un valor de <span class="math inline">\(\widehat{p}\)</span> a través
de:</p>
<p><span class="math display">\[\widehat{p} = \frac{\widehat{x}}{n}\]</span></p>
<p>Por lo que el gráfico anterior puede tratarse a escala de <span class="math inline">\(\widehat{p}\)</span></p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-447-1.svg" width="672" /></p>
<p>Si nos interesamos por la probabilidad de obtener una proporción de 0.25 ó superior en la muestra, debemos transformarla a una cantidad de éxitos muestrales:</p>
<p><span class="math display">\[\widehat{x} = n*\widehat{p} = 100*0.25 = 25\]</span></p>
<p>Entonces:</p>
<p><span class="math display">\[P(\widehat{p} \geq 0.25) = P(\widehat{x} \geq 25) = B(\widehat{x} \geq 25;\ 100;0.20)\]</span></p>
<p>Al que solicitamos como complemento de la probabilidad acumulada de 24:</p>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb494-1"><a href="distribuciones-en-el-muestreo.html#cb494-1" tabindex="-1"></a><span class="fu">round</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="dv">24</span>, <span class="dv">100</span>, .<span class="dv">2</span>), <span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0.1314</code></pre>
<p><span class="math display">\[P(\widehat{x} \geq 25;100;0.20) = 0.1314\]</span></p>
<p>Interpretamos este resultado diciendo que, si en la población completa,
la proporción de personas que consultan es del 20%, la probabilidad que
en una muestra de 100 personas, hayan consultado el 25% ó más es de
0.1314. En otros términos, el 13% de las muestras de tamaño 100 que se
extraigan de esa población, mostrarán una proporción de 0.25 ó mayor.</p>
<p>Dado que el número de casos en la muestra es elevado (100) y que <span class="math inline">\(n*P\)</span>
es 20 y <span class="math inline">\(n*(1-P)\)</span> es 80, ambos mayores a 5, podemos usar la
aproximación normal. Según esa aproximación, la distribución de los
diferentes valores de <span class="math inline">\(\widehat{p}\)</span> es:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-449-1.svg" width="672" /></p>
<p>El eje horizontal de este gráfico representa todas las proporciones que
pueden encontrarse en las diferentes muestras. La distribución está
centrada en el parámetro <span class="math inline">\(P = 0.20\)</span>.</p>
<p>Resolveremos la pregunta anterior transformando el valor
<span class="math inline">\(\widehat{p} \geq 0.25\)</span> en un puntaje <span class="math inline">\(z\)</span>. Conocemos la media y la
varianza de <span class="math inline">\(\widehat{p}\)</span> por lo que haremos:</p>
<p><span class="math display">\[z = \frac{\widehat{p} - P}{\sigma_{\widehat{p}}}\]</span></p>
<p>Reemplazando por el error estándar de <span class="math inline">\(\widehat{p}\)</span>, tenemos:</p>
<p><span class="math display">\[z = \frac{\widehat{p} - P}{\sqrt{\frac{P*(1 - P)}{n}}}\]</span></p>
<p>Esta es la expresión con la que transformamos los valores de
<span class="math inline">\(\widehat{p}\)</span> a puntajes <span class="math inline">\(z\)</span>. Sin embargo es necesario hacer una
corrección debido a que vamos a aproximar una distribución discreta
(binomial) a través de una continua (normal)<a href="#fn64" class="footnote-ref" id="fnref64"><sup>64</sup></a>, por lo que la
expresión toma la forma:</p>
<p><span class="math display">\[z = \frac{\widehat{p} - \frac{1}{2*n} - P}{\sqrt{\frac{P*(1 - P)}{n}}} = \frac{0.25 - \frac{1}{200} - 0.20}{\sqrt{\frac{0.20*(1 - 0.20)}{100}}} = 1.125\]</span></p>
<p>Con lo que:<br />
<span class="math display">\[P(\widehat{p} \geq 0.25) = P(z \geq 1.125)\]</span></p>
<p>Que es el complemento de la probabilidad acumulada:</p>
<div class="sourceCode" id="cb496"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb496-1"><a href="distribuciones-en-el-muestreo.html#cb496-1" tabindex="-1"></a><span class="fu">round</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">1.125</span>), <span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0.1303</code></pre>
<p><span class="math display">\[P(\widehat{p} \geq 0.25) = 0.1303\]</span></p>
<p>Cuando anteriormente se usó la distribución binomial encontramos una probabilidad de 0.1314; por lo que ésta última es una buena aproximación.</p>
<p>A partir de los resultados encontrados en este capítulo podremos hacer
estimaciones de la media y la proporción poblacionales a partir de los
respectivos valores muestrales. Hemos visto entonces que el carácter
aleatorio de las muestras hace que las estimaciones sean inciertas, pero que, debido a que conocemos la distribución de probabilidades de los estimadores podemos establecer qué valores de ellos son más probables, así podremos hacer el camino inverso, que es el que más nos interesa: el de alcanzar a los parámetros a partir de los estimadores.</p>
<p>Usando la distribución normal como aproximación a la binomial, entonces,
para los dos estimadores que hemos mencionado en este capítulo se cumple
la relación:
<span class="math display">\[z=\frac{E_s-P_a}{EEE}\]</span>
En que resumimos:</p>
<ul>
<li><span class="math inline">\(P_a\)</span> es el parámetro</li>
<li><span class="math inline">\(E_s\)</span> es el estimador</li>
<li><span class="math inline">\(EEE\)</span> el error estándar del estimador</li>
</ul>
<p>Veremos en los próximos capítulos que esta expresión es válida para
relacionar otros parámetros con sus correspondientes estimadores,
mientras pueda usarse la distribución normal.</p>
<p>Con los contenidos vistos hasta este punto, en la expresión anterior,
los componentes pueden ser:</p>
<ul>
<li><p><span class="math inline">\(P_a\)</span>: <span class="math inline">\(\mu\)</span> ó <span class="math inline">\(P\)</span></p></li>
<li><p><span class="math inline">\(E_s\)</span>: <span class="math inline">\(\overline{x}\)</span> ó <span class="math inline">\(\widehat{p}\)</span></p></li>
<li><p><span class="math inline">\(EEE\)</span>: <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span> ó
<span class="math inline">\(\sqrt{\frac{P*(1 - P)}{n}}\)</span></p></li>
</ul>
</div>
</div>
<div id="muestras-pequeñas" class="section level3 hasAnchor" number="9.3.4">
<h3><span class="header-section-number">9.3.4</span> Muestras pequeñas<a href="#muestras-peque%C3%B1as" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Las distribuciones de la media y la proporción muestral son
asintóticamente modeladas por la distribución normal. Esto quiere decir
que, a medida que el tamaño de las muestras crece, la distribución de
estos estimadores va siendo más cercana a la curva del modelo normal.
Sin embargo, cuando las muestras son pequeñas, se debe usar un modelo
diferente. William Gosset (<span class="citation">Student (<a href="#ref-student1908a">1908b</a>)</span>, <span class="citation">Student (<a href="#ref-student1908b">1908a</a>)</span>) desarrolló la distribución conocida
como t de Student, que se adecua a describir la distribución de las
medias muestrales cuando éstas provienen de muestras pequeñas. Expresado
formalmente, si las muestras son pequeñas y la variable tiene distribución normal en la población, entonces:</p>
<p><span class="math display">\[\frac{\overline{x} - \mu}{\frac{s}{\sqrt{n}}}\]</span></p>
<p>Tiene distribución <span class="math inline">\(t\)</span> con <span class="math inline">\(n - 1\)</span> grados de libertad. En el ejemplo
de las horas de sueño <!--referencia a ese ejemplo-->, si las muestras fueran de tamaño 15 en lugar de 200, se debe usar la distribución t. Así, la pregunta ¿cuál es la probabilidad que en muestras de tamaño 15, la media de horas de sueño supere las 7 horas?, se responde usando la distribución t con 14 grados de libertad.</p>
<p><span class="math display">\[P(\overline{x} &gt; 7) = P(t_{14} &gt; \frac{7 - 6.5}{\frac{3}{\sqrt{15}}}) = P(t_{14} &gt; 3.87)\]</span></p>
<div class="sourceCode" id="cb498"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb498-1"><a href="distribuciones-en-el-muestreo.html#cb498-1" tabindex="-1"></a><span class="fu">round</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pt</span>(<span class="fl">3.87</span>, <span class="dv">14</span>), <span class="dv">5</span>)</span></code></pre></div>
<pre><code>## [1] 0.00085</code></pre>
<p>Cuando la muestra crece, la diferencia entre los modelos normal y t, se
reduce. Si se repite la operación del ejemplo de las horas de sueño, con muestras de tamaño 200, usando la distribución <span class="math inline">\(t\)</span>, resulta que:</p>
<pre><code>## [1] 0.00913</code></pre>
<p><span class="math display">\[P(t_{199} &gt; 2.38) = 0.009\]</span></p>
<p>Que es, hasta el tercer decimal, igual al que ofrece la distribución normal. A esto se refiere la idea que la distribución t converge a la normal: cuando las muestras son grandes, la distribución t da resultados muy parecidos a los de la normal. El criterio usual para decidir si corresponde usar una distribución <span class="math inline">\(t\)</span> o una normal es de 30 casos. Sin embargo, a fin de ahorrar recursos, cuando se necesita hacer estimaciones que involucran a una u otra de esta distribuciones, los programas estadísticos usan siempre la distribución <span class="math inline">\(t\)</span>.</p>
</div>
<div id="distribución-de-la-varianza" class="section level3 hasAnchor" number="9.3.5">
<h3><span class="header-section-number">9.3.5</span> Distribución de la varianza<a href="#distribuci%C3%B3n-de-la-varianza" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La media y la proporción muestrales tienen distribuciones simétricas
(normal o <span class="math inline">\(t\)</span>); por el contrario, la varianza muestral se distribuye de
manera asimétrica, lo que puede ilustrarse con el ejemplo de las notas del tercer parcial. Si se
solicitan 10000 muestras de tamaño 10, el siguiente es el histograma de ellas, con una curva normal superpuesta, para
mostrar la calidad del ajuste:</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="distribuciones-en-el-muestreo.html#cb501-1" tabindex="-1"></a><span class="fu">ggplot</span>(muestra_tercer_parcial) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(</span>
<span id="cb501-2"><a href="distribuciones-en-el-muestreo.html#cb501-2" tabindex="-1"></a>  <span class="at">x =</span> Media,</span>
<span id="cb501-3"><a href="distribuciones-en-el-muestreo.html#cb501-3" tabindex="-1"></a>  <span class="at">y =</span> ..density..</span>
<span id="cb501-4"><a href="distribuciones-en-el-muestreo.html#cb501-4" tabindex="-1"></a>), <span class="at">fill =</span> <span class="st">&quot;green&quot;</span>) <span class="sc">+</span> <span class="fu">stat_function</span>(</span>
<span id="cb501-5"><a href="distribuciones-en-el-muestreo.html#cb501-5" tabindex="-1"></a>  <span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(</span>
<span id="cb501-6"><a href="distribuciones-en-el-muestreo.html#cb501-6" tabindex="-1"></a>    <span class="at">mean =</span> <span class="fu">mean</span>(muestra_tercer_parcial<span class="sc">$</span>Media),</span>
<span id="cb501-7"><a href="distribuciones-en-el-muestreo.html#cb501-7" tabindex="-1"></a>    <span class="at">sd =</span> <span class="fu">sd</span>(muestra_tercer_parcial<span class="sc">$</span>Media)</span>
<span id="cb501-8"><a href="distribuciones-en-el-muestreo.html#cb501-8" tabindex="-1"></a>  )</span>
<span id="cb501-9"><a href="distribuciones-en-el-muestreo.html#cb501-9" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb501-10"><a href="distribuciones-en-el-muestreo.html#cb501-10" tabindex="-1"></a>  <span class="fu">theme_tufte</span>()</span></code></pre></div>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-454-1.svg" width="672" /></p>
<p>Puede verse que el modelo normal “copia” razonablemente bien la
distribución real de las medias muestrales, considerando que no se han extraído todas, sino “solo” 10000. Pero si se hace lo mismo con las
varianzas muestrales, se obtiene:</p>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb502-1"><a href="distribuciones-en-el-muestreo.html#cb502-1" tabindex="-1"></a><span class="fu">ggplot</span>(muestra_tercer_parcial) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(</span>
<span id="cb502-2"><a href="distribuciones-en-el-muestreo.html#cb502-2" tabindex="-1"></a>  <span class="at">x =</span> Varianza,</span>
<span id="cb502-3"><a href="distribuciones-en-el-muestreo.html#cb502-3" tabindex="-1"></a>  <span class="at">y =</span> ..density..</span>
<span id="cb502-4"><a href="distribuciones-en-el-muestreo.html#cb502-4" tabindex="-1"></a>), <span class="at">fill =</span> <span class="st">&quot;green&quot;</span>) <span class="sc">+</span></span>
<span id="cb502-5"><a href="distribuciones-en-el-muestreo.html#cb502-5" tabindex="-1"></a>  <span class="fu">theme_tufte</span>()</span></code></pre></div>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-455-1.svg" width="672" /></p>
<p>Que muestra la asimetría de la distribución de las varianzas, la distribución normal no modela bien esta variable. Para las varianzas muestrales, el modelo adecuado es <span class="math inline">\(\chi^{2}\)</span>. La relación entre la varianza muestral y la poblacional es:</p>
<p><span class="math display">\[\frac{(n - 1)*s^{2}}{\sigma^{2}} \sim \chi_{n - 1}^{2}\]</span></p>
<p>Que quiere decir que, dada una población con una determinada varianza
<span class="math inline">\(\sigma^{2}\)</span>, si se extraen todas las muestras posibles de un tamaño
dado y en cada una de ellas se calcula la varianza muestral <span class="math inline">\(s^{2}\)</span>, la
expresión de arriba se distribuye con un modelo ji cuadrado con <span class="math inline">\(n-1\)</span>
grados de libertad.</p>
</div>
<div id="muestreo-desde-dos-poblaciones" class="section level3 hasAnchor" number="9.3.6">
<h3><span class="header-section-number">9.3.6</span> Muestreo desde dos poblaciones<a href="distribuciones-en-el-muestreo.html#muestreo-desde-dos-poblaciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para comparar muestras que provienen de diferentes poblaciones (participantes y no participantes de un programa, grupo experimental y grupo control, residentes en ciudades grandes y pequeñas, etc.) y dependiendo del nivel de medición de la variable que se compara, se calculan diferencias de medias o bien de proporciones. Para ello se extrae una muestra de cada población, cuyos tamaños se llaman <span class="math inline">\(n_{1}\)</span> y <span class="math inline">\(n_{2}\)</span>.<br />
Para comparar las medias de dos poblaciones, el parámetro es <span class="math inline">\(\mu_{1} - \mu_{2}\)</span> y su estimador <span class="math inline">\({\overline{x}}_{1} - {\overline{x}}_{2}\)</span>. Cuando se compara la proporción de casos en una categoría de una variable categórica, el parámetro es la diferencia de
proporciones poblacionales: <span class="math inline">\(P_{1} - P_{2}\)</span> y su estimador, la
diferencia de proporciones muestrales: <span class="math inline">\({\widehat{p}}_{1} - {\widehat{p}}_{2}\)</span>. Cuando se cumple que las muestras son grandes, ambos estimadores (diferencia de medias y diferencia de proporciones) tienen distribución normal, o bien, en el caso de la media, distribución t, si se trata de muestras pequeñas y puede suponerse la distribución normal en la población.<br />
La forma general de la relacióon entre estimadores y parámetros es, para la diferencia de medias: <span class="math display">\[\frac{(\overline{x}_1 - \overline{x}_2)-(\mu_1-\mu_2)}{s_{(\overline{x}_1 - \overline{x}_2})}\]</span></p>
<p>Donde <span class="math inline">\(s_{(\overline{x}_1 - \overline{x}_2)}\)</span> tomará diferentes valores según como sean las varianzas poblacionales. En los próximos capítulos se trata este tema.</p>
<p>Para la diferencia de proporciones: <span class="math display">\[\frac{({\widehat{p}}_{1}-{\widehat{p}}_{2})-(P_{2}-P_{2})}{\sqrt{\frac{P_{1}*(1-P_{1})}{n_{1}}-\frac{P_{2}*(1-P_{2})}{n_{2}}}}\]</span></p>
</div>
<div id="distribución-del-cociente-de-varianzas" class="section level3 hasAnchor" number="9.3.7">
<h3><span class="header-section-number">9.3.7</span> Distribución del cociente de varianzas<a href="#distribuci%C3%B3n-del-cociente-de-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para comparar varianzas, en lugar de restarlas, se las divide y el parámetro es el cociente de las varianzas poblacionales <span class="math display">\[\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}\]</span>; el estimador es el
cociente de las varianzas muestrales <span class="math display">\[\frac{s_{1}^{2}}{s_{2}^{2}}\]</span>. La relación entre estimador y parámetro es:</p>
<p><span class="math display">\[\frac{\frac{s_{1}^{2}}{\sigma_{1}^{2}}}{\frac{s_{2}^{2}}{\sigma_{2}^{2}}} \sim F_{n_{1} - 1,n_{2} - 1}\]</span></p>
<p>Que se puede escribir más compacto así:</p>
<p><span class="math display">\[\frac{s_1^2*\sigma_2^2}{s_2^2*\sigma_1^2} \sim F_{n_{1} - 1,n_{2} - 1}\]</span></p>
<p>Que indica que ese cociente es modelado por una distribución <span class="math inline">\(F\)</span> con
<span class="math inline">\(n_{1} - 1\)</span> grados de libertad en el numerador y <span class="math inline">\(n_{2} - 1\)</span> grados de
libertad en el denominador.</p>
</div>
</div>
<div id="resumen-de-la-relación-entre-estimadores-y-parámetros" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Resumen de la relación entre estimadores y parámetros<a href="#resumen-de-la-relaci%C3%B3n-entre-estimadores-y-par%C3%A1metros" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Parámetro
</th>
<th style="text-align:center;">
Estimador
</th>
<th style="text-align:center;">
Estandarización del estimador
</th>
<th style="text-align:center;">
Distribución
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Media: <span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\overline{x}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\overline{x} - \mu}{\frac{\sigma}{\sqrt{n}}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(N(\mu,\sigma^{2})\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Media: <span class="math inline">\(\mu\)</span> (muestras pequeñas)
</td>
<td style="text-align:center;">
<span class="math inline">\(\overline{x}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\overline{x} - \mu}{\frac{\sigma}{\sqrt{n}}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(t_{n - 1}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Número de éxitos en la población X
</td>
<td style="text-align:center;">
<span class="math inline">\(\widehat{x}\)</span>
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(B(x, n,p)\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Proporción de casos en una categoría: P (muestras grandes)
</td>
<td style="text-align:center;">
<span class="math inline">\(\widehat{p}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\widehat{p} - P}{\sigma_{\widehat{p}}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(N(P,\frac{P*(1 - P)}{n})\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Varianza: <span class="math inline">\(\sigma^{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(s^{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{n - 1*s^{2}}{\sigma^{2}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\chi_{n - 1}^{2}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Cociente de varianzas: <span class="math inline">\(\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{s_{1}^{2}}{s_{2}^{2}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{s_1^2*\sigma_2^2}{s_2^2*\sigma_1^2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(F_{n_{1} - 1,n_{2} - 1}\)</span>
</td>
</tr>
</tbody>
</table>
<div style="page-break-after: always;"></div>
</div>
<div id="hacerlo-en-r-7" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Hacerlo en R<a href="distribuciones-en-el-muestreo.html#hacerlo-en-r-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En este capítulo se ha recurrido a R solo para el cálculo de probabilidades, por lo que no hay nada nuevo.
Agregamos solamente que la varianza que R calcula cuando se solicita <code>var(x)</code> es la varianza muestral, es decir, con denominador <span class="math inline">\(n-1\)</span>. Si se necesita calcular una varianza poblacional, se puede corregir esta varianza por medio de:</p>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb503-1"><a href="distribuciones-en-el-muestreo.html#cb503-1" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">8</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">3</span>)</span>
<span id="cb503-2"><a href="distribuciones-en-el-muestreo.html#cb503-2" tabindex="-1"></a><span class="fu">var</span>(x) <span class="sc">*</span> (<span class="fu">length</span>(x) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="fu">length</span>(x)</span></code></pre></div>
<pre><code>## [1] 3.388889</code></pre>
<p>Así se elimina el denominador <span class="math inline">\(n-1\)</span> de la varianza muestral y se reemplaza por <span class="math inline">\(n\)</span>.</p>
<p>También puede definirse una función para que la calcule directamente:</p>
<div class="sourceCode" id="cb505"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb505-1"><a href="distribuciones-en-el-muestreo.html#cb505-1" tabindex="-1"></a>var.p <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb505-2"><a href="distribuciones-en-el-muestreo.html#cb505-2" tabindex="-1"></a>  <span class="fu">var</span>(x) <span class="sc">*</span> (<span class="fu">length</span>(x) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="fu">length</span>(x)</span>
<span id="cb505-3"><a href="distribuciones-en-el-muestreo.html#cb505-3" tabindex="-1"></a>}</span></code></pre></div>

</div>
</div>



<p>Una vez que disponemos de una síntesis de la información que hemos recogido de un conjunto de individuos, pasa a interesar otro problema: el de preguntarnos si eso que se ha observado vale también casos que no han sido observados.</p>
<p>Si hemos visto a muchas personas, algunas exigentes consigo mismas y otras que no lo son y hallamos que las primeras manifiestan más ansiedad en los exámenes que las segundas, ¿podemos decir que la autoexigencia incide en la ansiedad?, es decir, ¿podemos generalizar nuestro resultado? La Estadística inferencial se ocupará de esto, de decirnos bajo qué condiciones se pueden extender nuestros hallazgos a casos no observados.</p>
<p>Si encontramos personas cuyas madres que han tomado bebidas alcohólicas durante el embarazo y otras personas que son hijas de madres que no bebieron y descubrimos que, en promedio, las primeras tienen niveles de desarrollo motor más bajo que las segundas, ¿podemos afirmar que beber alcohol durante el embarazo retrasa el desarrollo motor de hijas e hijos <em>en general</em>? Según cuántas personas hayan sido observadas, según qué tan grande sea la diferencia entre el promedio de desarrollo motor de quienes tienen madres bebedoras y no bebedoras, según qué tan variable sea el desarrollo entre las personas evaluadas, tendremos o no argumentos para generalizar el resultado y afirmar que existe o no una relación entre consumo de alcohol durante el embarazo y desarrollo motor de los hijos e hijas. Se establece así una relación entre variables que pasa a tener validez general, no solo para las personas que fueron efectivamente observadas.</p>
<p>Cuando una intervención social tiene los efectos esperados en un grupo que fue beneficiario de ella, ¿bajo qué condiciones puede decirse que esa intervención es efectiva para otros grupos que no han participado aun?</p>
<p>Cuando se realicen generalizaciones, éstas estarán limitadas a un contexto específico. El análisis que se haga, de la relación entre pobreza y educación en Argentina, puede no ser válido para la población de Brasil, ni el efecto de la fijación de metas elevadas es el mismo en los países asiáticos que en los latinoamericanos, ni una política de transferencias condicionadas tiene igual impacto en distintas regiones. Por ello, debe estar explícita cuál es la población de referencia a la cual es válido extender los resultados que se obtienen. De un modo diferente, la relación entre el consumo de alcohol de las madres y el desarrollo de sus embarazos, como tiene anclaje biológico, puede hacerse extensiva a la población general, salvo que, entre poblaciones, haya diferencias genéticas asociadas a este efecto.</p>
<p>Los dos procedimientos que se desarrollan en los capítulos siguientes son: estimación por intervalo (o estimación de parámetros o también intervalos de confianza) y pruebas de hipótesis (conocida también como docimasia de hipótesis).</p>
<p>Estos son los dos métodos que se utilizan para producir generalizaciones estadísticas a partir de muestras, es decir, inferencias.</p>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Alvarado2007" class="csl-entry">
Alvarado, Hugo, and Carmen Batanero. 2007. <span>“<span class="nocase">Dificultades de Comprensi<span class="nocase">ó</span>n de la Aproximaci<span class="nocase">ó</span>n Normal a la Distribuci<span class="nocase">ó</span>n Binomial</span>.”</span> <em>N<span>Ú</span>MEROS, Revista Digital de Educaci<span>ó</span>n Matem<span>á</span>tica.</em>, no. 67. <a href="http://www.sinewton.org/numeros/numeros/67/ideas%7B\_%7D01.php">http://www.sinewton.org/numeros/numeros/67/ideas{\_}01.php</a>.
</div>
<div id="ref-anuariounc2014" class="csl-entry">
Estadísticas Universitarias, Programa de. 2015. <em><span class="nocase">Anuario Estad<span class="nocase">í</span>stico 2015</span></em>. C<span>ó</span>rdoba: Secretar<span>í</span>a de Asuntos Acad<span>é</span>micos. Univeridad Nacional de C<span>ó</span>rdoba.
</div>
<div id="ref-Scheaffer2006" class="csl-entry">
Scheaffer, Richard L., William Mendenhall, and Lyman Ott. 2006. <em><span class="nocase">Elementos de Muestreo</span></em>. Madrid: Paraninfo.
</div>
<div id="ref-student1908b" class="csl-entry">
Student. 1908a. <span>“<span class="nocase">Probable Error of a Correlation Coefficient</span>.”</span> <em>Biometrika</em>, no. 6: 302–10.
</div>
<div id="ref-student1908a" class="csl-entry">
———. 1908b. <span>“<span class="nocase">The Probable Error of a Mean</span>.”</span> <em>Biometrika</em>, no. 6: 1–25.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="52">
<li id="fn52"><p>Las fórmulas para hacer inferencias que aparecen en este capítulo y los siguientes, son correctas si el muestreo es irrestricto aleatorio, cuando se usen otros diseños de muestra (siempre probabilísticos), será necesario introducir ajustes; el texto de <span class="citation">Scheaffer, Mendenhall, and Ott (<a href="#ref-Scheaffer2006">2006</a>)</span> es una adecuada referencia para esas correcciones.<a href="distribuciones-en-el-muestreo.html#fnref52" class="footnote-back">↩︎</a></p></li>
<li id="fn53"><p>Considerar al valor poblacional como fijo o aleatorio depende de la concepción de azar que se adopte. El enfoque frecuencial, los toma como fijos, mientras que el enfoque bayesiano los toma como variables aleatorias, ya que trata como azaroso un proceso cuyo resultado no puede anticiparse con certeza. En lo que sigue, adoptaremos el enfoque frecuencial.<a href="distribuciones-en-el-muestreo.html#fnref53" class="footnote-back">↩︎</a></p></li>
<li id="fn54"><p>Dado que puede haber confusión al escribir p o P, se usa <span class="math inline">\(\widehat{p}\)</span> para indicar la proporción muestral, con la misma notación que se usó en regresión para indica el valor estimado de la variable dependiente.<a href="distribuciones-en-el-muestreo.html#fnref54" class="footnote-back">↩︎</a></p></li>
<li id="fn55"><p>Lo que se consigue con esa corrección es que, si se calculan las varianzas de todas las muestras que se saquen de una población dada, éstas promedien la varianza de la población, lo cual no sucede si se usa el denominador <span class="math inline">\(n\)</span>. Se denomina insesgabilidad del estimador, por lo que podemos decir que el denominador de la varianza muestral se transforma en <span class="math inline">\(n-1\)</span> para lograr que sea un estimador insesgado de la varianza poblacional.<a href="distribuciones-en-el-muestreo.html#fnref55" class="footnote-back">↩︎</a></p></li>
<li id="fn56"><p>Suponer que en el hospital solo hay tres personas internadas es una gran simplificación, por cierto ficticia. Se usa con fines expositivos, para poder hacer intuitiva la comparación entre la población y las muestras.<a href="distribuciones-en-el-muestreo.html#fnref56" class="footnote-back">↩︎</a></p></li>
<li id="fn57"><p>Esta categoría se eligió arbitrariamente, podría haber sido la otra y calcular la proporción de varones.<a href="distribuciones-en-el-muestreo.html#fnref57" class="footnote-back">↩︎</a></p></li>
<li id="fn58"><p>Nuevamente se trata de una simplificación expositiva. Esta forma de extraer una muestra no es la que se aplica en la práctica, porque no se permite elegir dos veces al mismo individuo. Sin embargo, este muestreo con reposición en una buena aproximación a los muestreos verdaderos (sin reposición) cuando se trabaja con poblaciones grandes. Es así porque la extracción de unos pocos casos, aunque sean sin reposición, altera poco la probabilidad de ser extraídos de los otros casos.<a href="distribuciones-en-el-muestreo.html#fnref58" class="footnote-back">↩︎</a></p></li>
<li id="fn59"><p>De modo equivalente, la desviación estándar de la media es la desviación estándar de la población dividida en la raíz cuadrada del tamaño de la muestra. Es conocida también como error estándar de la media.<a href="distribuciones-en-el-muestreo.html#fnref59" class="footnote-back">↩︎</a></p></li>
<li id="fn60"><p>Alternativamente podemos solicitar a R la probabilidad acumulada de 7 con parámetros <span class="math inline">\(\mu=6.5\)</span> y <span class="math inline">\(\sigma=0.14\)</span> y obtener el mismo resultado sin pasar por <span class="math inline">\(z\)</span>. Hacemos este recorrido porque necesitamos estar familiarizados con el puntaje <span class="math inline">\(z\)</span> para los contenidos que veremos más adelante.<a href="distribuciones-en-el-muestreo.html#fnref60" class="footnote-back">↩︎</a></p></li>
<li id="fn61"><p>Es el mínimo tamaño que podemos usar para que sea válida la aplicación de la distribución normal<a href="distribuciones-en-el-muestreo.html#fnref61" class="footnote-back">↩︎</a></p></li>
<li id="fn62"><p>Aunque puede interpretarse como si los individuos constituyeran muestras de tamaño 1.<a href="distribuciones-en-el-muestreo.html#fnref62" class="footnote-back">↩︎</a></p></li>
<li id="fn63"><p><span class="citation">Alvarado and Batanero (<a href="#ref-Alvarado2007">2007</a>)</span>, indican que “Respecto al valor de <span class="math inline">\(n\)</span> requerido para una correcta aproximación de la distribución binomial, los textos no siempre están de acuerdo.” En algunos textos se solicita que <span class="math inline">\(n&gt;30\)</span>, pero la calidad de la aproximación depende también de <span class="math inline">\(P\)</span>.<a href="distribuciones-en-el-muestreo.html#fnref63" class="footnote-back">↩︎</a></p></li>
<li id="fn64"><p>La distribución binomial tiene como variable discreta a <span class="math inline">\(\widehat{x}\)</span>, la cantidad de éxitos en la muestra, si nos interesa la probabilidad de los valores mayores o iguales a un <span class="math inline">\(\widehat{x}\)</span> dado, debemos tener en cuenta que al pasar a la normal, como es continua, no se pueden calcular probabilidades de valores exactos. Así, el conjunto <span class="math inline">\(\widehat{x} \geq 3\)</span>, debe transformarse en <span class="math inline">\(\widehat{x} &gt; 2.5\)</span>; dado que la probabilidad de <span class="math inline">\(\widehat{x} = 3\)</span> es cero cuando la tratamos como variable continua. De manera análoga, si buscáramos <span class="math inline">\(P(\widehat{x} \leq 3)\)</span>, deberemos tratarlo como <span class="math inline">\(P(\widehat{x} &lt; 3.5)\)</span>. La corrección consiste entonces en tomar media unidad menos cuando calculamos probabilidades de valores mayores o iguales a uno dado, y media unidad más si se trata de la probabilidad de un valor menor o igual. Veamos el efecto que tiene esta corrección sobre <span class="math inline">\(\widehat{p}\)</span>. Dado que <span class="math inline">\(\widehat{p} = \frac{\widehat{x}}{n}\)</span>, cuando corregimos el número de éxitos en media unidad por debajo, nos queda <span class="math inline">\(\frac{\widehat{x} - 0.5}{n} = \frac{\widehat{x}}{n} - \frac{0.5}{n} = \widehat{p} - \frac{1}{2*n}\)</span>. Cuando la corrección exija que se tome media unidad más, la corrección será <span class="math inline">\(\widehat{p} + \frac{1}{2*n}\)</span>.<a href="distribuciones-en-el-muestreo.html#fnref64" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probabilidad-los-modelos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimación-por-intervalo.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/jcrodriguez1989/EstadisticaParaCienciasSocialesConR/edit/master/10-capitulo9.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["EstadisticaParaCienciasSocialesConR.pdf", "EstadisticaParaCienciasSocialesConR.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
