<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 5 Relación entre variables: el análisis | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R</title>
  <meta name="description" content="Capítulo 5 Relación entre variables: el análisis | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 5 Relación entre variables: el análisis | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="imagenes/cover.jpg" />
  
  <meta name="github-repo" content="jcrodriguez1989/EstadisticaParaCienciasSocialesConR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 5 Relación entre variables: el análisis | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  
  
  <meta name="twitter:image" content="imagenes/cover.jpg" />

<meta name="author" content="Eduardo Bologna" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="relación-entre-variables-los-fundamentos.html"/>
<link rel="next" href="obtención-de-la-muestra.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística para Ciencias Sociales con R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Colaboradores</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#edición-en-bookdown"><i class="fa fa-check"></i>Edición en bookdown:</a><ul>
<li><a href="index.html#juan-cruz-rodriguez"><span>Juan Cruz Rodriguez</span></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#comité-editorial"><i class="fa fa-check"></i>Comité Editorial:</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="presentación.html"><a href="presentación.html"><i class="fa fa-check"></i>Presentación</a><ul>
<li class="chapter" data-level="" data-path="presentación.html"><a href="presentación.html#recorridos-posibles"><i class="fa fa-check"></i>Recorridos posibles</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html"><i class="fa fa-check"></i>Materiales y herramientas</a><ul>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#materiales"><i class="fa fa-check"></i>Materiales</a><ul>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#encuesta-permanente-de-hogares"><i class="fa fa-check"></i>Encuesta Permanente de Hogares</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#encuesta-nacional-de-factores-de-riesgo"><i class="fa fa-check"></i>Encuesta Nacional de Factores de Riesgo</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#latinobarómetro"><i class="fa fa-check"></i>Latinobarómetro</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#encuesta-nacional-sobre-prevalencias-de-consumo-de-sustancias-psicoactivas"><i class="fa fa-check"></i>Encuesta Nacional sobre Prevalencias de Consumo de Sustancias Psicoactivas</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#aplicación-de-la-escala-de-bayley"><i class="fa fa-check"></i>Aplicación de la escala de Bayley</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#adultos-mayores"><i class="fa fa-check"></i>Adultos mayores</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#herramientas"><i class="fa fa-check"></i>Herramientas</a><ul>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#la-elección-de-r"><i class="fa fa-check"></i>La elección de R</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#instalación-de-r-y-rstudio"><i class="fa fa-check"></i>Instalación de R y RStudio</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#los-componentes-de-rstudio"><i class="fa fa-check"></i>Los componentes de RStudio</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#operaciones-en-el-script"><i class="fa fa-check"></i>Operaciones en el script</a></li>
<li class="chapter" data-level="" data-path="materiales-y-herramientas.html"><a href="materiales-y-herramientas.html#instalación-de-paquetes"><i class="fa fa-check"></i>Instalación de paquetes</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Estadística Descriptiva</b></span></li>
<li class="chapter" data-level="1" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html"><i class="fa fa-check"></i><b>1</b> Los datos estadísticos</a><ul>
<li class="chapter" data-level="1.1" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#la-selección-de-la-información-pertinente"><i class="fa fa-check"></i><b>1.1</b> La selección de la información pertinente</a></li>
<li class="chapter" data-level="1.2" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-entidades"><i class="fa fa-check"></i><b>1.2</b> Las entidades</a></li>
<li class="chapter" data-level="1.3" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-variables"><i class="fa fa-check"></i><b>1.3</b> Las variables</a></li>
<li class="chapter" data-level="1.4" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-categorías"><i class="fa fa-check"></i><b>1.4</b> Las categorías</a><ul>
<li class="chapter" data-level="1.4.1" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#requisitos-de-las-categorías"><i class="fa fa-check"></i><b>1.4.1</b> Requisitos de las categorías</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#los-símbolos-numéricos"><i class="fa fa-check"></i><b>1.5</b> Los símbolos numéricos</a></li>
<li class="chapter" data-level="1.6" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#la-medición"><i class="fa fa-check"></i><b>1.6</b> La medición</a><ul>
<li class="chapter" data-level="1.6.1" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#niveles-de-medición"><i class="fa fa-check"></i><b>1.6.1</b> Niveles de medición</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#resumen-de-los-niveles-de-medición"><i class="fa fa-check"></i><b>1.7</b> Resumen de los niveles de medición</a></li>
<li class="chapter" data-level="1.8" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#hacerlo-en-r"><i class="fa fa-check"></i><b>1.8</b> Hacerlo en R</a><ul>
<li class="chapter" data-level="1.8.1" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#lectura-de-la-base"><i class="fa fa-check"></i><b>1.8.1</b> Lectura de la base</a></li>
<li class="chapter" data-level="1.8.2" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-variables-1"><i class="fa fa-check"></i><b>1.8.2</b> Las variables</a></li>
<li class="chapter" data-level="1.8.3" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#los-niveles-de-medición-en-r"><i class="fa fa-check"></i><b>1.8.3</b> Los niveles de medición en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html"><i class="fa fa-check"></i><b>2</b> Distribuciones de frecuencia</a><ul>
<li class="chapter" data-level="2.1" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#tablas-de-distribución-de-frecuencia"><i class="fa fa-check"></i><b>2.1</b> Tablas de distribución de frecuencia</a></li>
<li class="chapter" data-level="2.2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#recategorización"><i class="fa fa-check"></i><b>2.2</b> Recategorización</a><ul>
<li class="chapter" data-level="2.2.1" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#variable-discreta-con-muchas-categorías"><i class="fa fa-check"></i><b>2.2.1</b> Variable discreta con muchas categorías</a></li>
<li class="chapter" data-level="2.2.2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#variable-continua"><i class="fa fa-check"></i><b>2.2.2</b> Variable continua</a></li>
<li class="chapter" data-level="2.2.3" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#formas-de-recategorizar"><i class="fa fa-check"></i><b>2.2.3</b> Formas de recategorizar</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#la-presentación-gráfica-de-los-resultados"><i class="fa fa-check"></i><b>2.3</b> La presentación gráfica de los resultados</a></li>
<li class="chapter" data-level="2.4" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#hacerlo-en-r-1"><i class="fa fa-check"></i><b>2.4</b> Hacerlo en R</a><ul>
<li class="chapter" data-level="2.4.1" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#tablas-univariadas"><i class="fa fa-check"></i><b>2.4.1</b> Tablas univariadas</a></li>
<li class="chapter" data-level="2.4.2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#recategorización-1"><i class="fa fa-check"></i><b>2.4.2</b> Recategorización</a></li>
<li class="chapter" data-level="2.4.3" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#representaciones-gráficas"><i class="fa fa-check"></i><b>2.4.3</b> Representaciones gráficas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html"><i class="fa fa-check"></i><b>3</b> La expresión resumida de la información</a><ul>
<li class="chapter" data-level="3.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#medidas-de-posición"><i class="fa fa-check"></i><b>3.1</b> Medidas de posición</a><ul>
<li class="chapter" data-level="3.1.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-proporciones"><i class="fa fa-check"></i><b>3.1.1</b> Variables nominales: proporciones</a></li>
<li class="chapter" data-level="3.1.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-tasas"><i class="fa fa-check"></i><b>3.1.2</b> Variables nominales: tasas</a></li>
<li class="chapter" data-level="3.1.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-razones"><i class="fa fa-check"></i><b>3.1.3</b> Variables nominales: razones</a></li>
<li class="chapter" data-level="3.1.4" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-el-modo"><i class="fa fa-check"></i><b>3.1.4</b> Variables nominales: el modo</a></li>
<li class="chapter" data-level="3.1.5" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-ordinales-cuantiles"><i class="fa fa-check"></i><b>3.1.5</b> Variables ordinales: cuantiles</a></li>
<li class="chapter" data-level="3.1.6" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-métricas-la-media-o-promedio"><i class="fa fa-check"></i><b>3.1.6</b> Variables métricas: la media o promedio</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#la-forma-de-la-distribución"><i class="fa fa-check"></i><b>3.2</b> La forma de la distribución</a><ul>
<li class="chapter" data-level="3.2.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#asimetría"><i class="fa fa-check"></i><b>3.2.1</b> Asimetría</a></li>
<li class="chapter" data-level="3.2.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#curtosis"><i class="fa fa-check"></i><b>3.2.2</b> Curtosis</a></li>
<li class="chapter" data-level="3.2.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#box-plots"><i class="fa fa-check"></i><b>3.2.3</b> Box-plots</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>3.3</b> Medidas de dispersión</a><ul>
<li class="chapter" data-level="3.3.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#recorrido"><i class="fa fa-check"></i><b>3.3.1</b> Recorrido</a></li>
<li class="chapter" data-level="3.3.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#amplitud-intercuartílica"><i class="fa fa-check"></i><b>3.3.2</b> Amplitud intercuartílica</a></li>
<li class="chapter" data-level="3.3.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#medidas-de-dispersión-basadas-en-la-media"><i class="fa fa-check"></i><b>3.3.3</b> Medidas de dispersión basadas en la media</a></li>
<li class="chapter" data-level="3.3.4" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#varianza"><i class="fa fa-check"></i><b>3.3.4</b> Varianza</a></li>
<li class="chapter" data-level="3.3.5" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#desviación-estándar"><i class="fa fa-check"></i><b>3.3.5</b> Desviación estándar</a></li>
<li class="chapter" data-level="3.3.6" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#coeficiente-de-variación"><i class="fa fa-check"></i><b>3.3.6</b> Coeficiente de variación</a></li>
<li class="chapter" data-level="3.3.7" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#box-plots-y-dispersión"><i class="fa fa-check"></i><b>3.3.7</b> Box-plots y dispersión</a></li>
<li class="chapter" data-level="3.3.8" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#medida-de-la-dispersión-cuando-no-hay-distancias"><i class="fa fa-check"></i><b>3.3.8</b> Medida de la dispersión cuando no hay distancias</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#el-individuo-en-relación-a-su-grupo"><i class="fa fa-check"></i><b>3.4</b> El individuo en relación a su grupo</a></li>
<li class="chapter" data-level="3.5" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#resumen-de-medidas-descriptivas"><i class="fa fa-check"></i><b>3.5</b> Resumen de medidas descriptivas</a><ul>
<li class="chapter" data-level="3.5.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#medidas-de-posición-1"><i class="fa fa-check"></i><b>3.5.1</b> Medidas de posición</a></li>
<li class="chapter" data-level="3.5.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#medidas-de-dispersión-1"><i class="fa fa-check"></i><b>3.5.2</b> Medidas de dispersión</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#hacerlo-en-r-2"><i class="fa fa-check"></i><b>3.6</b> Hacerlo en R</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html"><i class="fa fa-check"></i><b>4</b> Relación entre variables: los fundamentos</a><ul>
<li class="chapter" data-level="4.1" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#tablas-de-contingencia"><i class="fa fa-check"></i><b>4.1</b> Tablas de contingencia</a></li>
<li class="chapter" data-level="4.2" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#frecuencias-relativas"><i class="fa fa-check"></i><b>4.2</b> Frecuencias relativas</a></li>
<li class="chapter" data-level="4.3" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#una-clasificación-en-referencia-al-tiempo"><i class="fa fa-check"></i><b>4.3</b> Una clasificación en referencia al tiempo</a></li>
<li class="chapter" data-level="4.4" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#la-dirección-de-la-relación"><i class="fa fa-check"></i><b>4.4</b> La dirección de la relación</a></li>
<li class="chapter" data-level="4.5" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#concepto-de-riesgo-relativo"><i class="fa fa-check"></i><b>4.5</b> Concepto de riesgo relativo</a></li>
<li class="chapter" data-level="4.6" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#la-intensidad"><i class="fa fa-check"></i><b>4.6</b> La intensidad</a></li>
<li class="chapter" data-level="4.7" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#el-concepto-de-independencia-estadística"><i class="fa fa-check"></i><b>4.7</b> El concepto de independencia estadística</a></li>
<li class="chapter" data-level="4.8" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#hacerlo-en-r-3"><i class="fa fa-check"></i><b>4.8</b> Hacerlo en R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html"><i class="fa fa-check"></i><b>5</b> Relación entre variables: el análisis</a><ul>
<li class="chapter" data-level="5.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#relaciones-entre-variables-vs.comparación-de-grupos"><i class="fa fa-check"></i><b>5.1</b> Relaciones entre variables vs. comparación de grupos</a></li>
<li class="chapter" data-level="5.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#variables-nominales"><i class="fa fa-check"></i><b>5.2</b> Variables nominales</a><ul>
<li class="chapter" data-level="5.2.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#coeficientes-de-asociación-para-variables-nominales"><i class="fa fa-check"></i><b>5.2.1</b> Coeficientes de asociación para variables nominales</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#variables-de-nivel-ordinal"><i class="fa fa-check"></i><b>5.3</b> Variables de nivel ordinal</a></li>
<li class="chapter" data-level="5.4" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#nivel-intervalar-o-proporcional"><i class="fa fa-check"></i><b>5.4</b> Nivel intervalar o proporcional</a></li>
<li class="chapter" data-level="5.5" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#dicotomías-reales-y-artificiales"><i class="fa fa-check"></i><b>5.5</b> Dicotomías reales y artificiales</a></li>
<li class="chapter" data-level="5.6" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#niveles-de-medición-combinados"><i class="fa fa-check"></i><b>5.6</b> Niveles de medición combinados</a><ul>
<li class="chapter" data-level="5.6.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#una-variable-dicotómica-real-y-una-proporcional"><i class="fa fa-check"></i><b>5.6.1</b> Una variable dicotómica real y una proporcional</a></li>
<li class="chapter" data-level="5.6.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#una-variable-continua-dicotomizada-y-una-proporcional"><i class="fa fa-check"></i><b>5.6.2</b> Una variable continua dicotomizada y una proporcional</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#resumen-de-coeficientes-de-asociación"><i class="fa fa-check"></i><b>5.7</b> Resumen de coeficientes de asociación</a></li>
<li class="chapter" data-level="5.8" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#matriz-de-correlaciones"><i class="fa fa-check"></i><b>5.8</b> Matriz de correlaciones</a></li>
<li class="chapter" data-level="5.9" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#la-forma-de-la-relación"><i class="fa fa-check"></i><b>5.9</b> La forma de la relación</a><ul>
<li class="chapter" data-level="5.9.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#ordenada-al-origen"><i class="fa fa-check"></i><b>5.9.1</b> Ordenada al origen</a></li>
<li class="chapter" data-level="5.9.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#pendiente"><i class="fa fa-check"></i><b>5.9.2</b> Pendiente</a></li>
<li class="chapter" data-level="5.9.3" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#obtención-de-la-recta-de-regresión"><i class="fa fa-check"></i><b>5.9.3</b> Obtención de la recta de regresión</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#la-visualización-de-los-datos"><i class="fa fa-check"></i><b>5.10</b> La visualización de los datos</a></li>
<li class="chapter" data-level="5.11" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#hacerlo-en-r-4"><i class="fa fa-check"></i><b>5.11</b> Hacerlo en R</a><ul>
<li class="chapter" data-level="5.11.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#distancia-chi2"><i class="fa fa-check"></i><b>5.11.1</b> Distancia <span class="math inline">\(\chi^{2}\)</span></a></li>
<li class="chapter" data-level="5.11.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#coeficientes"><i class="fa fa-check"></i><b>5.11.2</b> Coeficientes</a></li>
<li class="chapter" data-level="5.11.3" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#modelo-lineal"><i class="fa fa-check"></i><b>5.11.3</b> Modelo lineal</a></li>
<li class="chapter" data-level="5.11.4" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#cuarteto-de-anscombe"><i class="fa fa-check"></i><b>5.11.4</b> Cuarteto de Anscombe</a></li>
<li class="chapter" data-level="5.11.5" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#datasaurus"><i class="fa fa-check"></i><b>5.11.5</b> Datasaurus</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II De la descripción a la inferencia</b></span></li>
<li class="chapter" data-level="6" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html"><i class="fa fa-check"></i><b>6</b> Obtención de la muestra</a><ul>
<li class="chapter" data-level="6.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#población"><i class="fa fa-check"></i><b>6.1</b> Población</a><ul>
<li class="chapter" data-level="6.1.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestra"><i class="fa fa-check"></i><b>6.1.1</b> Muestra</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreos-probabilísticos"><i class="fa fa-check"></i><b>6.2</b> Muestreos probabilísticos</a><ul>
<li class="chapter" data-level="6.2.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-irrestricto-aleatorio-o-aleatorio-simple"><i class="fa fa-check"></i><b>6.2.1</b> Muestreo irrestricto aleatorio o aleatorio simple</a></li>
<li class="chapter" data-level="6.2.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-sistemático"><i class="fa fa-check"></i><b>6.2.2</b> Muestreo sistemático</a></li>
<li class="chapter" data-level="6.2.3" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-estratificado"><i class="fa fa-check"></i><b>6.2.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="6.2.4" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-por-conglomerados"><i class="fa fa-check"></i><b>6.2.4</b> Muestreo por conglomerados</a></li>
<li class="chapter" data-level="6.2.5" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#método-de-kish"><i class="fa fa-check"></i><b>6.2.5</b> Método de Kish</a></li>
<li class="chapter" data-level="6.2.6" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#uso-combinado-de-técnicas-de-muestreo"><i class="fa fa-check"></i><b>6.2.6</b> Uso combinado de técnicas de muestreo</a></li>
<li class="chapter" data-level="6.2.7" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-de-panel"><i class="fa fa-check"></i><b>6.2.7</b> Muestreo de panel</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreos-no-probabilísticos"><i class="fa fa-check"></i><b>6.3</b> Muestreos no probabilísticos</a><ul>
<li class="chapter" data-level="6.3.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-por-cuotas"><i class="fa fa-check"></i><b>6.3.1</b> Muestreo por cuotas</a></li>
<li class="chapter" data-level="6.3.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-de-juicio-o-intencional"><i class="fa fa-check"></i><b>6.3.2</b> Muestreo de juicio o intencional</a></li>
<li class="chapter" data-level="6.3.3" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-autoelegido"><i class="fa fa-check"></i><b>6.3.3</b> Muestreo autoelegido</a></li>
<li class="chapter" data-level="6.3.4" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-accidental-o-según-disponibilidad"><i class="fa fa-check"></i><b>6.3.4</b> Muestreo accidental o según disponibilidad</a></li>
<li class="chapter" data-level="6.3.5" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-bola-de-nieve"><i class="fa fa-check"></i><b>6.3.5</b> Muestreo bola de nieve</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#hacerlo-en-r-5"><i class="fa fa-check"></i><b>6.4</b> Hacerlo en R</a><ul>
<li class="chapter" data-level="6.4.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#aleatorio-simple"><i class="fa fa-check"></i><b>6.4.1</b> Aleatorio simple</a></li>
<li class="chapter" data-level="6.4.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#estratificado"><i class="fa fa-check"></i><b>6.4.2</b> Estratificado</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html"><i class="fa fa-check"></i><b>7</b> Probabilidad: los fundamentos</a><ul>
<li class="chapter" data-level="7.1" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#formas-para-asignar-probabilidades"><i class="fa fa-check"></i><b>7.1</b> Formas para asignar probabilidades</a><ul>
<li class="chapter" data-level="7.1.1" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#asignación-a-priori"><i class="fa fa-check"></i><b>7.1.1</b> Asignación a priori</a></li>
<li class="chapter" data-level="7.1.2" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#asignación-a-posteriori"><i class="fa fa-check"></i><b>7.1.2</b> Asignación a posteriori</a></li>
<li class="chapter" data-level="7.1.3" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#la-relación-entre-asignación-a-priori-y-a-posteriori"><i class="fa fa-check"></i><b>7.1.3</b> La relación entre asignación a priori y a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#operando-con-probabilidades"><i class="fa fa-check"></i><b>7.2</b> Operando con probabilidades</a><ul>
<li class="chapter" data-level="7.2.1" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#con-probabilidades-frecuenciales"><i class="fa fa-check"></i><b>7.2.1</b> Con probabilidades frecuenciales</a></li>
<li class="chapter" data-level="7.2.2" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#con-probabilidades-a-priori"><i class="fa fa-check"></i><b>7.2.2</b> Con probabilidades a priori</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#el-teorema-de-bayes"><i class="fa fa-check"></i><b>7.3</b> El teorema de Bayes</a></li>
<li class="chapter" data-level="7.4" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#variables-aleatorias"><i class="fa fa-check"></i><b>7.4</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html"><i class="fa fa-check"></i><b>8</b> Probabilidad: los modelos</a><ul>
<li class="chapter" data-level="8.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#concepto-de-modelización"><i class="fa fa-check"></i><b>8.1</b> Concepto de modelización</a></li>
<li class="chapter" data-level="8.2" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#distribución-binomial"><i class="fa fa-check"></i><b>8.2</b> Distribución binomial</a><ul>
<li class="chapter" data-level="8.2.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#esperanza-y-varianza"><i class="fa fa-check"></i><b>8.2.1</b> Esperanza y varianza</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#distribución-normal"><i class="fa fa-check"></i><b>8.3</b> Distribución normal</a><ul>
<li class="chapter" data-level="8.3.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#cuantiles"><i class="fa fa-check"></i><b>8.3.1</b> Cuantiles</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#la-idea-de-grados-de-libertad"><i class="fa fa-check"></i><b>8.4</b> La idea de grados de libertad</a></li>
<li class="chapter" data-level="8.5" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#la-distribución-ji-cuadrado-chi2"><i class="fa fa-check"></i><b>8.5</b> La distribución ji cuadrado (<span class="math inline">\(\chi^{2}\)</span>)</a></li>
<li class="chapter" data-level="8.6" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#la-distribución-t-de-student"><i class="fa fa-check"></i><b>8.6</b> La distribución t de Student</a><ul>
<li class="chapter" data-level="8.6.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#la-distribución-f"><i class="fa fa-check"></i><b>8.6.1</b> La distribución F</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#hacerlo-en-r-6"><i class="fa fa-check"></i><b>8.7</b> Hacerlo en R</a><ul>
<li class="chapter" data-level="8.7.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#probabilidades-exactas"><i class="fa fa-check"></i><b>8.7.1</b> Probabilidades exactas</a></li>
<li class="chapter" data-level="8.7.2" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#probabilidades-acumuladas"><i class="fa fa-check"></i><b>8.7.2</b> Probabilidades acumuladas</a></li>
<li class="chapter" data-level="8.7.3" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#cuantiles-1"><i class="fa fa-check"></i><b>8.7.3</b> Cuantiles</a></li>
<li class="chapter" data-level="8.7.4" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#áreas-centrales"><i class="fa fa-check"></i><b>8.7.4</b> Áreas centrales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html"><i class="fa fa-check"></i><b>9</b> Distribuciones en el muestreo</a><ul>
<li class="chapter" data-level="9.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#variabilidad-muestral"><i class="fa fa-check"></i><b>9.1</b> Variabilidad muestral</a><ul>
<li class="chapter" data-level="9.1.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#dos-aspectos-importantes-para-recordar-cuando-se-usan-muestras"><i class="fa fa-check"></i><b>9.1.1</b> Dos aspectos importantes para recordar cuando se usan muestras:</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#características-de-los-estimadores"><i class="fa fa-check"></i><b>9.2</b> Características de los estimadores</a><ul>
<li class="chapter" data-level="9.2.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#insesgabilidad"><i class="fa fa-check"></i><b>9.2.1</b> Insesgabilidad</a></li>
<li class="chapter" data-level="9.2.2" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#consistencia"><i class="fa fa-check"></i><b>9.2.2</b> Consistencia</a></li>
<li class="chapter" data-level="9.2.3" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#eficiencia"><i class="fa fa-check"></i><b>9.2.3</b> Eficiencia</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#distribuciones-de-probabilidad-de-los-estimadores"><i class="fa fa-check"></i><b>9.3</b> Distribuciones de probabilidad de los estimadores</a><ul>
<li class="chapter" data-level="9.3.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#primera-aproximación"><i class="fa fa-check"></i><b>9.3.1</b> Primera aproximación</a></li>
<li class="chapter" data-level="9.3.2" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#distribución-de-la-media-muestral"><i class="fa fa-check"></i><b>9.3.2</b> Distribución de la media muestral</a></li>
<li class="chapter" data-level="9.3.3" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#distribución-de-la-proporción-muestral"><i class="fa fa-check"></i><b>9.3.3</b> Distribución de la proporción muestral</a></li>
<li class="chapter" data-level="9.3.4" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#muestras-pequeñas"><i class="fa fa-check"></i><b>9.3.4</b> Muestras pequeñas</a></li>
<li class="chapter" data-level="9.3.5" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#distribución-de-la-varianza"><i class="fa fa-check"></i><b>9.3.5</b> Distribución de la varianza</a></li>
<li class="chapter" data-level="9.3.6" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#muestreo-desde-dos-poblaciones"><i class="fa fa-check"></i><b>9.3.6</b> Muestreo desde dos poblaciones</a></li>
<li class="chapter" data-level="9.3.7" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#distribución-del-cociente-de-varianzas"><i class="fa fa-check"></i><b>9.3.7</b> Distribución del cociente de varianzas</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#resumen-de-la-relación-entre-estimadores-y-parámetros"><i class="fa fa-check"></i><b>9.4</b> Resumen de la relación entre estimadores y parámetros</a></li>
<li class="chapter" data-level="9.5" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#hacerlo-en-r-7"><i class="fa fa-check"></i><b>9.5</b> Hacerlo en R</a></li>
</ul></li>
<li class="part"><span><b>III Estadística inferencial</b></span></li>
<li class="chapter" data-level="10" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html"><i class="fa fa-check"></i><b>10</b> Estimación por intervalo</a><ul>
<li class="chapter" data-level="10.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#estimación-puntual"><i class="fa fa-check"></i><b>10.1</b> Estimación puntual</a></li>
<li class="chapter" data-level="10.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>10.2</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="10.3" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#estimación-de-la-media"><i class="fa fa-check"></i><b>10.3</b> Estimación de la media</a></li>
<li class="chapter" data-level="10.4" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#estimación-de-la-proporción"><i class="fa fa-check"></i><b>10.4</b> Estimación de la proporción</a><ul>
<li class="chapter" data-level="10.4.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-clopper-pearson"><i class="fa fa-check"></i><b>10.4.1</b> Intervalo de Clopper-Pearson</a></li>
<li class="chapter" data-level="10.4.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-wald"><i class="fa fa-check"></i><b>10.4.2</b> Intervalo de Wald</a></li>
<li class="chapter" data-level="10.4.3" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-wilson"><i class="fa fa-check"></i><b>10.4.3</b> Intervalo de Wilson</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#la-calidad-de-las-estimaciones-por-intervalo"><i class="fa fa-check"></i><b>10.5</b> La calidad de las estimaciones por intervalo</a><ul>
<li class="chapter" data-level="10.5.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#el-error-de-estimación-en-la-media"><i class="fa fa-check"></i><b>10.5.1</b> El error de estimación en la media</a></li>
<li class="chapter" data-level="10.5.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#el-error-de-estimación-en-la-proporción"><i class="fa fa-check"></i><b>10.5.2</b> El error de estimación en la proporción</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#probabilidad-de-cobertura"><i class="fa fa-check"></i><b>10.6</b> Probabilidad de cobertura</a></li>
<li class="chapter" data-level="10.7" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#hacerlo-en-r-8"><i class="fa fa-check"></i><b>10.7</b> Hacerlo en R</a><ul>
<li class="chapter" data-level="10.7.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-para-la-media"><i class="fa fa-check"></i><b>10.7.1</b> Intervalo para la media</a></li>
<li class="chapter" data-level="10.7.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-para-la-proporción"><i class="fa fa-check"></i><b>10.7.2</b> Intervalo para la proporción</a></li>
<li class="chapter" data-level="10.7.3" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#cobertura"><i class="fa fa-check"></i><b>10.7.3</b> Cobertura</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html"><i class="fa fa-check"></i><b>11</b> Prueba de hipótesis: la lógica</a><ul>
<li class="chapter" data-level="11.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#el-razonamiento-de-la-prueba-de-hipótesis"><i class="fa fa-check"></i><b>11.1</b> El razonamiento de la prueba de hipótesis</a></li>
<li class="chapter" data-level="11.2" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#prueba-sobre-la-media"><i class="fa fa-check"></i><b>11.2</b> Prueba sobre la media</a><ul>
<li class="chapter" data-level="11.2.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#la-toma-de-decisión"><i class="fa fa-check"></i><b>11.2.1</b> La toma de decisión</a></li>
<li class="chapter" data-level="11.2.2" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#los-puntos-críticos-en-términos-del-estimador"><i class="fa fa-check"></i><b>11.2.2</b> Los puntos críticos en términos del estimador</a></li>
<li class="chapter" data-level="11.2.3" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#pruebas-unilaterales"><i class="fa fa-check"></i><b>11.2.3</b> Pruebas unilaterales</a></li>
<li class="chapter" data-level="11.2.4" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#otros-ejemplos-de-prueba-de-hipótesis-sobre-la-media"><i class="fa fa-check"></i><b>11.2.4</b> Otros ejemplos de prueba de hipótesis sobre la media</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#prueba-sobre-la-proporción"><i class="fa fa-check"></i><b>11.3</b> Prueba sobre la proporción</a></li>
<li class="chapter" data-level="11.4" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#tipos-de-error-en-las-pruebas-de-hipótesis"><i class="fa fa-check"></i><b>11.4</b> Tipos de error en las pruebas de hipótesis</a></li>
<li class="chapter" data-level="11.5" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#etii-mu-alpha-y-n"><i class="fa fa-check"></i><b>11.5</b> <em>ETII:</em> <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(n\)</span></a><ul>
<li class="chapter" data-level="11.5.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#curva-de-potencia"><i class="fa fa-check"></i><b>11.5.1</b> Curva de potencia</a></li>
<li class="chapter" data-level="11.5.2" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#significación-estadística-y-valor-p"><i class="fa fa-check"></i><b>11.5.2</b> Significación estadística y valor <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#muestras-pequeñas-y-pruebas-t"><i class="fa fa-check"></i><b>11.6</b> Muestras pequeñas y pruebas <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="11.7" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#hacerlo-en-r-9"><i class="fa fa-check"></i><b>11.7</b> Hacerlo en R</a><ul>
<li class="chapter" data-level="11.7.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#prueba-sobre-la-media-1"><i class="fa fa-check"></i><b>11.7.1</b> Prueba sobre la media</a></li>
<li class="chapter" data-level="11.7.2" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#prueba-sobre-la-proporción-1"><i class="fa fa-check"></i><b>11.7.2</b> Prueba sobre la proporción</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#resumen-de-pruebas-sobre-una-muestra"><i class="fa fa-check"></i><b>11.8</b> Resumen de pruebas sobre una muestra</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html"><i class="fa fa-check"></i><b>12</b> Prueba de hipótesis: las aplicaciones</a><ul>
<li class="chapter" data-level="12.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#muestras-independientes"><i class="fa fa-check"></i><b>12.1</b> Muestras independientes</a><ul>
<li class="chapter" data-level="12.1.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-de-diferencia-de-medias"><i class="fa fa-check"></i><b>12.1.1</b> Prueba de diferencia de medias</a></li>
<li class="chapter" data-level="12.1.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#muestras-apareadas"><i class="fa fa-check"></i><b>12.1.2</b> Muestras apareadas</a></li>
<li class="chapter" data-level="12.1.3" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#coeficiente-r-de-pearson"><i class="fa fa-check"></i><b>12.1.3</b> Coeficiente r de Pearson</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#hacerlo-en-r-10"><i class="fa fa-check"></i><b>12.2</b> Hacerlo en R</a><ul>
<li class="chapter" data-level="12.2.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-1."><i class="fa fa-check"></i><b>12.2.1</b> Ejemplo 1.</a></li>
<li class="chapter" data-level="12.2.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-2."><i class="fa fa-check"></i><b>12.2.2</b> Ejemplo 2.</a></li>
<li class="chapter" data-level="12.2.3" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#aplicación-a-los-datos-de-adultos-mayores"><i class="fa fa-check"></i><b>12.2.3</b> Aplicación a los datos de Adultos Mayores</a></li>
<li class="chapter" data-level="12.2.4" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-apareada"><i class="fa fa-check"></i><b>12.2.4</b> Prueba apareada</a></li>
<li class="chapter" data-level="12.2.5" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#coeficiente-de-correlación"><i class="fa fa-check"></i><b>12.2.5</b> Coeficiente de correlación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html"><i class="fa fa-check"></i><b>13</b> Cuando los supuestos no se cumplen</a><ul>
<li class="chapter" data-level="13.0.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#las-pruebas-ji-cuadrado-o-chi-cuadrado"><i class="fa fa-check"></i><b>13.0.1</b> Las pruebas ji cuadrado (o chi cuadrado)</a></li>
<li class="chapter" data-level="13.0.2" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#coeficiente-r_s-de-spearman"><i class="fa fa-check"></i><b>13.0.2</b> Coeficiente <span class="math inline">\(r_s\)</span> de Spearman</a></li>
<li class="chapter" data-level="13.0.3" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#alternativas-no-paramétricas-a-las-pruebas-t"><i class="fa fa-check"></i><b>13.0.3</b> Alternativas no paramétricas a las pruebas t</a></li>
<li class="chapter" data-level="13.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#hacerlo-en-r-11"><i class="fa fa-check"></i><b>13.1</b> Hacerlo en R</a><ul>
<li class="chapter" data-level="13.1.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#ejemplo-1"><i class="fa fa-check"></i><b>13.1.1</b> Ejemplo 1</a></li>
<li class="chapter" data-level="13.1.2" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#ejemplo-2"><i class="fa fa-check"></i><b>13.1.2</b> Ejemplo 2</a></li>
<li class="chapter" data-level="13.1.3" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#prueba-de-la-mediana-1"><i class="fa fa-check"></i><b>13.1.3</b> Prueba de la mediana</a></li>
<li class="chapter" data-level="13.1.4" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#prueba-de-wilcoxon"><i class="fa fa-check"></i><b>13.1.4</b> Prueba de Wilcoxon</a></li>
<li class="chapter" data-level="13.1.5" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#muestras-apareadas-1"><i class="fa fa-check"></i><b>13.1.5</b> Muestras apareadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html"><i class="fa fa-check"></i><b>14</b> Tamaño del efecto</a><ul>
<li class="chapter" data-level="14.1" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#significación-estadística-y-significación-práctica"><i class="fa fa-check"></i><b>14.1</b> Significación estadística y significación práctica</a></li>
<li class="chapter" data-level="14.2" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#medidas-de-tamaño-del-efecto"><i class="fa fa-check"></i><b>14.2</b> Medidas de tamaño del efecto</a><ul>
<li class="chapter" data-level="14.2.1" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#prueba-t-para-diferencia-de-medias"><i class="fa fa-check"></i><b>14.2.1</b> Prueba t para diferencia de medias</a></li>
<li class="chapter" data-level="14.2.2" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#análisis-de-la-varianza"><i class="fa fa-check"></i><b>14.2.2</b> Análisis de la varianza</a></li>
<li class="chapter" data-level="14.2.3" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#correlaciones"><i class="fa fa-check"></i><b>14.2.3</b> Correlaciones</a></li>
<li class="chapter" data-level="14.2.4" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#regresión-lineal"><i class="fa fa-check"></i><b>14.2.4</b> Regresión lineal</a></li>
<li class="chapter" data-level="14.2.5" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#pruebas-ji-cuadrado"><i class="fa fa-check"></i><b>14.2.5</b> Pruebas ji cuadrado</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#análisis-de-la-potencia"><i class="fa fa-check"></i><b>14.3</b> Análisis de la potencia</a></li>
<li class="chapter" data-level="14.4" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#hacerlo-en-r-12"><i class="fa fa-check"></i><b>14.4</b> Hacerlo en R</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Generado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="relación-entre-variables-el-análisis" class="section level1">
<h1><span class="header-section-number">Capítulo 5</span> Relación entre variables: el análisis</h1>
<p>En el capítulo anterior hemos tratado la relación entre dos variables en
escalas nominales, y señalamos que si se trata de variables de nivel
superior es posible crear categorías y tratarlas del mismo modo. En
cuanto a la medida de la intensidad de la relación, nos hemos limitado
al caso de dos variables dicotómicas, es decir, con dos categorías en
cada una, con lo que la tabla resultante es de dos por dos y calculamos
el coeficiente Q de Kendall - Yule. Ahora se amplía el dominio de
nuestro análisis, incorporando herramientas que permiten poner a prueba
la hipotética relación entre dos variables de nivel nominal con más de
dos categorías cada una y variables de nivel superior (ordinales y
métricas).</p>
<div id="relaciones-entre-variables-vs.comparación-de-grupos" class="section level2">
<h2><span class="header-section-number">5.1</span> Relaciones entre variables vs. comparación de grupos</h2>
<p>Según el contexto en que se aplique y también según el modo en que se formulan las preguntas, los resultados de los procedimientos estadísticos que veremos a continuación pueden interpretarse de diferente manera. Tomemos como ejemplo el caso que interese observar la relación del tipo de violencia<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> con el lugar donde sucede, que se analizará más adelante. Aunque son estadísticamente equivalentes, no es lo mismo preguntar si “el lugar incide sobre el tipo de violencia”, o si “el tipo de violencia difiere según el lugar”. Aquí es más pertinente el planteo del problema como una comparación de grupos (que quedan definidos por los diferentes lugares) antes que como una relación entre variables. Lo mismo pasa cuando se comparan los resultados de un examen entre quienes cursan por la tarde o la mañana. Cuando hay control de variables, como en el diseño experimental o en la evaluación de impacto, el paralelismo entre las dos lecturas es más cercano. Así, preguntar si un grupo de deportistas que recibió un suplemento en su dieta, tiene mejor rendimiento que uno que no lo recibió (planteo en términos de comparación de grupos), equivale a preguntar si el suplemento dietario incide sobre el rendimiento (planteo en términos de relación entre variables). Las operaciones estadísticas que responden a las dos preguntas son las mismas, pero según el caso, una manera de formular el problema puede ser más adecuada que otra, así como la lectura del resultado.<br />
Por ejemplo, cuando se busca evaluar el impacto de una política pública dirigida a reducir enfermedades parasitarias en memnores de edad, una estrategia consiste en comparar la prevalencia de esas enfermedades entre quienes han sido destinatarios de esa política, y quienes no lo fueron. Esta prevalencia es la “variable de salida” o “de respuesta” y es aquello sobre lo cual la política pretende impactar. La pregunta por la diferencia entre los dos grupos equivale a indagar sobre el efecto de la intervención.<br />
La investigación social apela continuamente a las comparaciones: el pasado y el presente, mujeres y varones, sociedades industriales y agrarias (<span class="citation">Pescosolido and Kelley (<a href="#ref-Pescosolido1983">1983</a>)</span>), grupos minoritarios y población general, por eso es necesario contar con herramientas que permitan analizar la manera en que suceden estas diferencias y las relaciones entre variables que se asocian a ellas.</p>
</div>
<div id="variables-nominales" class="section level2">
<h2><span class="header-section-number">5.2</span> Variables nominales</h2>
<p>Sobre el final del capítulo anterior presentamos el concepto de
independencia estadística y vimos la manera de calcular las frecuencias
de las celdas que se esperarían encontrar si las variables fueran
independientes. Para hacer esto es suficiente multiplicar las
frecuencias marginales correspondientes a cada celda y dividir el
resultado por el total de casos.
Para el ejemplo de las diferencias en el tipo de violencia según área
geográfica, una muestra de 500 casos provee la siguiente distribución
conjunta:</p>
<table>
<caption><span id="tab:frecObs">Tabla 5.1: </span>Clasificación de diferentes tipos de violencia según área donde se manifiesta (datos ficticios)</caption>
<thead>
<tr class="header">
<th></th>
<th align="center">áreas rurales</th>
<th align="center">ciudades grandes</th>
<th align="center">ciudades pequeñas</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>autoinfligida</td>
<td align="center">15</td>
<td align="center">100</td>
<td align="center">35</td>
<td align="center">150</td>
</tr>
<tr class="even">
<td>colectiva</td>
<td align="center">5</td>
<td align="center">35</td>
<td align="center">10</td>
<td align="center">50</td>
</tr>
<tr class="odd">
<td>interpersonal</td>
<td align="center">90</td>
<td align="center">110</td>
<td align="center">100</td>
<td align="center">300</td>
</tr>
<tr class="even">
<td>Total</td>
<td align="center">110</td>
<td align="center">245</td>
<td align="center">145</td>
<td align="center">500</td>
</tr>
</tbody>
</table>
<p>Una primera aproximación consiste en calcular frecuencias relativas.
Dado que nuestro interés está en comparar el tipo de violencia según las
áreas, calcularemos los porcentajes según las columnas de la tabla <a href="relación-entre-variables-el-análisis.html#tab:frecObs">5.1</a> y resulta:</p>
<table>
<caption><span id="tab:unnamed-chunk-264">Tabla 5.2: </span>Frecuencia relativas (en %) por columnas de la clasificación de diferentes tipos de violencia según área donde se manifiesta</caption>
<thead>
<tr class="header">
<th></th>
<th align="center">áreas rurales</th>
<th align="center">ciudades grandes</th>
<th align="center">ciudades pequeñas</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>autoinfligida</td>
<td align="center">13.6</td>
<td align="center">40.8</td>
<td align="center">24.1</td>
<td align="center">30</td>
</tr>
<tr class="even">
<td>colectiva</td>
<td align="center">4.5</td>
<td align="center">14.3</td>
<td align="center">6.9</td>
<td align="center">10</td>
</tr>
<tr class="odd">
<td>interpersonal</td>
<td align="center">81.8</td>
<td align="center">44.9</td>
<td align="center">69.0</td>
<td align="center">60</td>
</tr>
<tr class="even">
<td>Total</td>
<td align="center">100.0</td>
<td align="center">100.0</td>
<td align="center">100.0</td>
<td align="center">100</td>
</tr>
</tbody>
</table>
<p>Si no consideramos el área, se ve (en la columna de los totales) que la violencia interpersonal es la más frecuente (60%), seguida de la
autoinfligida con el 30%. Este patrón de distribución en las distintas
formas de violencia se mantiene en las diferentes áreas, pero en más
acentuado en las rurales, donde la categoría modal (que sigue siendo
interpersonal) alcanza el 82% del total del área. Por el contrario, la
violencia autoinfligida, que es el 30% del total, sube al 41% en grandes
ciudades y solo representa el 14% de las formas de violencia que se
observan en áreas rurales. Así, parecería que hay diferencia en la
distribución de los tipos de violencia según las áreas que están
considerándose.<br />
Buscaremos ahora de cuantificar la intensidad de esa relación, para lo que nos preguntaremos cuáles serían las frecuencias de las celdas si el tipo de violencia fuera independiente del área donde sucede, es decir, si se observara la misma proporción de los distintos tipos de violencia en todas las áreas. Usemos el concepto de independencia estadística para calcular las frecuencias esperadas correspondientes a la tabla <a href="relación-entre-variables-el-análisis.html#tab:frecObs">5.1</a>.</p>
<table>
<caption><span id="tab:frecEsperada">Tabla 5.3: </span>Frecuencias esperadas bajo la hipótesis de independencia entre el tipo de violencia y el área donde se observa</caption>
<thead>
<tr class="header">
<th></th>
<th align="center">áreas rurales</th>
<th align="center">ciudades grandes</th>
<th align="center">ciudades pequeñas</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>autoinfligida</td>
<td align="center">33</td>
<td align="center">74</td>
<td align="center">44</td>
<td align="center">151</td>
</tr>
<tr class="even">
<td>colectiva</td>
<td align="center">11</td>
<td align="center">24</td>
<td align="center">14</td>
<td align="center">49</td>
</tr>
<tr class="odd">
<td>interpersonal</td>
<td align="center">66</td>
<td align="center">147</td>
<td align="center">87</td>
<td align="center">300</td>
</tr>
<tr class="even">
<td>Total</td>
<td align="center">110</td>
<td align="center">245</td>
<td align="center">145</td>
<td align="center">500</td>
</tr>
</tbody>
</table>
<p>Estas frecuencias están calculadas como indicamos en el capítulo
anterior, haciendo:</p>
<p><span class="math display">\[f_{ij}^{e} = \frac{f_{i}*f_{j}}{n}\]</span></p>
<p>Por ejemplo, la frecuencia de la celda 1,2 resultó de <span class="math inline">\(f_{1 2}^{e} = \frac{151*245}{500} = 73.99\)</span> que redondeamos a 74.<br />
La tabla <a href="relación-entre-variables-el-análisis.html#tab:frecEsperada">5.3</a> muestra las frecuencias que esperaríamos encontrar si no hubiera relación entre las variables, es decir, si éstas fueran independientes. A ellas debemos compararlas con las que realmente hemos encontrado; las que se denominan frecuencias observadas.<br />
Si halláramos que nuestras frecuencias observadas son muy similares a
las que se esperan bajo la hipótesis de independencia, diríamos que las variables “están cerca” de ser independientes, o lo que es equivalente, que habría escasa relación entre ellas, . Por el contrario, si las frecuencias observadas fueran muy diferentes de las esperadas, creeríamos que las variables “están lejos” de ser independientes, es decir, que habría alguna relación entre ellas. Para decidir, debemos comparar la tabla <a href="relación-entre-variables-el-análisis.html#tab:frecObs">5.1</a> con la <a href="relación-entre-variables-el-análisis.html#tab:frecEsperada">5.3</a>.<br />
Una opción para medir la distancia entre los dos conjuntos de frecuencias es la de restar las correspondientes de cada celda; pero si hacemos eso nos encontraremos con un problema parecido al que tuvimos cuando intentamos observar la dispersión restando los valores de la media: la suma da cero. Por única vez realizaremos esta operación de manera manual para verificar el resultado:</p>
<p><span class="math display">\[(15 - 33) + (100 - 74) + (35 - 44) + (5 - 11) + (35 - 24) + (10 - 14) + (90 - 66) +\]</span>
<span class="math display">\[(110 - 147) + (100 - 87) = 0\]</span></p>
<p>Obtenemos este resultado porque las frecuencias marginales son fijas y lo que una celda tiene de más, lo tiene otra de menos. Siempre sucederá así y por esa razón, no podemos saber si las observadas están cerca o lejos de las esperadas con el procedimiento directo de restarlas. Por el contrario, para medir la distancia entre los dos conjuntos de frecuencias (observadas y esperadas) se usa la siguiente expresión:</p>
<p><span class="math display">\[\sum_{i=1; j=1}^{i=f; j=c}{\frac{(f_{ij}^o - f_{ij}^e)^2}{f_{ij}^e}}\]</span></p>
<p>La expresión nos dice que deben restarse cada una de las frecuencias esperadas de cada observada correspondiente, elevar esa diferencia al cuadrado<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> y dividir el resultado por cada una de las frecuencias esperadas. Los subíndices mantienen la notación del capítulo anterior: <span class="math inline">\(i\)</span> es el índice de filas, que va desde la primera (<span class="math inline">\(i=1\)</span>) hasta la última (<span class="math inline">\(f\)</span> es el número total de filas); <span class="math inline">\(j\)</span> es el índice de las columnas, que también empieza en 1 (<span class="math inline">\(j=1\)</span>) y termina en <span class="math inline">\(c\)</span>, que es el número total de columnas<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a>. Vamos a aplicarla una vez, solo para ver su funcionamiento, luego la pediremos al programa:</p>
<p><span class="math display">\[\frac{(15 - 33)^{2}}{33} +\frac{(100 - 74)^{2}}{74} + \frac{(35 - 44)^{2}}{44} + \frac{(5 - 11)^{2}}{11} + \frac{(35 - 24)^{2}}{24} + \frac{(10 - 14)^{2}}{14} +\]</span>
<span class="math display">\[\frac{(90 - 66)^{2}}{66} +  \frac{(110 - 147)^{2}}{147} + \frac{(100 - 87)^{2}}{87}   = 50.18\]</span></p>
<p>El número que resulta de esta operación se llama puntaje chi cuadrado (o también ji cuadrado), se indica con el símbolo <span class="math inline">\(\chi^{2}\)</span> y es una
medida de la distancia a la que se encuentran las frecuencias observadas de las que se esperaría encontrar si las variables fueran
independientes.<br />
El puntaje <span class="math inline">\(\chi^{2}\)</span> no puede ser negativo, ya que proviene de la suma de números elevados al cuadrado. Solo puede ser cero si todos los términos de la suma son cero, es decir, si cada frecuencia observada es exactamente igual a la esperada correspondiente. En ese caso no habría duda en decir que las variables son independientes, cumplirían exactamente con la definición de independencia estadística.<br />
El puntaje <span class="math inline">\(\chi^{2}\)</span> indica si las frecuencias observadas están cerca o lejos de las esperadas, pero ¿qué tan grande debe ser para que consideremos lejanas a las frecuencias?<br />
Dos problemas que tiene este puntaje son:<br />
- puede ser indefinidamente grande<br />
- su valor depende del número de casos que se evalúan y de la dimensión de la tabla.</p>
<p>Así, por ejemplo, si multiplicamos por 10 todas las frecuencias de la tabla <a href="relación-entre-variables-el-análisis.html#tab:frecObs">5.1</a>, obtenemos:</p>
<table>
<caption><span id="tab:unnamed-chunk-266">Tabla 5.4: </span>Ejemplo de expansión artificial del total de casos de la tabla de frecuencias observadas</caption>
<thead>
<tr class="header">
<th></th>
<th align="center">áreas rurales</th>
<th align="center">ciudades grandes</th>
<th align="center">ciudades pequeñas</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>autoinfligida</td>
<td align="center">150</td>
<td align="center">1000</td>
<td align="center">350</td>
<td align="center">1500</td>
</tr>
<tr class="even">
<td>colectiva</td>
<td align="center">50</td>
<td align="center">350</td>
<td align="center">100</td>
<td align="center">500</td>
</tr>
<tr class="odd">
<td>interpersonal</td>
<td align="center">900</td>
<td align="center">1100</td>
<td align="center">1000</td>
<td align="center">3000</td>
</tr>
<tr class="even">
<td>Total</td>
<td align="center">1100</td>
<td align="center">2450</td>
<td align="center">1450</td>
<td align="center">5000</td>
</tr>
</tbody>
</table>
<p>Aunque los valores absolutos son diez veces más grandes, no hubo cambios en las frecuencias relativas, por ejemplo, en la celda 1,1: <span class="math inline">\(\frac{150}{1100} = 0,14\ (14\%)\)</span> lo mismo que había dado esa celda en la tabla original. Cualquiera sea la intensidad de la relación entre estas dos variables, ésta no ha cambiado porque hayamos multiplicado todo por 10, sin embargo, si calculamos el puntaje <span class="math inline">\(\chi^{2}\)</span> en la tabla 5 obtenemos 501.9, es decir un número 10 veces más grande. Entonces el puntaje <span class="math inline">\(\chi^{2}\)</span> puede cambiar muy ampliamente sin que cambien las frecuencias relativas; esto nos dice que este puntaje no mide de manera directa la asociación entre dos variables, por ello:</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Para comparar la intensidad de la asociación, el puntaje <span class="math inline">\(\chi^{2}\)</span> solo en válido si las tablas tienen la misma dimensión y el mismo número de casos.</td>
</tr>
</tbody>
</table>
<div id="coeficientes-de-asociación-para-variables-nominales" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Coeficientes de asociación para variables nominales</h3>
<p>Para medir la asociación, debe eliminarse el efecto de la cantidad de
casos y también de la dimensión de la tabla. Calcularemos tres
coeficientes que nos permitan evaluar el grado o intensidad de la
relación y que tengan un límite superior de modo que podamos juzgarlos como elevados o bajos.<br />
El primero de ellos es el <strong>coeficiente <span class="math inline">\(\varphi\)</span></strong><a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a>, válido para medir la asociación entre dos variables dicotómicas (o binarias), se calcula como:</p>
<p><span class="math display">\[\varphi = \sqrt{\frac{\chi^{2}}{n}}\]</span></p>
<p>Vale cero si las variables son independientes e indica mayor asociación cuando está más cerca de uno.<br />
Ejemplo (datos ficticios): en el análisis de la calidad de ítems de un examen, se observa las veces que una pregunta es correctamente
respondida por quienes aprobaron el examen y por quienes no lo aprobaron. Para el caso de una pregunta a la que se llama #7745, que fue respondida por 100 personas (a quienes les tocó por azar), la
información se presenta en una tabla de <span class="math inline">\(2 \times 2\)</span>:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">correcta</th>
<th align="center">incorrecta</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>aprobó</td>
<td align="center">50</td>
<td align="center">15</td>
<td align="center">65</td>
</tr>
<tr class="even">
<td>no aprobó</td>
<td align="center">10</td>
<td align="center">25</td>
<td align="center">35</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="center">60</td>
<td align="center">40</td>
<td align="center">100</td>
</tr>
</tbody>
</table>
<p>Para la que el puntaje <span class="math inline">\(\chi^{2}\)</span> vale 22.16, y el coeficiente resulta en:</p>
<p><span class="math display">\[\varphi = \sqrt{\frac{22.16}{100}} = 0.47\]</span></p>
<p>Como el cálculo del puntaje <span class="math inline">\(\chi^{2}\)</span> es engorroso para hacer
manualmente, existe una expresión alternativa para obtener el coeficiente <span class="math inline">\(\varphi\)</span> cuando las tablas son de dos por dos, que solo usa las frecuencias observadas en la tabla. Si estas son:</p>
<table>
<thead>
<tr class="header">
<th align="left">a</th>
<th align="left">b</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">c</td>
<td align="left">d</td>
</tr>
</tbody>
</table>
<p>La fórmula de cálculo del coeficiente <span class="math inline">\(\varphi\)</span> es:</p>
<p><span class="math display">\[\varphi = \frac{(c*b) - (a*d)}{\sqrt{(a + b)*(c + d)*(a + c)*(b + d)}}\]</span></p>
<p>Aplicado a los datos del ejemplo da:</p>
<p><span class="math display">\[\varphi = \frac{(10*15) - (50*25)}{\sqrt{(50 + 15)*(10 + 25)*(50 + 10)*(15 + 25)}} = \frac{1100}{2337} = 0.47\]</span></p>
<p>Otra forma de medir la asociación entre dos variables, cuando alguna de ellas o las dos, tienen más de dos categorías, es el <strong>coeficiente de contingencia</strong>, C de Pearson, se calcula del siguiente modo a partir del puntaje <span class="math inline">\(\chi^{2}\)</span>:</p>
<p><span class="math display">\[C = \sqrt{\frac{\chi^{2}}{\chi^{2} + n}}\]</span></p>
<p>Al igual que <span class="math inline">\(\varphi\)</span>, este coeficiente no puede ser menor que cero (0) y solo toma ese valor si las variables son independientes (es decir cuando <span class="math inline">\(\chi^{2} = 0\)</span>). Tampoco puede ser mayor que uno (1), pero su valor máximo depende de la dimensión de la tabla.<br />
Solo en el caso particular en que la tabla sea cuadrada (misma cantidad de filas que de columnas), el valor máximo del coeficiente es: <span class="math inline">\(C_{\max} = \sqrt{\frac{f - 1}{f}}\)</span> , o lo que es lo mismo :
<span class="math inline">\(C_{\max} = \sqrt{\frac{c - 1}{c}}\)</span></p>
<p>Porque nos referimos a tablas cuadradas, en las que <span class="math inline">\(f=c\)</span>.<br />
Si la tabla no es cuadrada, sino de dimensión <span class="math inline">\(f X c\)</span>, el valor máximo es:</p>
<p><span class="math display">\[C_{\max} = \sqrt{\frac{\min(f,c) - 1}{min(f,c)}}\]</span></p>
<p>En la que <span class="math inline">\(min(f,c)\)</span> es el más chico de los dos números <span class="math inline">\(f\)</span> o <span class="math inline">\(c\)</span>.<br />
De este modo se obtiene un coeficiente que indica el grado de la
asociación entre dos variables que es apto para tablas de cualquier dimensión, no solo para las de <span class="math inline">\(2 \times 2\)</span>, por lo que mejora lo que mide el coeficiente Q de Kendall - Yule. Reemplacemos los valores para el ejemplo de los tipos de violencia:</p>
<p><span class="math display">\[C = \sqrt{\frac{\chi^{2}}{\chi^{2} + n}} = \sqrt{\frac{50.19}{50.19 + 500}} = 0.30\]</span></p>
<p>Para decidir si este resultado es alto o bajo, es decir, si la relación es fuerte o débil, calculemos el máximo que podría haber alcanzado para una tabla de 3X3:</p>
<p><span class="math display">\[C_{\max} = \sqrt{\frac{f - 1}{f}} = \sqrt{\frac{3 - 1}{3}} = \sqrt{\frac{2}{3}} = 0.82\]</span></p>
<p>Entonces el valor que hemos encontrado es moderado, y nos indica que la relación entre el tipo de violencia y el tamaño de las ciudades no es intensa.<br />
El tercer (y último) coeficiente que calcularemos para variables
nominales está también basado en el puntaje <span class="math inline">\(\chi^{2}\)</span> y tiene un valor máximo de 1 (uno). Se llama <strong>coeficiente V de Cramer</strong> y se calcula así:</p>
<p><span class="math display">\[V = \sqrt{\frac{\chi^{2}}{n*min(f - 1, c - 1)}}\]</span></p>
<p>La expresión <span class="math inline">\(min(f-1, c-1)\)</span>, tiene el mismo significado que en
<span class="math inline">\(C_{max}\)</span>; es mínimo entre el número de filas menos uno y el número de
columnas menos uno. Para obtenerlo, se resta 1 al número de filas, luego se resta 1 al número de columnas y se elige el menor de los dos. Si la tabla es de <span class="math inline">\(3 \times 2\)</span> se hace <span class="math inline">\(3 - 1 = 2\)</span> y <span class="math inline">\(2 - 1 = 1\)</span>, entre 2 y 1 el mínimo es 1 y ése es el número que ubicamos en el denominador, multiplicando a <span class="math inline">\(n\)</span>. En este ejemplo, las filas y las columnas son tres, por lo que se toma el mínimo entre <span class="math inline">\(3-1\)</span> y <span class="math inline">\(3-1\)</span>, el resultado es 2, y el coeficiente V de Cramer resulta:</p>
<p><span class="math display">\[V = \sqrt{\frac{\chi^{2}}{n*min(f - 1,c - 1)}} = \sqrt{\frac{50.19}{500*min(3 - 1,\ 3 - 1)}} = \sqrt{\frac{50.19}{500*2}} = 0.22\]</span></p>
<p>Como el valor máximo que puede alcanzar este coeficiente es 1 (uno), en este caso se trata de una relación moderada entre las dos variables.</p>
</div>
</div>
<div id="variables-de-nivel-ordinal" class="section level2">
<h2><span class="header-section-number">5.3</span> Variables de nivel ordinal</h2>
<p>Si nuestro problema es el de describir la relación entre variables cuyas
categorías están ordenadas, es decir variables ordinales, los
coeficientes anteriores son válidos: pero como sucedió con las medidas
descriptivas, el mayor nivel de medición permite calcular coeficientes
más elaborados y que, por esa razón, informen más acerca de la relación
entre las variables que se analizan. Un punto a tener en cuenta es que
cuando se trata con dos variables, la del menor nivel de medición es la
que manda. Así, para relacionar una ordinal y una nominal, debe usarse
un coeficiente <span class="math inline">\(V\)</span> o <span class="math inline">\(C\)</span>, como si fueran las dos nominales.<br />
Si las dos variables son ordinales o si una es ordinal y la otra
intervalar o proporcional, es posible calcular un coeficiente que tiene
en cuenta los “rangos” es decir la posición de cada categoría respecto
de las demás, su carácter de primera, segunda, etc., es decir, el orden.<br />
Sea el problema de indagar por la relación que podría haber entre el
resultado que se obtiene al rendir un examen de ingreso a una
carrera y el nivel de educación de las madres de quienes rinden, consideraremos como
variables <em>el nivel máximo de educación de la madre</em> de cada uno y <em>el orden de mérito alcanzado en el ingreso</em> a esa carrera; ambas variables
son ordinales. Tratemos solo la situación de pocos casos por ahora. Si
para el orden de mérito codificamos como 1, 2, 3, …, el primer lugar en el
ingreso, el segundo, etc. y para la educación de la madre usamos 1 =
universitario completo, 2 = universitario incompleto, etc., entonces el
fragmento de la matriz de datos para 8 observaciones tendría una forma
como esta:</p>
<table>
<thead>
<tr class="header">
<th align="center">OM</th>
<th align="center">educamadre</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">5</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">3</td>
</tr>
</tbody>
</table>
<p>Que está ordenada según los valores de la primera variable (orden de
mérito). A estos datos no conviene presentarlos en una tabla de doble entrada, porque cada orden de mérito corresponde a un único individuo, por lo que resultaría una tabla tan poco resumida como la siguiente:</p>
<table>
<caption><span id="tab:unnamed-chunk-269">Tabla 5.5: </span>Distribución conjunta de las frecuencias del orden de mérito en el ingreso a una carrera universitaria y el nivel de educación de la madre.</caption>
<thead>
<tr class="header">
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<p>Esta tabla no es útil, ya que tiene tantas filas como la matriz de datos (porque cada orden de mérito corresponde a una sola persona), hay solo un caso en cada celda no vacía y hay muchas celdas vacías (con frecuencia cero). Por eso, cuando se trata de variables de este nivel de medición, no se usan tablas de doble entrada para representar los datos, solo se calcula un coeficiente que indique la intensidad de la relación. Este coeficiente se llama coeficiente de <strong>correlación por rangos, de Spearman</strong> y para calcularlo hay que transformar los valores de las variables en rangos, de mayor a menor, de manera que al máximo valor de cada variable corresponda el 1, al siguiente el 2 y así sucesivamente.<br />
En nuestro ejemplo, el orden de mérito ya está en rangos, uno para el
primero, dos para el segundo y un rango para cada persona. No es así
para el nivel de educación, ya que varias personas pueden tener el
mismo, a esta variable la transformaremos en rangos. El mayor nivel de
educación observado es 2 (universitario incompleto) a ese valor le
correspondería el rango 1 (uno), pero hay tres madres con ese nivel de
educación, ellas deberían llevar los rangos 1, 2 y 3, como están
empatadas, les asignamos a todas el promedio de los tres rangos: 2.
Luego sigue el nivel de educación 3 (secundario completo) a quien
deberíamos asignar el rango 4, pero acá también hay empate entre tres
casos, corresponderían los rangos 4, 5 y 6, nuevamente usamos el
promedio de los tres rangos para asignar a los tres el mismo: 5. Sigue
el nivel 4 (secundario incompleto), al que asignamos el rango siguiente:
7, ya que hay solo un caso aquí; y lo mismo pasa con el nivel 5
(primario completo) al que le toca rango 8.<br />
Resumiendo entonces, la transformación de los valores de las variables
en rangos resulta así:</p>
<table>
<colgroup>
<col width="26%" />
<col width="23%" />
<col width="19%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Orden de mérito en el ingreso</th>
<th align="center">Rango del orden de mérito</th>
<th align="center">Educación de la madre</th>
<th align="center">Rango de la educación de la madre</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">3</td>
<td align="center">3</td>
<td align="center">5</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">4</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">5</td>
<td align="center">3</td>
<td align="center">5</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">6</td>
<td align="center">4</td>
<td align="center">7</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">7</td>
<td align="center">5</td>
<td align="center">8</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">8</td>
<td align="center">3</td>
<td align="center">5</td>
</tr>
</tbody>
</table>
<p>No ha sido necesario transformar los valores del orden de mérito, porque ya correspondían uno a cada persona.<br />
Una vez construidos los rangos, se observa, para cada caso la diferencia
entre el rango de una variable y de la otra, esas diferencias se
llamarán <span class="math inline">\(d\)</span>.</p>
<table>
<caption><span id="tab:unnamed-chunk-271">Tabla 5.6: </span>Cálculo de las diferencias entre los rangos de dos variables ordinales</caption>
<thead>
<tr class="header">
<th align="center">Rango del orden de mérito</th>
<th align="center">Rango de la educación de la madre</th>
<th align="center"><span class="math inline">\(d\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">-1</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">5</td>
<td align="center">-2</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">5</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">7</td>
<td align="center">-1</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">8</td>
<td align="center">-1</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">5</td>
<td align="center">3</td>
</tr>
</tbody>
</table>
<p>Estas diferencias indican la distancia que hay entre los dos
ordenamientos, si fueran ambos iguales (si el máximo de uno coincidiera
con el máximo del otro y así en todas las categorías), tendríamos una
asociación perfecta entre las dos variables. Por el contrario si el
orden estuviese exactamente invertido (si el rango máximo de una
variable coincidiera con el rango mínimo de la otra y así en las demás)
la relación también sería perfecta, pero inversa.<br />
La intensidad de la relación se mide entonces con el que hemos llamado
coeficiente de Spearman, la expresión de su cálculo es la siguiente:</p>
<p><span class="math display">\[r_{s} = 1 - \frac{6*\sum_{i = 1}^{n}d_{i}^{2}}{n^{3} - n}\]</span></p>
<p>En la que:<br />
- <span class="math inline">\(d_{i}\)</span> son las diferencias de rangos (calculadas en la última columna de la tabla de arriba) que en la fórmula van elevadas al cuadrado.<br />
- La sumatoria indica que ésta va desde la primera de las diferencias (<span class="math inline">\(i=1\)</span>) hasta la última (<span class="math inline">\(n\)</span>).<br />
- <span class="math inline">\(n\)</span> es el número total de observaciones.</p>
<p>Este coeficiente puede ser positivo o negativo y tiene un campo de
variación igual al del Q de Kendall - Yule, es decir, entre <span class="math inline">\(-1\)</span> y 1, es decir:</p>
<p><span class="math display">\[- 1 \leq r_{s} \leq 1\]</span></p>
<p>Al igual que el coeficiente de Kendall - Yule, los valores próximos a 1 ó a <span class="math inline">\(-1\)</span> se interpretan como propios de una asociación fuerte (intensa) y
los cercanos a 0 (cero), sean positivos o negativos, corresponden a
asociaciones débiles. Si un coeficiente vale 1 ó <span class="math inline">\(-1\)</span> diremos que la
asociación es perfecta, pero eso no es algo que suceda en la realidad,
del mismo modo que si el coeficiente fuera exactamente 0 (cero), la
asociación sería nula y otra vez es muy poco común que eso suceda con
datos reales.<br />
A diferencia de los coeficientes usados para variables nominales, ahora
el signo importa: cuando es positivo da cuenta de una relación directa
entre las dos variables, una relación en la que cuando una aumenta, la
otra también lo hace. Si el coeficiente es negativo indica relación
inversa, el crecimiento de una variable se acompaña del decrecimiento de
la otra. En este nivel de medición (ordinal) podemos hacer estos
juicios, podemos decir “aumenta” o “disminuye”, porque las categorías
están ordenadas, por esa razón podemos analizar no solo la intensidad de
la relación, sino también si se trata de una relación directa o inversa.<br />
Se trata de dos características independientes de cada relación: puede
ser fuerte y directa; o fuerte e inversa; o bien débil y directa; o
débil e inversa. Un error muy frecuente es creer que si el coeficiente
es negativo, la relación es débil, no es así. Es débil si el coeficiente
es cercano a 0 (cero), es igualmente débil si <span class="math inline">\(r_s=0.03\)</span> como si
<span class="math inline">\(r_s=-0.03\)</span>, el signo del coeficiente no aporta para saber si es fuerte
o débil. Del mismo modo, es igual de fuerte una relación en la que
<span class="math inline">\(r_s=0.96\)</span> como una en la que <span class="math inline">\(r_s=-0.96\)</span>.<br />
Para obtener el valor del coeficiente en nuestro ejemplo, vamos primero
a calcular las <span class="math inline">\({d_{i}}^{2}\)</span>:</p>
<table>
<thead>
<tr class="header">
<th align="center">Rango del orden de mérito</th>
<th align="center">Rango de la educación de la madre</th>
<th align="center"><span class="math inline">\(d\)</span></th>
<th align="center"><span class="math inline">\(d_i^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">-1</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">5</td>
<td align="center">-2</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">5</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">7</td>
<td align="center">-1</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">8</td>
<td align="center">-1</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">5</td>
<td align="center">3</td>
<td align="center">9</td>
</tr>
</tbody>
</table>
<p>Por lo que la suma de la última columna es 20. Al reemplazar los valores
en la expresión de <span class="math inline">\(r_s\)</span>, obtenemos:</p>
<p><span class="math display">\[r_{s} = 1 - \frac{6*\sum_{i = 1}^{n}d_{i}^{2}}{n^{3} - n} = 1 - \frac{6*20}{8^{3} - 8} = 1 - \frac{120}{512 - 8} = 1 - \frac{120}{504} = 0.76\]</span></p>
<p>Este valor de <span class="math inline">\(r_{s} = 0.76\)</span>, indica una asociación intensa y positiva
entre la educación de la madre y los resultados del ingreso a la
universidad. Que sea positiva quiere decir que estudiantes con madres de
mayor educación obtienen mejores resultados en el ingreso a esa carrera.
Como ya hemos señalado, esto no quiere decir causalidad, no significa
que la causa del resultado en el ingreso sea la educación de la madre.
El problema de la causalidad es teórico y depende del análisis que se
hace de las relaciones entre los conceptos, en este ejemplo, la
educación de la madre es uno de muchos de los factores
interrelacionados, que inciden sobre el resultado que obtiene en el examen de ingreso.
Este coeficiente (como sucede con todos los coeficientes de asociación)
no revelan la causalidad sino cuán frecuente resulta que los cambios
de una variable se vean acompañados de cambios en la otra.<br />
Para ilustrar con otros ejemplos de relaciones entre variables
ordinales, consideremos el caso de poner en correspondencia el ranking de temas
musicales de una semana con la frecuencia con que cada tema es
reproducido en la radio, esperamos hallar que la relación sea muy fuerte
y directa: los temas de mayor posición en el ranking son también los que
más frecuentemente se pasan en la radio. Al revés, en la relación entre
el rating de los programas de televisión y el contenido cultural que
ofrecen esperamos una relación también fuerte, pero ahora inversa: los
de mayor rating son habitualmente lo que menos contenido cultural
tienen.<br />
Este coeficiente es adecuado, no solo cuando las variables son ordinales, sino cuando son cuantitativas (intervalares o proporcionales) y existen casos atípicos, que afectarían el cálculo de otro coeficiente que se verá a continuación. Se dice que este coeficiente es “robusto”, para indicar que se ve poco afectado cuando no se cumplen supuestos sobre las variables cuya relación se analiza. Para que la interpretación del coeficiente de Spearman sea correcta, es necesario de las variables guarden entre sí una relación directa o inversa, en todo su conjunto de valores, es decir, que la relación sea monótona creciente o decreciente.</p>
</div>
<div id="nivel-intervalar-o-proporcional" class="section level2">
<h2><span class="header-section-number">5.4</span> Nivel intervalar o proporcional</h2>
<p>Si tratamos con variables intervalares o proporcionales, podríamos usar los procedimientos que referimos antes para el cálculo de la intensidad de las relaciones entre variables nominales. Para ello, deberíamos construir intervalos y tratarlos como las categorías de las dos variables, sin embargo, al operar de ese modo, perderíamos la información que provee una variable cuantitativa. Por ejemplo, si disponemos de un conjunto de personas adultas de las que sabemos la edad a la que cada una se casó (o unió) por primera vez y los años de escolarización, y nos interesamos por la relación entre estas dos variables; una opción sería la de categorizar ambas variables, por ejemplo, en tres intervalos. La matriz de datos para estas dos variables en 13 casos es:</p>
<table>
<thead>
<tr class="header">
<th align="center">edad.union</th>
<th align="center">escolarizacion</th>
<th align="center">edad.union.3</th>
<th align="center">escolariz.3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">18</td>
<td align="center">10.0</td>
<td align="center">(17,23]</td>
<td align="center">(9.99,13.3]</td>
</tr>
<tr class="even">
<td align="center">17</td>
<td align="center">12.0</td>
<td align="center">(17,23]</td>
<td align="center">(9.99,13.3]</td>
</tr>
<tr class="odd">
<td align="center">25</td>
<td align="center">10.5</td>
<td align="center">(23,29]</td>
<td align="center">(9.99,13.3]</td>
</tr>
<tr class="even">
<td align="center">19</td>
<td align="center">11.5</td>
<td align="center">(17,23]</td>
<td align="center">(9.99,13.3]</td>
</tr>
<tr class="odd">
<td align="center">23</td>
<td align="center">18.0</td>
<td align="center">(17,23]</td>
<td align="center">(16.7,20]</td>
</tr>
<tr class="even">
<td align="center">20</td>
<td align="center">14.0</td>
<td align="center">(17,23]</td>
<td align="center">(13.3,16.7]</td>
</tr>
<tr class="odd">
<td align="center">18</td>
<td align="center">15.5</td>
<td align="center">(17,23]</td>
<td align="center">(13.3,16.7]</td>
</tr>
<tr class="even">
<td align="center">20</td>
<td align="center">12.0</td>
<td align="center">(17,23]</td>
<td align="center">(9.99,13.3]</td>
</tr>
<tr class="odd">
<td align="center">24</td>
<td align="center">13.0</td>
<td align="center">(23,29]</td>
<td align="center">(9.99,13.3]</td>
</tr>
<tr class="even">
<td align="center">24</td>
<td align="center">15.0</td>
<td align="center">(23,29]</td>
<td align="center">(13.3,16.7]</td>
</tr>
<tr class="odd">
<td align="center">26</td>
<td align="center">16.0</td>
<td align="center">(23,29]</td>
<td align="center">(13.3,16.7]</td>
</tr>
<tr class="even">
<td align="center">30</td>
<td align="center">18.0</td>
<td align="center">(29,35]</td>
<td align="center">(16.7,20]</td>
</tr>
<tr class="odd">
<td align="center">35</td>
<td align="center">20.0</td>
<td align="center">(29,35]</td>
<td align="center">(16.7,20]</td>
</tr>
</tbody>
</table>
<p>Si se intenta construir una tabla de doble entrada para las dos variables originales (las dos primeras columnas de la matriz de datos anterior), el problema es aún mayor que con las ordinales, dado que habría un gran número de filas y de columnas, y resultaría casi imposible de leer. Además, muchas celdas estarían vacías y habría muy pocos casos en cada una de las restantes. Los trece datos de la matriz anterior quedarán, en una tabla de doble entrada, así:</p>
<table>
<caption><span id="tab:distrConj">Tabla 5.7: </span>Distribución conjunta de los años de escolarización y la edad a la que se realizó la primera unión conyugal</caption>
<thead>
<tr class="header">
<th></th>
<th align="center">10</th>
<th align="center">10.5</th>
<th align="center">11.5</th>
<th align="center">12</th>
<th align="center">13</th>
<th align="center">14</th>
<th align="center">15</th>
<th align="center">15.5</th>
<th align="center">16</th>
<th align="center">18</th>
<th align="center">20</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>17</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td>18</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td>19</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td>20</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td>23</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td>24</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td>25</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td>26</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td>30</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td>35</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>Tal como sucedió con las variables ordinales, esta no es una tabla adecuada para representar estos datos y sería más legible con las categorías agrupadas (usando las columnas tres y cuatro de la matriz):</p>
<table>
<caption><span id="tab:unnamed-chunk-275">Tabla 5.8: </span>Distribución conjunta de los años de escolarización y la edad a la que se realizó la primera unión conyugal (categorías agrupadas)</caption>
<thead>
<tr class="header">
<th></th>
<th align="center">(9.99,13.3]</th>
<th align="center">(13.3,16.7]</th>
<th align="center">(16.7,20]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(17,23]</td>
<td align="center">4</td>
<td align="center">2</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td>(23,29]</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td>(29,35]</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">2</td>
</tr>
</tbody>
</table>
<p>Ahora la tabla se lee con más facilidad y podemos tratarla como hicimos antes, como si fueran dos variables nominales y calcular un puntaje chi cuadrado y coeficientes <em>C de Pearson</em> y <em>V de Cramer</em>, o bien, como los intervalos están ordenados, poner una ranking y calcular el coeficiente de Spearman. Sin embargo, al hacer esto, se trata como si se hubiesen unido a la misma edad todas las personas que están entre 18 y 23.7 años. Del mismo modo, se trata como iguales a quienes tienen escolariación entre 10 y 13 años, no se puede distinguir entre quienes estudiaron 11, 12, 13 años: al interior del intervalo todos son considerados iguales. Además de esto, se pierden las posibilidades de análisis que ofrecen las variables cuantitativas.<br />
Para poder mantener las variables con sus verdaderos valores (sin
agrupar) y tener al mismo tiempo una representación abreviada de los
datos, existe un recurso muy valioso: una representación gráfica de los valores que se denomina <strong>diagrama de dispersión</strong> que se muestra en la figura siguiente (<a href="relación-entre-variables-el-análisis.html#fig:dispersion">5.1</a>).</p>
<div class="figure"><span id="fig:dispersion"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/dispersion-1.svg" alt="Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal" width="672" />
<p class="caption">
Figura 5.1: Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal
</p>
</div>
<p>Este gráfico usa los ejes cartesianos para indicar los valores de las
dos variables que estamos analizando y representa con un punto cada
concordancia de dos categorías que puede corresponder a un caso o a
varios. Cada punto es un par ordenado: el primer número son los años de escolarización y el segundo la edad a la que se unió por primera vez. Los ceros de la tabla <a href="relación-entre-variables-el-análisis.html#tab:distrConj">5.7</a> ya no aparecen en este diagrama. El primer punto de la izquierda corresponde a alguien que alcanzó 10 años de escolarización y se unió a los 18 años de edad.<br />
Lo que eran filas y columnas en todas las tablas mostradas hasta aquí, son ahora ejes coordenados, porque ya no se trata con categorías
separadas de cada variable sino con valores cuantitativos de las
variables que ahora son intervalares o proporcionales. Estos ejes se
llaman <strong>ordenadas</strong> el vertical y <strong>abscisas</strong> el horizontal. En el
ejemplo están representados los valores de los años de escolarización en el eje de las abscisas (primer elemento de cada par ordenado) y la edad a la primera unión en el eje de las ordenadas (segundo elemento de cada par).<br />
La manera en que los puntos se distribuyen en el diagrama de dispersión nos da una primera aproximación a la relación entre las dos variables.
Así, en el caso del ejemplo, hay una cierta tendencia creciente, en la
que se vería que <em>globalmente</em>, las personas con más años de
escolarización tenderían a unirse más tardíamente. Esta observación es
equivalente a ver la concentración de casos en las celdas de la diagonal
de una tabla bivariada.<br />
Por el contrario, si los datos se dispersan como lo muestra <a href="relación-entre-variables-el-análisis.html#fig:dispDebil">5.2</a>.</p>
<div class="figure"><span id="fig:dispDebil"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/dispDebil-1.svg" alt="Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal (relación débil)" width="672" />
<p class="caption">
Figura 5.2: Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal (relación débil)
</p>
</div>
<p>No hay ninguna razón para creer que las variables estén relacionadas:
los puntos no muestran una tendencia clara.<br />
Una asociación más acentuada entre las mismas dos variables se observa en el diagrama de dispersión de <a href="relación-entre-variables-el-análisis.html#fig:dispInt">5.3</a>.</p>
<div class="figure"><span id="fig:dispInt"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/dispInt-1.svg" alt="Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal (relación intensa)" width="672" />
<p class="caption">
Figura 5.3: Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal (relación intensa)
</p>
</div>
<p>En el que la tendencia <em>lineal</em> es más clara, por lo que resulta más
definido el efecto de la escolarización sobre la edad a la que se
produce la primera unión. Aquí, la nube de puntos está más aplanada que en el ejemplo anterior; en efecto, en el gráfico <a href="relación-entre-variables-el-análisis.html#fig:dispDebil">5.2</a> la nube de puntos tiene forma más circular que en el <a href="relación-entre-variables-el-análisis.html#fig:dispInt">5.3</a>, donde es más elíptica.<br />
El ejemplo que hemos mostrado hasta aquí corresponde a una relación directa: más años de escolarización parecen asociarse con edades más tardías para la primera unión. De manera equivalente pueden representarse relaciones inversas. Consideremos el caso de la ansiedad frente a los exámenes y la calificación que se obtiene. En un estudio realizado por el Laboratorio de Evaluación Psicológica y Educativa (LEPE, Facultad de Psicología UNC, <span class="citation">Furlan, Ferrero, and Gallart (<a href="#ref-furlan2014">2014</a>)</span>) se observó que a mayor puntaje en una prueba de ansiedad ante los exámenes, menor rendimiento académico, por lo que la relación entre las variables es inversa.<br />
Los esquemas de la figura <a href="relación-entre-variables-el-análisis.html#fig:comparanubes">5.4</a> muestran el achatamiento de la nube de puntos según la relación sea más fuerte o más débil y según sea directa o inversa.</p>
<div class="figure"><span id="fig:comparanubes"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/comparanubes-1.svg" alt="Comparación de la forma de las nubes de puntos según la intensidad de la relación" width="672" />
<p class="caption">
Figura 5.4: Comparación de la forma de las nubes de puntos según la intensidad de la relación
</p>
</div>
<p>La intensidad de la relación está vinculada al achatamiento de la elipse
que rodea la nube de puntos y éste al grado de alineación que los puntos
tengan. Luego volveremos sobre esta idea.</p>
<p>Solo nos ocuparemos de relaciones como las que acabamos de ejemplificar: aquellas en las que la tendencia es creciente o decreciente, pero
siempre siguiendo un camino parecido a una línea recta. Son las que
llamaremos <em>relaciones lineales</em>. No son la únicas que existen; para ilustrarlo, consideremos cómo se representa la relación entre la edad
de las personas y la frecuencia con que consultan al médico. Estas dos
variables son tales que, en términos muy generales y sin considerar
situaciones específicas, para valores pequeños de la primera (en la
infancia) las consultas son frecuentes, luego se reducen durante la
adultez para volver a incrementarse en la vejez. Por eso el gráfico que las representa tiene una forma similar a la figura <a href="relación-entre-variables-el-análisis.html#fig:dispMedic">5.5</a>.</p>
<div class="figure"><span id="fig:dispMedic"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/dispMedic-1.svg" alt="Diagrama de dispersión del número medio de consultas médicas anuales y la edad." width="672" />
<p class="caption">
Figura 5.5: Diagrama de dispersión del número medio de consultas médicas anuales y la edad.
</p>
</div>
<p>Este conjunto de puntos muestra una tendencia <em>no lineal</em>, eso no
implica que las variables no estén relacionadas; por el contrario, la
relación existe, pero no es lineal. Estos puntos, en lugar de ser
aproximados por una línea recta, lo serían con una curva con forma de
parábola. No nos ocuparemos aquí de relaciones no lineales. Limitaremos
nuestro análisis a relaciones lineales, debido a que es muy frecuente
usarlas como primera aproximación a la forma que tiene la relación entre
dos variables y porque a menudo, cuando se trabaja con relaciones no
lineales, es posible realizar transformaciones de las variables para
lograr relaciones lineales.</p>
<p>Para analizar la intensidad de la relación lineal entre dos variables
(ambas medidas a nivel intervalar o proporcional) calcularemos un
coeficiente comparable a los que hemos visto hasta aquí, que tendrá una
interpretación similar a la del coeficiente de correlación por rangos de
Spearman. Este coeficiente se llama <strong>coeficiente de correlación r de Pearson</strong>, fue presentado por <span class="citation">Pearson and Galton (<a href="#ref-pearson1895">1895</a>)</span>, pero antes ya había sido mencionado por <span class="citation">Galton (<a href="#ref-galton1877">1877</a>)</span>, es uno de los de mayor utilización cuando las variables que
se analizan alcanzan el nivel de medición que autoriza su cálculo. Este
coeficiente va a medir qué tan bien se puede aproximar el conjunto de
puntos con una función lineal y va a depender de lo que antes llamamos
el “achatamiento” de la elipse. Será grande (próximo a <span class="math inline">\(1\)</span> ó a <span class="math inline">\(-1\)</span>) si las
variables están muy relacionadas linealmente, es decir, si la nube de
puntos se elonga hacia una línea; y será pequeño (próximo a cero) si las
variables guardan poca relación lineal, es decir si la nube de puntos
tiene forma redondeada. Será positivo y elevado (próximo a 1) si valores
pequeños de una variable están acompañados de valores pequeños de la
otra y valores grandes de una siguen a valores grandes de la otra, como
sucedió en el ejemplo de la relación entre escolarización y edad a la primera unión, representada en el gráfico <a href="relación-entre-variables-el-análisis.html#fig:dispInt">5.3</a>. Será negativo y elevado (próximo a <span class="math inline">\(-1\)</span>) si los valores grandes de una de las variables acompañan a los pequeños de la otra y viceversa, como en el caso de la relación entre ansiedad y rendimiento académico. La correlación será perfecta positiva (<span class="math inline">\(r = 1\)</span>) si todos los puntos se ubican sobre una recta creciente:</p>
<div class="figure"><span id="fig:rectaCrec"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/rectaCrec-1.svg" alt="Ejemplo de situación ideal con todas las observaciones alineadas en una recta creciente, por lo que $r = 1$" width="672" />
<p class="caption">
Figura 5.6: Ejemplo de situación ideal con todas las observaciones alineadas en una recta creciente, por lo que <span class="math inline">\(r = 1\)</span>
</p>
</div>
<p>Y será perfecta negativa (<span class="math inline">\(r = - 1\)</span>) si todos los puntos se ubican sobre una recta decreciente:</p>
<div class="figure"><span id="fig:rectaDecrec"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/rectaDecrec-1.svg" alt="Ejemplo de situación ideal con todas las observaciones alineadas en una recta decreciente, por lo que $r = - 1$" width="672" />
<p class="caption">
Figura 5.7: Ejemplo de situación ideal con todas las observaciones alineadas en una recta decreciente, por lo que <span class="math inline">\(r = - 1\)</span>
</p>
</div>
<p>Ambas son situaciones ideales que no se encuentran en la realidad,
constituyen el límite de la intensidad que pueden alcanzar las
relaciones lineales directas o inversas.</p>
<p>Las unidades en que se miden las variables que se relacionan pueden ser
muy diferentes, en el ejemplo de ansiedad y resultado de los exámenes,
la primera se puede medir en una escala de cero a cien y la segunda de cero a diez, por lo que
un valor elevado de la primera sería 95 y uno elevado de la segunda, 9.
Esto impide que se comparen directamente los valores grandes con los
grandes y los pequeños con los pequeños. Vamos a usar un recurso que ya fue presentado: las puntuaciones <em>z</em>, aquellas que indican a cuántas desviaciones estándar se encuentra cada observación de la media. Son los puntajes que permiten decidir si se trata de un valor grande (muy superior a la media) o pequeño (muy inferior a la media) o intermedio (semejante a la media), sin tener unidades, por lo que permite la comparación de elementos que pueden tener cualquier unidad de medida.</p>
<p>Recordemos que para los valores bajos de la variable (menores a la media), el puntaje <em>z</em> es negativo y es positivo para los valores altos (superiores a la media). Si dos variables están correlacionadas
positivamente (altos con altos y bajos con bajos), entonces sus puntajes <em>z</em> se corresponderán positivos con positivos y negativos con negativos.</p>
<p>Si para cada sujeto multiplicamos los puntajes z de las dos variables
que se relacionan, obtendremos siempre un resultado positivo, ya sea
porque multiplicamos dos números positivos (<span class="math inline">\(+\times+=+\)</span>) o dos negativos (<span class="math inline">\(-\times-=+\)</span>). Si luego sumamos esos productos para todos los sujetos obtendremos un número alto positivo.</p>
<p>A la inversa, si dos variables se correlacionan negativamente los productos de sus puntajes <em>z</em> serán negativos, porque los valores altos de una irán con los bajos de la otra (que equivale a <em>z</em> positivos con <em>z</em> negativos, y <span class="math inline">\(+\times-=-\)</span>) y bajos con altos (que es lo mismo que <em>z</em> negativos con <em>z</em> positivos y <span class="math inline">\(-\times+=-\)</span>). Cuando sumemos estos productos para todos los casos tendremos un número alto y negativo.</p>
<p>Si las variables no estuvieran correlacionadas, habría casos en el que
un valor alto de una variable se acompaña de uno alto de la otra y casos
en que un valor alto va seguido de uno bajo, algunos productos de <em>z</em>
serían positivos y otros negativos y entonces, al sumarlos, obtendríamos
un número bajo, que puede ser positivo o negativo, pero será cercano a
cero.</p>
<p>Entonces el producto de las puntuaciones <em>z</em> ofrece un resultado que será:</p>
<ul>
<li><p>alto y positivo si las variables tienen una correlación fuerte y directa</p></li>
<li><p>alto y negativo si la correlación es fuerte e inversa</p></li>
<li><p>cercano a cero si no están correlacionadas</p></li>
</ul>
<p>Haciendo uso de este razonamiento, el coeficiente de correlación de
Pearson se calcula como<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a>:</p>
<p><span class="math display">\[r = \frac{\sum_{i = 1}^{n}{z_{x_{i}}*z_{y_{i}}}}{n - 1}\]</span></p>
<p>Donde <span class="math inline">\(z\)</span> representan los desvíos estándar de las variables <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, <span class="math inline">\(n\)</span> es el total de observaciones y los subíndices <span class="math inline">\(i\)</span> corresponden a cada una de ellas. El signo de suma señala que ésta debe extenderse desde el primer caso (<span class="math inline">\(i=1\)</span>) hasta el último (cuando <span class="math inline">\(i=n\)</span>).</p>
<p>Como en el caso del coeficiente de Spearman, el campo de variación del coeficiente de Pearson es el intervalo <span class="math inline">\([-1, 1]\)</span>.</p>
<p>Para el cálculo del coeficiente de Pearson, no es necesario que las dos variables tengan las mismas unidades, porque se usan los puntajes <span class="math inline">\(z\)</span>, que carecen de unidades. No hay inconveniente en correlacionar el peso (en kilogramos) con la talla (medida en centímetros).</p>
<p>A continuación, se presenta un ejemplo de cómo calcular el coeficiente
de correlación de Pearson para evaluar la relación entre dos variables.
Las variables seleccionadas para el ejemplo son: 1) puntaje obtenido en
una escala de inteligencia lógico-matemática y 2) cantidad de ejercicios
correctamente realizados en una prueba de matemática. El fragmento de la
matriz de datos correspondiente es el siguiente:</p>
<table>
<thead>
<tr class="header">
<th align="center">puntaje.escala</th>
<th align="center">ejercic.corr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">46</td>
<td align="center">7</td>
</tr>
<tr class="even">
<td align="center">44</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">56</td>
<td align="center">7</td>
</tr>
<tr class="even">
<td align="center">57</td>
<td align="center">8</td>
</tr>
<tr class="odd">
<td align="center">30</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">60</td>
<td align="center">9</td>
</tr>
<tr class="odd">
<td align="center">45</td>
<td align="center">5</td>
</tr>
<tr class="even">
<td align="center">43</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">64</td>
<td align="center">9</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">3</td>
</tr>
</tbody>
</table>
<p>Una vez que se ha obtenido la media y desviación estándar de las medidas
del puntaje en la escala de inteligencia lógico-matemática
(<span class="math inline">\(\overline{x} = 47.7\)</span> <span class="math inline">\(s_{x} = 11.44\)</span>) y de cantidad de ejercicios
matemáticos correctamente realizados
(<span class="math inline">\(\overline{y} = 5.3\)</span> <span class="math inline">\(s_{y} = 3.09\)</span>), se deben convertir las
observaciones brutas en puntuaciones <em>z</em>. Para ello se calcula la
diferencia entre la puntuación bruta original y la media del grupo, y el
resultado de esta operación se divide por la desviación estándar del
grupo. La transformación a puntaje <em>z</em> se obtiene como vimos antes:</p>
<p>Para el puntaje en inteligencia lógico - matemática (<em>x</em>),</p>
<p><span class="math display">\[z_{x} = \frac{x - \overline{x}}{s_{x}}\]</span></p>
<p>Para la cantidad de ejercicios correctamente realizados (<em>y</em>),</p>
<p><span class="math display">\[z_{y} = \frac{y - \overline{y}}{s_{y}}\]</span></p>
<p>Entonces, el puntaje <em>z</em> del sujeto 1 para cada escala se obtiene de la siguiente manera:</p>
<p><span class="math display">\[z_{x_{1}} = \frac{46 - 47.7}{11.44} = - 0.15\]</span></p>
<p><span class="math display">\[z_{y_{1}} = \frac{7 - 5.3}{3.09} = 0.55\]</span></p>
<p>Y del mismo modo para cada uno de los sujetos observados, para obtener la siguiente tabla:</p>
<table>
<colgroup>
<col width="7%" />
<col width="44%" />
<col width="36%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Sujetos</th>
<th align="center">Puntaje escala inteligencia lógico-matemática <span class="math inline">\(z_{x}\)</span></th>
<th align="center">Ejercicios correctamente realizados <span class="math inline">\(z_{y}\)</span></th>
<th align="center"><span class="math inline">\(z_{x}*z_{y}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">-0.15</td>
<td align="center">0.55</td>
<td align="center">-0.08</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">-0.32</td>
<td align="center">-1.07</td>
<td align="center">0.35</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">0.73</td>
<td align="center">0.55</td>
<td align="center">0.40</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">0.81</td>
<td align="center">0.87</td>
<td align="center">0.71</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">-1.55</td>
<td align="center">-1.07</td>
<td align="center">1.65</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">1.08</td>
<td align="center">1.20</td>
<td align="center">1.29</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">-0.24</td>
<td align="center">-0.10</td>
<td align="center">0.02</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">-0.41</td>
<td align="center">-1.39</td>
<td align="center">0.57</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">1.42</td>
<td align="center">1.20</td>
<td align="center">1.70</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">-1.37</td>
<td align="center">-0.74</td>
<td align="center">1.02</td>
</tr>
</tbody>
</table>
<p>El numerador del coeficiente r de Pearson se obtiene sumando la última columna:</p>
<p><span class="math display">\[\sum_{}^{}{z_{x}*z_{y} = 7.63}\]</span></p>
<p>y solo queda dividir este número por <span class="math inline">\(n-1=10-1=9\)</span> para obtener <span class="math inline">\(r = 0.85\)</span>.</p>
<p>El coeficiente dio positivo, lo que indica que la relación es directa.
Como se habría esperado: las personas con mayor puntaje en la escala de
inteligencia lógico-matemática, son quienes tienen una mayor cantidad de
ejercicios correctamente realizados.<br />
Además, el valor <span class="math inline">\(0.85\)</span> es elevado, lo que indica que la relación entre
las dos variables es intensa.</p>
<p>La decisión acerca de considerar como grande o pequeño al valor de un
coeficiente de asociación o de correlación depende del tipo de variable
con que se esté trabajando y en especial de la forma en que son medidas
esas variables. En buena medida, el uso de estos coeficientes es
comparativo y puede ser muy valioso saber si una variable se asocia (o
se correlaciona) más con una que con otra. Cuando tratamos de explicar
un fenómeno y formulamos hipótesis sobre varios factores, es útil saber
cuáles de ellos se asocian más intensamente con ese fenómeno.</p>
<p>Se han establecido algunos valores de referencia, según los cuales la
correlación se considera nula si <span class="math inline">\(r &lt; 0.10\)</span>, pequeña si
<span class="math inline">\(0.10 \leq r &lt; 0.30\)</span>, media si <span class="math inline">\(0.30 \leq r \leq 0.50\)</span> y grande si
<span class="math inline">\(r &gt; 0.50\)</span>. Coincidimos con <span class="citation">Cohen (<a href="#ref-Cohen1988">1988</a>)</span>, en que estos criterios son un
tanto arbitrarios y siempre debe considerarse al coeficiente de
correlación en contexto.</p>
<p>Para poder interpretar el coeficiente de Pearson, se requiere que las
variables guarden entre sí una relación lineal, de lo contrario, la
interpretación como intensidad de la relación es incorrecta. Además,
este coeficiente se ve afectado por valores extremos, es decir aquellos
que se apartan de la tendencia mayoritaria, por lo que si éstos existen
convienen calcular el coeficiente de Spearman. Ambas situaciones,
tendencia lineal o no, y existencia o no de casos atípicos pueden verse
en el diagrama de dispersión, que es muy necesario observar antes de analizar la intensidad de una relación.</p>
<p>Cuando la relación entre dos variables es lineal, el coeficiente de
Pearson da una interpretación más detallada de la incidencia de una
variable sobre la otra. Cuando este coeficiente se eleva al cuadrado, se
obtiene un número que se llama <strong>coeficiente general de determinación</strong>,
que se indica como <span class="math inline">\(R^{2}\)</span> y que mide la parte de la varianza que es
compartida por las dos variables.<br />
Cuando la relación es asimétrica y una variable opera como antecedente y
la otra como consecuente, el coeficiente general de determinación mide
la parte de la varianza de la variable consecuente que se explica por la
antecedente. O bien la parte de la variabilidad de la variable
dependiente que puede atribuirse a la variable independiente. Así, en
nuestro ejemplo: <span class="math inline">\(R^{2} = {0.85}^{2} = 0.72\)</span>, lo podemos indicar como
72% y quiere decir que el 72% de la variabilidad total que aparece en el
número de ejercicios correctamente realizados, se explica por el puntaje
alcanzado en la escala de inteligencia lógico matemática. Así, con este
coeficiente identificamos la magnitud del aporte que una variable hace a
explicar los cambios de la otra. Los hechos que se observan obedecen a
una multiplicidad factores explicativos, por esa razón es muy valioso
disponer de un coeficiente como <span class="math inline">\(R^{2}\)</span>, que mide qué parte de los
cambios en lo observado pueden atribuirse a un determinado factor
explicativo.</p>
<p>En el apartado siguiente volveremos sobre el coeficiente general de
determinación en una aplicación más general.</p>
</div>
<div id="dicotomías-reales-y-artificiales" class="section level2">
<h2><span class="header-section-number">5.5</span> Dicotomías reales y artificiales</h2>
<p>Cuando se trabaja con variables dicotómicas, estas pueden tener dos
orígenes diferentes; hay dicotomías reales y las hay artificiales. Las primeras son variables que por su construcción, solo admiten dos
categorías, como turno (mañana - tarde), sexo (varón - mujer), grupo
(experimental - control). Las segundas, provienen de haber
recategorizado una variable continua en dos grupos, como puntaje (alto - bajo), ingresos medidos según línea de pobreza (pobre - no pobre), resultado de un examen (aprobado - no aprobado), posición política (izquierda - derecha). Esta situación es especialmente interesante en la medición de rasgos latentes a los que se considera continuos, pero que se miden de manera dicotómica. Por ejemplo, la actitud hacia la política, puede ir desde el desinterés completo hasta la participación activa, pudiendo identificarse graduaciones entre esos extremos. Si se usa la afiliación a un partido como indicador de participación, se toma una medida dicotómica (está afiliado - no está afiliado); esta dicotomización se considera artificial, porque se supone que es un punto de corte que define dos categorías en un continuo. La distición entre estudiantes que <em>promovieron</em> y que <em>no promovieron</em> es una dicotomizacion sobre una variable originalmente continua: el promedio de las notas. Clasificar a los países en <em>desarrollados</em> y <em>en vías de desarrollo</em>, implica cortar en dos (dicotomizar) un conjunto de indicadores de desarrollo, que son continuos (PIB per cápita, educación, etc.). Lo cual es diferente de distinguir países <em>con arsenal nuclear</em> y <em>sin arsenal nuclear</em>, porque aquí no hay graduación entre las categorías, esta última es una dicotomía real.</p>
<p>Cuando se trata de dicotomías reales, el coeficiente <span class="math inline">\(\varphi\)</span> que ya se mencionó, es adecuado. Por el contrario, en los análisis de la intensidad de la asociación entre dos variables que han sido dicotomizadas de manera artificial a partir de una variable que se considera continua, se usa una estimación del coeficiente de Pearson que habría resultado si las variables no hubieran sido dicotomizadas y hubiese entre ellas una
relación lineal. El coeficiente para este caso se denomina <strong>coeficiente de correlación tetracórica</strong>, su cálculo requiere procedimientos matemáticos complejos, por lo que hay que usar programas informáticos. También hay fórmulas aproximadas, como la siguiente</p>
<p><span class="math display">\[r_{tet} = \cos(\frac{\pi}{1 + \sqrt{\frac{a*d}{b*c}}})\]</span></p>
<p>En la que a, b, c y d son las frecuencias absolutas de una tabla de <span class="math inline">\(2 \times 2\)</span>
dispuestas así:</p>
<table>
<thead>
<tr class="header">
<th align="left">a</th>
<th align="left">b</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">c</td>
<td align="left">d</td>
</tr>
</tbody>
</table>
<p>El resultado de <span class="math inline">\(r_{tet}\)</span> puede variar entre <span class="math inline">\(-1\)</span> y 1, los valores
más cercanos a 1 o a <span class="math inline">\(-1\)</span> indican mayor intensidad en la asociación.
Respecto del signo, es más claro no considerarlo en el coeficiente y
observar en qué sentido se da la relación a partir de las frecuencias
relativas calculadas en la tabla.</p>
<p>Ejemplo a partir de la base bayley: para analizar la relación entre los puntajes en las subescalas mental y motora de la prueba de Bayley, se dicotomizan
las dos variables en la media, asignando el valor 0 a quienes tienen
puntajes inferiores a la media en cada subescala y uno a quienes superan a la media. Resulta así la tabla:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td align="center">139</td>
<td align="center">102</td>
<td align="center">241</td>
</tr>
<tr class="even">
<td>1</td>
<td align="center">102</td>
<td align="center">200</td>
<td align="center">302</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="center">241</td>
<td align="center">302</td>
<td align="center">543</td>
</tr>
</tbody>
</table>
<p>El cálculo del coeficiente de correlación tetracórico para esa tabla es:</p>
<p><span class="math display">\[r_{tet} = \cos(\frac{\pi}{1 + \sqrt{\frac{139*200}{102*102}}}) = \cos{(\frac{\pi}{2.63}) = 0.37}\]</span></p>
<p>Que indica una correlación moderada entre las variables. Como en este
caso sí se dispone de los valores originales y la dicotomización se hizo a fines de ilustración, es posible calcularlo, su valor es <span class="math inline">\(0.35\)</span>. Pero si solo se hubiese contado con la dicotomía, el tetracórico es el único que puede calcularse.</p>
<p>El coeficiente de Kendall - Yule es otra aproximación al coeficiente
tetracórico. En este caso da <span class="math inline">\(0.45\)</span>, que es de peor calidad que la que se obtiene con la expresión anterior.</p>
</div>
<div id="niveles-de-medición-combinados" class="section level2">
<h2><span class="header-section-number">5.6</span> Niveles de medición combinados</h2>
<p>Las operaciones que pueden hacerse a un nivel de medición
son también válidas para los niveles superiores, pero no a la inversa; Por eso cada vez que haya variables con niveles de medición diferente, habrá que tener en cuenta el nivel más bajo para decidir qué coeficiente corresponde usar. Por ejemplo, la correlación entre una variable ordinal y una continua debe hacerse con el coeficiente de Spearman, porque las operaciones que este requiere se puede realizar tanto con variables ordinales como con continuas. Por el contrario, el coeficiente de Pearson requiere operaciones que no son válidas cunado la variable es ordinal.</p>
<p>Sin embargo, hay algunos casos particulares que merecen mención.</p>
<div id="una-variable-dicotómica-real-y-una-proporcional" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Una variable dicotómica real y una proporcional</h3>
<p>La comparación de los valores de una variable continua entre dos grupos se trata como la correlación entre una variable dicotómica real (que define los grupos) y una continua. Allí, los grupos se codifican como cero y uno, y se calcula el coeficiente de Pearson entre las dos variables.</p>
<p>Sin embargo, para esta situación existe un coeficiente específico, que se denomina <strong>punto biserial</strong> (<span class="math inline">\(r_{pb}\)</span>). Su fórmula de cálculo conduce al mismo resultado que el coeficiente de Pearson, pero tiene en cuenta las medias de la variable continua y la proporción de casos en cada grupo, junto con la desviación estándar de la variable continua:</p>
<p><span class="math display">\[r_{pb} = \frac{{\overline{x}}_{1} - {\overline{x}}_{0}}{s}*\sqrt{p*(1 - p)*\frac{n}{n - 1}}\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\({\overline{x}}_{1}\)</span> Es la media de la variable en el grupo codificado como uno</p></li>
<li><p><span class="math inline">\({\overline{x}}_{0}\)</span> Es la media de la variable en el grupo codificado como cero</p></li>
<li><p><span class="math inline">\(p\)</span> Es la proporción de casos que hay en grupo codificado como uno</p></li>
<li><p><span class="math inline">\(n\)</span> Es el número total de observaciones y</p></li>
<li><p><span class="math inline">\(s\)</span> Es la desviación estándar de la variable continua</p></li>
</ul>
<p>El signo de este coeficiente indica el sentido de la diferencia; es positivo cuando el grupo codificado como uno tiene valores más altos y negativo en el caso contrario. Su valor absoluto mide la magnitud de la relación entre las dos variables.<br />
Ejemplo (datos ficticios): se comparan los puntajes alcanzados en una prueba por personas asignadas a los grupos experimental y
control, y se obtienen estos valores:</p>
<table>
<thead>
<tr class="header">
<th align="left">grupo</th>
<th align="center">puntaje</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">control</td>
<td align="center">8.0</td>
</tr>
<tr class="even">
<td align="left">control</td>
<td align="center">5.0</td>
</tr>
<tr class="odd">
<td align="left">control</td>
<td align="center">6.0</td>
</tr>
<tr class="even">
<td align="left">control</td>
<td align="center">5.0</td>
</tr>
<tr class="odd">
<td align="left">control</td>
<td align="center">6.0</td>
</tr>
<tr class="even">
<td align="left">control</td>
<td align="center">8.0</td>
</tr>
<tr class="odd">
<td align="left">control</td>
<td align="center">6.0</td>
</tr>
<tr class="even">
<td align="left">experimental</td>
<td align="center">4.0</td>
</tr>
<tr class="odd">
<td align="left">experimental</td>
<td align="center">5.6</td>
</tr>
<tr class="even">
<td align="left">experimental</td>
<td align="center">5.6</td>
</tr>
<tr class="odd">
<td align="left">experimental</td>
<td align="center">8.0</td>
</tr>
<tr class="even">
<td align="left">experimental</td>
<td align="center">7.2</td>
</tr>
<tr class="odd">
<td align="left">experimental</td>
<td align="center">6.4</td>
</tr>
<tr class="even">
<td align="left">experimental</td>
<td align="center">7.2</td>
</tr>
<tr class="odd">
<td align="left">experimental</td>
<td align="center">8.0</td>
</tr>
<tr class="even">
<td align="left">experimental</td>
<td align="center">8.0</td>
</tr>
<tr class="odd">
<td align="left">experimental</td>
<td align="center">7.2</td>
</tr>
</tbody>
</table>
<p>Se toma como grupo de referencia (grupo 1) al experimental y resulta:</p>
<ul>
<li><p><span class="math inline">\({\overline{x}}_{1} = 6.7\)</span></p></li>
<li><p><span class="math inline">\({\overline{x}}_{0} = 6.3\)</span></p></li>
<li><p><span class="math inline">\(p = 0.59\)</span></p></li>
<li><p><span class="math inline">\(n = 17\)</span></p></li>
<li><p><span class="math inline">\(s = 1.27\)</span></p></li>
</ul>
<p>La fórmula da:</p>
<p><span class="math display">\[r_{pb} = \frac{6.7 - 6.3}{1.27}*\sqrt{0.59*(1 - 0.59)*\frac{17}{17 - 1}} = 0.1734\]</span></p>
<p>Que sea positivo indica que el grupo al que se codificó uno (el
experimental) tiene puntajes medios más altos. Su valor absoluto señala una correlación pequeña entre la pertenencia a los grupos y los puntajes de la prueba.</p>
</div>
<div id="una-variable-continua-dicotomizada-y-una-proporcional" class="section level3">
<h3><span class="header-section-number">5.6.2</span> Una variable continua dicotomizada y una proporcional</h3>
<p>Si la variable dicotómica proviene de la recategorización de una
continua que se dividió en dos categorías, es decir, si la dicotomía es artificial; y se supone que hay una variable latente continua, entonces el coeficiente que corresponde calcular es el llamado <strong>biserial</strong> <span class="math inline">\(r_{b}\)</span>. Como sucedió con el coeficiente de correlación tetracórico, se trata de una estimación del valor que tendría el coeficiente de Pearson si la variable no hubiese sido dicotomizada.</p>
<p><span class="math display">\[r_{b} = \frac{{\overline{x}}_{1} - {\overline{x}}_{0}}{s}*\frac{p*(1 - p)}{y}\]</span></p>
<p>Con la misma notación que se usó para el coeficiente <span class="math inline">\(r_{pb}\)</span>. Lo diferente es la <span class="math inline">\(y\)</span> en el denominador, cuyo cálculo depende de la
distribución normal, que se verá más adelante<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a>.</p>
</div>
</div>
<div id="resumen-de-coeficientes-de-asociación" class="section level2">
<h2><span class="header-section-number">5.7</span> Resumen de coeficientes de asociación</h2>
<!-- a este cuadro hay que arreglarlo, no está muy mal, pero las columnas están mal definidas-->
<table>
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="16%" />
<col width="42%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Nivel de medición de las variables</th>
<th align="left">Coeficiente</th>
<th align="center">Rango de variación</th>
<th align="left">Lectura</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Ambas dicotómicas reales</td>
<td align="left"><span class="math inline">\(\varphi\)</span> (phi) de Yule</td>
<td align="center"><span class="math inline">\([-1; 1]\)</span></td>
<td align="left">No importa el signo, la relación es fuerte si es cercano a 1 ó a -1 y débil si está cerca de 0</td>
</tr>
<tr class="even">
<td align="left">Ambas dicotómicas provenientes de dos continuas recategorizadas</td>
<td align="left">tetracórico <span class="math inline">\(r_{tet}\)</span> o bien Q de Kendall - Yule</td>
<td align="center"><span class="math inline">\([-1; 1]\)</span></td>
<td align="left">No importa el signo, la relación es fuerte si es cercano a 1 ó a -1 y débil si está cerca de 0</td>
</tr>
<tr class="odd">
<td align="left">Ambas nominales</td>
<td align="left">de contingencia, C</td>
<td align="center"><span class="math inline">\([0; C_{max}]\)</span> depende de la dimensión de la tabla</td>
<td align="left">Más intensa si es próximo a <span class="math inline">\(C_{max}\)</span></td>
</tr>
<tr class="even">
<td align="left">Ambas nominales</td>
<td align="left">V de Cramer</td>
<td align="center"><span class="math inline">\([0; 1]\)</span></td>
<td align="left">Más intensa si es próximo a 1</td>
</tr>
<tr class="odd">
<td align="left">Ambas ordinales o una ordinal y una proporcional</td>
<td align="left"><span class="math inline">\(r_s\)</span> de Spearman</td>
<td align="center"><span class="math inline">\([-1; 1]\)</span></td>
<td align="left">El signo indica la dirección, positivo es directa, negativo es inversa. Fuerte si es cercano a 1 ó a <span class="math inline">\(-1\)</span> y débil si está cerca de 0</td>
</tr>
<tr class="even">
<td align="left">Ambas proporcionales</td>
<td align="left"><span class="math inline">\(r\)</span> de Pearson</td>
<td align="center"><span class="math inline">\([-1; 1]\)</span></td>
<td align="left">El signo indica la dirección, positivo es directa, negativo es inversa. Fuerte si es cercano a 1 ó a <span class="math inline">\(-1\)</span> y débil si está cerca de 0</td>
</tr>
<tr class="odd">
<td align="left">Una dicotómica real y una proporcional</td>
<td align="left"><span class="math inline">\(r_{pb}\)</span> punto biserial</td>
<td align="center"><span class="math inline">\([-1; 1]\)</span></td>
<td align="left">Más intensa si es próximo a 1 o a <span class="math inline">\(-1\)</span></td>
</tr>
<tr class="even">
<td align="left">Una dicotómica proveniente de una continua recategorizada y otra proporcional</td>
<td align="left"><span class="math inline">\(r_b\)</span> biserial</td>
<td align="center"><span class="math inline">\([-1; 1]\)</span></td>
<td align="left">Más intensa si es próximo a 1 o a <span class="math inline">\(-1\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="matriz-de-correlaciones" class="section level2">
<h2><span class="header-section-number">5.8</span> Matriz de correlaciones</h2>
<p>A menudo resulta de interés observar grados de asociación entre más de dos variables, para ello, una disposición adecuada es la matriz de correlaciones. Se trata de una organización de las variables que se correlacionan, en filas y columnas; las variables se repiten en la primera fila y la primera columna, por lo que la matriz de correlaciones es cuadrada. La diagonal de la matriz tiene unos (1s), que indican la correlación perfecta de cada variable consigo misma. Las celdas que se encuentran por encima y por debajo de la diagonal muestran los coeficientes de correlación entre cada par de variables. Porque esos valores son idénticos, la matriz se llama simétrica.<br />
La matriz permite advertir patrones de asociación entre variables, es decir cuáles tienden a variar de manera más semejante.</p>
<p>Ejemplo (datos reales): el cuestionaro de Latinobarómetro (2017) pregunta por la confianza que se tiene en diferentes instituciones, con los siguientes ítems:</p>
<p>Para cada uno de los grupos, instituciones o personas de la lista ¿cuánta confianza tiene usted en ellas: mucha (1), algo (2), poca (3), ninguna (4) confianza en…?</p>
<ul>
<li>P14STGBS.A Las Fuerzas Armadas</li>
<li>P14STGBS.B La policía/ Carabineros</li>
<li>P14ST.C La Iglesia</li>
<li>P14ST.D Congreso</li>
<li>P14ST.E Gobierno</li>
<li>P14ST.F Poder Judicial</li>
<li>P14ST.G Los partidos políticos</li>
</ul>
<p>Los coeficientes de correlación de cada par de variables son los siguientes:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">P14STGBS.A</th>
<th align="center">P14STGBS.B</th>
<th align="center">P14ST.C</th>
<th align="center">P14ST.D</th>
<th align="center">P14ST.E</th>
<th align="center">P14ST.F</th>
<th align="center">P14ST.G</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">P14STGBS.A</td>
<td align="center">1.00</td>
<td align="center">0.57</td>
<td align="center">0.19</td>
<td align="center">0.27</td>
<td align="center">0.34</td>
<td align="center">0.38</td>
<td align="center">0.26</td>
</tr>
<tr class="even">
<td align="left">P14STGBS.B</td>
<td align="center">0.57</td>
<td align="center">1.00</td>
<td align="center">0.18</td>
<td align="center">0.35</td>
<td align="center">0.42</td>
<td align="center">0.44</td>
<td align="center">0.35</td>
</tr>
<tr class="odd">
<td align="left">P14ST.C</td>
<td align="center">0.19</td>
<td align="center">0.18</td>
<td align="center">1.00</td>
<td align="center">0.22</td>
<td align="center">0.16</td>
<td align="center">0.18</td>
<td align="center">0.14</td>
</tr>
<tr class="even">
<td align="left">P14ST.D</td>
<td align="center">0.27</td>
<td align="center">0.35</td>
<td align="center">0.22</td>
<td align="center">1.00</td>
<td align="center">0.54</td>
<td align="center">0.49</td>
<td align="center">0.49</td>
</tr>
<tr class="odd">
<td align="left">P14ST.E</td>
<td align="center">0.34</td>
<td align="center">0.42</td>
<td align="center">0.16</td>
<td align="center">0.54</td>
<td align="center">1.00</td>
<td align="center">0.55</td>
<td align="center">0.50</td>
</tr>
<tr class="even">
<td align="left">P14ST.F</td>
<td align="center">0.38</td>
<td align="center">0.44</td>
<td align="center">0.18</td>
<td align="center">0.49</td>
<td align="center">0.55</td>
<td align="center">1.00</td>
<td align="center">0.48</td>
</tr>
<tr class="odd">
<td align="left">P14ST.G</td>
<td align="center">0.26</td>
<td align="center">0.35</td>
<td align="center">0.14</td>
<td align="center">0.49</td>
<td align="center">0.50</td>
<td align="center">0.48</td>
<td align="center">1.00</td>
</tr>
</tbody>
</table>
<p>Esta matriz de correlaciones muestra simultáneamente los coeficientes de correlación entre las siete variables seleccionadas. De las 49 celdas de la matriz, 7 están ocupadas con los unos de la diagonal. Las 42 restantes muestran los 21 coeficientes de correlación, repetidos por encima y por debajo de la diagonal.</p>
<p>El coeficiente que se pidió es el de Spearman, porque los números codifican categorías ordinales.</p>
<p>Esta matriz no es explicativa, no se identifican variables antecedentes y consecuentes, por eso se trata de una descripción del modo en que las respuestas a estas preguntas varían conjuntamente.</p>
<p>La lectura de la matriz puede empezar señalando que todos los coeficientes son positivos. Eso quiere decir que los encuestados tomaron posición similar respecto de las diferentes instituciones por las que se les consultó, es decir que dieron respuestas no opuestas a las diferentes preguntas. Quienes dijeron tener mucha confianza en algunas instituciones también la tienen por otras y a la inversa, quienes no confían en algunas, tampoco lo hacen en otras. Por ser relaciones descriptivas, nos informan que el conjunto de encuestados se caracteriza porque algunas personas tienden a confiar en estas instituciones y otras tienden a desconfiar de ellas.</p>
<p>Nótese que este es un patrón posible, pero no el único. por ejemplo podría haber coeficientes negativos que indicarían que algunos pares de instituciones gozan de confianza inversa: quienes confían en unas, desconfían de otras.</p>
<p>En segundo lugar, puede leerse que el valor más elevado, que es 0.57 corresponde a la asociación entre las Fuerzas Armadas y Policía. La intensidad, comparativamente elevada, de esta asociación indica que la confianza en ambas “va pareja”, de manera gruesa, podríamos decir que quienes confían en una de las dos instituciones, tienden a confiar también en la otra e inversamente, quienes desconfían de una también lo hacen de la otra. De manera similar se pueden analizar los demás pares de variables.
En el otro extremo, la más tenue de las relaciones, con coeficiente de 0.14 es la de La Iglesia y Los partidos políticos. En este caso hay poca relación entre la confianza que se tiene a una y a la otra de estas dos instituciones. Se podría decir que son “relativamente independientes”.</p>
<p>La matriz de correlaciones informa acerca de la asociación (o varianción conjunta) entre las variables, no dice nada sobre los valores de cada una de ellas. Para conocer qué institución goza de más o menos confianza, hay que ver las distribuciones univariadas. Un modo rápido de tener una visión de conjunto es por medio de un gráfico de barras para cada una.</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-282-1.svg" width="672" /></p>
<p>Aquí se ve que la única institución que concentra casos en “mucha confianza” es la iglesia. La comparación de los gráficos muestra que el patrón de respuestas de carabineros/policía es similar al de las fuerzas armadas, y eso es lo que se refleja en el coeficiente de correlación mayor (<span class="math inline">\(0.57\)</span>).</p>
<p>La matriz de correlaciones es una herramienta útil en minería de datos, porque ofrece un primer pantallazo sobre el modo en que se asocian (de a pares) un conjunto de variables. Otra técnicas, como el análisis factorial y el clustering, que profundizan en la búsqueda de estructura en los datos, tienen su punto de partida en la matriz de correlaciones.</p>
</div>
<div id="la-forma-de-la-relación" class="section level2">
<h2><span class="header-section-number">5.9</span> La forma de la relación</h2>
<p>En este apartado vamos a concentrarnos en relaciones asimétricas: aquellas en las que es posible identificar a una de las variables como antecedente y a la otra como consecuente (o como independiente y
dependiente, en el marco de un diseño experimental). Se trata de
relaciones que se dirigen a explicar una variable (la consecuente) a
partir de los valores de la otra (la antecedente). Por ejemplo, cuando preguntamos si una droga es efectiva para tratar la depresión, buscamos la relación entre las diferentes dosis de la droga y la reducción de síntomas de la depresión, por ejemplo a través del puntaje alcanzado en una prueba que la evalúa. O también, si preguntamos por el efecto del nivel de ansiedad (variable antecedente) sobre los resultados que se obtienen en un examen (variable consecuente, a explicar), o el impacto de una campaña de vacunación (variable antecedente) sobre la frecuencia de casos de gripe, o el tamaño del arsenal de un país como factor explicativo del riesgo de conflictos.</p>
<p>Cuando las variables tienen nivel de medición proporcional, es posible
representar la relación con un diagrama de dispersión y, como hemos
visto, cuanto más intensa es la relación (coeficiente de correlación de Pearson cercano a 1), tanto más se aplana la nube de puntos, yendo hacia una tendencia lineal, aproximándose a una alineación a lo largo de una recta.</p>
<p>En este apartado avanzamos un paso más en el análisis de la relación
entre variables: cuando los puntos del diagrama de dispersión tengan una
disposición semejante a una recta (creciente o
decreciente), podremos buscar la función lineal que mejor
aproxima esos puntos. Usaremos a partir de aquí una notación general:
llamaremos <em>x</em> a la variable antecedente (o independiente) e <em>y</em> a la
consecuente (o dependiente). Porque la relación se supone asimétrica,
esperamos que <em>x</em> tenga efectos sobre <em>y</em> (la dosis de droga sobre la
depresión, o la ansiedad sobre los resultados del examen, la cobertura de la campaña de vacunación sobre la prevalencia de gripe, la cantidad de armas sobre el riesgo de conflicto, en los ejemplos mencionados). Se trata de modelar la nube de puntos a través de una recta, como en el gráfico siguiente:</p>
<div class="figure"><span id="fig:unnamed-chunk-283"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-283-1.svg" alt="Ejemplo de función lineal que aproxima los puntos con una tendencia creciente" width="672" />
<p class="caption">
Figura 5.8: Ejemplo de función lineal que aproxima los puntos con una tendencia creciente
</p>
</div>
<p>Aquí, la recta que aproxima los puntos está trazada de modo que
equilibre lo que los puntos se apartan de ella por encima y por debajo.
La búsqueda de esa función lineal implica proponer un <strong>modelo</strong> para la
forma de la relación entre las dos variables, veremos cuán realista
resulta suponer que las dos variables se relacionan de manera lineal.
Antes de eso, haremos un pequeño repaso de los conceptos relacionados con esta función.</p>
<p>La <strong>función lineal</strong> tiene una expresión matemática como la siguiente
<span class="math display">\[y = b_{0} + b_{1}*x\]</span> en la que <em>x</em> e <em>y</em> son las variables cuya
relación analizamos y los números <span class="math inline">\(b_{0}\)</span> y <span class="math inline">\(b_{1}\)</span> son valores fijos que
determinan cuál es la recta de la que hablamos. Hallar la recta implica
encontrar esos dos números <span class="math inline">\(b_{0}\)</span> y <span class="math inline">\(b_{1}\)</span>. Una vez que están
determinados, se conoce la recta y se la puede trazar.</p>
<div id="ordenada-al-origen" class="section level3">
<h3><span class="header-section-number">5.9.1</span> Ordenada al origen</h3>
<p>El número <span class="math inline">\(b_{0}\)</span> se llama ordenada al origen y representa el valor de
<em>y</em> cuando <em>x</em> vale cero. Eso puede verse fácilmente en la expresión de
la recta cuando se reemplaza a <em>x</em> por cero, así se obtiene:<br />
<span class="math display">\[y = b_{0} + b_{1}*x = b_{0} + b_{1}*0 = b_{0}\]</span></p>
<p>Entonces, si <span class="math inline">\(x = 0\)</span>, tendremos <span class="math inline">\(y = b_0\)</span>. Como los ejes
tienen el cero en el punto en que se cortan, gráficamente esta ordenada
al origen se ubica sobre el eje <em>y</em> (por ser una ordenada), como indican
las diferentes rectas en el gráfico <a href="relación-entre-variables-el-análisis.html#fig:rectasvarias">5.9</a>.</p>
<div class="figure"><span id="fig:rectasvarias"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/rectasvarias-1.svg" alt="Ejemplos de funciones lineales con diferentes valores de la ordenada al origen y de la pendiente" width="672" />
<p class="caption">
Figura 5.9: Ejemplos de funciones lineales con diferentes valores de la ordenada al origen y de la pendiente
</p>
</div>
<p>Las rectas R1 y R3 tienen ordenada al origen positiva (<span class="math inline">\(b_{0} &gt; 0\)</span>). La ordenada al origen de R3 es mayor que la de R1, porque su <span class="math inline">\(b_{0}\)</span> está más arriba en el eje de ordenadas. A los efectos de la ordenada al origen, no hay ninguna diferencia en que R1 vaya subiendo y R3 baje. La recta R2 pasa exactamente por el origen de coordenadas, por lo que su ordenada al origen es cero, <span class="math inline">\(b_{0} = 0\)</span>. La recta R4, si se prolonga para llegar a cortar al eje de ordenadas, lo hace en un valor negativo (<span class="math inline">\(b_{0} &lt; 0\)</span>).</p>
<p>Según las variables con que se trabaje, a veces <span class="math inline">\(b_{0}\)</span> no tiene
interés, porque no se consideran los valores negativos o bien porque no tiene sentido que la variable antecedente sea cero (<span class="math inline">\(x=0\)</span>).</p>
<p>En los ejemplos que hemos mencionado hay diferentes situaciones con
respecto al valor de <span class="math inline">\(b_{0}\)</span>. En la relación <em>dosis droga</em>-<em>depresión</em>, el valor cero para la dosis es la no-administración de la misma. Aquellos sujetos que tienen <span class="math inline">\(x = 0\)</span> son quienes no recibieron la droga y
la ordenada al origen será el valor que hallemos en la escala de
depresión (variable <em>y</em>) para quienes no tomaron la droga (a dosis
cero). Por el contrario, no es posible considerar un valor cero de la
ansiedad en el segundo ejemplo, por lo que allí no nos interesamos por la ordenada al origen.</p>
</div>
<div id="pendiente" class="section level3">
<h3><span class="header-section-number">5.9.2</span> Pendiente</h3>
<p>El otro número que determina de qué función lineal se trata, es <span class="math inline">\(b_{1}\)</span> que se llama pendiente y gráficamente indica la inclinación de la recta: su valor es responsable de que la recta “suba” o “baje”, siempre mirándola de izquierda a derecha.</p>
<p>Las rectas R1, R2 y R4 son crecientes, van aumentando hacia la derecha (a medida que <em>x</em> crece), por eso la pendiente es positiva (<span class="math inline">\(b_{1} &gt; 0\)</span>).</p>
<p>La recta R3 desciende, es una función decreciente, porque a medida que <em>x</em> aumenta <em>y</em> disminuye y la pendiente es negativa (<span class="math inline">\(b_{1} &lt; 0\)</span>).</p>
<p>Vemos entonces que la pendiente depende de que sea una relación directa o inversa. Cuando es directa, <em>x</em> crece e <em>y</em> crece y la pendiente es positiva; cuando es inversa, <em>x</em> crece e <em>y</em> disminuye y la pendiente es negativa. Esto es lo mismo que sucede con el coeficiente de Pearson: positivo indica relación directa y negativo, inversa. Por esta razón, <span class="math inline">\(b_{1}\)</span> (la pendiente de la recta) siempre tiene el mismo signo de <em>r</em>, porque en ambos casos el signo indica si se trata de una relación directa o inversa.</p>
<p>Además del gráfico, el significado analítico de la pendiente es muy
importante, porque indica en cuánto varía <em>y</em> por cada unidad que
aumenta <em>x</em>. El número <span class="math inline">\(b_{1}\)</span> mide cuánto cambia la variable
consecuente (<em>y</em>. la dependiente), cuando la variable antecedente
(<em>x</em>, la independiente) aumenta en una unidad. Como <span class="math inline">\(b_{1}\)</span> puede ser positivo o
negativo, el cambio en <em>y</em> puede ser en dirección de aumentar cuando <em>x</em>
aumenta o de reducirse. En el ejemplo de la relación <em>dosis droga</em>-<em>depresión</em>, se esperaría que el valor de <span class="math inline">\(b_{1}\)</span> fuera negativo,
porque mide en cuánto se reduce la depresión (medida con el puntaje
correspondiente a la escala que se use) por cada unidad que se aumente
la dosis. Del mismo modo con la <em>ansiedad</em> y el <em>resultado del examen</em>,
se espera que los sujetos con mayor ansiedad alcancen resultados menores
en el examen, por lo que la relación se espera que sea inversa, con
pendiente negativa y que la recta sea decreciente.</p>
<p>Por el contrario, si observamos la relación entre las <em>horas dedicadas al estudio</em> -como variable antecedente, <em>x</em>- y el <em>resultado del examen</em> -como consecuente, <em>y</em>-, esperaríamos una relación directa, una pendiente positiva (<span class="math inline">\(b_{1} &gt; 0\)</span>), una recta creciente que indica cómo aumenta el resultado del examen a medida que se dedican más horas al estudio.</p>
</div>
<div id="obtención-de-la-recta-de-regresión" class="section level3">
<h3><span class="header-section-number">5.9.3</span> Obtención de la recta de regresión</h3>
<p>Para encontrar <span class="math inline">\(b_{0}\)</span> y <span class="math inline">\(b_{1}\)</span> y determinar así la función lineal que
corresponde a nuestra recta de regresión, deben usarse los puntos del
diagrama, es decir los pares ordenados correspondientes a cada caso.
Para hacerlo usaremos las fórmulas que mostramos a continuación pero
solo será para ver el modo de usarlas, luego lo pediremos a R.</p>
<p>Llamando <span class="math inline">\(x_i\)</span> e <span class="math inline">\(y_i\)</span> a cada valor de cada par ordenado y
<em>n</em> al número total de observaciones, la expresión para calcular la
pendiente de la recta es:</p>
<p><span class="math display">\[b_1=\frac{n*\sum_{i=1}^{n}{x_i*y_i}-(\sum_{i=1}^{n}x_i)*(\sum_{i=1}^{n}y_i)}{n*\sum_{i=1}^{n}x_i^{2}-(\sum_{i=1}^{n}x_i )^{2}}\]</span></p>
<p>Una vez que conocemos la pendiente, se puede hallar la ordenada al
origen haciendo:</p>
<p><span class="math display">\[b_{0} = \overline{y} - b_{1}*\overline{x}\]</span></p>
<p>Donde <span class="math inline">\(\overline{x}\)</span> e <span class="math inline">\(\overline{y}\)</span> son las medias de <em>x</em> y de <em>y</em>
respectivamente.</p>
<p>Vamos a aplicar estas expresiones para encontrar la función lineal que mejor ajusta los puntos del ejemplo en el que relacionamos el <em>puntaje en la escala de inteligencia lógico-matemática</em> con el <em>número de ejercicios correctamente realizados</em>. Tratamos de manera asimétrica a esta relación y tomamos al puntaje de la escala de inteligencia lógico-matemática como antecedente (<em>x</em>) y al número de aciertos como consecuente (<em>y</em>). Es decir que en nuestro modelo estamos tratando de explicar el <em>número de aciertos</em> a partir del <em>puntaje en la escala de inteligencia lógico-matemática</em>. Y sea que este puntaje de la prueba tiene valores que están entre 30 y 60, es decir, <span class="math inline">\(30\le x\le60\)</span>; que se lee &quot;equis toma valores comprendidos entre 30 y 60.</p>
<p>Para facilitar el uso de la expresión del cálculo de la pendiente,
agregamos dos columnas adicionales a los valores de las dos variables: la de los productos de cada <em>x</em> por cada <em>y</em>, y la de las <em>x</em> al cuadrado, del siguiente modo:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center"><span class="math inline">\(x_i\)</span></th>
<th align="center"><span class="math inline">\(y_i\)</span></th>
<th align="center"><span class="math inline">\(x_i*y_i\)</span></th>
<th align="center"><span class="math inline">\(x_i^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td align="center">46</td>
<td align="center">7</td>
<td align="center">322</td>
<td align="center">2116</td>
</tr>
<tr class="even">
<td></td>
<td align="center">44</td>
<td align="center">2</td>
<td align="center">88</td>
<td align="center">1936</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">56</td>
<td align="center">7</td>
<td align="center">392</td>
<td align="center">3136</td>
</tr>
<tr class="even">
<td></td>
<td align="center">57</td>
<td align="center">8</td>
<td align="center">456</td>
<td align="center">3249</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">30</td>
<td align="center">2</td>
<td align="center">60</td>
<td align="center">900</td>
</tr>
<tr class="even">
<td></td>
<td align="center">60</td>
<td align="center">9</td>
<td align="center">540</td>
<td align="center">3600</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">45</td>
<td align="center">5</td>
<td align="center">225</td>
<td align="center">2025</td>
</tr>
<tr class="even">
<td></td>
<td align="center">43</td>
<td align="center">1</td>
<td align="center">43</td>
<td align="center">1849</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">64</td>
<td align="center">9</td>
<td align="center">576</td>
<td align="center">4096</td>
</tr>
<tr class="even">
<td></td>
<td align="center">32</td>
<td align="center">3</td>
<td align="center">96</td>
<td align="center">1024</td>
</tr>
<tr class="odd">
<td>Sumas</td>
<td align="center">477</td>
<td align="center">53</td>
<td align="center">2798</td>
<td align="center">23931</td>
</tr>
</tbody>
</table>
<p>Tenemos entonces</p>
<p><span class="math display">\[\sum_{i=1}^{10}x_i=477\]</span>
<span class="math display">\[\sum_{i=1}^{10}y_i=53\]</span>
<span class="math display">\[\sum_{i=1}^{10}x_i*yi=2789\]</span>
<span class="math display">\[\sum_{i=1}^{10}x_i^{2}=23931\]</span></p>
<p>Reemplazando, obtenemos la pendiente de la recta:</p>
<p><span class="math display">\[b_1=\frac{n*\sum_{i=1}^{n}{x_i*y_i}-(\sum_{i=1}^{n}x_i)*(\sum_{i=1}^{n}y_i)}{n*\sum_{i=1}^{n}x_i^{2}-(\sum_{i=1}^{n}x_i )^{2}}=\]</span></p>
<p><span class="math display">\[\frac{10*2798-477*53}{10*23931-477^{2}}=\frac{2699}{11781}=0.23\]</span></p>
<p>Esta pendiente es positiva, como lo había sido <span class="math inline">\(r\)</span>, y eso indica que la relación es directa. La pendiente además nos informa que por cada punto adicional en la variable antecedente (puntaje escala inteligencia lógico-matemática) se espera que se incremente en 0.23 el número de ejercicios bien resueltos. De manera más comprensible,puede decirse que se espera que cada cuatro unidades que aumente la puntuación de la inteligencia lógico-matemática, se espera un ejercicio bien resuelto más.</p>
<p>Las medias de <span class="math inline">\(x\)</span> y de <span class="math inline">\(y\)</span> habían sido calculadas cuando las necesitamos
para <em>r</em>: <span class="math inline">\(\overline{x} = 47,7\)</span> e <span class="math inline">\(\overline{y} = 5,3\)</span> por lo que la
ordenada al origen de la recta es:</p>
<p><span class="math display">\[b_0=\bar{y}-b_1*\bar{x}=5.3-0.23*47.7=-5.63\]</span></p>
<p>El valor de la ordenada al origen no tiene interés en este ejemplo
-salvo para el trazado de la recta-, porque sería el número de aciertos esperado (que resultan negativos, es decir sin interpretación posible) para alguien con puntaje cero en la escala de inteligencia, lo cual no está definido; recordemos que <span class="math inline">\(30\le x\le60\)</span>.</p>
<p>Conociendo la pendiente y la ordenada al origen, podemos escribir la
ecuación de la recta: <span class="math inline">\(\widehat{y} = - 5.63 + 0.23*x\)</span>. Esta es la
función lineal que describe los cambios de <em>y</em> a partir de los de <em>x</em>.
Hemos escrito a <em>y</em> con una indicación especial, un
circunflejo: <span class="math inline">\(\widehat{y}\)</span>, vamos a llamarla “<em>y</em> estimada” y es la que
vamos a usar para trazar la recta:</p>
<div class="figure"><span id="fig:unnamed-chunk-285"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-285-1.svg" alt="Diagrama de dispersión de la relación entre el puntaje en la escala de inteligencia lógico-matemática y el número de ejercicios de matemática correctamente realizados, y la recta de regresión que mejor ajusta los puntos" width="672" />
<p class="caption">
Figura 5.10: Diagrama de dispersión de la relación entre el puntaje en la escala de inteligencia lógico-matemática y el número de ejercicios de matemática correctamente realizados, y la recta de regresión que mejor ajusta los puntos
</p>
</div>
<p>La recta que hemos encontrado usando las fórmulas de arriba es la que
hace mínimos los cuadrados de las distancias de cada punto a la
recta<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a>, por eso, a esta también se la llama <strong>recta de mínimos cuadrados</strong>.</p>
<p>Además de mostrarnos la forma del modelo, la recta de regresión sirve
para hacer estimaciones de valores no observados, porque nos ofrece
valores de <span class="math inline">\(\widehat{y}\)</span> para cada <em>x</em> que reemplacemos. Por ejemplo, si
preguntamos por la cantidad de ejercicios bien resueltos que se esperan
en alguien que alcanzó 55 puntos en la escala de inteligencia
lógico-matemática, respondemos reemplazando en la función el valor de
<span class="math inline">\(x=55\)</span> y resulta:</p>
<p><span class="math display">\[\widehat{y} = - 5.63 + 0.23*x = - 5.63 + 0.23*55 = 7.02\]</span></p>
<p>Que puede redondearse a 7. Este es el valor estimado del número de
aciertos para alguien con 55 puntos en la escala de inteligencia lógico
matemática.</p>
<p>Estas estimaciones son muy valiosas para hacer predicciones sobre
valores que no han sido observados, por ejemplo hacia el futuro.
Ejemplos muy útiles de esta aplicación son las proyecciones de
población, y más específicamente las de proyección de matrícula escolar, que ofrecen estimaciones del volumen de ingresantes que se prevé para años próximos. Si se conoce la relación entre el peso de la deuda como porcentaje del PBI y el riesgo de crisis económica, se puede predecir el riesgo de crisis conociendo el porcentaje del PBI que representa la deuda. Cundo se cuenta con un modelo que explica la relación entre el monto de una transferencia condicionada de renta (como la Asignación Universal por Hijo en Argentina o la Bolsa Familia en Brasil) sobre la propensión a buscar empleo por parte de jefes y jefas de hogar, se puede estimar el monto que permite cumplir con la condición del programa (controles de salud, escolarización), pero no desincentiva la búsqueda de empleo. En general, si se tiene un modelo que explica el comportamiento de una variable en base a las variaciones de otra, entonces se puede predecir qué sucederá con la primera para diferentes valores de la segunda.</p>
<p>Los modelos que relacionan variables son diferentes según:</p>
<ul>
<li><p>la forma de la relación</p></li>
<li><p>la cantidad de variables involucradas</p></li>
</ul>
<p>La primera puede provenir de una teoría, o de la observación del diagrama de dispersión. Es decir pueder haberse propuesto el modelo inicialmente a partir de deducciones teóricas, o bien puede buscarse a regularidad en los datos, de manera empírica.<br />
La segunda depende de las hipótesis; de cuántas y cuáles son las variables que participan en la explicación del fenómeno o proceso bajo análisis (que queda resumido en la variable consecuente).</p>
<p>Aquí nos ocuparemos por solo una de las formas posibles: el modelo lineal y solo del caso en que hay una sola variable explicativa (antecedente).</p>
<p>Cuando se reemplaza cada uno de los <em>x</em> observados en la función, se
encuentran las estimaciones para cada uno de ellos. En la tabla
siguiente indicamos cada uno de los pares ordenados como fueron
observados y agregamos los valores de <span class="math inline">\(\widehat{y}\)</span> estimados a través
de la función lineal<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a>; por último, restamos los valores estimados de
<em>y</em>, de los observados, para ver las diferencias entre los que la recta
estima y los que hemos observado:</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(x\)</span></th>
<th align="center"><span class="math inline">\(y\)</span></th>
<th align="center"><span class="math inline">\(\widehat{y}\)</span></th>
<th align="center"><span class="math inline">\(y - \widehat{y}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">46</td>
<td align="center">7</td>
<td align="center">4.91</td>
<td align="center">2.09</td>
</tr>
<tr class="even">
<td align="center">44</td>
<td align="center">2</td>
<td align="center">4.45</td>
<td align="center">-2.45</td>
</tr>
<tr class="odd">
<td align="center">56</td>
<td align="center">7</td>
<td align="center">7.20</td>
<td align="center">-0.20</td>
</tr>
<tr class="even">
<td align="center">57</td>
<td align="center">8</td>
<td align="center">7.43</td>
<td align="center">0.57</td>
</tr>
<tr class="odd">
<td align="center">30</td>
<td align="center">2</td>
<td align="center">1.24</td>
<td align="center">0.76</td>
</tr>
<tr class="even">
<td align="center">60</td>
<td align="center">9</td>
<td align="center">8.12</td>
<td align="center">0.88</td>
</tr>
<tr class="odd">
<td align="center">45</td>
<td align="center">5</td>
<td align="center">4.68</td>
<td align="center">0.32</td>
</tr>
<tr class="even">
<td align="center">43</td>
<td align="center">1</td>
<td align="center">4.22</td>
<td align="center">-3.22</td>
</tr>
<tr class="odd">
<td align="center">64</td>
<td align="center">9</td>
<td align="center">9.03</td>
<td align="center">-0.03</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">3</td>
<td align="center">1.70</td>
<td align="center">1.30</td>
</tr>
</tbody>
</table>
<p>La última columna mide la distancia que hay entre cada punto y la recta.
Es un indicador de la calidad del ajuste que hace la función lineal de
los puntos. Cuando esas distancias son pequeñas tenemos una recta que
ajusta mejor los puntos que cuando las distancias son grandes. Como
vemos, en este ejemplo hay algunas positivas, que corresponden a los
puntos que están encima de la recta, y otras negativas, las de los
puntos por debajo de la recta. Veamos en el gráfico siguiente la
ubicación de uno de estos puntos, por ejemplo el que corresponde al par
observado <span class="math inline">\((43; 1)\)</span>, al que la recta estima con el valor <span class="math inline">\(\widehat{y} = 4.22\)</span>:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-287"></span>
<img src="imagenes/grafico13.png" alt="Ubicación gráfica de la diferencia entre el valor de $y$ observado y su estimación $\widehat{y}$" width="175" />
<p class="caption">
Figura 5.11: Ubicación gráfica de la diferencia entre el valor de <span class="math inline">\(y\)</span> observado y su estimación <span class="math inline">\(\widehat{y}\)</span>
</p>
</div>
<p>Este desvío es negativo porque el punto está debajo de la recta, la
estimación <span class="math inline">\(\widehat{y}\)</span> es mayor que el valor observado, <em>y</em>.</p>
<p>La suma de todos estos desvíos es cero, por haber pedido a la recta la
condición de equilibrar los puntos. Estas diferencias son los errores
que se cometen al estimar a través de la función lineal. Para verlos
como tales, observemos que si la correlación fuera perfecta (positiva o
negativa) como en los gráficos <a href="relación-entre-variables-el-análisis.html#fig:rectaCrec">5.6</a> y <a href="relación-entre-variables-el-análisis.html#fig:rectaDecrec">5.7</a> todos los puntos estarían sobre la
recta y coincidirían los valores de <em>y</em> con los de <span class="math inline">\(\widehat{y}\)</span>, por lo
que las diferencias de la última columna serían todas cero, no habría
error en una relación perfecta. Como hemos dicho, esa es una situación
ideal, que no puede observarse en la realidad: en los casos reales
siempre hay apartamientos de los puntos a la recta, que constituyen el
error de estimación. Para llegar a una medida de la calidad de nuestro
modelo, es decir una medida de qué tan bueno es el ajuste que la recta
hace sobre los puntos realmente observados, trabajaremos sobre la
dispersión, a través de la varianza.</p>
<p>En primer lugar, la variable tiene su varianza, que mide lo que los
valores se apartan de la media, vamos a llamarla <span class="math inline">\(s_{y}^{2}\)</span> (la
varianza de <em>y</em>). En segundo lugar, los <span class="math inline">\(\widehat{y}\)</span> también se apartan
de la media y esas distancias pueden resumirse en otra varianza, la que
mide las distancias desde los <span class="math inline">\(\widehat{y}\)</span> hasta la media de <em>y</em>, la
llamaremos <span class="math inline">\(s_{\widehat{y}}^{2}\)</span> (la varianza de <span class="math inline">\(\widehat{y}\)</span>). Así
entonces resumimos los desvíos de la variable hasta la media, con la
varianza de <em>y</em>, y los desvíos de las estimaciones hasta la media, con
la varianza de <span class="math inline">\(\widehat{y}\)</span>. Si se traza una recta horizontal para
ubicar a la media de <em>y</em> (<span class="math inline">\(\overline{y}\)</span> en <span class="math inline">\(5.3\)</span>) y se recuerda que los
valores de <em>y</em> son los que están en los puntos realmente observados,
mientras que los de <span class="math inline">\(\widehat{y}\)</span> están sobre la recta de regresión,
estos desvíos pueden verse gráficamente así:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-288"></span>
<img src="imagenes/grafico14.png" alt="Ubicación gráfica de los alejamientos (desvíos) de $y$ observada y de $\widehat{y}$ estimada, hasta la media de $y$ ($\overline{y}$)" width="172" />
<p class="caption">
Figura 5.12: Ubicación gráfica de los alejamientos (desvíos) de <span class="math inline">\(y\)</span> observada y de <span class="math inline">\(\widehat{y}\)</span> estimada, hasta la media de <span class="math inline">\(y\)</span> (<span class="math inline">\(\overline{y}\)</span>)
</p>
</div>
<p>Lo que cada observación se aleja de la media es la diferencia
<span class="math inline">\(y - \overline{y}\)</span>. Cuando se consideran todas ellas, su medida es la
varianza de <em>y</em> (indicada <span class="math inline">\(s_{y}^{2}\)</span>).</p>
<p>Lo que se desvía la estimación (ubicada sobre la recta de regresión) de
la media es <span class="math inline">\(\widehat{y} - \overline{y}\)</span>, que cuando se extiende a todos
los puntos se resume en la varianza de <span class="math inline">\(\widehat{y}\)</span> (que indicamos como
<span class="math inline">\(s_{\widehat{y}}^{2}\)</span>).</p>
<p>La calidad del ajuste se aprecia en la proximidad que la recta tiene a
los puntos, en el caso ideal (si <span class="math inline">\(r = 1\)</span> o <span class="math inline">\(r = - 1\)</span>), las distancias
son todas cero. En una situación real, el ajuste será tanto mejor cuanto
más cerca estén los puntos de la recta; es decir, cuanto más pequeñas
sean esas distancias. Para medir esta calidad se usa el cociente entre
las dos varianzas anteriores, que resulta ser el ya mencionado
coeficiente general de determinación:
<span class="math inline">\(R^{2} = \frac{s_{\widehat{y}}^{2}}{s_{y}^{2}}\)</span>.</p>
<p>Al que ahora calculamos como la varianza de <span class="math inline">\(\widehat{y}\)</span> sobre la
varianza de <em>y</em>, por lo que mide qué porción de la variabilidad total de
<em>y</em> (el denominador) representa la variabilidad de <span class="math inline">\(\widehat{y}\)</span>, puede
leerse como la parte de toda la variabilidad de la variable dependiente
que es explicada por el modelo lineal.</p>
<p>Este cociente no puede ser negativo ni mayor que 1, porque el numerador
es menor o igual que el denominador. Solo vale 1 en el caso de una
asociación perfecta, en que las varianzas son iguales -porque los puntos
están sobre la recta-, <span class="math inline">\(r = 1\)</span> <span class="math inline">\(r = - 1\)</span> y, en consecuencia <span class="math inline">\(R^2=1\)</span>.</p>
<p>El coeficiente general de determinación mide la proporción de los
cambios de <em>y</em> (expresados con la varianza) que se explican a través de
la función lineal. Por eso es muy valioso, porque cuantifica el peso
relativo de la variable <em>x</em> (a través de la función lineal) en la
explicación de <em>y</em>.<br />
Podemos así decir que, por ejemplo, el 30% de las diferencias en el
rendimiento escolar en la escuela primaria se explica por la
educación de los padres, o que el 60% de la disminución del puntaje en
una prueba que evalúa la depresión se puede atribuir a la administración de una determinada droga. Se aprecia con estos ejemplos la gran potencialidad explicativa de este coeficiente.<br />
Todo el análisis de regresión que hemos desarrollado hasta aquí puede
hacerse de manera equivalente si la relación entre las variables no es
lineal. En vez de obtener la ecuación de una recta, se obtendrá la de
una parábola, una cúbica o cualquier otra función que aproxime
adecuadamente los pares ordenados que se observan. La definición del
coeficiente general de determinación que hemos dado:
<span class="math inline">\(R^{2} = \frac{s_{\widehat{y}}^{2}}{s_{y}^{2}}\)</span> no cambia, pero los
<span class="math inline">\(\widehat{y}\)</span> se calcularán con la función adecuada, no con la lineal
que vimos.<br />
Sobre el coeficiente de correlación de Pearson, debe recordarse que solo
es adecuado para evaluar la intensidad de la relación entre dos
variables si ésta es lineal. En presencia de una relación de otro tipo,
como la del gráfico <a href="relación-entre-variables-el-análisis.html#fig:dispMedic">5.5</a>, el coeficiente de Pearson dará un valor muy bajo,
pero eso no quiere decir que la relación sea débil o inexistente, sino
que el modelo lineal no es adecuado para describirla. Por ello, si se
encuentra un coeficiente de Pearson muy bajo, debe explorarse la
existencia de una relación no lineal, esto puede hacerse fácilmente
observando cómo se disponen los puntos en el diagrama de dispersión.<br />
Cuando la relación se modela con una función lineal -y solo en estos
casos-, el coeficiente general de determinación (<span class="math inline">\(R^2\)</span>) se calcula
directamente elevando al cuadrado al coeficiente de Pearson.<br />
Hemos señalado que el coeficiente de Spearman es adecuado cuando una
variable o ambas están medidas a nivel ordinal. Pero también es adecuado
cuando no se puede suponer que las variables tengan, en la población,
distribución normal, que es un requisito para el cálculo del coeficiente
de Pearson. Una ventaja adicional del coeficiente de Spearman es que es
poco sensible a valores extremos. La relación que hay entre estos dos coeficientes es similar a la que hay entre la media y la mediana.
Cuando existen excepcionalmente altos o bajos, es conveniente calcular este coeficiente, aun cuando las variables sean ambas cuantitativas. Se
dice que el coeficiente de Spearman es más “robusto” que es de Pearson,
porque se afecta menos por valores atípicos de la variable. El siguiente ejemplo con datos ficticios ilustra la diferencia.<br />
Consideremos la siguiente relación</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-289-1.svg" width="672" /></p>
<p>Los coeficientes resultan:</p>
<pre><code>## [1] &quot;coeficiente de Pearson: 0.662&quot;</code></pre>
<pre><code>## [1] &quot;coeficiente de Spearman: 0.694&quot;</code></pre>
<p>Se trata de una tendencia lineal, con un par de valores extremos que se apartan del
grupo. Los coeficientes de Pearson y de Spearman dan 0.662 y 0.694 respectivamente. La diferencia se debe a que el coeficiente de Pearson tiene en cuenta cada uno de los valores de la variable, mientras que el de Spearman considera los “rangos”, el efecto de los valores aislados es detectado por el primero de los coeficientes y en menor medida por el segundo. El
tratamiento de estas situaciones requiere atención. Por un lado, se debe
repetir el análisis sin los valores extremos y comparar nuevamente los
coeficientes; por el otro, observar qué hizo que esos casos tuvieran valores tan atípicos. La diferencia entre los dos coeficientes, da una
señal para mirar más de cerca los datos.</p>
</div>
</div>
<div id="la-visualización-de-los-datos" class="section level2">
<h2><span class="header-section-number">5.10</span> La visualización de los datos</h2>
<p>La medidas descriptivas que se mencionaron en los capítulos anteriores ofrecen un resumen de las variables individualmente; en estos dos últimos capítulos hemos recorrido un amplio conjunto de formas en que pueden suceder las relaciones entre dos variables y mucho de lo que se ha dicho, puede extrapolarse a modelos más complejos, con más de dos variables bajo análisis simultáneo y con relaciones que no son lineales. La decisión sobre el modelo más adecuado es en parte teórica, pero está influida por la observación de los datos. En estudios exploratorios, en los que no se cuenta con hipótesis sobre la forma en que dos o más variables se relacionan, es muy necesario observar el conjunto de datos antes de proponer modelos.<br />
Para mostrar la utilidad de las representaciones gráficas, existe un conjunto de datos producido por Francis Anscombe en la década de los setenta del siglo pasado (<span class="citation">Anscombe (<a href="#ref-Anscombe1973a">1973</a>)</span>, <span class="citation">Tufte (<a href="#ref-Tufte1989">1989</a>)</span>). Su autor muestra por este medio, tanto la importancia de la visualización de los datos, como el impacto que pueden tener los casos atípicos sobre las medidas descriptivas. Más adelante se analiza en detalle ese conjunto de datos, lo importante es que muestra que el conocimiento de medidas resumen como los descriptivos univariados, los coeficientes de correlación y aun los coeficientes de un modelo que ajuste la relación, pueden dar una idea equivocada de la manera en que los datos se organizan, y que la visualización permite apreciarla mejor.</p>
<p>En la misma dirección, Steph Locke (<span class="citation">Locke (<a href="#ref-Locke2018">2018</a>)</span>) generó una matriz de datos, llamada “Datasaurus”, con 13 pares <span class="math inline">\(x-y\)</span>, cada uno de los cuales tiene medidas descriptivas (media y desviación estándar de <span class="math inline">\(x\)</span> y de <span class="math inline">\(y\)</span>), así como coeficientes de correlación entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, muy similares, pero los diagramas de dispersión muestran las grandes diferencias entre los pares de datos. La idea, en línea con la de Anscombe, es la de llamar la atención sobre la importancia de la visualización de los datos para tener una descripción completa y mostrar que las medidas descriptivas pueden engañar.</p>
</div>
<div id="hacerlo-en-r-4" class="section level2">
<h2><span class="header-section-number">5.11</span> Hacerlo en R</h2>
<div id="distancia-chi2" class="section level3">
<h3><span class="header-section-number">5.11.1</span> Distancia <span class="math inline">\(\chi^{2}\)</span></h3>
<p>En el paquete base de R existe una función que realiza operaciones relacionadas con el puntaje <span class="math inline">\(\chi^{2}\)</span>; el comando es chi.test y se aplica sobre una tabla de contingencia. Estas operaciones contituyen lo que se denomina “prueba <span class="math inline">\(\chi^{2}\)</span>”, sobre la que trabajaremos más adelante. Por ahora, solo se usará una parte de los resultados de esta prueba.</p>
<p>La aplicación de la prueba a una tabla de contingencia da como resultado un objeto de clase “htest”, de ello, nos van a interesar sus componentes. Para construir la tabla que cruza los tipos de violencia con el tamaño de las ciudades, primero debemos leer la base (datos ficticios), denominamos “violencia” a esa base:</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb317-1" data-line-number="1">violencia &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;bases/archivostxt/violencia.txt&quot;</span>,</a>
<a class="sourceLine" id="cb317-2" data-line-number="2">  <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb317-3" data-line-number="3">)</a></code></pre></div>
<p>Los nombres de las variables son:</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb318-1" data-line-number="1"><span class="kw">names</span>(violencia)</a></code></pre></div>
<pre><code>## [1] &quot;tipo&quot;     &quot;ciudades&quot;</code></pre>
<p>A continuación llamamos “tabla.viol” al cruce de las dos variables:</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb320-1" data-line-number="1">tabla.viol &lt;-<span class="st"> </span><span class="kw">table</span>(violencia<span class="op">$</span>tipo, violencia<span class="op">$</span>ciudades)</a></code></pre></div>
<p>Y vemos su aspecto:</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb321-1" data-line-number="1">tabla.viol</a></code></pre></div>
<pre><code>##                
##                 áreas rurales ciudades grandes ciudades pequeñas
##   autoinfligida            15              100                35
##   colectiva                 5               35                10
##   interpersonal            90              110               100</code></pre>
<p>Ahora aplicamos la prueba a esa tabla, y se guarda el resultado de la prueba con el nombre “jicu.viol”.</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb323-1" data-line-number="1">jicu.viol &lt;-<span class="st"> </span><span class="kw">chisq.test</span>(tabla.viol)</a></code></pre></div>
<p>Preguntamos cuáles son los atributos de este objeto:</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb324-1" data-line-number="1"><span class="kw">attributes</span>(jicu.viol)</a></code></pre></div>
<pre><code>## $names
## [1] &quot;statistic&quot; &quot;parameter&quot; &quot;p.value&quot;   &quot;method&quot;    &quot;data.name&quot; &quot;observed&quot; 
## [7] &quot;expected&quot;  &quot;residuals&quot; &quot;stdres&quot;   
## 
## $class
## [1] &quot;htest&quot;</code></pre>
<p>Los “nombres” indican lo que este objeto contiene en su interior, la “clase” es el tipo de objeto. De los nombres, por ahora nos interesan:</p>
<ul>
<li><p><code>statistic</code> que es el valor de la distancia <span class="math inline">\(\chi^{2}\)</span>.</p></li>
<li><p><code>observed</code> es la tabla de frecuencias original, las frecuencias observadas</p></li>
<li><p><code>expected</code> es la tabla de frecuencias esperadas bajo la hipótesis de independencia</p></li>
</ul>
<p>Para llegar a ellos, se usa el mismo procedimiento que para referirse a las variables de una matriz de datos. Así, la distancia <span class="math inline">\(\chi^{2}\)</span> es:</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb326-1" data-line-number="1">jicu.viol<span class="op">$</span>statistic</a></code></pre></div>
<pre><code>## X-squared 
##  50.18553</code></pre>
<p>La tabla de frecuencias observadas (que son los datos originales):</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb328-1" data-line-number="1">jicu.viol<span class="op">$</span>observed</a></code></pre></div>
<pre><code>##                
##                 áreas rurales ciudades grandes ciudades pequeñas
##   autoinfligida            15              100                35
##   colectiva                 5               35                10
##   interpersonal            90              110               100</code></pre>
<p>Y la de esperadas:</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb330-1" data-line-number="1">jicu.viol<span class="op">$</span>expected</a></code></pre></div>
<pre><code>##                
##                 áreas rurales ciudades grandes ciudades pequeñas
##   autoinfligida            33             73.5              43.5
##   colectiva                11             24.5              14.5
##   interpersonal            66            147.0              87.0</code></pre>
<p>Los decimales de la última pueden quitarse redondeando:</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb332-1" data-line-number="1"><span class="kw">round</span>(jicu.viol<span class="op">$</span>expected, <span class="dv">0</span>)</a></code></pre></div>
<pre><code>##                
##                 áreas rurales ciudades grandes ciudades pequeñas
##   autoinfligida            33               74                44
##   colectiva                11               24                14
##   interpersonal            66              147                87</code></pre>
<p>El número total de observaciones no es uno de los elementos que la prueba da directamente. Hay que pedirlo a partir de la suma de las frecuencias de la tabla de observadas (o de esperadas, que totaliza lo mismo). Definimos como “n” al ese valor, porque lo vamos a necesitar para calcular los coeficientes:</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb334-1" data-line-number="1">n &lt;-<span class="st"> </span><span class="kw">sum</span>(jicu.viol<span class="op">$</span>observed)</a></code></pre></div>
<p>Y es:</p>
<pre><code>## [1] 500</code></pre>
<p>Del mismo modo, rotulamos como <span class="math inline">\(f\)</span> al número de filas y <span class="math inline">\(c\)</span> al de columnas:</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb336-1" data-line-number="1">f &lt;-<span class="st"> </span><span class="kw">nrow</span>(jicu.viol<span class="op">$</span>observed)</a>
<a class="sourceLine" id="cb336-2" data-line-number="2">c &lt;-<span class="st"> </span><span class="kw">ncol</span>(jicu.viol<span class="op">$</span>observed)</a></code></pre></div>
<p>Una vez que se cuenta con el puntaje <span class="math inline">\(\chi^{2}\)</span>, se pueden calcular los coeficientes. Para tenerlo disponible más fácilmente, le vamos a asignar un nombre:</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb337-1" data-line-number="1">d.ji.cuad &lt;-<span class="st"> </span>jicu.viol<span class="op">$</span>statistic</a></code></pre></div>
<p>Ahora d.ji.cuad es la distancia <span class="math inline">\(\chi^{2}\)</span></p>
</div>
<div id="coeficientes" class="section level3">
<h3><span class="header-section-number">5.11.2</span> Coeficientes</h3>
<div id="varphi" class="section level4">
<h4><span class="header-section-number">5.11.2.1</span> <span class="math inline">\(\varphi\)</span></h4>
<p>Se calcula la raiz cuadrada de la distancia <span class="math inline">\(\chi^{2}\)</span> dividida en el número de casos: <span class="math display">\[\varphi=\sqrt{\frac{\chi^2}{n}}\]</span></p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb338-1" data-line-number="1"><span class="kw">sqrt</span>(d.ji.cuad <span class="op">/</span><span class="st"> </span>n)</a></code></pre></div>
<pre><code>## X-squared 
## 0.3168139</code></pre>
</div>
<div id="c-de-pearson" class="section level4">
<h4><span class="header-section-number">5.11.2.2</span> C de Pearson</h4>
<p>Como el anterior, sumando <span class="math inline">\(\chi^{2}\)</span> a <span class="math inline">\(n\)</span> en el denominador<br />
<span class="math display">\[C=\sqrt{\frac{\chi^2}{\chi^2+n}}\]</span></p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb340-1" data-line-number="1"><span class="kw">sqrt</span>(d.ji.cuad <span class="op">/</span><span class="st"> </span>(d.ji.cuad <span class="op">+</span><span class="st"> </span>n))</a></code></pre></div>
<pre><code>## X-squared 
## 0.3020193</code></pre>
</div>
<div id="v-de-cramer" class="section level4">
<h4><span class="header-section-number">5.11.2.3</span> V de Cramer</h4>
<p>Incluye al mínimo entre el número de filas menos uno y el número de columnas menos uno. <code>min</code> es una función de biblioteca de R base.
<span class="math display">\[V=\sqrt{\frac{\chi^2}{n*min(f-1,c-1)}}\]</span></p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb342-1" data-line-number="1"><span class="kw">sqrt</span>(d.ji.cuad <span class="op">/</span><span class="st"> </span>(n <span class="op">*</span><span class="st"> </span><span class="kw">min</span>(c <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, f <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)))</a></code></pre></div>
<pre><code>## X-squared 
## 0.2240213</code></pre>
</div>
<div id="spearman" class="section level4">
<h4><span class="header-section-number">5.11.2.4</span> Spearman</h4>
<p>El comando para calcular coeficientes de correlación en R es <code>cor</code>, al cual en este caso deberá indicársele que estamos trabajando con variables ordinales, por lo que queremos el coeficiente de Spearman; de lo contrario, por defecto calcula el coeficiente de Pearson. La matriz de datos del ejemplo mostrado antes se llama merito.educa.mad y las variables son OM (orden de mérito) y educamadre. Así definidas, el pedido del coeficiente se hace indicando cuáles son las dos variables que se correlacionan y qué método debe usarse, en base a su nivel de medición:</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb344-1" data-line-number="1"><span class="kw">cor</span>(merito.educa.mad<span class="op">$</span>OM, merito.educa.mad<span class="op">$</span>educamadre,</a>
<a class="sourceLine" id="cb344-2" data-line-number="2">  <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span></a>
<a class="sourceLine" id="cb344-3" data-line-number="3">)</a></code></pre></div>
<pre><code>## [1] 0.7509393</code></pre>
<p>Redondeado a tres decimales</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb346-1" data-line-number="1"><span class="kw">round</span>(<span class="kw">cor</span>(merito.educa.mad<span class="op">$</span>OM, merito.educa.mad<span class="op">$</span>educamadre,</a>
<a class="sourceLine" id="cb346-2" data-line-number="2">  <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span></a>
<a class="sourceLine" id="cb346-3" data-line-number="3">), <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.751</code></pre>
</div>
<div id="pearson" class="section level4">
<h4><span class="header-section-number">5.11.2.5</span> Pearson</h4>
<p>El comando <code>cor</code> devuelve, por defecto, el coeficiente de Pearson, por lo que no es necesario especificar el parámetro <code>method</code>.</p>
<p>Para el ejemplo que correlaciona el puntaje en la escala de inteligencia lógico matemática y el puntaje en una prueba, el cálculo se pide así (incluyendo el redondeo a tres decimales):</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb348-1" data-line-number="1"><span class="kw">round</span>(<span class="kw">cor</span>(puntaje.escala, ejercic.corr), <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.847</code></pre>
</div>
<div id="dicotomías-artificiales" class="section level4">
<h4><span class="header-section-number">5.11.2.6</span> Dicotomías artificiales</h4>
<p>Las dicotomías sobre variables continuas pueden hacerse con la función <code>cut</code> que se usó antes para construir categorías de variables cuantitativas, solo que ahora el corte se da solo en dos grupos. Para el caso de los puntajes de la subescala motora de la prueba de Bayley, si se quieren dos categorías que tengan la misma amplitud en los valores de la variable, se indican dos cortes. En este ejemplo, primero leemos la base “bayley”, luego introducimos la variable dicotomizada como una columna más de la matriz de datos y visualizamos el resultado pidiendo una tabla:</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb350-1" data-line-number="1">bayley &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;bases/archivostxt/bayley.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;;&quot;</span>)</a>
<a class="sourceLine" id="cb350-2" data-line-number="2">bayley<span class="op">$</span>motor.dic &lt;-<span class="st"> </span><span class="kw">cut</span>(bayley<span class="op">$</span>baymotor, <span class="dt">breaks =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb350-3" data-line-number="3"><span class="kw">table</span>(bayley<span class="op">$</span>motor.dic)</a></code></pre></div>
<pre><code>## 
## (63.9,107]  (107,150] 
##        257        197</code></pre>
<p>El corte se realizó en 107 que es el centro de los valores de la variable (promedio entre el mínimo y el máximo).</p>
<p>Otra opción es cortar en la mediana, de modo que la cantidad de casos en las dos categorías sea similar. Para ello, hay que especificar todos los cortes que determinan los intervalos; el mínimo, la mediana y el máximo:</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb352-1" data-line-number="1">bayley<span class="op">$</span>motor.dic<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">cut</span>(bayley<span class="op">$</span>baymotor, <span class="dt">breaks =</span> <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb352-2" data-line-number="2">  <span class="kw">min</span>(bayley<span class="op">$</span>baymotor),</a>
<a class="sourceLine" id="cb352-3" data-line-number="3">  <span class="kw">median</span>(bayley<span class="op">$</span>baymotor),</a>
<a class="sourceLine" id="cb352-4" data-line-number="4">  <span class="kw">max</span>(bayley<span class="op">$</span>baymotor)</a>
<a class="sourceLine" id="cb352-5" data-line-number="5">))</a>
<a class="sourceLine" id="cb352-6" data-line-number="6"><span class="kw">table</span>(bayley<span class="op">$</span>motor.dic<span class="fl">.2</span>)</a></code></pre></div>
<pre><code>## 
##  (64,105] (105,150] 
##       231       222</code></pre>
<p>Ahora el corte está en 105 y quedan cantidades similares de casos en los dos grupos.</p>
<p>La decisión sobre el mejor modo de hacer el corte es teórica, y con ella presente, puede denominarse “grupo bajo” y “grupo alto” a los dos resultantes de la dicotomización.</p>
</div>
<div id="tetracórico" class="section level4">
<h4><span class="header-section-number">5.11.2.7</span> Tetracórico</h4>
<p>El paquete <code>psych</code> (<span class="citation">Revelle (<a href="#ref-Revelle2019">2019</a>)</span>) cuenta con la función <code>tetrachoric</code>, cuyo argumento es la matriz de datos original y no la tabla de contingencia. Aquí se aplica al análisis de la relación entre los puntajes de las subescalas motora y mental de la prueba de Bayley, dicotomizadas.</p>
<p>Primero se carga el paquete</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb354-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;psych&quot;</span>)</a></code></pre></div>
<p>Y luego se aplica la función a la matriz de datos que solo contiene las dos variables dicotomizadas:</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb355-1" data-line-number="1"><span class="kw">tetrachoric</span>(compara.escalas.dic)</a></code></pre></div>
<pre><code>## Call: tetrachoric(x = compara.escalas.dic)
## tetrachoric correlation 
##                  sbscl.mt sbscl.mn
## subescala.motora 1.00             
## subescala.mental 0.37     1.00    
## 
##  with tau of 
## subescala.motora subescala.mental 
##            -0.14            -0.14</code></pre>
<p>La salida muestra varias cosas, nos interesa la tabla con las dos variables en filas y columnas, con “unos” en la diagonal (correlación de cada variable consigo misma) y en la celda <span class="math inline">\((2; 1)\)</span> (inferior izquierda), está el coeficiente solicitado, 0.37.</p>
</div>
<div id="punto-biserial" class="section level4">
<h4><span class="header-section-number">5.11.2.8</span> Punto biserial</h4>
<p>Los grupos deben codificarse como cero y uno, para luego solicitar un coeficiente de Pearson. En este ejemplo, se crea la base de datos con siete casos en el grupo control y diez en el experimental. Se codifica a los grupos control y experimental como cero y uno respectivamente, y luego se solicita el coeficiente de correlación de Pearson entre la variable dicotómica que codifica los grupos, y los puntajes.</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb357-1" data-line-number="1">grupo &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;control&quot;</span>, <span class="dv">7</span>), <span class="kw">rep</span>(<span class="st">&quot;experimental&quot;</span>, <span class="dv">10</span>))</a>
<a class="sourceLine" id="cb357-2" data-line-number="2">puntaje &lt;-<span class="st"> </span><span class="kw">c</span>(</a>
<a class="sourceLine" id="cb357-3" data-line-number="3">  <span class="dv">8</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">6</span>, <span class="dv">4</span>, <span class="fl">5.6</span>, <span class="fl">5.6</span>, <span class="dv">8</span>, <span class="fl">7.2</span>, <span class="fl">6.4</span>,</a>
<a class="sourceLine" id="cb357-4" data-line-number="4">  <span class="fl">7.2</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="fl">7.2</span></a>
<a class="sourceLine" id="cb357-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb357-6" data-line-number="6">grupo.cod &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">7</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>))</a>
<a class="sourceLine" id="cb357-7" data-line-number="7">compara.grupos &lt;-<span class="st"> </span><span class="kw">data.frame</span>(grupo, puntaje, grupo.cod)</a>
<a class="sourceLine" id="cb357-8" data-line-number="8"></a>
<a class="sourceLine" id="cb357-9" data-line-number="9"><span class="kw">cor</span>(<span class="dt">x =</span> compara.grupos<span class="op">$</span>puntaje, compara.grupos<span class="op">$</span>grupo.cod)</a></code></pre></div>
<pre><code>## [1] 0.1734252</code></pre>
</div>
</div>
<div id="modelo-lineal" class="section level3">
<h3><span class="header-section-number">5.11.3</span> Modelo lineal</h3>
<p>El ajuste de una variable como función (lineal en el caso que nos interesa) de otra (u otras) constituye un objeto en R. Lo denominaremos “modelo.1”. El comando para construir ese objeto es <code>lm</code> (modelo lineal) y usaremos como argumento la variable consecuente (<em>y</em>, la dependiente, lavariable a explicar) relacionada por medio del signo <code>~</code> (alt + 126 en windows) con la variable antecedente (<em>x</em>, la independiente o factor explicativo). El orden entre estas dos variables es determinante para el modelo, por lo que debe cuidarse, si <em>x</em> es antecedente e <em>y</em> consecuente y la relación se plantea</p>
<p><span class="math display">\[X \rightarrow Y\]</span></p>
<p>entonces el argumento de lm es</p>
<p><span class="math display">\[Y \: \tilde{} \: X\]</span></p>
<p>El modelo se construye así:</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb359-1" data-line-number="1">modelo<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(ejercic.corr <span class="op">~</span><span class="st"> </span>puntaje.escala)</a></code></pre></div>
<p>El objeto que resulta tiene muchos resultados en su interior, los pedimos así:</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb360-1" data-line-number="1"><span class="kw">attributes</span>(modelo<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>## $names
##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;        
## 
## $class
## [1] &quot;lm&quot;</code></pre>
<p>La clase es <code>lm</code>, modelo lineal, un tipo particular de objeto R. De los nombres, por ahora solo nos interesan los coeficientes, a los que evocamos del mismo modo que a las variables de una matriz de datos:</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb362-1" data-line-number="1">modelo<span class="fl">.1</span><span class="op">$</span>coefficients</a></code></pre></div>
<pre><code>##    (Intercept) puntaje.escala 
##     -5.6279603      0.2290977</code></pre>
<p>Estos son:</p>
<ul>
<li><p><code>intercept</code>: la intersección con el eje <span class="math inline">\(y\)</span>, es decir, la ordenada al origen.</p></li>
<li><p><code>puntaje.escala</code>: el nombre de la variable antecedente, es la pendiente de la recta.</p></li>
</ul>
<p>Cada uno de estos valores puede accederse separamente, así:</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb364-1" data-line-number="1">modelo<span class="fl">.1</span><span class="op">$</span>coefficients[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## (Intercept) 
##    -5.62796</code></pre>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb366-1" data-line-number="1">modelo<span class="fl">.1</span><span class="op">$</span>coefficients[<span class="dv">2</span>]</a></code></pre></div>
<pre><code>## puntaje.escala 
##      0.2290977</code></pre>
<p>Y luego usarse para calcular un valor de <span class="math inline">\(y\)</span> (aciertos estimados) para un valor elegido de <span class="math inline">\(x\)</span> (puntaje en la escala). El ejemplo hecho manualmente antes resulta ahora:</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb368-1" data-line-number="1">modelo<span class="fl">.1</span><span class="op">$</span>coefficients[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>modelo<span class="fl">.1</span><span class="op">$</span>coefficients[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span><span class="dv">55</span></a></code></pre></div>
<pre><code>## (Intercept) 
##    6.972413</code></pre>
<p>Que se diferencia del obtenido antes por el redondeo y sigue siendo un promedio de siete errores esperados para quienes tienen puntaje 55 en la escala.</p>
<p>También es posible crear una función para que calcule automáticamente valores de <span class="math inline">\(y\)</span> para cualquier <span class="math inline">\(x\)</span> que se elija. Vamos a llamar <em>yest</em> (<em>y</em> estimada) a esa función:</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb370-1" data-line-number="1">yest &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb370-2" data-line-number="2">  modelo<span class="fl">.1</span><span class="op">$</span>coefficients[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>modelo<span class="fl">.1</span><span class="op">$</span>coefficients[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>x</a>
<a class="sourceLine" id="cb370-3" data-line-number="3">}</a></code></pre></div>
<p>Para usarla, damos a esta nueva función un valor de <em>x</em>, como en el ejemplo anterior, <span class="math inline">\(x=55\)</span>:</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb371-1" data-line-number="1"><span class="kw">yest</span>(<span class="dv">55</span>)</a></code></pre></div>
<pre><code>## (Intercept) 
##    6.972413</code></pre>
<p>Y se obtiene el valor de <em>y</em> que estima el modelo. Para <span class="math inline">\(x=75\)</span>, es:</p>
<pre><code>## (Intercept) 
##    11.55437</code></pre>
</div>
<div id="cuarteto-de-anscombe" class="section level3">
<h3><span class="header-section-number">5.11.4</span> Cuarteto de Anscombe</h3>
<p>El cuarteto de Anscombe, es invento lúdico-pedagógico, desarrollado para destacar la importancia que tiene visualizar los datos, antes de extraer conclusiones a partir de sus medidas descriptivas. Es una matriz de datos de once casos en cuatro pares de variables y viene cargado en R base. Se lo puede ver, llamándolo por su nombre:</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb374-1" data-line-number="1">anscombe</a></code></pre></div>
<pre><code>##    x1 x2 x3 x4    y1   y2    y3    y4
## 1  10 10 10  8  8.04 9.14  7.46  6.58
## 2   8  8  8  8  6.95 8.14  6.77  5.76
## 3  13 13 13  8  7.58 8.74 12.74  7.71
## 4   9  9  9  8  8.81 8.77  7.11  8.84
## 5  11 11 11  8  8.33 9.26  7.81  8.47
## 6  14 14 14  8  9.96 8.10  8.84  7.04
## 7   6  6  6  8  7.24 6.13  6.08  5.25
## 8   4  4  4 19  4.26 3.10  5.39 12.50
## 9  12 12 12  8 10.84 9.13  8.15  5.56
## 10  7  7  7  8  4.82 7.26  6.42  7.91
## 11  5  5  5  8  5.68 4.74  5.73  6.89</code></pre>
<p>Para ver las medidas descriptivas, se solicita el resumen completo de la matriz de datos, ya que son pocas variables:</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb376-1" data-line-number="1"><span class="kw">summary</span>(anscombe)</a></code></pre></div>
<pre><code>##        x1             x2             x3             x4           y1        
##  Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  
##  1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  
##  Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  
##  Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  
##  3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  
##  Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  
##        y2              y3              y4        
##  Min.   :3.100   Min.   : 5.39   Min.   : 5.250  
##  1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  
##  Median :8.140   Median : 7.11   Median : 7.040  
##  Mean   :7.501   Mean   : 7.50   Mean   : 7.501  
##  3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  
##  Max.   :9.260   Max.   :12.74   Max.   :12.500</code></pre>
<p>Un modo de expresar el resultado de manera más compacta es usando el paquete <code>dplyr</code>:</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb378-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;dplyr&quot;</span>)</a>
<a class="sourceLine" id="cb378-2" data-line-number="2"></a>
<a class="sourceLine" id="cb378-3" data-line-number="3"><span class="kw">apply</span>(anscombe, <span class="dv">2</span>, summary)</a></code></pre></div>
<pre><code>##           x1   x2   x3 x4        y1       y2    y3        y4
## Min.     4.0  4.0  4.0  8  4.260000 3.100000  5.39  5.250000
## 1st Qu.  6.5  6.5  6.5  8  6.315000 6.695000  6.25  6.170000
## Median   9.0  9.0  9.0  8  7.580000 8.140000  7.11  7.040000
## Mean     9.0  9.0  9.0  9  7.500909 7.500909  7.50  7.500909
## 3rd Qu. 11.5 11.5 11.5  8  8.570000 8.950000  7.98  8.190000
## Max.    14.0 14.0 14.0 19 10.840000 9.260000 12.74 12.500000</code></pre>
<p>Se observa la similitud de las medidas resumen de <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, <span class="math inline">\(x_3\)</span>, <span class="math inline">\(x_4\)</span> por un lado y de <span class="math inline">\(y_1\)</span>, <span class="math inline">\(y_2\)</span>, <span class="math inline">\(y_3\)</span>, <span class="math inline">\(y_4\)</span> por otro.</p>
<p>Además, las correlaciones entre los pares son casi idénticas:</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb380-1" data-line-number="1"><span class="kw">round</span>(<span class="kw">cor</span>(anscombe<span class="op">$</span>x1, anscombe<span class="op">$</span>y1), <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.816</code></pre>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb382-1" data-line-number="1"><span class="kw">round</span>(<span class="kw">cor</span>(anscombe<span class="op">$</span>x2, anscombe<span class="op">$</span>y2), <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.816</code></pre>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb384-1" data-line-number="1"><span class="kw">round</span>(<span class="kw">cor</span>(anscombe<span class="op">$</span>x3, anscombe<span class="op">$</span>y3), <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.816</code></pre>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb386-1" data-line-number="1"><span class="kw">round</span>(<span class="kw">cor</span>(anscombe<span class="op">$</span>x4, anscombe<span class="op">$</span>y4), <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.817</code></pre>
<p>Y también son muy similares los modelos lineales que ajustan cada relación. Las ordenadas al origen:</p>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb388-1" data-line-number="1"><span class="kw">lm</span>(anscombe<span class="op">$</span>y1 <span class="op">~</span><span class="st"> </span>anscombe<span class="op">$</span>x1)<span class="op">$</span>coefficients[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## (Intercept) 
##    3.000091</code></pre>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb390-1" data-line-number="1"><span class="kw">lm</span>(anscombe<span class="op">$</span>y2 <span class="op">~</span><span class="st"> </span>anscombe<span class="op">$</span>x2)<span class="op">$</span>coefficients[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## (Intercept) 
##    3.000909</code></pre>
<div class="sourceCode" id="cb392"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb392-1" data-line-number="1"><span class="kw">lm</span>(anscombe<span class="op">$</span>y3 <span class="op">~</span><span class="st"> </span>anscombe<span class="op">$</span>x3)<span class="op">$</span>coefficients[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## (Intercept) 
##    3.002455</code></pre>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb394-1" data-line-number="1"><span class="kw">lm</span>(anscombe<span class="op">$</span>y4 <span class="op">~</span><span class="st"> </span>anscombe<span class="op">$</span>x4)<span class="op">$</span>coefficients[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## (Intercept) 
##    3.001727</code></pre>
<p>Y las pendientes:</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb396-1" data-line-number="1"><span class="kw">lm</span>(anscombe<span class="op">$</span>y1 <span class="op">~</span><span class="st"> </span>anscombe<span class="op">$</span>x1)<span class="op">$</span>coefficients[<span class="dv">2</span>]</a></code></pre></div>
<pre><code>## anscombe$x1 
##   0.5000909</code></pre>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb398-1" data-line-number="1"><span class="kw">lm</span>(anscombe<span class="op">$</span>y2 <span class="op">~</span><span class="st"> </span>anscombe<span class="op">$</span>x2)<span class="op">$</span>coefficients[<span class="dv">2</span>]</a></code></pre></div>
<pre><code>## anscombe$x2 
##         0.5</code></pre>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb400-1" data-line-number="1"><span class="kw">lm</span>(anscombe<span class="op">$</span>y3 <span class="op">~</span><span class="st"> </span>anscombe<span class="op">$</span>x3)<span class="op">$</span>coefficients[<span class="dv">2</span>]</a></code></pre></div>
<pre><code>## anscombe$x3 
##   0.4997273</code></pre>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb402-1" data-line-number="1"><span class="kw">lm</span>(anscombe<span class="op">$</span>y4 <span class="op">~</span><span class="st"> </span>anscombe<span class="op">$</span>x4)<span class="op">$</span>coefficients[<span class="dv">2</span>]</a></code></pre></div>
<pre><code>## anscombe$x4 
##   0.4999091</code></pre>
<p>Sin embargo, los diagramas de dispersión muestran que se trata de conjuntos muy diferentes entre sí. Usamos el paquete ggplot para hacer los cuatro gráficos a los que se llama <span class="math inline">\(p_1, p_2, p_3, p_4\)</span>. En la primera capa de cada gráfico colocamos el origen de los datos, que es la matriz <em>anscombe</em>, luego sumamos una capa con puntos correspondientes a <span class="math inline">\(x_1, y_1\)</span> en el primer gráfico y así en los tres siguientes. La tercera capa es la función lineal que mejor ajusta los puntos. Finalmente el theme_tufte da a cada gráfico el formato que elegimos. Para mostrarlos, usamos el comando grid.arrange al que indicamos los cuatro objetos y la dimensión del arreglo, que son dos filas y dos columnas:</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb404-1" data-line-number="1">p1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(anscombe) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(x1, y1)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb404-2" data-line-number="2"><span class="st">  </span><span class="kw">theme_tufte</span>()</a>
<a class="sourceLine" id="cb404-3" data-line-number="3">p2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(anscombe) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(x2, y2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb404-4" data-line-number="4"><span class="st">  </span><span class="kw">theme_tufte</span>()</a>
<a class="sourceLine" id="cb404-5" data-line-number="5">p3 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(anscombe) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(x3, y3)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb404-6" data-line-number="6"><span class="st">  </span><span class="kw">theme_tufte</span>()</a>
<a class="sourceLine" id="cb404-7" data-line-number="7">p4 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(anscombe) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(x4, y4)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb404-8" data-line-number="8"><span class="st">  </span><span class="kw">theme_tufte</span>()</a>
<a class="sourceLine" id="cb404-9" data-line-number="9"></a>
<a class="sourceLine" id="cb404-10" data-line-number="10"><span class="kw">grid.arrange</span>(p1, p2, p3, p4, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">2</span>) <span class="co"># para ordenar los</span></a></code></pre></div>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-330-1.svg" width="672" /></p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb405-1" data-line-number="1"><span class="co"># cuatro gráficos en una grilla de 2 x 2</span></a></code></pre></div>
</div>
<div id="datasaurus" class="section level3">
<h3><span class="header-section-number">5.11.5</span> Datasaurus</h3>
<p>Para usar el Datasaurus, se debe primero instalar el paquete y cargarlo en la sesión, la matriz de datos se llama <code>datasaurus_dozen</code>:</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb406-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;datasauRus&quot;</span>)</a>
<a class="sourceLine" id="cb406-2" data-line-number="2"></a>
<a class="sourceLine" id="cb406-3" data-line-number="3">datasaurus_dozen</a></code></pre></div>
<pre><code>## # A tibble: 1,846 x 3
##    dataset     x     y
##    &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;
##  1 dino     55.4  97.2
##  2 dino     51.5  96.0
##  3 dino     46.2  94.5
##  4 dino     42.8  91.4
##  5 dino     40.8  88.3
##  6 dino     38.7  84.9
##  7 dino     35.6  79.9
##  8 dino     33.1  77.6
##  9 dino     29.0  74.5
## 10 dino     26.2  71.4
## # … with 1,836 more rows</code></pre>
<p>Los datos están organizados en tres columnas; la primera, que se llama <code>dataset</code> es el nombre del subconjunto, son 13 subconjuntos en total, que se llaman: “away”, “bullseye”, “circle”, “dino”, “dots”, “h_lines”, “high_lines”, “slant_down”, “slant_up”, “star”, “v_lines”, “wide_lines” y “x_shape”.</p>
<p>Ahora vamos a usar el paquete <code>dplyr</code>, que facilita hacer las operaciones por grupos con la función <code>group_by</code>. Se solicita que, sobre la matriz <code>datasaurus_dozen</code> agrupe por <code>dataset</code> y resuma, calculando las medias y desviaciones estándar de <span class="math inline">\(x\)</span> y de <span class="math inline">\(y\)</span> y la correlación entre ellas. La aplicación secuencial de estas operaciones se logra por medio del operador <code>%&gt;%</code> “pipe”.</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb408-1" data-line-number="1">datasaurus_dozen <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb408-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(dataset) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb408-3" data-line-number="3"><span class="st">  </span><span class="kw">summarize</span>(</a>
<a class="sourceLine" id="cb408-4" data-line-number="4">    <span class="dt">media_x =</span> <span class="kw">mean</span>(x),</a>
<a class="sourceLine" id="cb408-5" data-line-number="5">    <span class="dt">media_y =</span> <span class="kw">mean</span>(y),</a>
<a class="sourceLine" id="cb408-6" data-line-number="6">    <span class="dt">s_x =</span> <span class="kw">sd</span>(x),</a>
<a class="sourceLine" id="cb408-7" data-line-number="7">    <span class="dt">s_y =</span> <span class="kw">sd</span>(y),</a>
<a class="sourceLine" id="cb408-8" data-line-number="8">    <span class="dt">r_x_y =</span> <span class="kw">cor</span>(x, y)</a>
<a class="sourceLine" id="cb408-9" data-line-number="9">  )</a></code></pre></div>
<pre><code>## # A tibble: 13 x 6
##    dataset    media_x media_y   s_x   s_y   r_x_y
##    &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1 away          54.3    47.8  16.8  26.9 -0.0641
##  2 bullseye      54.3    47.8  16.8  26.9 -0.0686
##  3 circle        54.3    47.8  16.8  26.9 -0.0683
##  4 dino          54.3    47.8  16.8  26.9 -0.0645
##  5 dots          54.3    47.8  16.8  26.9 -0.0603
##  6 h_lines       54.3    47.8  16.8  26.9 -0.0617
##  7 high_lines    54.3    47.8  16.8  26.9 -0.0685
##  8 slant_down    54.3    47.8  16.8  26.9 -0.0690
##  9 slant_up      54.3    47.8  16.8  26.9 -0.0686
## 10 star          54.3    47.8  16.8  26.9 -0.0630
## 11 v_lines       54.3    47.8  16.8  26.9 -0.0694
## 12 wide_lines    54.3    47.8  16.8  26.9 -0.0666
## 13 x_shape       54.3    47.8  16.8  26.9 -0.0656</code></pre>
<p>Cada fila corresponde a un subconjunto de datos. En la tabla se observa la similitud de las <span class="math inline">\(x\)</span> y de las <span class="math inline">\(y\)</span> y también de las correlaciones entre ellas. Para completar la idea que se tiene de los subconjuntos de datos, construimos un diagrama de dispersión para cada uno de ellos:</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb410-1" data-line-number="1"><span class="kw">ggplot</span>(datasaurus_dozen) <span class="op">+</span><span class="st"> </span><span class="co"># haremos un plot con los datos</span></a>
<a class="sourceLine" id="cb410-2" data-line-number="2"><span class="st">  </span><span class="co"># datasaurus_dozen</span></a>
<a class="sourceLine" id="cb410-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(x, y, <span class="dt">col =</span> dataset)) <span class="op">+</span><span class="st"> </span><span class="co"># puntos x, y, con el color</span></a>
<a class="sourceLine" id="cb410-4" data-line-number="4"><span class="st">  </span><span class="co">## mapeado al nombre de cada conjunto de datos</span></a>
<a class="sourceLine" id="cb410-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_abline</span>() <span class="op">+</span><span class="st"> </span><span class="co"># agregamos una linea recta</span></a>
<a class="sourceLine" id="cb410-6" data-line-number="6"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>dataset, <span class="dt">ncol =</span> <span class="dv">3</span>) <span class="op">+</span><span class="st"> </span><span class="co"># separamos en subplots por dataset</span></a>
<a class="sourceLine" id="cb410-7" data-line-number="7"><span class="st">  </span><span class="kw">theme_tufte</span>() <span class="op">+</span><span class="st"> </span><span class="co"># plantilla estética</span></a>
<a class="sourceLine" id="cb410-8" data-line-number="8"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="co"># eliminamos la leyenda</span></a></code></pre></div>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-333-1.svg" width="672" /></p>
<p>Aquí se mapeó el nombre de cada subconjunto al color de los puntos de los diagramas de dispersión y se agregó la función lineal que mejor los ajusta.
Como con el cuarteto de Anscombe, los gráfcos aportan una visión muy diferente de los conjuntos de datos, comparada con la que se tenía a partir de la observación solo de sus medidas descriptivas.</p>

</div>
</div>
</div>



<p>Hasta aquí hemos trabajado sobre datos que han sido observados; pudo haberse tratado de datos de una encuesta o un relevamiento que nosotros hayamos realizado o bien que nos haya provisto alguna fuente de buena calidad: conjunto de hogares encuestados por la EPH, lista de de personas afiliadas a un partido político, registros de una institución educativa, historias clínicas de un hospital, etc. Se trata de información realmente recopilada, que ha sido obtenida por observación a través de algún instrumento de recolección de datos o registrada oficialmente. Por el contrario, en los capítulos que siguen nos ocuparemos de lo que <em>no</em> ha sido observado, haremos <em>inferencias</em> para sacar conclusiones acerca de lo que no hemos visto. Partiremos de la información que provee una muestra y con ello generalizaremos a un conjunto mayor. Como resultado de ello buscaremos dar respuesta a preguntas como las siguientes:</p>
<ul>
<li><p>Si en varias escuelas primarias se ven más dificultades en el aprendizaje de Matemática que de Lengua, ¿será esta observación válida para las escuelas primarias?</p></li>
<li><p>Si un nuevo medicamento tiene efecto en un grupo de pacientes sobre quienes se experimenta, ¿bajo qué condiciones podemos saber si también tendrá efecto en la población general de pacientes?</p></li>
<li><p>Si en una muestra de 200 personas encuestadas el 42% dice que va a votar al partido A, ¿qué porcentaje se votos puede esperar obtener el partido A cuando sean las elecciones?</p></li>
<li><p>Si en un grupo conformado voluntariamente, que participa en un experimento se descubre una relación entre las expectativas de logro y el número de errores que se cometen en una prueba, ¿es suficiente con eso para afirmar que esa relación se mantiene entre quienes no participaron del experimento?, o dicho de otra manera ¿es esa una relación general entre esas variables (<span class="math inline">\(expectativa\: de\: logro \rightarrow cantidad \:de \: errores\)</span>)?</p></li>
<li><p>Si en la muestra de la EPH se detecta un 8% de personas desocupadas, ¿Cuál es la tasa de desocupación de la población completa?</p></li>
<li><p>Si a una muestra de pacientes de sexo femenino con diagnóstico de psicosis se administra una droga y se encuentra que produce estabilización en los síntomas en el 90% de ellas, ¿corresponde recomendar que esa droga sea utilizada en las pacientes diagnosticadas como psicóticas?</p></li>
</ul>
<p>Como vemos, se trata de llevar los resultados más allá del ámbito en el que fueron obtenidos, se trata de generalizarlos. Para hacer esto será necesario usar conceptos nuevos, a los que nos dedicaremos en los capítulos de esta parte. Veremos cómo seleccionar casos para que lo que se observe en ellos tenga validez general (muestreo), luego cómo decidir en el terreno de la incertidumbre (probabilidad), y finalmente, lo que sucede con las medidas descriptivas que conocemos cuando se las pone en correspondencia con valores generales (distribuciones en el muestreo).</p>
<p>Sobre la relación entre la probabilidad y la inferencia, <span class="citation">Hacking (<a href="#ref-hacking_2006">2006</a>)</span> cita un pasaje de un relato indio<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a> en el que uno de los personajes estima “el número de hojas y frutos que hay en dos grandes ramas de un árbol frondoso. Aparentemente lo hace en base a una sola rama más pequeña que observa. Hay, según afirma, 2095 frutos. [<span class="math inline">\(\ldots\)</span>] y cuando le preguntan ¿cómo pudo saberlo?, responde: <em>Yo de los dados poseo su ciencia y así en los números diestro soy</em>” (<span class="citation">Hacking (<a href="#ref-hacking_2006">2006</a>)</span>). De este modo aparecen relacionadas, en este antiguo texto, la capacidad para hacer una estimación de lo que no es observado con “la ciencia de los dados”, desde tan temprano hay indicios de la relación entre estimación y probabilidad.</p>
<p>Las respuestas a las preguntas que buscan generalidad no pueden ser certeras, como en el relato mítico, sino inciertas. A diferencia de las descripciones, que se limitan a mostrar información recopilada, las inferencias solo pueden ser afirmaciones tentativas, aproximativas, probabilísticas. La diferencia entre la certeza de una descripción y la incertidumbre de una inferencia se ve con claridad al comparar las siguientes expresiones:</p>
<ol style="list-style-type: decimal">
<li><p>“El tiempo promedio que tardaron estas 100 personas en responder al cuestionario fue de 12 minutos”</p></li>
<li><p>“Cuando este cuestionario sea aplicado, se espera que quienes lo respondan tarden entre 11 y 13 minutos para hacerlo, con una certeza del 95%”.</p></li>
</ol>
<p>Hay dos diferencias en estos enunciados, que pertenecen a distintos niveles de proximidad a los datos. Una diferencia es que el primero ofrece un valor único: los 12 minutos que se obtuvieron al promediar los tiempos de los 100 personas que fueron observadas. Por el contrario, el segundo ofrece un intervalo: entre 11 y 13 minutos.</p>
<p>La segunda diferencia es que el primer enunciado <em>afirma</em> ese valor, mientras que el segundo expresa que <em>hay una certeza del 95%</em>. Esto quiere decir que no estamos seguros que el tiempo que tardarán en responder vaya a estar realmente entre 11 y 13 minutos; hay una confianza del 95% que sea así, pero no una certeza plena. Por eso, puede ser que el tiempo sea, o bien menor que 11 minutos, o bien mayor que 13; y esto puede suceder con una probabilidad de 5%. Los enunciados del segundo tipo transmiten incertidumbre porque se refieren a casos que no han sido observados, sino inferidos. Esta incertidumbre, para la que disponemos de procedimientos que permiten cuantificarla de manera probabilística, es inherente a todo proceso de inducción, donde se requiere formular generalizaciones.</p>
<p>Los capítulos que vienen a continuación ofrecen las bases para ingresar a la <em>Estadística Inferencial</em>, son cuatro capítulos de articulación que fundamentan los procedimientos de inferencia.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Anscombe1973a">
<p>Anscombe, Francis J. 1973. “Graphs in Statistical Analysis.” <em>The American Statistician</em> 27 (1): 17–21.</p>
</div>
<div id="ref-Cohen1988">
<p>Cohen, Jacob. 1988. <em>Statistical Power Analysis for the Behavioral Sciences (2nd Edition)</em>. Lawrence Erlbaum Associates.</p>
</div>
<div id="ref-furlan2014">
<p>Furlan, Luis Alberto, María José Ferrero, and Gabriela Gallart. 2014. “Ansiedad Ante Los Exámenes, Procrastinación Y Síntomas Mentales En Estudiantes de La Universidad Nacional de Córdoba.” <em>Revista Argentina de Ciencias Del Comportamiento</em>. <a href="https://www.redalyc.org/articulo.oa?id=333432764005 ">https://www.redalyc.org/articulo.oa?id=333432764005</a>.</p>
</div>
<div id="ref-galton1877">
<p>Galton, Francis. 1877. “Typical laws of heredity.” <em>Nature</em> 15. <a href="http://galton.org/bib/JournalItem.aspx{\_}action=view{\_}id=61">http://galton.org/bib/JournalItem.aspx{\_}action=view{\_}id=61</a>.</p>
</div>
<div id="ref-hacking_2006">
<p>Hacking, Ian. 2006. <em>The Emergence of Probability: A Philosophical Study of Early Ideas About Probability, Induction and Statistical Inference</em>. 2nd ed. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511817557">https://doi.org/10.1017/CBO9780511817557</a>.</p>
</div>
<div id="ref-Locke2018">
<p>Locke, Steph. 2018. “The Datasaurus data package.” <a href="https://cran.r-project.org/web/packages/datasauRus/vignettes/Datasaurus.html">https://cran.r-project.org/web/packages/datasauRus/vignettes/Datasaurus.html</a>.</p>
</div>
<div id="ref-pearson1895">
<p>Pearson, Karl, and Francis Galton. 1895. “VII. Note on Regression and Inheritance in the Case of Two Parents.” <em>Proceedings of the Royal Society of London</em> 58 (347-352): 240–42. <a href="https://doi.org/10.1098/rspl.1895.0041">https://doi.org/10.1098/rspl.1895.0041</a>.</p>
</div>
<div id="ref-Pescosolido1983">
<p>Pescosolido, Bernice A., and Jonathan Kelley. 1983. “Confronting Sociological Theory With Data: Regression Analysis Goodman’s Log-Linear Models And Comparative Research.” <em>Sociology</em> 17 (3). Sage Publications, Ltd.: 359–79. <a href="https://doi.org/10.2307/42852586">https://doi.org/10.2307/42852586</a>.</p>
</div>
<div id="ref-Revelle2019">
<p>Revelle, William. 2019. “psych: Procedures for Psychological, Psychometric, and Personality Research.” Evanston, Illinois: Northwestern University. <a href="https://cran.r-project.org/package=psych">https://cran.r-project.org/package=psych</a>.</p>
</div>
<div id="ref-Tufte1989">
<p>Tufte, Edward R. 1989. <em>The Visual Display of Quantitative Information</em>. Graphics Press.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="26">
<li id="fn26"><p>Según la clasificación sugerida por el Informe Mundial sobre la Violencia y la Salud, Organización Panamericana de la Salud, 2003.<a href="relación-entre-variables-el-análisis.html#fnref26" class="footnote-back">↩</a></p></li>
<li id="fn27"><p>El mismo recurso que se usó cuando se definió la varianza y no era posible usar la suma de los desvíos porque daba cero. Nuevamente aquí, usamos el exponente 2 para volver positivos a los números negativos.<a href="relación-entre-variables-el-análisis.html#fnref27" class="footnote-back">↩</a></p></li>
<li id="fn28"><p>Recordemos que, de manera general la dimensión de la tabla es <span class="math inline">\(f X c\)</span>, filas por columnas.<a href="relación-entre-variables-el-análisis.html#fnref28" class="footnote-back">↩</a></p></li>
<li id="fn29"><p>Ver Ekström, J. (2011) para las discusiones en torno a este coeficiente en el llamado “debate Pearson-Yule”.<a href="relación-entre-variables-el-análisis.html#fnref29" class="footnote-back">↩</a></p></li>
<li id="fn30"><p>Esta expresión puede encontrarse un poco diferente en algunos manuales. Si las desviaciones estándar, que se usan para calcular los puntajes z, se calcularan con denominador <span class="math inline">\(n\)</span> (como si correspondieran a observaciones provenientes de toda la población), entonces la fórmula de <span class="math inline">\(r\)</span> llevaría denominador <span class="math inline">\(n\)</span> también. Aquí mantenemos el modo de cálculo de la desviación estándar muestral con denominador <span class="math inline">\(n-1\)</span> y por eso esta fórmula lo lleva así también.<a href="relación-entre-variables-el-análisis.html#fnref30" class="footnote-back">↩</a></p></li>
<li id="fn31"><p>Es la ordenada correspondiente a un valor de z que deja a derecha e izquierda, en una distribución normal, proporciones del área bajo la curva iguales a <span class="math inline">\(p\)</span> y <span class="math inline">\(1-p\)</span> respectivamente.<a href="relación-entre-variables-el-análisis.html#fnref31" class="footnote-back">↩</a></p></li>
<li id="fn32"><p>No es posible poner como condición que la recta haga mínimas las distancias porque hay puntos por encima y por debajo, por lo que la suma de las distancias se hace cero (igual a lo que sucedió con la suma de los desvíos alrededor de la media y que llevó a usar sus cuadrados para definir la varianza). Por esa razón se usan los cuadrados de las distancias.<a href="relación-entre-variables-el-análisis.html#fnref32" class="footnote-back">↩</a></p></li>
<li id="fn33"><p>Para calcular los valores de <span class="math inline">\(y\)</span> estimado (<span class="math inline">\(\widehat{y}\)</span>) hemos conservado más decimales en <span class="math inline">\(b_0\)</span> y <span class="math inline">\(b_1\)</span> que los mostrados.<a href="relación-entre-variables-el-análisis.html#fnref33" class="footnote-back">↩</a></p></li>
<li id="fn34"><p>Se trata de la epopeya Mahabarata, cuya versión actual habría sido concluida hacia el año 400d.c.<a href="relación-entre-variables-el-análisis.html#fnref34" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="relación-entre-variables-los-fundamentos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="obtención-de-la-muestra.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jcrodriguez1989/EstadisticaParaCienciasSocialesConR/edit/master/06-capitulo5.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["EstadisticaParaCienciasSocialesConR.pdf", "EstadisticaParaCienciasSocialesConR.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
