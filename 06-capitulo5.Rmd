# Relación entre variables: el análisis

```{r}
source("depencias.R")
```

En el capítulo anterior hemos tratado la relación entre dos variables en
escalas nominales, y señalamos que si se trata de variables de nivel
superior es posible crear categorías y tratarlas del mismo modo. En
cuanto a la medida de la intensidad de la relación, nos hemos limitado
al caso de dos variables dicotómicas, es decir, con dos categorías en
cada una, con lo que la tabla resultante es de dos por dos y calculamos
el coeficiente Q de Kendall - Yule. Ahora se amplía el dominio de
nuestro análisis, incorporando herramientas que permiten poner a prueba
la hipotética relación entre dos variables de nivel nominal con más de
dos categorías cada una y variables de nivel superior (ordinales y
métricas).

## Variables nominales con más de dos categorías cada una

### La distancia entre frecuencias esperadas y observadas

Sobre el final del capítulo anterior presentamos el concepto de
independencia estadística y vimos la manera de calcular las frecuencias
de las celdas que se esperarían encontrar si las variables fueran
independientes. Para hacer esto es suficiente multiplicar las
frecuencias marginales correspondientes a cada celda y dividir el
resultado por el total de casos. Sea el caso que interese analizar la
relación del tipo de violencia[^rel_violencia] con el lugar donde sucede. Aunque
estadísticamente equivalente, no es adecuado preguntar si el lugar
incide sobre el tipo de violencia, sino más bien si el tipo de violencia
difiere según el lugar. Aquí es más pertinente el planteo del problema
como una comparación de grupos (los definidos por los diferentes
lugares) antes que como una relación entre variables. Lo mismo pasa
cuando se comparan los resultados de un examen entre quienes cursan por
la tarde o la mañana. Cuando hay control de variables, como en el diseño
experimental o en la evaluación de impacto, el paralelismo entre las dos
lecturas es más cercano. Así, preguntar si un grupo de niños que recibió
un suplemento en su dieta, tiene mejor desarrollo que uno que no lo
recibió (planteo en términos de comparación de grupos), equivale a
preguntar si el suplemento dietario incide sobre el desarrollo (planteo
en términos de relación entre variables). Las operaciones estadísticas
que responden a las dos preguntas son las mismas, pero según el caso,
una manera de formular el problema puede ser más adecuada que otra.

La investigación social apela continuamente a las comparaciones: el pasado y el presente, mujeres y varones, sociedades industriales y agrarias (arrobaPescosolido1983), grupos minoritarios y población general, por eso es necesario contar con herramientas que permitan analizar la manera en que suceden estas diferencias y las relaciones entre variables que se asocian a ellas.  

Cuando se busca evaluar el impacto de una política pública dirigida a reducir enfermedades parasitarias en niños, una estrategia consiste en comparar la prevalencia de esas enfermedades entre niños que han sido destinatarios de esa política, con niños que no lo fueron. La pregunta por la diferencia entre los dos grupos equivale a indagar sobre el efecto de la política.

Para el ejemplo de las diferencias en el tipo de violencia según área
geográfica, una muestra de 500 casos provee la siguiente distribución
conjunta:

```{r}
tipo <- c(
  rep("autoinfligida", 150),
  rep("interpersonal", 300),
  rep("colectiva", 50))
ciudades <- c(
  rep("ciudades grandes", 100),
  rep("ciudades pequeñas", 35),
  rep("áreas rurales", 15),
  rep("ciudades grandes", 110),
  rep("ciudades pequeñas", 100),
  rep("áreas rurales", 90),
  rep("ciudades grandes", 35),
  rep("ciudades pequeñas", 10),
  rep("áreas rurales", 5))
violencia <- data.frame(tipo, ciudades)
tabla25 <- table(violencia$tipo, violencia$ciudades)
aux_table <- addmargins(tabla25)
colnames(aux_table) <- sub("Sum", "Total", colnames(aux_table))
rownames(aux_table) <- sub("Sum", "Total", rownames(aux_table))
kableExtra::kable_styling(
  knitr::kable(aux_table, format = "pandoc", booktabs = TRUE, align = "cccc",
               label = "frecObs",
               caption = "Clasificación de diferentes tipos de violencia según área donde se manifiesta (datos ficticios)"),
  latex_options = "striped")
```

Una primera aproximación consiste en calcular frecuencias relativas.
Dado que nuestro interés está en comparar el tipo de violencia según las
áreas, calcularemos los porcentajes según las columnas de la tabla 1 y
resulta:

```{r}
aux_table <- 100 * round(addmargins(prop.table(tabla25, 2), 1), 3)

aux_table <- cbind(tabla25, Total = rowSums(tabla25))
aux_table <- prop.table(aux_table, 2)
aux_table <- rbind(aux_table, Total = colSums(aux_table))
aux_table <- 100 * round(aux_table, 3)
kableExtra::kable_styling(
  knitr::kable(aux_table, format = "pandoc", booktabs = TRUE, align = "cccc",
               caption = "Frecuencia relativas por columnas de la clasificación de diferentes tipos de violencia según área donde se manifiesta"),
  latex_options = "striped")
```

Si no consideramos el área, se ve (en la columna de los totales) que la <!-- esta es la columna que no logro obtener-->
violencia interpersonal es la más frecuente (60%), seguida de la
autoinfligida con el 30%. Este patrón de distribución en las distintas
formas de violencia se mantiene en las diferentes áreas, pero en más
acentuado en las rurales, donde la categoría modal (que sigue siendo
interpersonal) alcanza el 82% del total del área. Por el contrario, la
violencia autoinfligida, que es el 30% del total, sube al 41% en grandes
ciudades y solo representa el 14% de las formas de violencia que se
observan en áreas rurales. Así, parecería que hay diferencia en la
distribución de los tipos de violencia según las áreas que están
considerándose.

Buscaremos ahora de cuantificar la intensidad de esa relación, para lo que nos preguntaremos cuáles serían las frecuencias de las celdas si el tipo de violencia fuera independiente del área donde sucede, es decir, si se observara la misma proporción de los distintos tipos de violencia en todas las áreas. Usemos el concepto de independencia estadística para calcular las frecuencias esperadas correspondientes a la tabla \@ref(tab:frecObs).

```{r}
jicu.viol <- chisq.test(tabla25)
aux_table <- round(jicu.viol$expected, 0)
aux_table <- cbind(aux_table, Total = rowSums(aux_table))
aux_table <- rbind(aux_table, Total = colSums(aux_table))
kableExtra::kable_styling(
  knitr::kable(aux_table, format = "pandoc", booktabs = TRUE, align = "cccc",
               label = "frecEsperada",
               caption = "Frecuencias esperadas bajo la hipótesis de independencia entre el tipo de violencia y el área donde se observa"),
  latex_options = "striped")
```

Estas frecuencias están calculadas como indicamos en el capítulo
anterior, haciendo:

$$f_{\text{ij}}^{e} = \frac{f_{i}*f_{j}}{n}$$

Por ejemplo, la frecuencia de la celda 1,2 resultó de $f_{\text{1 2}}^{e} = \frac{151*245}{500} = 73,99$ que redondeamos a 74.

La tabla \@ref(tab:frecEsperada) muestra las frecuencias que esperaríamos encontrar si no hubiera relación entre las variables, si éstas fueran independientes. A ellas debemos compararlas con las que realmente hemos encontrado, las que se denominan frecuencias observadas.

Si halláramos que nuestras frecuencias observadas son muy similares a
las que se esperan bajo la hipótesis de independencia, diríamos que las variables "están cerca" de ser independientes, o lo que es equivalente, que habría escasa relación entre ellas. Por el contrario, si las frecuencias observadas fueran muy diferentes de las esperadas, creeríamos que las variables "están lejos" de ser independientes, es decir, que habría alguna relación entre ellas. Para decidir, debemos comparar la tabla \@ref(tab:frecObs) con la \@ref(tab:frecEsperada).

Una opción para medir la distancia entre los dos conjuntos de frecuencias es la de restar las correspondientes de cada celda; pero si hacemos eso nos encontraremos con un problema parecido al que tuvimos cuando intentamos observar la dispersión restando los valores de la media: la suma da cero. Por única vez realizaremos esta operación de manera manual:

$$(15 - 33) + (100 - 74) + (35 - 44) + (5 - 11) + (35 - 24) + (10 - 14) + (90 - 66) +$$
$$(110 - 147) + (100 - 87) = 0$$

Obtenemos este resultado porque las frecuencias marginales son fijas y lo que una celda tiene de más, lo tiene otra de menos. Siempre sucederá así y por esa razón, no podemos saber si las observadas están cerca o lejos de las esperadas con el procedimiento directo de restarlas. Por el contrario, para medir la distancia entre los dos conjuntos de frecuencias (observadas y esperadas) se usa la siguiente expresión:

$$\sum_{i=1; j=1}^{i=f; j=c}{\frac{(f_{ij}^o - f_{ij}^e)^2}{f_{ij}^e}}$$

La expresión nos dice que deben restarse cada una de las frecuencias esperadas de cada observada correspondiente, elevar esa diferencia al cuadrado[^35] y dividir el resultado por cada una de las frecuencias esperadas. Los subíndices mantienen la notación del capítulo anterior: $i$ es el índice de filas, que va desde la primera ($i=1$) hasta la última ($f$ es el número total de filas); $j$ es el índice de las columnas, que también empieza en 1 ($j=1$) y termina en $c$, que es el número total de columnas[^36]. Vamos a aplicarla una vez, solo para ver su funcionamiento, luego la pediremos al programa:

$$\frac{(15 - 33)^{2}}{33} +\frac{(100 - 74)^{2}}{74} + \frac{(35 - 44)^{2}}{44} + \frac{(5 - 11)^{2}}{11} + \frac{(35 - 24)^{2}}{24} + \frac{(10 - 14)^{2}}{14} +$$
$$\frac{(90 - 66)^{2}}{66} +  \frac{(110 - 147)^{2}}{147} + \frac{(100 - 87)^{2}}{87}   = 50,18$$

El número que resulta de esta operación se llama puntaje chi cuadrado (o también ji cuadrado), se indica con el símbolo $\chi^{2}$ y es una
medida de la distancia a la que se encuentran las frecuencias observadas de las que se esperaría encontrar si las variables fueran
independientes.

El puntaje $\chi^{2}$ no puede ser negativo, ya que proviene de la suma de números elevados al cuadrado. Solo puede ser cero si todos los términos de la suma son cero, es decir, si cada frecuencia observada es exactamente igual a la esperada correspondiente. En ese caso no habría duda en decir que las variables son independientes, cumplirían exactamente con la definición de independencia estadística.

El puntaje $\chi^{2}$ indica si las frecuencias observadas están cerca o lejos de las esperadas, pero ¿qué tan grande debe ser para que consideremos lejanas a las frecuencias?

Dos problemas que tiene este puntaje son:

- puede ser indefinidamente grande
- su valor depende del número de casos que se evalúan y de la dimensión de la tabla.

Así, por ejemplo, si multiplicamos por 10 todas las frecuencias de la tabla \@ref(tab:frecObs), obtenemos:

```{r}
aux_table <- addmargins(10 * tabla25)
colnames(aux_table) <- sub("Sum", "Total", colnames(aux_table))
rownames(aux_table) <- sub("Sum", "Total", rownames(aux_table))
kableExtra::kable_styling(
  knitr::kable(aux_table, format = "pandoc", booktabs = TRUE, align = "cccc",
               caption = "Ejemplo de expansión artificial del total de casos de la tabla de frecuencias observadas"),
  latex_options = "striped")
```

Aunque los valores absolutos son diez veces más grandes, no hubo cambios en las frecuencias relativas, por ejemplo, en la celda 1,1: $\frac{150}{1100} = 0,14\ (14\%)$ lo mismo que había dado esa celda en la tabla original. Cualquiera sea la intensidad de la relación entre estas dos variables, ésta no ha cambiado porque hayamos multiplicado todo por 10, sin embargo, si calculamos el puntaje $\chi^{2}$ en la tabla 5 obtenemos `r round(chisq.test(10*tabla25)$statistic, 1)`, es decir un número 10 veces más grande. Entonces el puntaje $\chi^{2}$ puede cambiar muy ampliamente sin que cambien las frecuencias relativas; esto nos dice que este puntaje no mide de manera directa la asociación entre dos variables, por ello:

||
|:--:|
| Para comparar la intensidad de la asociación, el puntaje $\chi^{2}$ solo en válido si las tablas tienen la misma dimensión y el mismo número de casos. |

### Coeficientes de asociación para variables nominales

Para medir la asociación, debe eliminarse el efecto de la cantidad de
casos y también de la dimensión de la tabla. Calcularemos tres
coeficientes que nos permitan evaluar el grado o intensidad de la
relación y que tengan un límite superior de modo que podamos juzgarlos como elevados o bajos.

El primero de ellos es el **coeficiente $\varphi$**[^37], válido para medir la asociación entre dos variables dicotómicas (o binarias), se calcula como:

$$\varphi = \sqrt{\frac{\chi^{2}}{n}}$$

Vale cero si las variables son independientes e indica mayor asociación cuando está más cerca de uno.

Ejemplo (datos ficticios): en el análisis de la calidad de ítems de un examen, se observa las veces que una pregunta es correctamente
respondida por los alumnos que aprobaron el examen y por quienes no lo aprobaron. Para el caso de una pregunta a la que se llama \#7745, que fue respondida por 100 alumnos (a quienes les tocó por azar), la
información se presenta en una tabla de $2 \times 2$:

```{r}
res.examen <- c(rep("aprobó", 65), rep("no aprobó", 35))
respuesta.7745 <- c(
  rep("correcta", 50),
  rep("incorrecta", 15),
  rep("correcta", 10),
  rep("incorrecta", 25))
preg.7745 <- data.frame(res.examen, respuesta.7745)
tabla26 <- addmargins(table(preg.7745$res.examen, preg.7745$respuesta.7745))
colnames(tabla26) <- sub("Sum", "Total", colnames(tabla26))
rownames(tabla26) <- sub("Sum", "Total", rownames(tabla26))
kableExtra::kable_styling(
  knitr::kable(tabla26, format = "pandoc", booktabs = TRUE, align = "ccc"),
  latex_options = "striped")
```

Para la que el puntaje $\chi^{2}$ vale `r round(chisq.test(tabla26)$statistic, 2)`, y el coeficiente resulta en:

$$\varphi = \sqrt{\frac{22.16}{100}} = 0.47$$

Como el cálculo del puntaje $\chi^{2}$ es engorroso para hacer
manualmente, existe una expresión alternativa para obtener el coeficiente $\varphi$, que solo usa las frecuencias observadas en la tabla. Si estas son:

  a   b
  --- ---
  c   d

La fórmula de cálculo del coeficiente $\varphi$ es:

$$\varphi = \frac{(c*b) - (a*d)}{\sqrt{(a + b)*(c + d)*(a + c)*(b + d)}}$$

Aplicado a los datos del ejemplo da:

$$\varphi = \frac{(10*15) - (50*25)}{\sqrt{(50 + 15)*(10 + 25)*(50 + 10)*(15 + 25)}} = \frac{1100}{2337} = 0.47$$

Otra forma de medir la asociación entre dos variables, cuando alguna de ellas o las dos, tienen más de dos categorías, es el **coeficiente de contingencia**, C de Pearson, se calcula del siguiente modo a partir del puntaje $\chi^{2}$:

$$C = \sqrt{\frac{\chi^{2}}{\chi^{2} + n}}$$

Al igual que $\varphi$, este coeficiente no puede ser menor que cero (0) y solo toma ese valor si las variables son independientes (es decir cuando $\chi^{2} = 0$). Tampoco puede ser mayor que uno (1), pero su valor máximo depende de la dimensión de la tabla.

Solo en el caso particular en que la tabla sea cuadrada (misma cantidad de filas que de columnas), el valor máximo del coeficiente es: $C_{\max} = \sqrt{\frac{f - 1}{f}}$ , o lo que es lo mismo :
$C_{\max} = \sqrt{\frac{c - 1}{c}}$

Porque nos referimos a tablas cuadradas, en las que $f=c$.

Si la tabla no es cuadrada, sino de dimansión $f X c$, el valor máximo es:

$$C_{\max} = \sqrt{\frac{\min(f,c) - 1}{min(f,c)}}$$

En la que $min(f,c)$ es el más chico de los dos números $f$ o $c$.

De este modo se obtiene un coeficiente que indica el grado de la
asociación entre dos variables que es apto para tablas de cualquier dimensión, no solo para las de $2 \times 2$, por lo que mejora lo que mide el coeficiente Q de Kendall - Yule. Reemplacemos los valores para el ejemplo anterior:

$$C = \sqrt{\frac{\chi^{2}}{\chi^{2} + n}} = \sqrt{\frac{50,19}{50,19 + 500}} = 0,30$$

Para decidir si este resultado es alto o bajo, es decir, si la relación es fuerte o débil, calculemos el máximo que podría haber alcanzado para una tabla de 3X3:

$$C_{\max} = \sqrt{\frac{f - 1}{f}} = \sqrt{\frac{3 - 1}{3}} = \sqrt{\frac{2}{3}} = 0,82$$

Entonces el valor que hemos encontrado es moderado, y nos indica que la relación entre el tipo de violencia y el tamaño de las ciudades no es intensa.

El tercer (y último) coeficiente que calcularemos para variables
nominales está también basado en el puntaje $\chi^{2}$ y tiene un valor máximo de 1 (uno). Se llama **coeficiente V de Cramer** y se calcula así:

$$V = \sqrt{\frac{\chi^{2}}{n*min(f - 1, c - 1)}}$$

La expresión $min(f-1, c-1)$, tiene el mismo significado que en
$C_{max}$, es mínimo entre el número de filas menos uno y el número de
columnas menos uno. Para obtenerlo se resta 1 al número de filas, luego se resta 1 al número de columnas y se elige el menor de los dos. Si la tabla es de $3 \times 2$ se hace $3 - 1 = 2$ y $2 - 1 = 1$, entre 2 y 1 el mínimo es 1 y ése es el número que ubicamos en el denominador, multiplicando a $n$. En este ejemplo, las filas y las columnas son tres, por lo que se toma el mínimo entre $3-1$ y $3-1$, el resultado es 2, y el coeficiente V de Cramer resulta:

$$V = \sqrt{\frac{\chi^{2}}{n*min(f - 1,c - 1)}} = \sqrt{\frac{50,19}{500*min(3 - 1,\ 3 - 1)}} = \sqrt{\frac{50,19}{500*2}} = 0,22$$

Como el valor máximo que puede alcanzar este coeficiente es 1 (uno), en este caso se trata de una relación moderada entre las dos variables.

## Variables de nivel ordinal

Si nuestro problema es el de describir la relación entre variables cuyas
categorías están ordenadas, es decir variables ordinales, los
coeficientes anteriores son válidos: pero como sucedió con las medidas
descriptivas, el mayor nivel de medición permite calcular coeficientes
más elaborados y que, por esa razón, informen más acerca de la relación
entre las variables que se analizan. Un punto a tener en cuenta es que
cuando se trata con dos variables, la del menor nivel de medición es la
que manda. Así, para relacionar una ordinal y una nominal, debe usarse
un coeficiente V o C, como si fueran las dos nominales.

Si las dos variables son ordinales o si una es ordinal y la otra
intervalar o proporcional, es posible calcular un coeficiente que tiene
en cuenta los "rangos" es decir la posición de cada categoría respecto
de las demás, su carácter de primera, segunda, etc., es decir, el orden.
Sea el problema de indagar por la relación que podría haber entre el
resultado que obtienen los alumnos al rendir un examen de ingreso a una
carrera y el nivel de educación de sus madres, consideraremos como
variables *el nivel máximo de educación de la madre* de cada uno y *el orden de mérito alcanzado en el ingreso* a esa carrera; ambas variables
son ordinales. Tratemos solo la situación de pocos casos por ahora. Si
para el orden de mérito codificamos como 1, 2, 3, ... el primer lugar en el
ingreso, el segundo, etc. y para la educación de la madre usamos 1 =
universitario completo, 2 = universitario incompleto, etc., entonces el
fragmento de la matriz de datos para 8 observaciones tendría una forma
como esta:

```{r}
OM <- c(1, 2, 3, 4, 5, 6, 7, 8)
educamadre <- c(2, 2, 3, 2, 3, 4, 5, 3)
merito.educa.mad <- data.frame(OM, educamadre)
kableExtra::kable_styling(
  knitr::kable(merito.educa.mad, format = "pandoc", booktabs = TRUE, align = "cc"),
  latex_options = "striped")
```

Que está ordenada según los valores de la primera variable (orden de
mérito). A estos datos no conviene presentarlos en una tabla de doble entrada, porque cada orden de mérito corresponde a un único individuo, por lo que resultaría una tabla tan poco resumida como la siguiente:

```{r}
tabla27 <- table(merito.educa.mad$OM, merito.educa.mad$educamadre)
kableExtra::kable_styling(
  knitr::kable(tabla27, format = "pandoc", booktabs = TRUE, align = "cccc",
               caption = "Distribución conjunta de las frecuencias del orden de mérito en el ingreso a una carrera universitaria y el nivel de educación de la madre."),
  latex_options = "striped")
```

Esta tabla no es útil, ya que tiene tantas filas como la matriz de datos (porque cada orden de mérito corresponde a una sola persona), hay solo un caso en cada celda no vacía y hay muchas celdas vacías (con frecuencia cero). Por eso, cuando se trata de variables de este nivel de medición, no se usan tablas de doble entrada para representar los datos, solo se calcula un coeficiente que indique la intensidad de la relación. Este coeficiente se llama coeficiente de **correlación por rangos, de Spearman** y para calcularlo hay que transformar los valores de las variables en rangos, de mayor a menor, de manera que al máximo valor de cada variable corresponda el 1, al siguiente el 2 y así sucesivamente.

En nuestro ejemplo, el orden de mérito ya está en rangos, uno para el
primero, dos para el segundo y un rango para cada persona. No es así
para el nivel de educación, ya que varias personas pueden tener el
mismo, a esta variable la transformaremos en rangos. El mayor nivel de
educación observado es 2 (universitario incompleto) a ese valor le
correspondería el rango 1 (uno), pero hay tres madres con ese nivel de
educación, ellas deberían llevar los rangos 1, 2 y 3, como están
empatadas, les asignamos a todas el promedio de los tres rangos: 2.
Luego sigue el nivel de educación 3 (secundario completo) a quien
deberíamos asignar el rango 4, pero acá también hay empate entre tres
casos, corresponderían los rangos 4, 5 y 6, nuevamente usamos el
promedio de los tres rangos para asignar a los tres el mismo: 5. Sigue
el nivel 4 (secundario incompleto), al que asignamos el rango siguiente:
7, ya que hay solo un caso aquí; y lo mismo pasa con el nivel 5
(primario completo) al que le toca rango 8.

Resumiendo entonces, la transformación de los valores de las variables
en rangos resulta así:

```{r}
aux_table <- tibble::tribble(
  ~"Orden de mérito en el ingreso", ~"Rango del orden de mérito", ~"Educación de la madre", ~"Rango de la educación de la madre",
  1, 1, 2, 2,
  2, 2, 2, 2,
  3, 3, 3, 5,
  4, 4, 2, 2,
  5, 5, 3, 5,
  6, 6, 4, 7,
  7, 7, 5, 8,
  8, 8, 3, 5,
)
kableExtra::kable_styling(
  knitr::kable(aux_table, format = "pandoc", booktabs = TRUE, align = "cccc",
               caption = "Transformación de las categorías de la variable a rangos"),
  latex_options = "striped")
```

No ha sido necesario transformar los valores del orden de mérito, porque ya correspondían uno a cada sujeto.

Una vez construidos los rangos, se observa, para cada caso la diferencia
entre el rango de una variable y de la otra, esas diferencias se
llamarán $d$.

```{r}
aux_table <- aux_table[, c(2, 4)]
aux_table[, "$d$"] <- aux_table[, 1] - aux_table[, 2]
kableExtra::kable_styling(
  knitr::kable(aux_table, format = "pandoc", booktabs = TRUE, align = "ccc",
               caption = "Cálculo de las diferencias entre los rangos de dos variables ordinales"),
  latex_options = "striped")
```

Estas diferencias indican la distancia que hay entre los dos
ordenamientos, si fueran ambos iguales (si el máximo de uno coincidiera
con el máximo del otro y así en todas las categorías), tendríamos una
asociación perfecta entre las dos variables. Por el contrario si el
orden estuviese exactamente invertido (si el rango máximo de una
variable coincidiera con el rango mínimo de la otra y así en las demás)
la relación también sería perfecta, pero inversa.

La intensidad de la relación se mide entonces con el que hemos llamado
coeficiente se Spearman, la expresión de su cálculo es la siguiente:

$$r_{s} = 1 - \frac{6*\sum_{i = 1}^{n}d_{i}^{2}}{n^{3} - n}$$

En la que:

- $d_{i}$ son las diferencias de rangos (calculadas en la última columna de la tabla de arriba) que en la fórmula van elevadas al cuadrado.

- La sumatoria indica que ésta va desde la primera de las diferencias ($i=1$) hasta la última ($n$).

- $n$ es el número total de observaciones.

Este coeficiente puede ser positivo o negativo y tiene un campo de
variación igual al del Q de Kendall - Yule, es decir, entre $-1$ y 1, es decir:

$$- 1 \leq r_{s} \leq 1$$

Al igual que el coeficiente de Kendall - Yule, los valores próximos a 1 ó a $-1$ se interpretan como propios de una asociación fuerte (intensa) y
los cercanos a 0 (cero), sean positivos o negativos, corresponden a
asociaciones débiles. Si un coeficiente vale 1 ó $-1$ diremos que la
asociación es perfecta, pero eso no es algo que suceda en la realidad,
del mismo modo que si el coeficiente es exactamente 0 (cero), la
asociación será nula y otra vez es muy poco común que eso suceda con
datos reales.

A diferencia de los coeficientes usados para variables nominales, ahora
el signo importa: cuando es positivo da cuenta de una relación directa
entre las dos variables, una relación en la que cuando una aumenta, la
otra también lo hace. Si el coeficiente es negativo indica relación
inversa, el crecimiento de una variable se acompaña del decrecimiento de
la otra. En este nivel de medición (ordinal) podemos hacer estos
juicios, podemos decir "aumenta" o "disminuye", porque las categorías
están ordenadas, por esa razón podemos analizar no solo la intensidad de
la relación, sino también si se trata de una relación directa o inversa.

Se trata de dos características independientes de cada relación: puede
ser fuerte y directa; o fuerte e inversa; o bien débil y directa; o
débil e inversa. Un error muy frecuente es creer que si el coeficiente
es negativo, la relación es débil, no es así. Es débil si el coeficiente
es cercano a 0 (cero), es igualmente débil si $r_s=0,03$ como si
$r_s=-0,03$, el signo del coeficiente no aporta para saber si es fuerte
o débil. Del mismo modo es igual de fuerte una relación en la que
$r_s=0,96$ como una en la que $r_s=-0,96$.

Para obtener el valor del coeficiente en nuestro ejemplo, vamos primero
a calcular las ${d_{i}}^{2}$:

```{r}
aux_table[, "$d_i^2$"] <- (aux_table[, 1] - aux_table[, 2])^2
kableExtra::kable_styling(
  knitr::kable(aux_table, format = "pandoc", booktabs = TRUE, align = "cccc"),
  latex_options = "striped")
```

Por lo que la suma de la última columna es 20. Al reemplazar los valores
en la expresión de , obtenemos:

$$r_{s} = 1 - \frac{6*\sum_{i = 1}^{n}d_{i}^{2}}{n^{3} - n} = 1 - \frac{6*20}{8^{3} - 8} = 1 - \frac{120}{512 - 8} = 1 - \frac{120}{504} = 0,76$$

Este valor de $r_{s} = 0,76$, indica una asociación intensa y positiva
entre la educación de la madre y los resultados del ingreso a la
universidad. Que sea positiva quiere decir que los alumnos con madres de
mayor educación obtienen mejores resultados en el ingreso a esa carrera.
Como ya hemos señalado, esto no quiere decir causalidad, no significa
que la causa del resultado en el ingreso sea la educación de la madre.
El problema de la causalidad es teórico y depende del análisis que se
hace de las relaciones entre los conceptos, en este ejemplo, la
educación de la madre es uno de muchos de los factores
interrelacionados, que inciden sobre el resultado que obtiene el alumno.
Este coeficiente (como sucede con todos los coeficientes de asociación)
no revelan la causalidad sino lo frecuente que resulta que los cambios
de una variable se vean acompañados de cambios en la otra.

Para ilustrar con otros ejemplos de relaciones entre variables
ordinales, sea que se pone en correspondencia el ranking de temas
musicales de una semana con la frecuencia con que cada tema es
reproducido en la radio, esperamos hallar que la relación sea muy fuerte
y directa: los temas de mayor posición en el ranking son también los que
más frecuentemente se pasan en la radio. Al revés, en la relación entre
el rating de los programas de televisión y el contenido cultural que
ofrecen esperamos una relación también fuerte, pero ahora inversa: los
de mayor rating son habitualmente lo que menos contenido cultural
tienen.

Este coeficiente es adecuado, no solo cuando las variables son ordinales, sino cuando son cuantitativas (intervalares o proporcionales) pero existen casos atípicos, que afectarían el cálculo de otro coeficiente que se verá a continuación. Para que la interpretación del coeficiente de Spearman sea correcta, es necesario de las variables guarden entre sí una relación directa o inversa, en todo su conjunto de valores, es decir, que la relación sea monótona creciente o decreciente.

## Nivel intervalar o proporcional

Si tratamos con variables intervalares o proporcionales, podríamos usar los procedimientos que referimos antes para el cálculo de la intensidad de las relaciones entre variables nominales. Para ello, deberíamos construir intervalos y tratarlos como las categorías de las dos variables. De ese modo, perderíamos la información que provee una variable cuantitativa. Por ejemplo, si disponemos de un conjunto de personas adultas de las que sabemos la edad a la que cada una se casó (o unió) por primera vez y los años de escolarización, y nos interesamos por la relación entre estas dos variables. La  matriz de datos para estas dos variables en 13 casos es:

```{r}
edad.union <- c(18, 17, 25, 19, 23, 20, 18, 20, 24, 24, 26, 30, 35)
escolarizacion <- c(10, 12, 10.5, 11.5, 18, 14, 15.5, 12, 13, 15, 16, 18, 20)
edad.union.escolariz <- data.frame(edad.union, escolarizacion)
edad.union.escolariz$edad.union.3 <- cut(edad.union.escolariz$edad.union, breaks = 3)
edad.union.escolariz$escolariz.3 <- cut(edad.union.escolariz$escolarizacion, breaks = 3)
kableExtra::kable_styling(
  knitr::kable(edad.union.escolariz, format = "pandoc", booktabs = TRUE, align = "cccc"),
  latex_options = "striped")
```

Si se intenta construir una tabla de doble entrada para estas dos variables, el problema es aún mayor que con las ordinales, dado que habría un gran número de filas y de columnas, y resultaría casi imposible de leer. Además, muchas celdas estarían vacías y habría muy pocos casos en cada una de las restantes. Los trece datos de la matriz anterior quedarán, en una tabla de doble entrada, así:

```{r}
aux_table <- table(edad.union.escolariz$edad.union, edad.union.escolariz$escolarizacion)
kableExtra::kable_styling(
  knitr::kable(aux_table, format = "pandoc", booktabs = TRUE, align = "cccc",
               caption = "Distribución conjunta de los años de escolarización y la edad a la que se realizó la primera unión conyugal"),
  latex_options = "striped")
```

Nuevamente, esta no es una tabla adecuada para representar estos datos y sería más legible con las categorías agrupadas:

```{r}
aux_table <- table(edad.union.escolariz$edad.union.3, edad.union.escolariz$escolariz.3)
kableExtra::kable_styling(
  knitr::kable(aux_table, format = "pandoc", booktabs = TRUE, align = "ccc",
               caption = "Distribución conjunta de los años de escolarización y la edad a la que se realizó la primera unión conyugal (categorías agrupadas)"),
  latex_options = "striped")
```

Ahora la tabla se lee con más facilidad y podemos tratarla como hicimos antes, como si fueran nominales y calcular un puntaje chi cuadrado y coeficientes *C de Pearson* y *V de Cramer*, o bien, como los intervalos están ordenados, poner una ranking y calcular el coeficiente de Spearman. Sin embargo, al hacer esto, se trata como si se hubiesen unido a la misma edad todas las personas que están entre 18 y 23.7 años. Del mismo modo, se trata como iguales a quienes tienen escolariación entre 10 y 13 años, no se puede distinguir entre quienes estudiaron 11, 12, 13 años: al interior del intervalo todos son considerados iguales. Además de esto, se pierden las posibilidades de análisis que ofrecen las variables cuantitativas.

Para poder mantener las variables con sus verdaderos valores (sin
agrupar) y tener al mismo tiempo una representación abreviada de los
datos, existe un recurso muy valioso: una representación gráfica de los valores que se denomina **diagrama de dispersión**.

```{r fig.cap="Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal"}
ggplot(edad.union.escolariz) +
  geom_point(aes(escolarizacion, edad.union)) +
  theme_tufte() +
  ylab("Edad a la primera unión") +
  xlab("Años de escolarización")
```

Este gráfico usa los ejes cartesianos para indicar los valores de las
dos variables que estamos analizando y representa con un punto cada
concordancia de dos categorías que puede corresponder a un caso o a
varios. Cada punto es un par ordenado: el primer número son los años de escolarización y el segundo la edad a la que se unió por primera vez. Los ceros de la anterior <!--referencia--> ya no aparecen en este diagrama. El primer punto de la izquierda corresponde a alguien que alcanzó 10 años de escolarización y se unió a los 18 años de edad.

Lo que eran filas y columnas en todas las tablas mostradas hasta aquí, son ahora ejes coordenados, porque ya no se trata con categorías
separadas de cada variable sino con valores cuantitativos de las
variables que ahora son intervalares o proporcionales. Estos ejes se
llaman **ordenadas** el vertical y **abscisas** el horizontal. En el
ejemplo están representados los valores de los años de escolarización en el eje de las abscisas (primer elemento de cada par ordenado) y la edad a la primera unión en el eje de las ordenadas (segundo elemento de cada par).

La manera en que los puntos se distribuyen en el diagrama de dispersión nos da una primera aproximación a la relación entre las dos variables.
Así, en el caso del ejemplo, hay una cierta tendencia creciente, en la
que se vería que *globalmente*, las personas con más años de
escolarización tenderían a unirse más tardíamente. Esta observación es
equivalente a ver la concentración de casos en las celdas de la diagonal
de una tabla bivariada.

Por el contrario, si los datos se dispersan de este otro modo:

```{r fig.cap="Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal (relación débil)"}
edad.union.debil <- rnorm(20, 25, 2)
escolarizacion.debil <- rnorm(20, 11, 1.5)
edad.union.escolariz.deb <- data.frame(edad.union.debil, escolarizacion.debil)
ggplot(edad.union.escolariz.deb) +
  geom_point(aes(escolarizacion.debil, edad.union.debil)) +
  theme_tufte() +
  ylab("Edad a la primera unión") +
  xlab("Años de escolarización")
```

No hay ninguna razón para creer que las variables estén relacionadas:
los puntos no muestran una tendencia clara.

Una asociación más acentuada entre las mismas dos variables se observa en el siguiente diagrama de dispersión:

```{r fig.cap="Diagrama de dispersión de los años de escolarización y la edad a la que se realizó la primera unión conyugal (relación intensa)"}
escolarizac.fuerte <- rnorm(30, 12, 2)
edad.fuerte <- 1.4 * escolarizac.fuerte + 4 + rnorm(30)
edad.debil <- 1.4 * escolarizac.fuerte + 4 + rnorm(30, 0, 3)
fuerte <- data.frame(escolarizac.fuerte, edad.fuerte, edad.debil)
ansiedad <- rnorm(50, 7, 1)
nota.fuerte <- -ansiedad + 10 + rnorm(50, 0, .3)
nota.debil <- -ansiedad + 10 + rnorm(50, 0, 3)
ans.nota <- data.frame(ansiedad, nota.debil, nota.fuerte)
ggplot(fuerte) +
  geom_point(aes(escolarizac.fuerte, edad.fuerte)) +
  theme_tufte() +
  ylab("Edad a la primera unión") +
  xlab("Años de escolarización")
```

En el que la tendencia *lineal* es más clara, por lo que resulta más
definido el efecto de la escolarización sobre la edad a la que se
produce la primera unión. Aquí, la nube de puntos está más aplanada que en el ejemplo anterior; en efecto, en el gráfico <!--referencia--> la nube de puntos tiene forma más circular que en el <!--referencia--> , donde es más elíptica.

El ejemplo que hemos mostrado hasta aquí corresponde a una relación directa: más años de escolarización parecen asociarse con edades más tardías para la primera unión. De manera equivalente pueden representarse relaciones inversas. Consideremos el caso de la ansiedad frente a los exámenes y la calificación que se obtiene. En un estudio realizado por el Laboratorio de Evaluación Psicológica y Educativa (LEPE, Facultad de Psicología UNC) se observó que a mayor puntaje en una prueba de ansiedad ante los exámenes, menor rendimiento académico (arrobafurlán2014), por lo que la relación entre las variables es inversa. 

Los esquemas siguientes muestran el achatamiento de la nube de puntos según la relación sea más fuerte o más débil y según sea directa o inversa.

<!-- no puedo acomodar bien los rótulos-->

```{r fig.cap="Comparación de la forma de las nubes de puntos según la intensidad de la relación"}
p1 <- ggplot(fuerte) +
  geom_point(aes(escolarizac.fuerte, edad.fuerte)) +
  theme_tufte() +
  ylab("Edad a la primera unión") +
  xlab("Años de escolarización") +
  stat_ellipse(aes(escolarizac.fuerte, edad.fuerte), col = "red") +
  annotate(geom = "text", label = "relación directa, fuerte", x = 10, y = 29, col = "red")

p2 <- ggplot(fuerte) +
  geom_point(aes(escolarizac.fuerte, edad.debil)) +
  theme_tufte() +
  ylab("Edad a la primera unión") +
  xlab("Años de escolarización") +
  stat_ellipse(aes(escolarizac.fuerte, edad.debil), col = "red") +
  annotate(geom = "text", label = "relación directa, débil", x = 10, y = 29, col = "red")

p3 <- ggplot(ans.nota) +
  geom_point(aes(ansiedad, nota.fuerte)) +
  theme_tufte() +
  ylab("Nota del examen") +
  xlab("Nivel de ansiedad") +
  stat_ellipse(aes(ansiedad, nota.fuerte), col = "red") +
  annotate(geom = "text", label = "relación inversa, fuerte", x = 7, y = 6, col = "red")

p4 <- ggplot(ans.nota) +
  geom_point(aes(ansiedad, nota.debil)) +
  theme_tufte() +
  ylab("Nota del examen") +
  xlab("Nivel de ansiedad") +
  stat_ellipse(aes(ansiedad, nota.debil), col = "red") +
  annotate(geom = "text", label = "relación inversa, débil", x = 8, y = 12, col = "red")

grid.arrange(p1, p2, p3, p4, nrow = 2, ncol = 2)
```

La intensidad de la relación está vinculada al achatamiento de la elipse
que rodea la nube de puntos y éste al grado de alineación que los puntos
tengan. Luego volveremos sobre esta idea.

Solo nos ocuparemos de relaciones como las que acabamos de ejemplificar:
aquellas en las que la tendencia es creciente o decreciente, pero
siempre siguiendo un camino parecido a una línea recta. Son las que
llamaremos *relaciones lineales*. No son la únicas que existen; solo a
modo de ilustración, veamos cómo se representa la relación entre la edad
de las personas y la frecuencia con que consultan al médico. Estas dos
variables son tales que, en términos muy generales y sin considerar
situaciones específicas, para valores pequeños de la primera (en la
infancia) las consultas son frecuentes, luego se reducen durante la
adultez para volver a incrementarse en la vejez. Por eso el gráfico que las representa tiene la siguiente forma aproximada:

```{r fig.cap="Diagrama de dispersión del número medio de consultas médicas anuales y la edad."}
edad <- c(1, 1, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 12, 15, 16, 16, 18, 20, 22, 28, 30, 40, 45, 45, 45, 50, 50, 55, 62, 63, 63, 64, 66, 70, 75, 76, 77, 79)
consultas <- c(10, 10, 12, 9, 8, 5, 4, 5, 4, 6, 5, 3, 5, 2, 2, 2, 1, 2, 0, 1, 2, 0, 2, 1, 3, 0, 4, 2, 2, 1, 3, 5, 7, 5, 7, 5, 6, 7, 8, 9, 10, 9, 9)
edad.consultas <- data.frame(edad, consultas)
ggplot(edad.consultas) +
  geom_point(aes(edad, consultas)) +
  theme_tufte() +
  xlab("Edad") +
  ylab("Número medio de consultas médicas anuales")
```

Este conjunto de puntos muestra una tendencia *no lineal*, eso no
implica que las variables no estén relacionadas; por el contrario, la
relación existe, pero no es lineal. Estos puntos, en lugar de ser
aproximados por una línea recta, lo serían con una curva con forma de
parábola. No nos ocuparemos aquí de relaciones no lineales. Limitaremos
nuestro análisis a relaciones lineales, debido a que es muy frecuente
usarlas como primera aproximación a la forma que tiene la relación entre
dos variables y porque a menudo, cuando se trabaja con relaciones no
lineales, es posible realizar transformaciones de las variables para
lograr relaciones lineales.

Para analizar la intensidad de la relación lineal entre dos variables
(ambas medidas a nivel intervalar o proporcional) calcularemos un
coeficiente comparable a los que hemos visto hasta aquí, que tendrá una
interpretación similar a la del coeficiente de correlación por rangos de
Spearman. Este coeficiente se llama **coeficiente de correlación r de Pearson** y es uno de los de mayor utilización cuando las variables que
se analizan alcanzan el nivel de medición que autoriza su cálculo. Este
coeficiente va a medir qué tan bien se puede aproximar el conjunto de
puntos con una función lineal y va a depender de lo que antes llamamos
el "achatamiento" de la elipse. Será grande (próximo a 1 ó a $-1$) si las
variables están muy relacionadas linealmente, es decir, si la nube de
puntos se elonga hacia una línea; y será pequeño (próximo a cero) si las
variables guardan poca relación lineal, es decir si la nube de puntos
tiene forma redondeada. Será positivo y elevado (próximo a 1) si valores
pequeños de una variable están acompañados de valores pequeños de la
otra y valores grandes de una siguen a valores grandes de la otra, como
sucedió en el ejemplo del gráfico <!--referencia al 3-->. Será negativo y elevado (próximo a
$-1$) si los valores grandes de una de las variables acompañan a los
pequeños de la otra y viceversa, como en el gráfico <!--referencia al 5-->. La correlación
será perfecta positiva ($r = 1$) si todos los puntos se ubican sobre una recta creciente:

```{r fig.cap="Ejemplo de situación ideal con todas las observaciones alineadas en una recta creciente, por lo que $r = 1$"}
x.r.1 <- rnorm(20)
y.r.1 <- 2 * x.r.1 + 1
y.r.neg <- -2 * x.r.1 + 3
ejemplos.perfecta <- data.frame(x.r.1, y.r.1, y.r.neg)
ggplot(ejemplos.perfecta) +
  geom_point(aes(x.r.1, y.r.1)) +
  xlab("x") +
  ylab("y") +
  theme_tufte()
```

Y será perfecta negativa ($r = - 1$) si todos los puntos se ubican sobre una recta decreciente:

```{r fig.cap="Ejemplo de situación ideal con todas las observaciones alineadas en una recta decreciente, por lo que $r = - 1$"}
ggplot(ejemplos.perfecta) +
  geom_point(aes(x.r.1, y.r.neg)) +
  xlab("x") +
  ylab("y") +
  theme_tufte()
```

Ambas son situaciones ideales que no se encuentran en la realidad,
constituyen el límite de la intensidad que pueden alcanzar las
relaciones lineales directas o inversas.

Las unidades en que se miden las variables que se relacionan pueden ser
muy diferentes, en el ejemplo de ansiedad y resultado de los exámenes,
la primera se puede medir en una escala de cero a cien y la segunda de cero a diez, por lo que
un valor elevado de la primera sería 95 y uno elevado de la segunda, 9.
Esto impide que se comparen directamente los valores grandes con los
grandes y los pequeños con los pequeños. Vamos a usar un recurso que ya fue presentado: las puntuaciones *z*, aquellas que indican a cuántas desviaciones estándar se encuentra cada observación de la media. Son los puntajes que permiten decidir si se trata de un valor grande (muy superior a la media) o pequeño (muy inferior a la media) o intermedio (semejante a la media), sin tener unidades, por lo que permite la comparación de elementos que pueden tener cualquier unidad de medida.

Recordemos que para los valores bajos de la variable (menores a la media), el puntaje *z* es negativo y es positivo para los valores altos (superiores a la media). Si dos variables están correlacionadas
positivamente (altos con altos y bajos con bajos), entonces sus puntajes *z* se corresponderán positivos con positivos y negativos con negativos.

Si para cada sujeto multiplicamos los puntajes z de las dos variables
que se relacionan, obtendremos siempre un resultado positivo, ya sea
porque multiplicamos dos números positivos ($+\times+=+$) o dos negativos ($-\times-=+$). Si luego sumamos esos productos para todos los sujetos obtendremos un número alto positivo.

A la inversa, si dos variables se correlacionan negativamente los productos de sus puntajes *z* serán negativos, porque los valores altos de una irán con los bajos de la otra (que equivale a *z* positivos con *z* negativos, y $+\times-=-$) y bajos con altos (que es lo mismo que *z* negativos con *z* positivos y $-\times+=-$). Cuando sumemos estos productos para todos los casos tendremos un número alto y negativo.

Si las variables no estuvieran correlacionadas, habría casos en el que
un valor alto de una variable se acompaña de uno alto de la otra y casos
en que un valor alto va seguido de uno bajo, algunos productos de *z*
serían positivos y otros negativos y entonces, al sumarlos, obtendríamos
un número bajo, que puede ser positivo o negativo, pero será cercano a
cero.

Entonces el producto de las puntuaciones *z* ofrece un resultado que será:

- alto y positivo si las variables tienen una correlación fuerte y directa

- alto y negativo si la correlación es fuerte e inversa

- cercano a cero si no están correlacionadas

Haciendo uso de este razonamiento, el coeficiente de correlación de
Pearson se calcula como[^39]:

$$r = \frac{\sum_{i = 1}^{n}{z_{x_{i}}*z_{y_{i}}}}{n - 1}$$

Donde $z$ representan los desvíos estándar de las variables $x$ e $y$, $n$ es el total de observaciones y los subíndices $i$ corresponden a cada una de ellas. El signo de suma señala que ésta debe extenderse desde el primer caso ($i=1$) hasta el último (cuando $i=n$).

Como en el caso del coeficiente de Spearman, el campo de variación del coeficiente de Pearson es el intervalo $-1$, 1.

Para el cálculo del coeficiente de Pearson, no es necesario que las dos variables tengan las mismas unidades, porque se usan los puntajes $z$, que carecen de unidades. No hay inconveniente en correlacionar el peso (en kilogramos) con la talla (medida en centímetros).

A continuación, se presenta un ejemplo de cómo calcular el coeficiente
de correlación de Pearson para evaluar la relación entre dos variables.
Las variables seleccionadas para el ejemplo son: 1) puntaje obtenido en
una escala de inteligencia lógico-matemática y 2) cantidad de ejercicios
correctamente realizados en una prueba de matemática. El fragmento de la
matriz de datos correspondiente es el siguiente:

```{r}
puntaje.escala <- c(46, 44, 56, 57, 30, 60, 45, 43, 64, 32)
ejercic.corr <- c(7, 2, 7, 8, 2, 9, 5, 1, 9, 3)
puntos.escala <- data.frame(puntaje.escala, ejercic.corr)
kableExtra::kable_styling(
  knitr::kable(puntos.escala, format = "pandoc", booktabs = TRUE, align = "cc"),
  latex_options = "striped")

```

Una vez que se ha obtenido la media y desviación estándar de las medidas
del puntaje en la escala de inteligencia lógico-matemática
($\overline{x} = 47,7$ $s_{x} = 11,44$) y de cantidad de ejercicios
matemáticos correctamente realizados
($\overline{y} = 5,3$ $s_{y} = 3,09$), se deben convertir las
observaciones brutas en puntuaciones *z*. Para ello se calcula la
diferencia entre la puntuación bruta original y la media del grupo, y el
resultado de esta operación se divide por la desviación estándar del
grupo. La transformación a puntaje *z* se obtiene como vimos antes:

Para el puntaje en inteligencia lógico - matemática (*x*),

$$z_{x} = \frac{x - \overline{x}}{s_{x}}$$

Para la cantidad de ejercicios correctamente realizados (*y*),

$$z_{y} = \frac{y - \overline{y}}{s_{y}}$$

Entonces, el puntaje *z* del sujeto 1 para cada escala se obtiene de la siguiente manera:

$$z_{x_{1}} = \frac{46 - 47,7}{11,44} = - 0,15$$

$$z_{y_{1}} = \frac{7 - 5,3}{3,09} = 0,55$$

Y del mismo modo para cada uno de los sujetos observados, para obtener la siguiente tabla:


[^rel_violencia]: Según la clasificación sugerida por el Informe Mundial sobre la Violencia y la Salud, Organización Panamericana de la Salud, 2003.

<!-- [^34]: En la salida no están redondeados los decimales de las frecuencias esperadas. -->

[^35]: El mismo recurso que se usó cuando se definió la varianza y no era posible usar la suma de los desvíos porque daba cero. Nuevamente aquí, usamos el exponente 2 para volver positivos a los números negativos.

[^36]: Recordemos que, de manera general la dimensión de la tabla es $f X c$, filas por columnas.

[^37]: Ver Ekström, J. (2011) para las discusiones en torno a este coeficiente en el llamado "debate Pearson-Yule".

<!-- [^38]: Nuevamente aquí recordemos que esto no quiere decir causalidad, de ningún modo podemos afirmar que la ansiedad "causa" bajos resultados. Bien podría ser que los alumnos lleguen más ansiosos cuanto menos han estudiado para el examen y eso sea lo que afecta la calificación. -->

[^39]: Esta expresión puede encontrarse un poco diferente en algunos manuales. Si las desviaciones estándar, que se usan para calcular los puntajes z, se calcularan con denominador $n$ (como si correspondieran a observaciones provenientes de toda la población), entonces la fórmula de $r$ llevaría denominador $n$ también. Aquí mantenemos el modo de cálculo de la desviación estándar muestral con denominador $n-1$ y por eso esta fórmula lo lleva así también.

[^40]: Es la ordenada correspondiente a un valor de z que deja a derecha e izquierda, en una distribución normal, proporciones del área bajo la curva iguales a $p$ y $1-p$ respectivamente.

[^41]: No es posible poner como condición que la recta haga mínimas las distancias porque hay puntos por encima y por debajo, por lo que la suma de las distancias se hace cero (igual a lo que sucedió con la suma de los desvíos alrededor de la media y que llevó a usar sus cuadrados para definir la varianza). Por esa razón se usan los cuadrados de las distancias.

[^42]: Para calcular los valores de $y$ estimado ($\widehat{y}$) hemos conservado más decimales en $b_0$ y $b_1$ que los mostrados.

<!-- [^43]: Se trata de la epopeya Mahabarata, cuya versión actual habría sido concluida hacia el año 400d.c. -->

<!-- [^44]: La idea de infinito no es la de la matemática, sino que se refiere a una relación pequeña entre la cantidad de casos de muestra y los de la de la población. Ver nota 48. -->
